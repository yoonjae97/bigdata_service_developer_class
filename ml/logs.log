2023-08-08 10:49:08,080:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-08 10:49:08,080:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-08 10:49:08,080:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-08 10:49:08,080:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-09 09:48:17,462:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-09 09:48:17,462:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-09 09:48:17,462:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-09 09:48:17,462:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-09 09:48:35,636:WARNING:C:\Users\user21\AppData\Local\Temp\ipykernel_2764\10761830.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.
  train[train['Weight_in_gms'].notnull()].corr()

2023-08-09 09:49:52,681:WARNING:C:\Users\user21\AppData\Local\Temp\ipykernel_2764\4068723189.py:2: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.
  train.corr()

2023-08-09 10:57:45,655:WARNING:C:\Users\user21\AppData\Local\Temp\ipykernel_2764\2189804198.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.
  train.corr()

2023-08-09 11:14:37,324:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2023-08-09 11:53:35,554:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:53:36,200:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:53:36,858:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:53:37,523:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:53:38,176:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:53:38,838:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:53:40,132:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:53:41,416:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:53:42,710:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:53:44,009:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:53:45,316:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:53:47,255:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:53:49,186:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:53:51,130:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:53:53,080:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:53:55,029:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:53:57,600:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:54:00,168:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:54:02,726:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:54:05,297:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:54:07,866:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:54:11,102:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:54:14,333:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:54:17,523:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:54:20,740:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:54:23,937:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:54:24,582:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:54:25,220:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:54:25,858:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:54:26,501:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:54:27,139:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:54:28,426:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:54:29,705:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:54:30,993:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:54:32,275:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:54:33,554:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:54:35,478:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:54:37,398:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:54:39,332:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:54:41,255:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:54:43,175:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:54:45,739:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:54:48,292:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:54:50,833:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:54:53,493:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:54:56,060:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:54:59,258:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:55:02,450:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:55:05,656:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:55:08,870:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:55:12,073:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:55:12,710:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:55:13,342:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:55:13,980:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:55:14,609:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:55:15,243:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:55:16,515:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:55:17,786:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:55:19,061:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:55:20,333:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:55:21,606:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:55:23,514:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:55:25,413:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:55:27,310:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:55:29,231:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:55:31,148:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:55:33,696:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:55:36,250:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:55:38,801:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:55:41,372:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:55:43,926:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:55:47,110:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:55:50,293:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:55:53,480:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:55:56,677:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:55:59,843:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:00,470:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:01,098:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:01,724:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:02,354:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:03,001:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:04,263:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:05,522:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:06,782:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:08,044:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:09,307:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:11,206:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:13,096:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:14,970:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:16,861:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:18,750:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:21,266:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:23,779:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:26,289:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:28,815:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:31,339:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:34,566:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:37,744:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:40,905:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:44,085:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:47,276:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:47,912:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:48,544:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:49,183:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:49,817:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:50,457:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:51,728:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:52,982:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:54,246:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:55,503:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:56,762:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:56:58,635:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:57:00,509:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:57:02,380:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:57:04,254:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:57:06,127:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:57:08,615:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:57:11,098:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:57:13,599:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:57:16,101:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:57:18,587:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:57:21,698:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:57:24,813:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:57:27,953:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:57:31,091:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:57:34,260:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:57:34,894:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:57:35,519:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:57:36,150:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:57:36,774:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:57:37,400:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:57:38,649:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:57:39,902:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:57:41,167:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:57:42,424:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:57:43,687:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:57:45,581:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:57:47,447:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:57:49,318:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:57:51,195:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:57:53,067:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:57:55,566:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:57:58,048:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:58:00,540:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:58:03,081:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:58:05,626:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:58:08,743:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:58:11,833:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:58:14,938:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:58:18,051:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:58:21,155:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:58:21,782:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:58:22,402:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:58:23,023:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:58:23,641:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:58:24,262:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:58:25,500:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:58:26,733:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:58:27,977:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:58:29,226:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:58:30,472:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:58:32,331:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:58:34,193:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:58:36,061:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:58:37,928:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:58:39,792:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:58:42,282:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:58:44,762:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:58:47,247:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:58:49,753:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:58:52,245:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:58:55,342:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:58:58,436:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:01,526:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:04,634:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:07,732:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:08,347:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:08,962:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:09,581:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:10,201:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:10,818:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:12,040:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:13,275:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:14,516:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:15,761:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:16,995:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:18,837:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:20,674:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:22,513:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:24,377:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:26,225:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:28,693:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:31,169:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:33,647:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:36,137:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:38,618:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:41,697:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:44,786:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:47,872:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:50,974:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:54,074:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:54,683:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:55,292:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:55,893:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:56,502:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:57,109:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:58,321:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 11:59:59,534:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:00:00,752:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:00:01,966:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:00:03,178:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:00:04,995:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:00:06,812:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:00:08,627:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:00:10,447:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:00:12,258:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:00:14,678:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:00:17,103:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:00:19,517:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:00:21,946:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:00:24,408:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:00:27,433:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:00:30,458:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:00:33,479:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:00:36,521:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:00:39,573:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:00:40,186:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:00:40,795:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:00:41,404:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:00:42,004:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:00:42,609:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:00:43,819:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:00:45,039:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:00:46,251:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:00:47,467:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:00:48,684:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:00:50,512:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:00:52,338:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:00:54,156:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:00:55,981:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:00:57,802:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:01:00,210:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:01:02,631:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:01:05,039:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:01:07,457:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:01:09,879:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:01:12,903:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:01:15,934:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:01:18,953:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:01:21,961:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:01:24,976:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:01:25,578:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:01:26,187:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:01:26,783:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:01:27,385:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:01:27,991:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:01:29,206:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:01:30,451:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:01:31,659:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:01:32,871:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:01:34,081:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:01:35,905:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:01:37,713:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:01:39,528:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:01:41,351:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:01:43,164:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:01:45,586:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:01:48,010:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:01:50,430:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:01:52,851:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:01:55,282:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:01:58,303:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:02:01,313:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:02:04,314:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:02:07,328:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:02:10,355:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:02:10,961:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:02:11,569:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:02:12,174:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:02:12,776:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:02:13,385:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:02:14,597:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:02:15,804:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:02:17,025:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:02:18,266:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:02:19,484:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:02:21,331:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:02:23,139:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:02:24,949:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:02:26,770:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:02:28,587:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:02:31,056:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:02:33,578:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:02:36,042:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:02:38,568:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:02:41,029:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:02:44,161:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:02:47,237:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:02:50,322:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:02:53,483:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:12:14,829:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:12:15,625:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:12:16,421:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:12:17,210:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:12:18,009:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:12:18,802:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:12:20,415:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:12:22,020:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:12:23,604:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:12:25,206:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:12:26,782:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:12:29,166:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:12:31,543:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:12:33,921:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:12:36,317:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:12:38,689:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:12:41,888:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:12:45,069:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:12:48,254:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:12:51,442:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:12:54,615:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:12:58,594:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:13:02,545:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:13:06,511:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:13:10,519:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:13:14,453:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:13:15,253:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:13:16,044:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:13:16,836:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:13:17,653:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:13:18,444:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:13:20,042:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:13:21,603:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:13:23,194:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:13:24,824:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:13:26,445:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:13:28,849:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:13:31,239:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:13:33,619:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:13:36,013:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:13:38,385:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:13:41,565:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:13:44,741:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:13:47,922:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:13:51,142:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:13:54,318:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:13:58,298:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:14:02,250:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:14:06,196:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:14:10,180:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:14:14,104:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:14:14,870:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:14:15,638:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:14:16,401:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:14:17,167:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:14:17,937:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:14:19,474:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:14:20,994:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:14:22,523:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:14:24,057:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:14:25,585:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:14:27,889:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:14:30,177:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:14:32,465:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:14:34,788:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:14:37,083:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:14:40,165:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:14:43,203:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:14:46,251:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:14:49,333:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:14:52,375:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:14:56,188:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:15:00,050:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:15:03,890:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:15:07,770:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:15:11,596:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:15:12,347:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:15:13,082:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:15:13,820:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:15:14,564:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:15:15,299:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:15:16,808:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:15:18,290:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:15:19,760:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:15:21,242:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:15:22,709:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:15:24,914:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:15:27,114:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:15:29,335:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:15:31,568:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:15:33,785:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:15:36,740:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:15:39,721:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:15:42,696:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:15:45,690:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:15:48,644:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:15:52,331:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:15:56,048:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:15:59,760:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:16:03,491:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:16:07,201:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:16:07,925:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:16:08,647:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:16:09,370:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:16:10,092:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:16:10,819:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:16:12,266:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:16:13,704:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:16:15,139:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:16:16,586:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:16:18,007:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:16:20,185:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:16:22,357:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:16:24,527:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:16:26,704:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:16:28,863:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:16:31,770:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:16:34,669:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:16:37,565:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:16:40,488:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:16:43,358:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:16:46,981:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:16:50,608:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:16:54,254:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:16:57,894:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:17:01,481:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:17:02,203:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:17:02,928:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:17:03,662:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:17:04,389:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:17:05,112:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:17:06,556:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:17:07,989:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:17:09,427:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:17:10,874:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:17:12,307:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:17:14,459:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:17:16,603:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:17:18,760:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:17:20,934:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:17:23,078:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:17:25,960:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:17:28,831:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:17:31,713:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:17:34,607:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:17:37,471:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:17:41,065:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:17:44,643:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:17:48,229:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:17:51,851:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:17:55,441:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:17:56,169:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:17:56,892:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:17:57,609:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:17:58,331:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:17:59,046:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:18:00,482:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:18:01,914:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:18:03,342:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:18:04,785:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:18:06,206:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:18:08,359:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:18:10,497:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:18:12,646:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:18:14,824:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:18:16,957:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:18:19,827:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:18:22,696:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:18:25,561:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:18:28,466:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:18:31,313:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:18:34,882:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:18:38,466:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:18:42,053:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:18:45,651:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:18:49,212:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:18:49,933:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:18:50,641:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:18:51,343:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:18:52,052:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:18:52,748:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:18:54,162:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:18:55,578:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:18:56,993:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:18:58,417:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:18:59,814:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:19:01,921:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:19:04,047:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:19:06,159:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:19:08,295:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:19:10,398:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:19:13,219:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:19:16,019:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:19:18,845:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:19:21,691:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:19:24,503:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:19:28,029:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:19:31,561:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:19:35,100:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:19:38,684:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:19:42,203:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:19:42,882:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:19:43,554:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:19:44,227:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:19:44,909:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:19:45,585:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:19:46,961:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:19:48,330:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:19:49,712:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:19:51,092:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:19:52,455:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:19:54,527:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:19:56,548:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:19:58,602:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:20:00,663:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:20:02,731:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:20:05,455:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:20:08,188:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:20:10,920:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:20:13,655:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:20:16,351:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:20:19,699:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:20:23,049:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:20:26,415:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:20:29,845:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:20:33,197:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:20:33,875:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:20:34,549:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:20:35,222:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:20:35,904:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:20:36,569:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:20:37,921:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:20:39,258:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:20:40,608:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:20:41,969:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:20:43,319:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:20:45,346:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:20:47,366:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:20:49,404:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:20:51,447:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:20:53,485:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:20:56,187:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:20:58,864:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:21:01,571:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:21:04,279:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:21:06,961:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:21:10,320:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:21:13,662:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:21:17,045:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:21:20,447:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:21:23,821:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:21:24,496:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:21:25,174:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:21:25,847:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:21:26,529:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:21:27,199:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:21:28,557:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:21:29,905:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:21:31,264:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:21:32,626:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:21:33,980:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:21:36,011:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:21:38,033:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:21:40,078:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:21:42,132:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:21:44,166:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:21:46,871:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:21:49,571:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:21:52,284:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:21:55,015:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:21:57,721:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:22:01,095:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:22:04,448:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:22:07,833:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:22:11,230:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:22:14,591:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:22:15,267:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:22:15,942:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:22:16,634:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:22:17,314:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:22:17,984:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:22:19,331:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:22:20,675:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:22:22,032:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:22:23,419:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:22:24,779:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:22:26,822:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:22:28,851:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:22:30,882:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:22:32,928:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:22:34,951:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:22:37,662:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:22:40,353:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:22:43,067:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:22:45,794:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:22:48,485:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:22:51,868:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:22:55,230:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:22:58,620:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:23:02,024:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:33:53,702:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:33:54,499:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:33:55,289:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:33:56,077:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:33:56,874:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:33:57,661:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:33:59,241:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:34:00,817:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:34:02,393:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:34:03,986:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:34:05,561:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:34:07,925:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:34:10,283:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:34:12,651:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:34:15,030:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:34:17,394:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:34:20,564:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:34:23,732:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:34:26,897:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:34:30,132:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:34:33,326:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:34:37,286:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:34:41,264:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:34:45,213:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:34:49,179:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:34:53,154:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:34:53,954:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:34:54,749:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:34:55,557:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:34:56,360:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:34:57,147:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:34:58,761:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:35:00,361:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:35:01,977:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:35:03,603:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:35:05,179:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:35:07,564:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:35:09,971:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:35:12,346:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:35:14,737:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:35:17,120:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:35:20,291:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:35:23,518:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:35:26,729:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:35:29,947:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:35:33,134:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:35:37,095:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:35:41,117:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:35:45,145:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:35:49,169:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:35:53,119:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:35:53,896:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:35:54,662:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:35:55,429:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:35:56,195:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:35:56,964:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:35:58,501:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:36:00,016:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:36:01,547:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:36:03,084:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:36:04,619:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:36:06,919:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:36:09,209:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:36:11,508:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:36:13,802:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:36:16,109:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:36:19,189:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:36:22,272:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:36:25,342:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:36:28,435:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:36:31,543:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:36:35,405:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:36:39,247:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:36:43,100:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:36:47,036:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:36:50,883:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:36:51,642:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:36:52,393:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:36:53,147:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:36:53,910:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:36:54,659:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:36:56,168:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:36:57,662:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:36:59,152:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:37:00,660:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:37:02,157:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:37:04,404:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:37:06,619:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:37:08,861:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:37:11,148:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:37:13,387:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:37:16,379:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:37:19,354:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:37:22,343:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:37:25,368:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:37:28,330:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:37:32,011:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:37:35,713:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:37:39,483:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:37:43,247:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:37:46,954:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:37:47,671:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:37:48,382:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:37:49,115:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:37:49,837:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:37:50,559:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:37:52,006:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:37:53,444:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:37:54,890:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:37:56,347:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:37:57,778:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:37:59,941:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:38:02,089:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:38:04,257:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:38:06,438:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:38:08,595:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:38:11,496:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:38:14,419:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:38:17,312:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:38:20,231:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:38:23,103:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:38:26,728:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:38:30,322:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:38:33,966:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:38:37,640:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:38:41,220:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:38:41,947:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:38:42,666:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:38:43,385:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:38:44,114:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:38:44,827:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:38:46,284:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:38:47,733:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:38:49,182:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:38:50,644:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:38:52,087:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:38:54,252:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:38:56,435:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:38:58,619:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:39:00,788:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:39:02,926:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:39:05,829:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:39:08,723:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:39:11,613:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:39:14,503:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:39:17,397:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:39:21,004:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:39:24,594:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:39:28,244:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:39:31,901:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:39:35,565:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:39:36,298:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:39:37,022:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:39:37,747:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:39:38,475:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:39:39,192:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:39:40,644:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:39:42,087:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:39:43,548:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:39:45,002:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:39:46,438:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:39:48,614:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:39:50,789:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:39:52,966:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:39:55,176:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:39:57,338:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:40:00,239:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:40:03,135:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:40:06,061:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:40:08,997:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:40:11,874:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:40:15,524:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:40:19,121:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:40:22,748:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:40:26,386:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:40:30,008:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:40:30,740:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:40:31,477:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:40:32,191:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:40:32,914:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:40:33,619:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:40:35,067:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:40:36,496:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:40:37,953:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:40:39,418:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:40:40,885:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:40:43,072:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:40:45,245:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:40:47,417:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:40:49,593:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:40:51,734:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:40:54,604:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:40:57,450:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:41:00,340:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:41:03,276:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:41:06,158:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:41:09,748:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:41:13,322:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:41:16,891:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:41:20,459:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:41:23,984:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:41:24,666:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:41:25,345:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:41:26,023:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:41:26,707:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:41:27,376:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:41:28,731:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:41:30,075:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:41:31,425:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:41:32,783:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:41:34,134:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:41:36,158:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:41:38,180:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:41:40,220:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:41:42,259:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:41:44,303:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:41:47,040:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:41:49,745:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:41:52,468:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:41:55,196:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:41:57,895:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:42:01,260:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:42:04,655:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:42:08,051:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:42:11,472:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:42:14,859:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:42:15,541:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:42:16,212:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:42:16,888:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:42:17,570:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:42:18,238:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:42:19,584:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:42:20,926:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:42:22,279:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:42:23,631:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:42:24,974:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:42:27,001:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:42:29,022:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:42:31,052:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:42:33,109:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:42:35,141:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:42:37,843:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:42:40,531:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:42:43,258:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:42:45,991:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:42:48,709:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:42:52,108:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:42:55,473:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:42:58,856:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:43:02,268:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:43:05,668:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:43:06,352:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:43:07,024:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:43:07,699:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:43:08,380:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:43:09,049:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:43:10,396:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:43:11,730:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:43:13,074:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:43:14,438:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:43:15,786:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:43:17,802:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:43:19,834:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:43:21,859:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:43:23,955:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:43:25,997:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:43:28,702:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:43:31,414:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:43:34,174:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:43:36,935:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:43:39,670:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:43:43,079:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:43:46,453:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:43:49,859:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:43:53,257:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:43:56,641:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:43:57,323:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:43:58,000:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:43:58,691:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:43:59,376:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:44:00,046:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:44:01,406:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:44:02,754:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:44:04,129:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:44:05,500:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:44:06,856:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:44:08,893:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:44:10,917:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:44:12,957:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:44:15,027:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:44:17,068:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:44:19,788:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:44:22,482:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:44:25,209:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:44:27,934:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:44:30,678:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:44:34,089:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:44:37,478:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:44:40,899:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:44:44,321:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:55:32,890:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:55:33,686:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:55:34,473:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:55:35,262:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:55:36,058:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:55:36,858:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:55:38,448:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:55:40,020:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:55:41,600:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:55:43,188:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:55:44,762:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:55:47,131:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:55:49,504:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:55:51,890:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:55:54,286:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:55:56,724:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:56:00,040:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:56:03,180:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:56:06,335:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:56:09,507:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:56:12,649:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:56:16,599:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:56:20,545:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:56:24,558:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:56:28,538:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:56:32,483:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:56:33,283:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:56:34,072:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:56:34,861:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:56:35,657:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:56:36,447:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:56:38,028:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:56:39,604:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:56:41,180:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:56:42,766:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:56:44,343:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:56:46,720:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:56:49,087:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:56:51,455:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:56:53,848:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:56:56,217:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:56:59,361:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:57:02,495:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:57:05,627:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:57:08,787:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:57:11,916:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:57:15,858:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:57:19,760:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:57:23,676:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:57:27,625:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:57:31,559:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:57:32,329:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:57:33,087:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:57:33,852:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:57:34,621:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:57:35,390:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:57:36,924:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:57:38,446:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:57:39,976:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:57:41,515:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:57:43,039:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:57:45,343:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:57:47,618:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:57:49,910:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:57:52,215:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:57:54,504:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:57:57,567:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:58:00,593:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:58:03,654:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:58:06,713:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:58:09,752:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:58:13,571:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:58:17,364:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:58:21,168:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:58:24,995:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:58:28,786:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:58:29,530:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:58:30,265:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:58:31,004:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:58:31,753:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:58:32,493:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:58:33,974:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:58:35,447:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:58:36,920:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:58:38,412:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:58:39,885:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:58:42,096:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:58:44,314:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:58:46,535:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:58:48,759:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:58:50,971:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:58:53,926:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:58:56,883:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:58:59,827:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:59:02,789:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:59:05,718:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:59:09,391:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:59:13,067:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:59:16,739:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:59:20,448:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:59:24,128:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:59:24,851:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:59:25,570:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:59:26,290:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:59:27,004:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:59:27,721:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:59:29,162:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:59:30,599:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:59:32,040:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:59:33,490:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:59:34,923:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:59:37,088:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:59:39,245:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:59:41,405:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:59:43,582:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:59:45,744:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:59:48,625:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:59:51,507:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:59:54,396:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 12:59:57,301:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:00:00,155:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:00:03,759:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:00:07,337:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:00:10,884:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:00:14,546:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:00:18,143:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:00:18,857:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:00:19,568:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:00:20,278:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:00:20,988:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:00:21,698:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:00:23,146:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:00:24,577:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:00:25,996:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:00:27,419:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:00:28,845:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:00:31,038:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:00:33,159:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:00:35,285:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:00:37,462:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:00:39,615:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:00:42,500:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:00:45,377:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:00:48,263:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:00:51,165:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:00:54,037:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:00:57,680:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:01:01,238:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:01:04,811:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:01:08,424:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:01:11,993:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:01:12,718:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:01:13,455:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:01:14,175:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:01:14,894:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:01:15,609:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:01:17,050:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:01:18,485:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:01:19,919:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:01:21,364:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:01:22,931:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:01:25,079:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:01:27,230:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:01:29,391:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:01:31,565:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:01:33,714:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:01:36,598:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:01:39,466:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:01:42,347:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:01:45,248:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:01:48,115:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:01:51,714:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:01:55,286:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:01:58,880:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:02:02,493:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:02:06,067:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:02:06,776:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:02:07,482:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:02:08,186:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:02:08,894:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:02:09,591:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:02:11,003:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:02:12,412:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:02:13,828:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:02:15,256:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:02:16,659:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:02:18,776:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:02:20,888:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:02:23,013:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:02:25,153:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:02:27,272:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:02:30,091:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:02:32,906:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:02:35,731:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:02:38,592:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:02:41,409:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:02:44,933:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:02:48,449:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:02:51,980:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:02:55,546:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:02:59,060:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:02:59,731:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:03:00,400:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:03:01,070:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:03:01,746:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:03:02,409:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:03:03,752:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:03:05,077:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:03:06,416:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:03:07,765:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:03:09,104:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:03:11,115:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:03:13,117:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:03:15,127:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:03:17,153:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:03:19,176:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:03:21,866:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:03:24,548:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:03:27,245:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:03:29,963:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:03:32,656:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:03:36,020:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:03:39,379:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:03:42,760:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:03:46,175:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:03:49,548:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:03:50,227:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:03:50,898:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:03:51,575:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:03:52,257:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:03:52,928:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:03:54,287:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:03:55,621:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:03:56,973:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:03:58,332:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:03:59,677:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:04:01,698:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:04:03,703:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:04:05,736:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:04:07,771:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:04:09,785:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:04:12,482:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:04:15,161:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:04:17,864:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:04:20,580:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:04:23,268:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:04:26,638:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:04:29,991:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:04:33,376:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:04:36,781:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:04:40,154:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:04:40,831:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:04:41,504:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:04:42,176:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:04:42,858:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:04:43,524:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:04:44,873:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:04:46,234:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:04:47,583:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:04:48,944:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:04:50,290:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:04:52,318:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:04:54,334:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:04:56,370:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:04:58,410:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:05:00,437:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:05:03,137:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:05:05,820:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:05:08,520:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:05:11,240:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:05:13,939:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:05:17,307:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:05:20,664:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:05:24,048:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:05:27,445:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:05:30,816:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:05:31,492:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:05:32,169:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:05:32,840:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:05:33,520:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:05:34,188:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:05:35,536:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:05:36,875:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:05:38,223:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:05:39,577:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:05:40,922:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:05:42,979:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:05:44,988:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:05:47,011:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:05:49,047:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:05:51,097:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:05:53,792:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:05:56,467:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:05:59,166:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:06:01,860:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:06:04,546:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:06:07,896:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:06:11,231:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:06:14,593:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:06:17,977:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 13:17:03,758:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 14:01:12,294:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 14:26:57,951:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 14:32:10,532:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\ensemble\_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.
  warn(

2023-08-09 14:35:49,187:WARNING:C:\Users\user21\AppData\Local\Temp\ipykernel_2764\2744435426.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.
  train[['Product_importance', 'Mode_of_Shipment']].groupby(['Product_importance']).mean()

2023-08-09 15:59:37,046:INFO:PyCaret ClassificationExperiment
2023-08-09 15:59:37,047:INFO:Logging name: clf-default-name
2023-08-09 15:59:37,047:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-09 15:59:37,047:INFO:version 3.0.4
2023-08-09 15:59:37,047:INFO:Initializing setup()
2023-08-09 15:59:37,047:INFO:self.USI: 1ce8
2023-08-09 15:59:37,047:INFO:self._variable_keys: {'data', 'y_train', 'USI', 'html_param', 'seed', 'target_param', 'exp_name_log', 'fold_groups_param', 'y', 'gpu_param', '_available_plots', 'gpu_n_jobs_param', 'fold_shuffle_param', 'pipeline', 'memory', 'X', 'fix_imbalance', 'fold_generator', 'is_multiclass', '_ml_usecase', 'log_plots_param', 'X_test', 'y_test', 'logging_param', 'n_jobs_param', 'exp_id', 'X_train', 'idx'}
2023-08-09 15:59:37,047:INFO:Checking environment
2023-08-09 15:59:37,047:INFO:python_version: 3.10.12
2023-08-09 15:59:37,047:INFO:python_build: ('main', 'Jul  5 2023 19:09:20')
2023-08-09 15:59:37,047:INFO:machine: AMD64
2023-08-09 15:59:37,047:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-09 15:59:37,047:INFO:Memory: svmem(total=16828977152, available=6960185344, percent=58.6, used=9868791808, free=6960185344)
2023-08-09 15:59:37,047:INFO:Physical Core: 14
2023-08-09 15:59:37,047:INFO:Logical Core: 20
2023-08-09 15:59:37,047:INFO:Checking libraries
2023-08-09 15:59:37,047:INFO:System:
2023-08-09 15:59:37,047:INFO:    python: 3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:09:20) [MSC v.1916 64 bit (AMD64)]
2023-08-09 15:59:37,047:INFO:executable: C:\Users\user21\anaconda3\python.exe
2023-08-09 15:59:37,047:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-09 15:59:37,047:INFO:PyCaret required dependencies:
2023-08-09 15:59:37,049:INFO:                 pip: 23.2.1
2023-08-09 15:59:37,049:INFO:          setuptools: 68.0.0
2023-08-09 15:59:37,049:INFO:             pycaret: 3.0.4
2023-08-09 15:59:37,049:INFO:             IPython: 8.12.0
2023-08-09 15:59:37,049:INFO:          ipywidgets: 8.1.0
2023-08-09 15:59:37,050:INFO:                tqdm: 4.65.0
2023-08-09 15:59:37,050:INFO:               numpy: 1.23.5
2023-08-09 15:59:37,050:INFO:              pandas: 1.5.3
2023-08-09 15:59:37,050:INFO:              jinja2: 3.1.2
2023-08-09 15:59:37,050:INFO:               scipy: 1.11.1
2023-08-09 15:59:37,050:INFO:              joblib: 1.3.1
2023-08-09 15:59:37,050:INFO:             sklearn: 1.2.2
2023-08-09 15:59:37,050:INFO:                pyod: 1.1.0
2023-08-09 15:59:37,050:INFO:            imblearn: 0.11.0
2023-08-09 15:59:37,050:INFO:   category_encoders: 2.6.1
2023-08-09 15:59:37,050:INFO:            lightgbm: 4.0.0
2023-08-09 15:59:37,050:INFO:               numba: 0.57.1
2023-08-09 15:59:37,050:INFO:            requests: 2.31.0
2023-08-09 15:59:37,050:INFO:          matplotlib: 3.7.2
2023-08-09 15:59:37,050:INFO:          scikitplot: 0.3.7
2023-08-09 15:59:37,050:INFO:         yellowbrick: 1.5
2023-08-09 15:59:37,050:INFO:              plotly: 5.15.0
2023-08-09 15:59:37,050:INFO:    plotly-resampler: Not installed
2023-08-09 15:59:37,050:INFO:             kaleido: 0.2.1
2023-08-09 15:59:37,050:INFO:           schemdraw: 0.15
2023-08-09 15:59:37,050:INFO:         statsmodels: 0.14.0
2023-08-09 15:59:37,050:INFO:              sktime: 0.21.0
2023-08-09 15:59:37,050:INFO:               tbats: 1.1.3
2023-08-09 15:59:37,050:INFO:            pmdarima: 2.0.3
2023-08-09 15:59:37,050:INFO:              psutil: 5.9.0
2023-08-09 15:59:37,050:INFO:          markupsafe: 2.1.1
2023-08-09 15:59:37,050:INFO:             pickle5: Not installed
2023-08-09 15:59:37,050:INFO:         cloudpickle: 2.2.1
2023-08-09 15:59:37,050:INFO:         deprecation: 2.1.0
2023-08-09 15:59:37,050:INFO:              xxhash: 3.3.0
2023-08-09 15:59:37,050:INFO:           wurlitzer: Not installed
2023-08-09 15:59:37,050:INFO:PyCaret optional dependencies:
2023-08-09 15:59:37,057:INFO:                shap: Not installed
2023-08-09 15:59:37,057:INFO:           interpret: Not installed
2023-08-09 15:59:37,057:INFO:                umap: Not installed
2023-08-09 15:59:37,057:INFO:    pandas_profiling: Not installed
2023-08-09 15:59:37,057:INFO:  explainerdashboard: Not installed
2023-08-09 15:59:37,057:INFO:             autoviz: Not installed
2023-08-09 15:59:37,057:INFO:           fairlearn: Not installed
2023-08-09 15:59:37,057:INFO:          deepchecks: Not installed
2023-08-09 15:59:37,057:INFO:             xgboost: 1.7.6
2023-08-09 15:59:37,057:INFO:            catboost: 1.2
2023-08-09 15:59:37,057:INFO:              kmodes: Not installed
2023-08-09 15:59:37,057:INFO:             mlxtend: Not installed
2023-08-09 15:59:37,057:INFO:       statsforecast: Not installed
2023-08-09 15:59:37,057:INFO:        tune_sklearn: Not installed
2023-08-09 15:59:37,057:INFO:                 ray: Not installed
2023-08-09 15:59:37,057:INFO:            hyperopt: Not installed
2023-08-09 15:59:37,057:INFO:              optuna: 3.2.0
2023-08-09 15:59:37,057:INFO:               skopt: Not installed
2023-08-09 15:59:37,057:INFO:              mlflow: Not installed
2023-08-09 15:59:37,057:INFO:              gradio: Not installed
2023-08-09 15:59:37,057:INFO:             fastapi: Not installed
2023-08-09 15:59:37,057:INFO:             uvicorn: Not installed
2023-08-09 15:59:37,057:INFO:              m2cgen: Not installed
2023-08-09 15:59:37,057:INFO:           evidently: Not installed
2023-08-09 15:59:37,057:INFO:               fugue: Not installed
2023-08-09 15:59:37,057:INFO:           streamlit: Not installed
2023-08-09 15:59:37,057:INFO:             prophet: Not installed
2023-08-09 15:59:37,057:INFO:None
2023-08-09 15:59:37,057:INFO:Set up data.
2023-08-09 15:59:37,063:INFO:Set up train/test split.
2023-08-09 15:59:37,070:INFO:Set up index.
2023-08-09 15:59:37,071:INFO:Set up folding strategy.
2023-08-09 15:59:37,071:INFO:Assigning column types.
2023-08-09 15:59:37,073:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-09 15:59:37,111:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-09 15:59:37,114:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 15:59:37,138:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 15:59:37,140:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 15:59:37,170:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-09 15:59:37,170:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 15:59:37,188:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 15:59:37,189:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 15:59:37,190:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-09 15:59:37,219:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 15:59:37,237:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 15:59:37,238:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 15:59:37,272:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 15:59:37,289:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 15:59:37,291:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 15:59:37,291:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-09 15:59:37,337:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 15:59:37,339:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 15:59:37,385:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 15:59:37,387:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 15:59:37,416:INFO:Preparing preprocessing pipeline...
2023-08-09 15:59:37,418:INFO:Set up simple imputation.
2023-08-09 15:59:37,419:INFO:Set up encoding of categorical features.
2023-08-09 15:59:37,420:INFO:Set up column name cleaning.
2023-08-09 15:59:37,488:INFO:Finished creating preprocessing pipeline.
2023-08-09 15:59:37,493:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_fea...
                                    transformer=OneHotEncoder(cols=['Warehouse_block',
                                                                    'Mode_of_Shipment',
                                                                    'Product_importance'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-09 15:59:37,493:INFO:Creating final display dataframe.
2023-08-09 15:59:37,653:INFO:Setup _display_container:                     Description                Value
0                    Session id                  123
1                        Target  Reached.on.Time_Y.N
2                   Target type               Binary
3           Original data shape           (6897, 10)
4        Transformed data shape           (6897, 18)
5   Transformed train set shape           (4827, 18)
6    Transformed test set shape           (2070, 18)
7              Numeric features                    6
8          Categorical features                    3
9                    Preprocess                 True
10              Imputation type               simple
11           Numeric imputation                 mean
12       Categorical imputation                 mode
13     Maximum one-hot encoding                   25
14              Encoding method                 None
15               Fold Generator      StratifiedKFold
16                  Fold Number                   10
17                     CPU Jobs                   -1
18                      Use GPU                False
19               Log Experiment                False
20              Experiment Name     clf-default-name
21                          USI                 1ce8
2023-08-09 15:59:37,708:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 15:59:37,710:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 15:59:37,757:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 15:59:37,758:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 15:59:37,758:INFO:setup() successfully completed in 0.72s...............
2023-08-09 16:00:13,943:INFO:Initializing compare_models()
2023-08-09 16:00:13,943:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002370651D2A0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002370651D2A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-09 16:00:13,943:INFO:Checking exceptions
2023-08-09 16:00:13,946:INFO:Preparing display monitor
2023-08-09 16:00:13,963:INFO:Initializing Logistic Regression
2023-08-09 16:00:13,963:INFO:Total runtime is 0.0 minutes
2023-08-09 16:00:13,965:INFO:SubProcess create_model() called ==================================
2023-08-09 16:00:13,965:INFO:Initializing create_model()
2023-08-09 16:00:13,965:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002370651D2A0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023706544790>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:00:13,965:INFO:Checking exceptions
2023-08-09 16:00:13,967:INFO:Importing libraries
2023-08-09 16:00:13,967:INFO:Copying training dataset
2023-08-09 16:00:13,971:INFO:Defining folds
2023-08-09 16:00:13,971:INFO:Declaring metric variables
2023-08-09 16:00:13,973:INFO:Importing untrained model
2023-08-09 16:00:13,975:INFO:Logistic Regression Imported successfully
2023-08-09 16:00:13,979:INFO:Starting cross validation
2023-08-09 16:00:13,980:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:00:16,742:INFO:Calculating mean and std
2023-08-09 16:00:16,744:INFO:Creating metrics dataframe
2023-08-09 16:00:16,748:INFO:Uploading results into container
2023-08-09 16:00:16,749:INFO:Uploading model into container now
2023-08-09 16:00:16,749:INFO:_master_model_container: 1
2023-08-09 16:00:16,749:INFO:_display_container: 2
2023-08-09 16:00:16,750:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-09 16:00:16,750:INFO:create_model() successfully completed......................................
2023-08-09 16:00:17,155:INFO:SubProcess create_model() end ==================================
2023-08-09 16:00:17,155:INFO:Creating metrics dataframe
2023-08-09 16:00:17,161:INFO:Initializing K Neighbors Classifier
2023-08-09 16:00:17,161:INFO:Total runtime is 0.05329517126083374 minutes
2023-08-09 16:00:17,163:INFO:SubProcess create_model() called ==================================
2023-08-09 16:00:17,164:INFO:Initializing create_model()
2023-08-09 16:00:17,164:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002370651D2A0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023706544790>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:00:17,164:INFO:Checking exceptions
2023-08-09 16:00:17,164:INFO:Importing libraries
2023-08-09 16:00:17,164:INFO:Copying training dataset
2023-08-09 16:00:17,168:INFO:Defining folds
2023-08-09 16:00:17,168:INFO:Declaring metric variables
2023-08-09 16:00:17,171:INFO:Importing untrained model
2023-08-09 16:00:17,174:INFO:K Neighbors Classifier Imported successfully
2023-08-09 16:00:17,179:INFO:Starting cross validation
2023-08-09 16:00:17,180:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:00:19,479:INFO:Calculating mean and std
2023-08-09 16:00:19,480:INFO:Creating metrics dataframe
2023-08-09 16:00:19,485:INFO:Uploading results into container
2023-08-09 16:00:19,486:INFO:Uploading model into container now
2023-08-09 16:00:19,486:INFO:_master_model_container: 2
2023-08-09 16:00:19,486:INFO:_display_container: 2
2023-08-09 16:00:19,487:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-09 16:00:19,487:INFO:create_model() successfully completed......................................
2023-08-09 16:00:19,840:INFO:SubProcess create_model() end ==================================
2023-08-09 16:00:19,840:INFO:Creating metrics dataframe
2023-08-09 16:00:19,847:INFO:Initializing Naive Bayes
2023-08-09 16:00:19,848:INFO:Total runtime is 0.09807787736256918 minutes
2023-08-09 16:00:19,850:INFO:SubProcess create_model() called ==================================
2023-08-09 16:00:19,850:INFO:Initializing create_model()
2023-08-09 16:00:19,850:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002370651D2A0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023706544790>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:00:19,850:INFO:Checking exceptions
2023-08-09 16:00:19,850:INFO:Importing libraries
2023-08-09 16:00:19,850:INFO:Copying training dataset
2023-08-09 16:00:19,853:INFO:Defining folds
2023-08-09 16:00:19,854:INFO:Declaring metric variables
2023-08-09 16:00:19,857:INFO:Importing untrained model
2023-08-09 16:00:19,859:INFO:Naive Bayes Imported successfully
2023-08-09 16:00:19,864:INFO:Starting cross validation
2023-08-09 16:00:19,865:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:00:20,119:INFO:Calculating mean and std
2023-08-09 16:00:20,119:INFO:Creating metrics dataframe
2023-08-09 16:00:20,122:INFO:Uploading results into container
2023-08-09 16:00:20,123:INFO:Uploading model into container now
2023-08-09 16:00:20,123:INFO:_master_model_container: 3
2023-08-09 16:00:20,123:INFO:_display_container: 2
2023-08-09 16:00:20,123:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-09 16:00:20,123:INFO:create_model() successfully completed......................................
2023-08-09 16:00:20,487:INFO:SubProcess create_model() end ==================================
2023-08-09 16:00:20,487:INFO:Creating metrics dataframe
2023-08-09 16:00:20,495:INFO:Initializing Decision Tree Classifier
2023-08-09 16:00:20,495:INFO:Total runtime is 0.10886683066685995 minutes
2023-08-09 16:00:20,498:INFO:SubProcess create_model() called ==================================
2023-08-09 16:00:20,498:INFO:Initializing create_model()
2023-08-09 16:00:20,498:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002370651D2A0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023706544790>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:00:20,498:INFO:Checking exceptions
2023-08-09 16:00:20,498:INFO:Importing libraries
2023-08-09 16:00:20,498:INFO:Copying training dataset
2023-08-09 16:00:20,502:INFO:Defining folds
2023-08-09 16:00:20,502:INFO:Declaring metric variables
2023-08-09 16:00:20,505:INFO:Importing untrained model
2023-08-09 16:00:20,507:INFO:Decision Tree Classifier Imported successfully
2023-08-09 16:00:20,510:INFO:Starting cross validation
2023-08-09 16:00:20,511:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:00:20,773:INFO:Calculating mean and std
2023-08-09 16:00:20,773:INFO:Creating metrics dataframe
2023-08-09 16:00:20,777:INFO:Uploading results into container
2023-08-09 16:00:20,777:INFO:Uploading model into container now
2023-08-09 16:00:20,777:INFO:_master_model_container: 4
2023-08-09 16:00:20,777:INFO:_display_container: 2
2023-08-09 16:00:20,777:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-08-09 16:00:20,777:INFO:create_model() successfully completed......................................
2023-08-09 16:00:21,141:INFO:SubProcess create_model() end ==================================
2023-08-09 16:00:21,141:INFO:Creating metrics dataframe
2023-08-09 16:00:21,149:INFO:Initializing SVM - Linear Kernel
2023-08-09 16:00:21,149:INFO:Total runtime is 0.11976019144058228 minutes
2023-08-09 16:00:21,151:INFO:SubProcess create_model() called ==================================
2023-08-09 16:00:21,151:INFO:Initializing create_model()
2023-08-09 16:00:21,151:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002370651D2A0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023706544790>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:00:21,151:INFO:Checking exceptions
2023-08-09 16:00:21,151:INFO:Importing libraries
2023-08-09 16:00:21,151:INFO:Copying training dataset
2023-08-09 16:00:21,155:INFO:Defining folds
2023-08-09 16:00:21,155:INFO:Declaring metric variables
2023-08-09 16:00:21,157:INFO:Importing untrained model
2023-08-09 16:00:21,160:INFO:SVM - Linear Kernel Imported successfully
2023-08-09 16:00:21,164:INFO:Starting cross validation
2023-08-09 16:00:21,165:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:00:21,332:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:00:21,341:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:00:21,353:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:00:21,358:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:00:21,358:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:00:21,362:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:00:21,362:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:00:21,373:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:00:21,375:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:00:21,387:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:00:21,394:INFO:Calculating mean and std
2023-08-09 16:00:21,394:INFO:Creating metrics dataframe
2023-08-09 16:00:21,398:INFO:Uploading results into container
2023-08-09 16:00:21,398:INFO:Uploading model into container now
2023-08-09 16:00:21,399:INFO:_master_model_container: 5
2023-08-09 16:00:21,399:INFO:_display_container: 2
2023-08-09 16:00:21,399:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-09 16:00:21,399:INFO:create_model() successfully completed......................................
2023-08-09 16:00:21,750:INFO:SubProcess create_model() end ==================================
2023-08-09 16:00:21,750:INFO:Creating metrics dataframe
2023-08-09 16:00:21,759:INFO:Initializing Ridge Classifier
2023-08-09 16:00:21,759:INFO:Total runtime is 0.12992846965789795 minutes
2023-08-09 16:00:21,761:INFO:SubProcess create_model() called ==================================
2023-08-09 16:00:21,761:INFO:Initializing create_model()
2023-08-09 16:00:21,761:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002370651D2A0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023706544790>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:00:21,761:INFO:Checking exceptions
2023-08-09 16:00:21,761:INFO:Importing libraries
2023-08-09 16:00:21,761:INFO:Copying training dataset
2023-08-09 16:00:21,765:INFO:Defining folds
2023-08-09 16:00:21,765:INFO:Declaring metric variables
2023-08-09 16:00:21,767:INFO:Importing untrained model
2023-08-09 16:00:21,770:INFO:Ridge Classifier Imported successfully
2023-08-09 16:00:21,775:INFO:Starting cross validation
2023-08-09 16:00:21,775:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:00:21,916:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:00:21,944:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:00:21,945:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:00:21,948:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:00:21,949:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:00:21,950:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:00:21,955:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:00:21,956:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:00:21,956:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:00:21,969:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:00:21,987:INFO:Calculating mean and std
2023-08-09 16:00:21,988:INFO:Creating metrics dataframe
2023-08-09 16:00:21,990:INFO:Uploading results into container
2023-08-09 16:00:21,991:INFO:Uploading model into container now
2023-08-09 16:00:21,991:INFO:_master_model_container: 6
2023-08-09 16:00:21,991:INFO:_display_container: 2
2023-08-09 16:00:21,991:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-08-09 16:00:21,991:INFO:create_model() successfully completed......................................
2023-08-09 16:00:22,348:INFO:SubProcess create_model() end ==================================
2023-08-09 16:00:22,348:INFO:Creating metrics dataframe
2023-08-09 16:00:22,356:INFO:Initializing Random Forest Classifier
2023-08-09 16:00:22,356:INFO:Total runtime is 0.13987741072972615 minutes
2023-08-09 16:00:22,357:INFO:SubProcess create_model() called ==================================
2023-08-09 16:00:22,357:INFO:Initializing create_model()
2023-08-09 16:00:22,357:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002370651D2A0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023706544790>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:00:22,357:INFO:Checking exceptions
2023-08-09 16:00:22,357:INFO:Importing libraries
2023-08-09 16:00:22,357:INFO:Copying training dataset
2023-08-09 16:00:22,362:INFO:Defining folds
2023-08-09 16:00:22,362:INFO:Declaring metric variables
2023-08-09 16:00:22,364:INFO:Importing untrained model
2023-08-09 16:00:22,366:INFO:Random Forest Classifier Imported successfully
2023-08-09 16:00:22,370:INFO:Starting cross validation
2023-08-09 16:00:22,371:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:00:23,403:INFO:Calculating mean and std
2023-08-09 16:00:23,404:INFO:Creating metrics dataframe
2023-08-09 16:00:23,410:INFO:Uploading results into container
2023-08-09 16:00:23,411:INFO:Uploading model into container now
2023-08-09 16:00:23,411:INFO:_master_model_container: 7
2023-08-09 16:00:23,411:INFO:_display_container: 2
2023-08-09 16:00:23,411:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-09 16:00:23,411:INFO:create_model() successfully completed......................................
2023-08-09 16:00:23,785:INFO:SubProcess create_model() end ==================================
2023-08-09 16:00:23,785:INFO:Creating metrics dataframe
2023-08-09 16:00:23,792:INFO:Initializing Quadratic Discriminant Analysis
2023-08-09 16:00:23,793:INFO:Total runtime is 0.1638283610343933 minutes
2023-08-09 16:00:23,795:INFO:SubProcess create_model() called ==================================
2023-08-09 16:00:23,795:INFO:Initializing create_model()
2023-08-09 16:00:23,795:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002370651D2A0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023706544790>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:00:23,795:INFO:Checking exceptions
2023-08-09 16:00:23,795:INFO:Importing libraries
2023-08-09 16:00:23,795:INFO:Copying training dataset
2023-08-09 16:00:23,799:INFO:Defining folds
2023-08-09 16:00:23,799:INFO:Declaring metric variables
2023-08-09 16:00:23,801:INFO:Importing untrained model
2023-08-09 16:00:23,803:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-09 16:00:23,807:INFO:Starting cross validation
2023-08-09 16:00:23,807:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:00:23,915:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:00:23,916:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:00:23,927:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:00:23,929:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:00:23,930:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:00:23,934:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:00:23,939:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:00:23,942:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:00:23,943:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:00:23,959:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:00:24,057:INFO:Calculating mean and std
2023-08-09 16:00:24,057:INFO:Creating metrics dataframe
2023-08-09 16:00:24,062:INFO:Uploading results into container
2023-08-09 16:00:24,063:INFO:Uploading model into container now
2023-08-09 16:00:24,063:INFO:_master_model_container: 8
2023-08-09 16:00:24,063:INFO:_display_container: 2
2023-08-09 16:00:24,063:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-09 16:00:24,063:INFO:create_model() successfully completed......................................
2023-08-09 16:00:24,412:INFO:SubProcess create_model() end ==================================
2023-08-09 16:00:24,412:INFO:Creating metrics dataframe
2023-08-09 16:00:24,419:INFO:Initializing Ada Boost Classifier
2023-08-09 16:00:24,419:INFO:Total runtime is 0.17427247365315754 minutes
2023-08-09 16:00:24,422:INFO:SubProcess create_model() called ==================================
2023-08-09 16:00:24,422:INFO:Initializing create_model()
2023-08-09 16:00:24,422:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002370651D2A0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023706544790>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:00:24,422:INFO:Checking exceptions
2023-08-09 16:00:24,422:INFO:Importing libraries
2023-08-09 16:00:24,422:INFO:Copying training dataset
2023-08-09 16:00:24,425:INFO:Defining folds
2023-08-09 16:00:24,427:INFO:Declaring metric variables
2023-08-09 16:00:24,429:INFO:Importing untrained model
2023-08-09 16:00:24,431:INFO:Ada Boost Classifier Imported successfully
2023-08-09 16:00:24,437:INFO:Starting cross validation
2023-08-09 16:00:24,438:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:00:25,037:INFO:Calculating mean and std
2023-08-09 16:00:25,038:INFO:Creating metrics dataframe
2023-08-09 16:00:25,045:INFO:Uploading results into container
2023-08-09 16:00:25,045:INFO:Uploading model into container now
2023-08-09 16:00:25,045:INFO:_master_model_container: 9
2023-08-09 16:00:25,045:INFO:_display_container: 2
2023-08-09 16:00:25,045:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-08-09 16:00:25,045:INFO:create_model() successfully completed......................................
2023-08-09 16:00:25,425:INFO:SubProcess create_model() end ==================================
2023-08-09 16:00:25,425:INFO:Creating metrics dataframe
2023-08-09 16:00:25,435:INFO:Initializing Gradient Boosting Classifier
2023-08-09 16:00:25,435:INFO:Total runtime is 0.19119261503219603 minutes
2023-08-09 16:00:25,437:INFO:SubProcess create_model() called ==================================
2023-08-09 16:00:25,437:INFO:Initializing create_model()
2023-08-09 16:00:25,437:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002370651D2A0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023706544790>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:00:25,437:INFO:Checking exceptions
2023-08-09 16:00:25,437:INFO:Importing libraries
2023-08-09 16:00:25,437:INFO:Copying training dataset
2023-08-09 16:00:25,441:INFO:Defining folds
2023-08-09 16:00:25,441:INFO:Declaring metric variables
2023-08-09 16:00:25,444:INFO:Importing untrained model
2023-08-09 16:00:25,447:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:00:25,451:INFO:Starting cross validation
2023-08-09 16:00:25,452:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:00:26,458:INFO:Calculating mean and std
2023-08-09 16:00:26,458:INFO:Creating metrics dataframe
2023-08-09 16:00:26,470:INFO:Uploading results into container
2023-08-09 16:00:26,470:INFO:Uploading model into container now
2023-08-09 16:00:26,471:INFO:_master_model_container: 10
2023-08-09 16:00:26,471:INFO:_display_container: 2
2023-08-09 16:00:26,471:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:00:26,471:INFO:create_model() successfully completed......................................
2023-08-09 16:00:26,834:INFO:SubProcess create_model() end ==================================
2023-08-09 16:00:26,834:INFO:Creating metrics dataframe
2023-08-09 16:00:26,841:INFO:Initializing Linear Discriminant Analysis
2023-08-09 16:00:26,841:INFO:Total runtime is 0.2146379510561625 minutes
2023-08-09 16:00:26,844:INFO:SubProcess create_model() called ==================================
2023-08-09 16:00:26,845:INFO:Initializing create_model()
2023-08-09 16:00:26,845:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002370651D2A0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023706544790>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:00:26,845:INFO:Checking exceptions
2023-08-09 16:00:26,845:INFO:Importing libraries
2023-08-09 16:00:26,845:INFO:Copying training dataset
2023-08-09 16:00:26,848:INFO:Defining folds
2023-08-09 16:00:26,848:INFO:Declaring metric variables
2023-08-09 16:00:26,851:INFO:Importing untrained model
2023-08-09 16:00:26,853:INFO:Linear Discriminant Analysis Imported successfully
2023-08-09 16:00:26,857:INFO:Starting cross validation
2023-08-09 16:00:26,858:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:00:27,158:INFO:Calculating mean and std
2023-08-09 16:00:27,159:INFO:Creating metrics dataframe
2023-08-09 16:00:27,168:INFO:Uploading results into container
2023-08-09 16:00:27,169:INFO:Uploading model into container now
2023-08-09 16:00:27,169:INFO:_master_model_container: 11
2023-08-09 16:00:27,169:INFO:_display_container: 2
2023-08-09 16:00:27,169:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-09 16:00:27,169:INFO:create_model() successfully completed......................................
2023-08-09 16:00:27,529:INFO:SubProcess create_model() end ==================================
2023-08-09 16:00:27,529:INFO:Creating metrics dataframe
2023-08-09 16:00:27,537:INFO:Initializing Extra Trees Classifier
2023-08-09 16:00:27,538:INFO:Total runtime is 0.22624547481536864 minutes
2023-08-09 16:00:27,540:INFO:SubProcess create_model() called ==================================
2023-08-09 16:00:27,540:INFO:Initializing create_model()
2023-08-09 16:00:27,540:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002370651D2A0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023706544790>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:00:27,540:INFO:Checking exceptions
2023-08-09 16:00:27,540:INFO:Importing libraries
2023-08-09 16:00:27,540:INFO:Copying training dataset
2023-08-09 16:00:27,544:INFO:Defining folds
2023-08-09 16:00:27,544:INFO:Declaring metric variables
2023-08-09 16:00:27,547:INFO:Importing untrained model
2023-08-09 16:00:27,549:INFO:Extra Trees Classifier Imported successfully
2023-08-09 16:00:27,554:INFO:Starting cross validation
2023-08-09 16:00:27,554:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:00:28,514:INFO:Calculating mean and std
2023-08-09 16:00:28,515:INFO:Creating metrics dataframe
2023-08-09 16:00:28,524:INFO:Uploading results into container
2023-08-09 16:00:28,525:INFO:Uploading model into container now
2023-08-09 16:00:28,525:INFO:_master_model_container: 12
2023-08-09 16:00:28,525:INFO:_display_container: 2
2023-08-09 16:00:28,526:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-08-09 16:00:28,526:INFO:create_model() successfully completed......................................
2023-08-09 16:00:28,885:INFO:SubProcess create_model() end ==================================
2023-08-09 16:00:28,885:INFO:Creating metrics dataframe
2023-08-09 16:00:28,895:INFO:Initializing Extreme Gradient Boosting
2023-08-09 16:00:28,895:INFO:Total runtime is 0.24886177380879718 minutes
2023-08-09 16:00:28,897:INFO:SubProcess create_model() called ==================================
2023-08-09 16:00:28,897:INFO:Initializing create_model()
2023-08-09 16:00:28,897:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002370651D2A0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023706544790>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:00:28,897:INFO:Checking exceptions
2023-08-09 16:00:28,897:INFO:Importing libraries
2023-08-09 16:00:28,897:INFO:Copying training dataset
2023-08-09 16:00:28,901:INFO:Defining folds
2023-08-09 16:00:28,901:INFO:Declaring metric variables
2023-08-09 16:00:28,903:INFO:Importing untrained model
2023-08-09 16:00:28,905:INFO:Extreme Gradient Boosting Imported successfully
2023-08-09 16:00:28,910:INFO:Starting cross validation
2023-08-09 16:00:28,911:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:00:29,669:INFO:Calculating mean and std
2023-08-09 16:00:29,670:INFO:Creating metrics dataframe
2023-08-09 16:00:29,687:INFO:Uploading results into container
2023-08-09 16:00:29,687:INFO:Uploading model into container now
2023-08-09 16:00:29,688:INFO:_master_model_container: 13
2023-08-09 16:00:29,688:INFO:_display_container: 2
2023-08-09 16:00:29,688:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-09 16:00:29,689:INFO:create_model() successfully completed......................................
2023-08-09 16:00:30,044:INFO:SubProcess create_model() end ==================================
2023-08-09 16:00:30,044:INFO:Creating metrics dataframe
2023-08-09 16:00:30,053:INFO:Initializing Light Gradient Boosting Machine
2023-08-09 16:00:30,053:INFO:Total runtime is 0.26816361745198564 minutes
2023-08-09 16:00:30,055:INFO:SubProcess create_model() called ==================================
2023-08-09 16:00:30,055:INFO:Initializing create_model()
2023-08-09 16:00:30,055:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002370651D2A0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023706544790>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:00:30,055:INFO:Checking exceptions
2023-08-09 16:00:30,055:INFO:Importing libraries
2023-08-09 16:00:30,055:INFO:Copying training dataset
2023-08-09 16:00:30,060:INFO:Defining folds
2023-08-09 16:00:30,060:INFO:Declaring metric variables
2023-08-09 16:00:30,063:INFO:Importing untrained model
2023-08-09 16:00:30,066:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-09 16:00:30,071:INFO:Starting cross validation
2023-08-09 16:00:30,072:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:00:31,508:INFO:Calculating mean and std
2023-08-09 16:00:31,509:INFO:Creating metrics dataframe
2023-08-09 16:00:31,528:INFO:Uploading results into container
2023-08-09 16:00:31,529:INFO:Uploading model into container now
2023-08-09 16:00:31,529:INFO:_master_model_container: 14
2023-08-09 16:00:31,529:INFO:_display_container: 2
2023-08-09 16:00:31,529:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-09 16:00:31,530:INFO:create_model() successfully completed......................................
2023-08-09 16:00:31,876:INFO:SubProcess create_model() end ==================================
2023-08-09 16:00:31,877:INFO:Creating metrics dataframe
2023-08-09 16:00:31,885:INFO:Initializing CatBoost Classifier
2023-08-09 16:00:31,885:INFO:Total runtime is 0.29870109955469765 minutes
2023-08-09 16:00:31,887:INFO:SubProcess create_model() called ==================================
2023-08-09 16:00:31,888:INFO:Initializing create_model()
2023-08-09 16:00:31,888:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002370651D2A0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023706544790>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:00:31,888:INFO:Checking exceptions
2023-08-09 16:00:31,888:INFO:Importing libraries
2023-08-09 16:00:31,888:INFO:Copying training dataset
2023-08-09 16:00:31,891:INFO:Defining folds
2023-08-09 16:00:31,891:INFO:Declaring metric variables
2023-08-09 16:00:31,894:INFO:Importing untrained model
2023-08-09 16:00:31,895:INFO:CatBoost Classifier Imported successfully
2023-08-09 16:00:31,900:INFO:Starting cross validation
2023-08-09 16:00:31,901:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:00:35,190:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py:378: FitFailedWarning: 
7 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
7 fits failed with the following error:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "C:\Users\user21\anaconda3\lib\site-packages\joblib\memory.py", line 655, in __call__
    return self._cached_call(args, kwargs)[0]
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "C:\Users\user21\anaconda3\lib\site-packages\catboost\core.py", line 5131, in fit
    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,
  File "C:\Users\user21\anaconda3\lib\site-packages\catboost\core.py", line 2357, in _fit
    self._train(
  File "C:\Users\user21\anaconda3\lib\site-packages\catboost\core.py", line 1761, in _train
    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)
  File "_catboost.pyx", line 4624, in _catboost._CatBoost._train
  File "_catboost.pyx", line 4673, in _catboost._CatBoost._train
_catboost.CatBoostError: C:/Go_Agent/pipelines/BuildMaster/catboost.git/catboost/libs/train_lib/dir_helper.cpp:26: Can't create train tmp dir: tmp

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-08-09 16:00:35,190:INFO:Calculating mean and std
2023-08-09 16:00:35,191:INFO:Creating metrics dataframe
2023-08-09 16:00:35,207:INFO:Uploading results into container
2023-08-09 16:00:35,207:INFO:Uploading model into container now
2023-08-09 16:00:35,208:INFO:_master_model_container: 15
2023-08-09 16:00:35,208:INFO:_display_container: 2
2023-08-09 16:00:35,208:INFO:<catboost.core.CatBoostClassifier object at 0x0000023706CAE320>
2023-08-09 16:00:35,208:INFO:create_model() successfully completed......................................
2023-08-09 16:00:35,570:WARNING:create_model() for <catboost.core.CatBoostClassifier object at 0x0000023706CAE320> raised an exception or returned all 0.0, trying without fit_kwargs:
2023-08-09 16:00:35,573:WARNING:Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 797, in compare_models
    np.sum(
AssertionError

2023-08-09 16:00:35,574:INFO:Initializing create_model()
2023-08-09 16:00:35,574:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002370651D2A0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023706544790>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:00:35,574:INFO:Checking exceptions
2023-08-09 16:00:35,574:INFO:Importing libraries
2023-08-09 16:00:35,574:INFO:Copying training dataset
2023-08-09 16:00:35,577:INFO:Defining folds
2023-08-09 16:00:35,578:INFO:Declaring metric variables
2023-08-09 16:00:35,580:INFO:Importing untrained model
2023-08-09 16:00:35,583:INFO:CatBoost Classifier Imported successfully
2023-08-09 16:00:35,587:INFO:Starting cross validation
2023-08-09 16:00:35,589:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:00:39,388:INFO:Calculating mean and std
2023-08-09 16:00:39,389:INFO:Creating metrics dataframe
2023-08-09 16:00:39,414:INFO:Uploading results into container
2023-08-09 16:00:39,415:INFO:Uploading model into container now
2023-08-09 16:00:39,415:INFO:_master_model_container: 16
2023-08-09 16:00:39,415:INFO:_display_container: 2
2023-08-09 16:00:39,415:INFO:<catboost.core.CatBoostClassifier object at 0x0000023706FB32B0>
2023-08-09 16:00:39,415:INFO:create_model() successfully completed......................................
2023-08-09 16:00:39,777:INFO:SubProcess create_model() end ==================================
2023-08-09 16:00:39,777:INFO:Creating metrics dataframe
2023-08-09 16:00:39,788:INFO:Initializing Dummy Classifier
2023-08-09 16:00:39,788:INFO:Total runtime is 0.43041921456654864 minutes
2023-08-09 16:00:39,791:INFO:SubProcess create_model() called ==================================
2023-08-09 16:00:39,791:INFO:Initializing create_model()
2023-08-09 16:00:39,791:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002370651D2A0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023706544790>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:00:39,792:INFO:Checking exceptions
2023-08-09 16:00:39,792:INFO:Importing libraries
2023-08-09 16:00:39,792:INFO:Copying training dataset
2023-08-09 16:00:39,796:INFO:Defining folds
2023-08-09 16:00:39,796:INFO:Declaring metric variables
2023-08-09 16:00:39,798:INFO:Importing untrained model
2023-08-09 16:00:39,801:INFO:Dummy Classifier Imported successfully
2023-08-09 16:00:39,806:INFO:Starting cross validation
2023-08-09 16:00:39,807:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:00:40,137:INFO:Calculating mean and std
2023-08-09 16:00:40,141:INFO:Creating metrics dataframe
2023-08-09 16:00:40,161:INFO:Uploading results into container
2023-08-09 16:00:40,162:INFO:Uploading model into container now
2023-08-09 16:00:40,162:INFO:_master_model_container: 17
2023-08-09 16:00:40,162:INFO:_display_container: 2
2023-08-09 16:00:40,162:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-08-09 16:00:40,162:INFO:create_model() successfully completed......................................
2023-08-09 16:00:40,523:INFO:SubProcess create_model() end ==================================
2023-08-09 16:00:40,523:INFO:Creating metrics dataframe
2023-08-09 16:00:40,538:INFO:Initializing create_model()
2023-08-09 16:00:40,538:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002370651D2A0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:00:40,538:INFO:Checking exceptions
2023-08-09 16:00:40,539:INFO:Importing libraries
2023-08-09 16:00:40,539:INFO:Copying training dataset
2023-08-09 16:00:40,543:INFO:Defining folds
2023-08-09 16:00:40,543:INFO:Declaring metric variables
2023-08-09 16:00:40,543:INFO:Importing untrained model
2023-08-09 16:00:40,543:INFO:Declaring custom model
2023-08-09 16:00:40,544:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:00:40,545:INFO:Cross validation set to False
2023-08-09 16:00:40,545:INFO:Fitting Model
2023-08-09 16:00:41,241:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:00:41,241:INFO:create_model() successfully completed......................................
2023-08-09 16:00:41,641:INFO:_master_model_container: 17
2023-08-09 16:00:41,641:INFO:_display_container: 2
2023-08-09 16:00:41,641:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:00:41,641:INFO:compare_models() successfully completed......................................
2023-08-09 16:01:11,522:INFO:Initializing create_model()
2023-08-09 16:01:11,523:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002370651D2A0>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:01:11,523:INFO:Checking exceptions
2023-08-09 16:01:11,534:INFO:Importing libraries
2023-08-09 16:01:11,534:INFO:Copying training dataset
2023-08-09 16:01:11,537:INFO:Defining folds
2023-08-09 16:01:11,537:INFO:Declaring metric variables
2023-08-09 16:01:11,540:INFO:Importing untrained model
2023-08-09 16:01:11,543:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:01:11,547:INFO:Starting cross validation
2023-08-09 16:01:11,549:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:01:11,951:INFO:Calculating mean and std
2023-08-09 16:01:11,951:INFO:Creating metrics dataframe
2023-08-09 16:01:11,955:INFO:Finalizing model
2023-08-09 16:01:12,056:INFO:Uploading results into container
2023-08-09 16:01:12,056:INFO:Uploading model into container now
2023-08-09 16:01:12,063:INFO:_master_model_container: 18
2023-08-09 16:01:12,064:INFO:_display_container: 3
2023-08-09 16:01:12,064:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:01:12,064:INFO:create_model() successfully completed......................................
2023-08-09 16:01:36,453:INFO:Initializing tune_model()
2023-08-09 16:01:36,453:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002370651D2A0>)
2023-08-09 16:01:36,453:INFO:Checking exceptions
2023-08-09 16:01:36,464:INFO:Copying training dataset
2023-08-09 16:01:36,466:INFO:Checking base model
2023-08-09 16:01:36,466:INFO:Base model : Gradient Boosting Classifier
2023-08-09 16:01:36,468:INFO:Declaring metric variables
2023-08-09 16:01:36,470:INFO:Defining Hyperparameters
2023-08-09 16:01:36,839:INFO:Tuning with n_jobs=-1
2023-08-09 16:01:36,839:INFO:Initializing RandomizedSearchCV
2023-08-09 16:01:45,892:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.4}
2023-08-09 16:01:45,893:INFO:Hyperparameter search completed
2023-08-09 16:01:45,893:INFO:SubProcess create_model() called ==================================
2023-08-09 16:01:45,893:INFO:Initializing create_model()
2023-08-09 16:01:45,893:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002370651D2A0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236D687ABC0>, model_only=True, return_train_score=False, kwargs={'subsample': 0.7, 'n_estimators': 190, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.3, 'max_features': 'sqrt', 'max_depth': 7, 'learning_rate': 0.4})
2023-08-09 16:01:45,893:INFO:Checking exceptions
2023-08-09 16:01:45,894:INFO:Importing libraries
2023-08-09 16:01:45,894:INFO:Copying training dataset
2023-08-09 16:01:45,897:INFO:Defining folds
2023-08-09 16:01:45,897:INFO:Declaring metric variables
2023-08-09 16:01:45,900:INFO:Importing untrained model
2023-08-09 16:01:45,900:INFO:Declaring custom model
2023-08-09 16:01:45,902:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:01:45,907:INFO:Starting cross validation
2023-08-09 16:01:45,908:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:01:46,538:INFO:Calculating mean and std
2023-08-09 16:01:46,539:INFO:Creating metrics dataframe
2023-08-09 16:01:46,543:INFO:Finalizing model
2023-08-09 16:01:47,057:INFO:Uploading results into container
2023-08-09 16:01:47,058:INFO:Uploading model into container now
2023-08-09 16:01:47,059:INFO:_master_model_container: 19
2023-08-09 16:01:47,059:INFO:_display_container: 4
2023-08-09 16:01:47,059:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=123, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:01:47,059:INFO:create_model() successfully completed......................................
2023-08-09 16:01:47,420:INFO:SubProcess create_model() end ==================================
2023-08-09 16:01:47,420:INFO:choose_better activated
2023-08-09 16:01:47,423:INFO:SubProcess create_model() called ==================================
2023-08-09 16:01:47,424:INFO:Initializing create_model()
2023-08-09 16:01:47,424:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002370651D2A0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:01:47,424:INFO:Checking exceptions
2023-08-09 16:01:47,425:INFO:Importing libraries
2023-08-09 16:01:47,425:INFO:Copying training dataset
2023-08-09 16:01:47,428:INFO:Defining folds
2023-08-09 16:01:47,428:INFO:Declaring metric variables
2023-08-09 16:01:47,428:INFO:Importing untrained model
2023-08-09 16:01:47,428:INFO:Declaring custom model
2023-08-09 16:01:47,428:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:01:47,428:INFO:Starting cross validation
2023-08-09 16:01:47,429:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:01:47,967:INFO:Calculating mean and std
2023-08-09 16:01:47,967:INFO:Creating metrics dataframe
2023-08-09 16:01:47,968:INFO:Finalizing model
2023-08-09 16:01:48,082:INFO:Uploading results into container
2023-08-09 16:01:48,083:INFO:Uploading model into container now
2023-08-09 16:01:48,083:INFO:_master_model_container: 20
2023-08-09 16:01:48,083:INFO:_display_container: 5
2023-08-09 16:01:48,084:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:01:48,084:INFO:create_model() successfully completed......................................
2023-08-09 16:01:48,453:INFO:SubProcess create_model() end ==================================
2023-08-09 16:01:48,453:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.6573
2023-08-09 16:01:48,453:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=123, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.6488
2023-08-09 16:01:48,454:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-08-09 16:01:48,454:INFO:choose_better completed
2023-08-09 16:01:48,454:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-08-09 16:01:48,462:INFO:_master_model_container: 20
2023-08-09 16:01:48,462:INFO:_display_container: 4
2023-08-09 16:01:48,462:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:01:48,462:INFO:tune_model() successfully completed......................................
2023-08-09 16:04:30,934:INFO:PyCaret ClassificationExperiment
2023-08-09 16:04:30,934:INFO:Logging name: clf-default-name
2023-08-09 16:04:30,934:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-09 16:04:30,934:INFO:version 3.0.4
2023-08-09 16:04:30,934:INFO:Initializing setup()
2023-08-09 16:04:30,934:INFO:self.USI: 9a17
2023-08-09 16:04:30,934:INFO:self._variable_keys: {'data', 'y_train', 'USI', 'html_param', 'seed', 'target_param', 'exp_name_log', 'fold_groups_param', 'y', 'gpu_param', '_available_plots', 'gpu_n_jobs_param', 'fold_shuffle_param', 'pipeline', 'memory', 'X', 'fix_imbalance', 'fold_generator', 'is_multiclass', '_ml_usecase', 'log_plots_param', 'X_test', 'y_test', 'logging_param', 'n_jobs_param', 'exp_id', 'X_train', 'idx'}
2023-08-09 16:04:30,934:INFO:Checking environment
2023-08-09 16:04:30,934:INFO:python_version: 3.10.12
2023-08-09 16:04:30,934:INFO:python_build: ('main', 'Jul  5 2023 19:09:20')
2023-08-09 16:04:30,934:INFO:machine: AMD64
2023-08-09 16:04:30,934:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-09 16:04:30,934:INFO:Memory: svmem(total=16828977152, available=3965870080, percent=76.4, used=12863107072, free=3965870080)
2023-08-09 16:04:30,934:INFO:Physical Core: 14
2023-08-09 16:04:30,934:INFO:Logical Core: 20
2023-08-09 16:04:30,934:INFO:Checking libraries
2023-08-09 16:04:30,934:INFO:System:
2023-08-09 16:04:30,934:INFO:    python: 3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:09:20) [MSC v.1916 64 bit (AMD64)]
2023-08-09 16:04:30,934:INFO:executable: C:\Users\user21\anaconda3\python.exe
2023-08-09 16:04:30,934:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-09 16:04:30,934:INFO:PyCaret required dependencies:
2023-08-09 16:04:30,934:INFO:                 pip: 23.2.1
2023-08-09 16:04:30,934:INFO:          setuptools: 68.0.0
2023-08-09 16:04:30,934:INFO:             pycaret: 3.0.4
2023-08-09 16:04:30,934:INFO:             IPython: 8.12.0
2023-08-09 16:04:30,934:INFO:          ipywidgets: 8.1.0
2023-08-09 16:04:30,934:INFO:                tqdm: 4.65.0
2023-08-09 16:04:30,934:INFO:               numpy: 1.23.5
2023-08-09 16:04:30,934:INFO:              pandas: 1.5.3
2023-08-09 16:04:30,934:INFO:              jinja2: 3.1.2
2023-08-09 16:04:30,934:INFO:               scipy: 1.11.1
2023-08-09 16:04:30,935:INFO:              joblib: 1.3.1
2023-08-09 16:04:30,935:INFO:             sklearn: 1.2.2
2023-08-09 16:04:30,935:INFO:                pyod: 1.1.0
2023-08-09 16:04:30,935:INFO:            imblearn: 0.11.0
2023-08-09 16:04:30,935:INFO:   category_encoders: 2.6.1
2023-08-09 16:04:30,935:INFO:            lightgbm: 4.0.0
2023-08-09 16:04:30,935:INFO:               numba: 0.57.1
2023-08-09 16:04:30,935:INFO:            requests: 2.31.0
2023-08-09 16:04:30,935:INFO:          matplotlib: 3.7.2
2023-08-09 16:04:30,935:INFO:          scikitplot: 0.3.7
2023-08-09 16:04:30,935:INFO:         yellowbrick: 1.5
2023-08-09 16:04:30,935:INFO:              plotly: 5.15.0
2023-08-09 16:04:30,935:INFO:    plotly-resampler: Not installed
2023-08-09 16:04:30,935:INFO:             kaleido: 0.2.1
2023-08-09 16:04:30,935:INFO:           schemdraw: 0.15
2023-08-09 16:04:30,935:INFO:         statsmodels: 0.14.0
2023-08-09 16:04:30,935:INFO:              sktime: 0.21.0
2023-08-09 16:04:30,935:INFO:               tbats: 1.1.3
2023-08-09 16:04:30,935:INFO:            pmdarima: 2.0.3
2023-08-09 16:04:30,935:INFO:              psutil: 5.9.0
2023-08-09 16:04:30,935:INFO:          markupsafe: 2.1.1
2023-08-09 16:04:30,935:INFO:             pickle5: Not installed
2023-08-09 16:04:30,935:INFO:         cloudpickle: 2.2.1
2023-08-09 16:04:30,935:INFO:         deprecation: 2.1.0
2023-08-09 16:04:30,935:INFO:              xxhash: 3.3.0
2023-08-09 16:04:30,935:INFO:           wurlitzer: Not installed
2023-08-09 16:04:30,935:INFO:PyCaret optional dependencies:
2023-08-09 16:04:30,935:INFO:                shap: Not installed
2023-08-09 16:04:30,935:INFO:           interpret: Not installed
2023-08-09 16:04:30,935:INFO:                umap: Not installed
2023-08-09 16:04:30,935:INFO:    pandas_profiling: Not installed
2023-08-09 16:04:30,935:INFO:  explainerdashboard: Not installed
2023-08-09 16:04:30,935:INFO:             autoviz: Not installed
2023-08-09 16:04:30,935:INFO:           fairlearn: Not installed
2023-08-09 16:04:30,935:INFO:          deepchecks: Not installed
2023-08-09 16:04:30,935:INFO:             xgboost: 1.7.6
2023-08-09 16:04:30,935:INFO:            catboost: 1.2
2023-08-09 16:04:30,935:INFO:              kmodes: Not installed
2023-08-09 16:04:30,935:INFO:             mlxtend: Not installed
2023-08-09 16:04:30,935:INFO:       statsforecast: Not installed
2023-08-09 16:04:30,935:INFO:        tune_sklearn: Not installed
2023-08-09 16:04:30,935:INFO:                 ray: Not installed
2023-08-09 16:04:30,935:INFO:            hyperopt: Not installed
2023-08-09 16:04:30,935:INFO:              optuna: 3.2.0
2023-08-09 16:04:30,935:INFO:               skopt: Not installed
2023-08-09 16:04:30,935:INFO:              mlflow: Not installed
2023-08-09 16:04:30,935:INFO:              gradio: Not installed
2023-08-09 16:04:30,935:INFO:             fastapi: Not installed
2023-08-09 16:04:30,935:INFO:             uvicorn: Not installed
2023-08-09 16:04:30,935:INFO:              m2cgen: Not installed
2023-08-09 16:04:30,935:INFO:           evidently: Not installed
2023-08-09 16:04:30,935:INFO:               fugue: Not installed
2023-08-09 16:04:30,935:INFO:           streamlit: Not installed
2023-08-09 16:04:30,935:INFO:             prophet: Not installed
2023-08-09 16:04:30,935:INFO:None
2023-08-09 16:04:30,935:INFO:Set up data.
2023-08-09 16:04:30,942:INFO:Set up train/test split.
2023-08-09 16:04:30,948:INFO:Set up index.
2023-08-09 16:04:30,948:INFO:Set up folding strategy.
2023-08-09 16:04:30,948:INFO:Assigning column types.
2023-08-09 16:04:30,951:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-09 16:04:30,981:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-09 16:04:30,982:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 16:04:30,999:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:04:31,000:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:04:31,029:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-09 16:04:31,030:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 16:04:31,047:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:04:31,047:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:04:31,049:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-09 16:04:31,077:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 16:04:31,094:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:04:31,095:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:04:31,125:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 16:04:31,144:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:04:31,146:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:04:31,146:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-09 16:04:31,192:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:04:31,194:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:04:31,241:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:04:31,243:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:04:31,244:INFO:Preparing preprocessing pipeline...
2023-08-09 16:04:31,245:INFO:Set up simple imputation.
2023-08-09 16:04:31,246:INFO:Set up encoding of categorical features.
2023-08-09 16:04:31,247:INFO:Set up column name cleaning.
2023-08-09 16:04:31,310:INFO:Finished creating preprocessing pipeline.
2023-08-09 16:04:31,315:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_fea...
                                    transformer=OneHotEncoder(cols=['Warehouse_block',
                                                                    'Mode_of_Shipment',
                                                                    'Product_importance'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-09 16:04:31,315:INFO:Creating final display dataframe.
2023-08-09 16:04:31,472:INFO:Setup _display_container:                     Description                Value
0                    Session id                  123
1                        Target  Reached.on.Time_Y.N
2                   Target type               Binary
3           Original data shape           (6897, 10)
4        Transformed data shape           (6897, 18)
5   Transformed train set shape           (4827, 18)
6    Transformed test set shape           (2070, 18)
7              Numeric features                    6
8          Categorical features                    3
9                    Preprocess                 True
10              Imputation type               simple
11           Numeric imputation                 mean
12       Categorical imputation                 mode
13     Maximum one-hot encoding                   25
14              Encoding method                 None
15               Fold Generator      StratifiedKFold
16                  Fold Number                   10
17                     CPU Jobs                   -1
18                      Use GPU                False
19               Log Experiment                False
20              Experiment Name     clf-default-name
21                          USI                 9a17
2023-08-09 16:04:31,525:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:04:31,526:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:04:31,573:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:04:31,574:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:04:31,575:INFO:setup() successfully completed in 0.67s...............
2023-08-09 16:04:31,605:INFO:Initializing compare_models()
2023-08-09 16:04:31,605:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-09 16:04:31,605:INFO:Checking exceptions
2023-08-09 16:04:31,608:INFO:Preparing display monitor
2023-08-09 16:04:31,625:INFO:Initializing Logistic Regression
2023-08-09 16:04:31,625:INFO:Total runtime is 0.0 minutes
2023-08-09 16:04:31,627:INFO:SubProcess create_model() called ==================================
2023-08-09 16:04:31,627:INFO:Initializing create_model()
2023-08-09 16:04:31,627:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023707036350>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:04:31,627:INFO:Checking exceptions
2023-08-09 16:04:31,627:INFO:Importing libraries
2023-08-09 16:04:31,627:INFO:Copying training dataset
2023-08-09 16:04:31,630:INFO:Defining folds
2023-08-09 16:04:31,630:INFO:Declaring metric variables
2023-08-09 16:04:31,633:INFO:Importing untrained model
2023-08-09 16:04:31,635:INFO:Logistic Regression Imported successfully
2023-08-09 16:04:31,639:INFO:Starting cross validation
2023-08-09 16:04:31,640:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:04:32,157:INFO:Calculating mean and std
2023-08-09 16:04:32,157:INFO:Creating metrics dataframe
2023-08-09 16:04:32,204:INFO:Uploading results into container
2023-08-09 16:04:32,204:INFO:Uploading model into container now
2023-08-09 16:04:32,204:INFO:_master_model_container: 1
2023-08-09 16:04:32,204:INFO:_display_container: 2
2023-08-09 16:04:32,205:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-09 16:04:32,205:INFO:create_model() successfully completed......................................
2023-08-09 16:04:32,599:INFO:SubProcess create_model() end ==================================
2023-08-09 16:04:32,599:INFO:Creating metrics dataframe
2023-08-09 16:04:32,605:INFO:Initializing K Neighbors Classifier
2023-08-09 16:04:32,605:INFO:Total runtime is 0.01633604367574056 minutes
2023-08-09 16:04:32,607:INFO:SubProcess create_model() called ==================================
2023-08-09 16:04:32,607:INFO:Initializing create_model()
2023-08-09 16:04:32,607:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023707036350>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:04:32,607:INFO:Checking exceptions
2023-08-09 16:04:32,608:INFO:Importing libraries
2023-08-09 16:04:32,608:INFO:Copying training dataset
2023-08-09 16:04:32,610:INFO:Defining folds
2023-08-09 16:04:32,610:INFO:Declaring metric variables
2023-08-09 16:04:32,613:INFO:Importing untrained model
2023-08-09 16:04:32,615:INFO:K Neighbors Classifier Imported successfully
2023-08-09 16:04:32,621:INFO:Starting cross validation
2023-08-09 16:04:32,622:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:04:33,268:INFO:Calculating mean and std
2023-08-09 16:04:33,269:INFO:Creating metrics dataframe
2023-08-09 16:04:33,316:INFO:Uploading results into container
2023-08-09 16:04:33,317:INFO:Uploading model into container now
2023-08-09 16:04:33,317:INFO:_master_model_container: 2
2023-08-09 16:04:33,317:INFO:_display_container: 2
2023-08-09 16:04:33,317:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-09 16:04:33,317:INFO:create_model() successfully completed......................................
2023-08-09 16:04:33,683:INFO:SubProcess create_model() end ==================================
2023-08-09 16:04:33,683:INFO:Creating metrics dataframe
2023-08-09 16:04:33,690:INFO:Initializing Naive Bayes
2023-08-09 16:04:33,690:INFO:Total runtime is 0.03442620833714803 minutes
2023-08-09 16:04:33,692:INFO:SubProcess create_model() called ==================================
2023-08-09 16:04:33,692:INFO:Initializing create_model()
2023-08-09 16:04:33,692:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023707036350>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:04:33,693:INFO:Checking exceptions
2023-08-09 16:04:33,693:INFO:Importing libraries
2023-08-09 16:04:33,693:INFO:Copying training dataset
2023-08-09 16:04:33,697:INFO:Defining folds
2023-08-09 16:04:33,697:INFO:Declaring metric variables
2023-08-09 16:04:33,700:INFO:Importing untrained model
2023-08-09 16:04:33,702:INFO:Naive Bayes Imported successfully
2023-08-09 16:04:33,706:INFO:Starting cross validation
2023-08-09 16:04:33,707:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:04:34,199:INFO:Calculating mean and std
2023-08-09 16:04:34,201:INFO:Creating metrics dataframe
2023-08-09 16:04:34,243:INFO:Uploading results into container
2023-08-09 16:04:34,244:INFO:Uploading model into container now
2023-08-09 16:04:34,244:INFO:_master_model_container: 3
2023-08-09 16:04:34,244:INFO:_display_container: 2
2023-08-09 16:04:34,244:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-09 16:04:34,244:INFO:create_model() successfully completed......................................
2023-08-09 16:04:34,610:INFO:SubProcess create_model() end ==================================
2023-08-09 16:04:34,610:INFO:Creating metrics dataframe
2023-08-09 16:04:34,617:INFO:Initializing Decision Tree Classifier
2023-08-09 16:04:34,617:INFO:Total runtime is 0.04986732800801595 minutes
2023-08-09 16:04:34,619:INFO:SubProcess create_model() called ==================================
2023-08-09 16:04:34,619:INFO:Initializing create_model()
2023-08-09 16:04:34,619:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023707036350>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:04:34,619:INFO:Checking exceptions
2023-08-09 16:04:34,619:INFO:Importing libraries
2023-08-09 16:04:34,619:INFO:Copying training dataset
2023-08-09 16:04:34,623:INFO:Defining folds
2023-08-09 16:04:34,623:INFO:Declaring metric variables
2023-08-09 16:04:34,626:INFO:Importing untrained model
2023-08-09 16:04:34,627:INFO:Decision Tree Classifier Imported successfully
2023-08-09 16:04:34,631:INFO:Starting cross validation
2023-08-09 16:04:34,632:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:04:35,132:INFO:Calculating mean and std
2023-08-09 16:04:35,134:INFO:Creating metrics dataframe
2023-08-09 16:04:35,183:INFO:Uploading results into container
2023-08-09 16:04:35,184:INFO:Uploading model into container now
2023-08-09 16:04:35,184:INFO:_master_model_container: 4
2023-08-09 16:04:35,184:INFO:_display_container: 2
2023-08-09 16:04:35,185:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-08-09 16:04:35,185:INFO:create_model() successfully completed......................................
2023-08-09 16:04:35,545:INFO:SubProcess create_model() end ==================================
2023-08-09 16:04:35,545:INFO:Creating metrics dataframe
2023-08-09 16:04:35,552:INFO:Initializing SVM - Linear Kernel
2023-08-09 16:04:35,552:INFO:Total runtime is 0.0654603640238444 minutes
2023-08-09 16:04:35,555:INFO:SubProcess create_model() called ==================================
2023-08-09 16:04:35,557:INFO:Initializing create_model()
2023-08-09 16:04:35,557:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023707036350>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:04:35,557:INFO:Checking exceptions
2023-08-09 16:04:35,557:INFO:Importing libraries
2023-08-09 16:04:35,557:INFO:Copying training dataset
2023-08-09 16:04:35,561:INFO:Defining folds
2023-08-09 16:04:35,562:INFO:Declaring metric variables
2023-08-09 16:04:35,566:INFO:Importing untrained model
2023-08-09 16:04:35,568:INFO:SVM - Linear Kernel Imported successfully
2023-08-09 16:04:35,573:INFO:Starting cross validation
2023-08-09 16:04:35,574:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:04:35,742:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:04:35,755:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:04:35,765:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:04:35,772:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:04:35,777:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:04:35,777:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:04:35,782:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:04:35,783:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:04:35,791:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:04:35,797:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:04:36,051:INFO:Calculating mean and std
2023-08-09 16:04:36,052:INFO:Creating metrics dataframe
2023-08-09 16:04:36,093:INFO:Uploading results into container
2023-08-09 16:04:36,093:INFO:Uploading model into container now
2023-08-09 16:04:36,094:INFO:_master_model_container: 5
2023-08-09 16:04:36,094:INFO:_display_container: 2
2023-08-09 16:04:36,094:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-09 16:04:36,094:INFO:create_model() successfully completed......................................
2023-08-09 16:04:36,451:INFO:SubProcess create_model() end ==================================
2023-08-09 16:04:36,451:INFO:Creating metrics dataframe
2023-08-09 16:04:36,460:INFO:Initializing Ridge Classifier
2023-08-09 16:04:36,460:INFO:Total runtime is 0.08058540423711141 minutes
2023-08-09 16:04:36,463:INFO:SubProcess create_model() called ==================================
2023-08-09 16:04:36,463:INFO:Initializing create_model()
2023-08-09 16:04:36,463:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023707036350>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:04:36,463:INFO:Checking exceptions
2023-08-09 16:04:36,463:INFO:Importing libraries
2023-08-09 16:04:36,463:INFO:Copying training dataset
2023-08-09 16:04:36,467:INFO:Defining folds
2023-08-09 16:04:36,467:INFO:Declaring metric variables
2023-08-09 16:04:36,468:INFO:Importing untrained model
2023-08-09 16:04:36,471:INFO:Ridge Classifier Imported successfully
2023-08-09 16:04:36,477:INFO:Starting cross validation
2023-08-09 16:04:36,478:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:04:36,621:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:04:36,621:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:04:36,622:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:04:36,640:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:04:36,642:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:04:36,648:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:04:36,648:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:04:36,648:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:04:36,659:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:04:36,659:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:04:36,913:INFO:Calculating mean and std
2023-08-09 16:04:36,914:INFO:Creating metrics dataframe
2023-08-09 16:04:36,963:INFO:Uploading results into container
2023-08-09 16:04:36,963:INFO:Uploading model into container now
2023-08-09 16:04:36,964:INFO:_master_model_container: 6
2023-08-09 16:04:36,964:INFO:_display_container: 2
2023-08-09 16:04:36,964:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-08-09 16:04:36,964:INFO:create_model() successfully completed......................................
2023-08-09 16:04:37,327:INFO:SubProcess create_model() end ==================================
2023-08-09 16:04:37,328:INFO:Creating metrics dataframe
2023-08-09 16:04:37,335:INFO:Initializing Random Forest Classifier
2023-08-09 16:04:37,335:INFO:Total runtime is 0.09517935911814372 minutes
2023-08-09 16:04:37,337:INFO:SubProcess create_model() called ==================================
2023-08-09 16:04:37,337:INFO:Initializing create_model()
2023-08-09 16:04:37,338:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023707036350>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:04:37,338:INFO:Checking exceptions
2023-08-09 16:04:37,338:INFO:Importing libraries
2023-08-09 16:04:37,338:INFO:Copying training dataset
2023-08-09 16:04:37,341:INFO:Defining folds
2023-08-09 16:04:37,341:INFO:Declaring metric variables
2023-08-09 16:04:37,344:INFO:Importing untrained model
2023-08-09 16:04:37,346:INFO:Random Forest Classifier Imported successfully
2023-08-09 16:04:37,352:INFO:Starting cross validation
2023-08-09 16:04:37,353:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:04:38,045:INFO:Calculating mean and std
2023-08-09 16:04:38,046:INFO:Creating metrics dataframe
2023-08-09 16:04:38,088:INFO:Uploading results into container
2023-08-09 16:04:38,089:INFO:Uploading model into container now
2023-08-09 16:04:38,089:INFO:_master_model_container: 7
2023-08-09 16:04:38,089:INFO:_display_container: 2
2023-08-09 16:04:38,089:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-09 16:04:38,089:INFO:create_model() successfully completed......................................
2023-08-09 16:04:38,445:INFO:SubProcess create_model() end ==================================
2023-08-09 16:04:38,445:INFO:Creating metrics dataframe
2023-08-09 16:04:38,455:INFO:Initializing Quadratic Discriminant Analysis
2023-08-09 16:04:38,455:INFO:Total runtime is 0.1138478716214498 minutes
2023-08-09 16:04:38,459:INFO:SubProcess create_model() called ==================================
2023-08-09 16:04:38,459:INFO:Initializing create_model()
2023-08-09 16:04:38,459:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023707036350>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:04:38,459:INFO:Checking exceptions
2023-08-09 16:04:38,459:INFO:Importing libraries
2023-08-09 16:04:38,459:INFO:Copying training dataset
2023-08-09 16:04:38,462:INFO:Defining folds
2023-08-09 16:04:38,463:INFO:Declaring metric variables
2023-08-09 16:04:38,465:INFO:Importing untrained model
2023-08-09 16:04:38,468:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-09 16:04:38,472:INFO:Starting cross validation
2023-08-09 16:04:38,473:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:04:38,570:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:04:38,579:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:04:38,585:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:04:38,587:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:04:38,592:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:04:38,593:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:04:38,595:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:04:38,619:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:04:38,621:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:04:38,625:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:04:38,968:INFO:Calculating mean and std
2023-08-09 16:04:38,969:INFO:Creating metrics dataframe
2023-08-09 16:04:39,013:INFO:Uploading results into container
2023-08-09 16:04:39,014:INFO:Uploading model into container now
2023-08-09 16:04:39,014:INFO:_master_model_container: 8
2023-08-09 16:04:39,014:INFO:_display_container: 2
2023-08-09 16:04:39,014:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-09 16:04:39,014:INFO:create_model() successfully completed......................................
2023-08-09 16:04:39,366:INFO:SubProcess create_model() end ==================================
2023-08-09 16:04:39,366:INFO:Creating metrics dataframe
2023-08-09 16:04:39,375:INFO:Initializing Ada Boost Classifier
2023-08-09 16:04:39,375:INFO:Total runtime is 0.1291665037473043 minutes
2023-08-09 16:04:39,377:INFO:SubProcess create_model() called ==================================
2023-08-09 16:04:39,378:INFO:Initializing create_model()
2023-08-09 16:04:39,378:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023707036350>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:04:39,378:INFO:Checking exceptions
2023-08-09 16:04:39,378:INFO:Importing libraries
2023-08-09 16:04:39,378:INFO:Copying training dataset
2023-08-09 16:04:39,381:INFO:Defining folds
2023-08-09 16:04:39,381:INFO:Declaring metric variables
2023-08-09 16:04:39,383:INFO:Importing untrained model
2023-08-09 16:04:39,385:INFO:Ada Boost Classifier Imported successfully
2023-08-09 16:04:39,390:INFO:Starting cross validation
2023-08-09 16:04:39,391:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:04:39,940:INFO:Calculating mean and std
2023-08-09 16:04:39,941:INFO:Creating metrics dataframe
2023-08-09 16:04:39,987:INFO:Uploading results into container
2023-08-09 16:04:39,987:INFO:Uploading model into container now
2023-08-09 16:04:39,987:INFO:_master_model_container: 9
2023-08-09 16:04:39,988:INFO:_display_container: 2
2023-08-09 16:04:39,988:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-08-09 16:04:39,988:INFO:create_model() successfully completed......................................
2023-08-09 16:04:40,342:INFO:SubProcess create_model() end ==================================
2023-08-09 16:04:40,342:INFO:Creating metrics dataframe
2023-08-09 16:04:40,352:INFO:Initializing Gradient Boosting Classifier
2023-08-09 16:04:40,352:INFO:Total runtime is 0.14545654058456423 minutes
2023-08-09 16:04:40,355:INFO:SubProcess create_model() called ==================================
2023-08-09 16:04:40,355:INFO:Initializing create_model()
2023-08-09 16:04:40,355:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023707036350>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:04:40,355:INFO:Checking exceptions
2023-08-09 16:04:40,355:INFO:Importing libraries
2023-08-09 16:04:40,355:INFO:Copying training dataset
2023-08-09 16:04:40,359:INFO:Defining folds
2023-08-09 16:04:40,359:INFO:Declaring metric variables
2023-08-09 16:04:40,361:INFO:Importing untrained model
2023-08-09 16:04:40,364:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:04:40,369:INFO:Starting cross validation
2023-08-09 16:04:40,370:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:04:40,911:INFO:Calculating mean and std
2023-08-09 16:04:40,912:INFO:Creating metrics dataframe
2023-08-09 16:04:40,959:INFO:Uploading results into container
2023-08-09 16:04:40,959:INFO:Uploading model into container now
2023-08-09 16:04:40,959:INFO:_master_model_container: 10
2023-08-09 16:04:40,959:INFO:_display_container: 2
2023-08-09 16:04:40,960:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:04:40,960:INFO:create_model() successfully completed......................................
2023-08-09 16:04:41,316:INFO:SubProcess create_model() end ==================================
2023-08-09 16:04:41,317:INFO:Creating metrics dataframe
2023-08-09 16:04:41,325:INFO:Initializing Linear Discriminant Analysis
2023-08-09 16:04:41,325:INFO:Total runtime is 0.161675496896108 minutes
2023-08-09 16:04:41,328:INFO:SubProcess create_model() called ==================================
2023-08-09 16:04:41,328:INFO:Initializing create_model()
2023-08-09 16:04:41,328:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023707036350>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:04:41,328:INFO:Checking exceptions
2023-08-09 16:04:41,328:INFO:Importing libraries
2023-08-09 16:04:41,328:INFO:Copying training dataset
2023-08-09 16:04:41,332:INFO:Defining folds
2023-08-09 16:04:41,332:INFO:Declaring metric variables
2023-08-09 16:04:41,334:INFO:Importing untrained model
2023-08-09 16:04:41,337:INFO:Linear Discriminant Analysis Imported successfully
2023-08-09 16:04:41,343:INFO:Starting cross validation
2023-08-09 16:04:41,344:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:04:41,829:INFO:Calculating mean and std
2023-08-09 16:04:41,830:INFO:Creating metrics dataframe
2023-08-09 16:04:41,876:INFO:Uploading results into container
2023-08-09 16:04:41,876:INFO:Uploading model into container now
2023-08-09 16:04:41,877:INFO:_master_model_container: 11
2023-08-09 16:04:41,877:INFO:_display_container: 2
2023-08-09 16:04:41,877:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-09 16:04:41,877:INFO:create_model() successfully completed......................................
2023-08-09 16:04:42,231:INFO:SubProcess create_model() end ==================================
2023-08-09 16:04:42,231:INFO:Creating metrics dataframe
2023-08-09 16:04:42,240:INFO:Initializing Extra Trees Classifier
2023-08-09 16:04:42,240:INFO:Total runtime is 0.17691688140233358 minutes
2023-08-09 16:04:42,242:INFO:SubProcess create_model() called ==================================
2023-08-09 16:04:42,242:INFO:Initializing create_model()
2023-08-09 16:04:42,242:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023707036350>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:04:42,242:INFO:Checking exceptions
2023-08-09 16:04:42,242:INFO:Importing libraries
2023-08-09 16:04:42,242:INFO:Copying training dataset
2023-08-09 16:04:42,246:INFO:Defining folds
2023-08-09 16:04:42,246:INFO:Declaring metric variables
2023-08-09 16:04:42,247:INFO:Importing untrained model
2023-08-09 16:04:42,250:INFO:Extra Trees Classifier Imported successfully
2023-08-09 16:04:42,255:INFO:Starting cross validation
2023-08-09 16:04:42,256:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:04:43,018:INFO:Calculating mean and std
2023-08-09 16:04:43,019:INFO:Creating metrics dataframe
2023-08-09 16:04:43,065:INFO:Uploading results into container
2023-08-09 16:04:43,065:INFO:Uploading model into container now
2023-08-09 16:04:43,065:INFO:_master_model_container: 12
2023-08-09 16:04:43,065:INFO:_display_container: 2
2023-08-09 16:04:43,067:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-08-09 16:04:43,067:INFO:create_model() successfully completed......................................
2023-08-09 16:04:43,439:INFO:SubProcess create_model() end ==================================
2023-08-09 16:04:43,439:INFO:Creating metrics dataframe
2023-08-09 16:04:43,449:INFO:Initializing Extreme Gradient Boosting
2023-08-09 16:04:43,449:INFO:Total runtime is 0.19706718126932782 minutes
2023-08-09 16:04:43,452:INFO:SubProcess create_model() called ==================================
2023-08-09 16:04:43,452:INFO:Initializing create_model()
2023-08-09 16:04:43,452:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023707036350>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:04:43,452:INFO:Checking exceptions
2023-08-09 16:04:43,452:INFO:Importing libraries
2023-08-09 16:04:43,452:INFO:Copying training dataset
2023-08-09 16:04:43,455:INFO:Defining folds
2023-08-09 16:04:43,455:INFO:Declaring metric variables
2023-08-09 16:04:43,459:INFO:Importing untrained model
2023-08-09 16:04:43,462:INFO:Extreme Gradient Boosting Imported successfully
2023-08-09 16:04:43,466:INFO:Starting cross validation
2023-08-09 16:04:43,467:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:04:44,043:INFO:Calculating mean and std
2023-08-09 16:04:44,044:INFO:Creating metrics dataframe
2023-08-09 16:04:44,084:INFO:Uploading results into container
2023-08-09 16:04:44,085:INFO:Uploading model into container now
2023-08-09 16:04:44,085:INFO:_master_model_container: 13
2023-08-09 16:04:44,085:INFO:_display_container: 2
2023-08-09 16:04:44,085:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-09 16:04:44,085:INFO:create_model() successfully completed......................................
2023-08-09 16:04:44,436:INFO:SubProcess create_model() end ==================================
2023-08-09 16:04:44,436:INFO:Creating metrics dataframe
2023-08-09 16:04:44,444:INFO:Initializing Light Gradient Boosting Machine
2023-08-09 16:04:44,444:INFO:Total runtime is 0.21366327206293745 minutes
2023-08-09 16:04:44,446:INFO:SubProcess create_model() called ==================================
2023-08-09 16:04:44,448:INFO:Initializing create_model()
2023-08-09 16:04:44,448:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023707036350>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:04:44,448:INFO:Checking exceptions
2023-08-09 16:04:44,448:INFO:Importing libraries
2023-08-09 16:04:44,448:INFO:Copying training dataset
2023-08-09 16:04:44,451:INFO:Defining folds
2023-08-09 16:04:44,451:INFO:Declaring metric variables
2023-08-09 16:04:44,454:INFO:Importing untrained model
2023-08-09 16:04:44,457:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-09 16:04:44,461:INFO:Starting cross validation
2023-08-09 16:04:44,462:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:04:45,106:INFO:Calculating mean and std
2023-08-09 16:04:45,107:INFO:Creating metrics dataframe
2023-08-09 16:04:45,150:INFO:Uploading results into container
2023-08-09 16:04:45,150:INFO:Uploading model into container now
2023-08-09 16:04:45,151:INFO:_master_model_container: 14
2023-08-09 16:04:45,151:INFO:_display_container: 2
2023-08-09 16:04:45,151:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-09 16:04:45,151:INFO:create_model() successfully completed......................................
2023-08-09 16:04:45,514:INFO:SubProcess create_model() end ==================================
2023-08-09 16:04:45,515:INFO:Creating metrics dataframe
2023-08-09 16:04:45,523:INFO:Initializing CatBoost Classifier
2023-08-09 16:04:45,523:INFO:Total runtime is 0.23164754311243696 minutes
2023-08-09 16:04:45,526:INFO:SubProcess create_model() called ==================================
2023-08-09 16:04:45,526:INFO:Initializing create_model()
2023-08-09 16:04:45,526:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023707036350>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:04:45,526:INFO:Checking exceptions
2023-08-09 16:04:45,526:INFO:Importing libraries
2023-08-09 16:04:45,526:INFO:Copying training dataset
2023-08-09 16:04:45,531:INFO:Defining folds
2023-08-09 16:04:45,531:INFO:Declaring metric variables
2023-08-09 16:04:45,534:INFO:Importing untrained model
2023-08-09 16:04:45,536:INFO:CatBoost Classifier Imported successfully
2023-08-09 16:04:45,541:INFO:Starting cross validation
2023-08-09 16:04:45,542:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:04:46,057:INFO:Calculating mean and std
2023-08-09 16:04:46,058:INFO:Creating metrics dataframe
2023-08-09 16:04:46,100:INFO:Uploading results into container
2023-08-09 16:04:46,101:INFO:Uploading model into container now
2023-08-09 16:04:46,101:INFO:_master_model_container: 15
2023-08-09 16:04:46,101:INFO:_display_container: 2
2023-08-09 16:04:46,101:INFO:<catboost.core.CatBoostClassifier object at 0x000002370651E020>
2023-08-09 16:04:46,101:INFO:create_model() successfully completed......................................
2023-08-09 16:04:46,480:INFO:SubProcess create_model() end ==================================
2023-08-09 16:04:46,480:INFO:Creating metrics dataframe
2023-08-09 16:04:46,489:INFO:Initializing Dummy Classifier
2023-08-09 16:04:46,489:INFO:Total runtime is 0.24773557186126713 minutes
2023-08-09 16:04:46,491:INFO:SubProcess create_model() called ==================================
2023-08-09 16:04:46,491:INFO:Initializing create_model()
2023-08-09 16:04:46,491:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023707036350>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:04:46,491:INFO:Checking exceptions
2023-08-09 16:04:46,491:INFO:Importing libraries
2023-08-09 16:04:46,491:INFO:Copying training dataset
2023-08-09 16:04:46,495:INFO:Defining folds
2023-08-09 16:04:46,495:INFO:Declaring metric variables
2023-08-09 16:04:46,498:INFO:Importing untrained model
2023-08-09 16:04:46,501:INFO:Dummy Classifier Imported successfully
2023-08-09 16:04:46,506:INFO:Starting cross validation
2023-08-09 16:04:46,506:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:04:46,988:INFO:Calculating mean and std
2023-08-09 16:04:46,988:INFO:Creating metrics dataframe
2023-08-09 16:04:47,035:INFO:Uploading results into container
2023-08-09 16:04:47,035:INFO:Uploading model into container now
2023-08-09 16:04:47,035:INFO:_master_model_container: 16
2023-08-09 16:04:47,035:INFO:_display_container: 2
2023-08-09 16:04:47,035:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-08-09 16:04:47,035:INFO:create_model() successfully completed......................................
2023-08-09 16:04:47,395:INFO:SubProcess create_model() end ==================================
2023-08-09 16:04:47,395:INFO:Creating metrics dataframe
2023-08-09 16:04:47,411:INFO:Initializing create_model()
2023-08-09 16:04:47,411:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:04:47,411:INFO:Checking exceptions
2023-08-09 16:04:47,412:INFO:Importing libraries
2023-08-09 16:04:47,413:INFO:Copying training dataset
2023-08-09 16:04:47,415:INFO:Defining folds
2023-08-09 16:04:47,415:INFO:Declaring metric variables
2023-08-09 16:04:47,415:INFO:Importing untrained model
2023-08-09 16:04:47,415:INFO:Declaring custom model
2023-08-09 16:04:47,415:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:04:47,417:INFO:Cross validation set to False
2023-08-09 16:04:47,417:INFO:Fitting Model
2023-08-09 16:04:47,517:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:04:47,517:INFO:create_model() successfully completed......................................
2023-08-09 16:04:47,911:INFO:_master_model_container: 16
2023-08-09 16:04:47,911:INFO:_display_container: 2
2023-08-09 16:04:47,911:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:04:47,911:INFO:compare_models() successfully completed......................................
2023-08-09 16:04:47,912:INFO:Initializing create_model()
2023-08-09 16:04:47,912:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:04:47,912:INFO:Checking exceptions
2023-08-09 16:04:47,920:INFO:Importing libraries
2023-08-09 16:04:47,921:INFO:Copying training dataset
2023-08-09 16:04:47,924:INFO:Defining folds
2023-08-09 16:04:47,924:INFO:Declaring metric variables
2023-08-09 16:04:47,926:INFO:Importing untrained model
2023-08-09 16:04:47,929:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:04:47,934:INFO:Starting cross validation
2023-08-09 16:04:47,935:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:04:48,500:INFO:Calculating mean and std
2023-08-09 16:04:48,500:INFO:Creating metrics dataframe
2023-08-09 16:04:48,504:INFO:Finalizing model
2023-08-09 16:04:48,633:INFO:Uploading results into container
2023-08-09 16:04:48,633:INFO:Uploading model into container now
2023-08-09 16:04:48,639:INFO:_master_model_container: 17
2023-08-09 16:04:48,639:INFO:_display_container: 3
2023-08-09 16:04:48,640:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:04:48,640:INFO:create_model() successfully completed......................................
2023-08-09 16:04:49,014:INFO:Initializing tune_model()
2023-08-09 16:04:49,014:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>)
2023-08-09 16:04:49,014:INFO:Checking exceptions
2023-08-09 16:04:49,025:INFO:Copying training dataset
2023-08-09 16:04:49,028:INFO:Checking base model
2023-08-09 16:04:49,028:INFO:Base model : Gradient Boosting Classifier
2023-08-09 16:04:49,030:INFO:Declaring metric variables
2023-08-09 16:04:49,033:INFO:Defining Hyperparameters
2023-08-09 16:04:49,404:INFO:Tuning with n_jobs=-1
2023-08-09 16:04:49,404:INFO:Initializing RandomizedSearchCV
2023-08-09 16:04:53,600:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.4}
2023-08-09 16:04:53,601:INFO:Hyperparameter search completed
2023-08-09 16:04:53,601:INFO:SubProcess create_model() called ==================================
2023-08-09 16:04:53,601:INFO:Initializing create_model()
2023-08-09 16:04:53,601:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023706FCF070>, model_only=True, return_train_score=False, kwargs={'subsample': 0.7, 'n_estimators': 190, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.3, 'max_features': 'sqrt', 'max_depth': 7, 'learning_rate': 0.4})
2023-08-09 16:04:53,601:INFO:Checking exceptions
2023-08-09 16:04:53,601:INFO:Importing libraries
2023-08-09 16:04:53,601:INFO:Copying training dataset
2023-08-09 16:04:53,607:INFO:Defining folds
2023-08-09 16:04:53,607:INFO:Declaring metric variables
2023-08-09 16:04:53,609:INFO:Importing untrained model
2023-08-09 16:04:53,609:INFO:Declaring custom model
2023-08-09 16:04:53,612:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:04:53,616:INFO:Starting cross validation
2023-08-09 16:04:53,618:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:04:54,257:INFO:Calculating mean and std
2023-08-09 16:04:54,258:INFO:Creating metrics dataframe
2023-08-09 16:04:54,263:INFO:Finalizing model
2023-08-09 16:04:54,383:INFO:Uploading results into container
2023-08-09 16:04:54,384:INFO:Uploading model into container now
2023-08-09 16:04:54,385:INFO:_master_model_container: 18
2023-08-09 16:04:54,385:INFO:_display_container: 4
2023-08-09 16:04:54,385:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=123, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:04:54,385:INFO:create_model() successfully completed......................................
2023-08-09 16:04:54,756:INFO:SubProcess create_model() end ==================================
2023-08-09 16:04:54,756:INFO:choose_better activated
2023-08-09 16:04:54,760:INFO:SubProcess create_model() called ==================================
2023-08-09 16:04:54,760:INFO:Initializing create_model()
2023-08-09 16:04:54,760:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:04:54,760:INFO:Checking exceptions
2023-08-09 16:04:54,762:INFO:Importing libraries
2023-08-09 16:04:54,762:INFO:Copying training dataset
2023-08-09 16:04:54,765:INFO:Defining folds
2023-08-09 16:04:54,765:INFO:Declaring metric variables
2023-08-09 16:04:54,765:INFO:Importing untrained model
2023-08-09 16:04:54,765:INFO:Declaring custom model
2023-08-09 16:04:54,765:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:04:54,765:INFO:Starting cross validation
2023-08-09 16:04:54,767:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:04:55,304:INFO:Calculating mean and std
2023-08-09 16:04:55,304:INFO:Creating metrics dataframe
2023-08-09 16:04:55,306:INFO:Finalizing model
2023-08-09 16:04:55,425:INFO:Uploading results into container
2023-08-09 16:04:55,425:INFO:Uploading model into container now
2023-08-09 16:04:55,427:INFO:_master_model_container: 19
2023-08-09 16:04:55,427:INFO:_display_container: 5
2023-08-09 16:04:55,427:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:04:55,427:INFO:create_model() successfully completed......................................
2023-08-09 16:04:55,792:INFO:SubProcess create_model() end ==================================
2023-08-09 16:04:55,793:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.6573
2023-08-09 16:04:55,793:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=123, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.6488
2023-08-09 16:04:55,794:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-08-09 16:04:55,794:INFO:choose_better completed
2023-08-09 16:04:55,794:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-08-09 16:04:55,800:INFO:_master_model_container: 19
2023-08-09 16:04:55,800:INFO:_display_container: 4
2023-08-09 16:04:55,801:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:04:55,801:INFO:tune_model() successfully completed......................................
2023-08-09 16:10:04,139:INFO:Initializing create_model()
2023-08-09 16:10:04,139:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:10:04,140:INFO:Checking exceptions
2023-08-09 16:10:04,150:INFO:Importing libraries
2023-08-09 16:10:04,151:INFO:Copying training dataset
2023-08-09 16:10:04,154:INFO:Defining folds
2023-08-09 16:10:04,154:INFO:Declaring metric variables
2023-08-09 16:10:04,156:INFO:Importing untrained model
2023-08-09 16:10:04,158:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:10:04,163:INFO:Starting cross validation
2023-08-09 16:10:04,164:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:10:07,163:INFO:Calculating mean and std
2023-08-09 16:10:07,163:INFO:Creating metrics dataframe
2023-08-09 16:10:07,168:INFO:Finalizing model
2023-08-09 16:10:07,288:INFO:Uploading results into container
2023-08-09 16:10:07,288:INFO:Uploading model into container now
2023-08-09 16:10:07,296:INFO:_master_model_container: 20
2023-08-09 16:10:07,296:INFO:_display_container: 5
2023-08-09 16:10:07,296:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:10:07,297:INFO:create_model() successfully completed......................................
2023-08-09 16:10:07,678:INFO:Initializing tune_model()
2023-08-09 16:10:07,678:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>)
2023-08-09 16:10:07,678:INFO:Checking exceptions
2023-08-09 16:10:07,688:INFO:Copying training dataset
2023-08-09 16:10:07,691:INFO:Checking base model
2023-08-09 16:10:07,691:INFO:Base model : Gradient Boosting Classifier
2023-08-09 16:10:07,694:INFO:Declaring metric variables
2023-08-09 16:10:07,697:INFO:Defining Hyperparameters
2023-08-09 16:10:08,087:INFO:Tuning with n_jobs=-1
2023-08-09 16:10:08,087:INFO:Initializing RandomizedSearchCV
2023-08-09 16:10:13,327:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.4}
2023-08-09 16:10:13,328:INFO:Hyperparameter search completed
2023-08-09 16:10:13,328:INFO:SubProcess create_model() called ==================================
2023-08-09 16:10:13,329:INFO:Initializing create_model()
2023-08-09 16:10:13,329:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236D86239A0>, model_only=True, return_train_score=False, kwargs={'subsample': 0.7, 'n_estimators': 190, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.3, 'max_features': 'sqrt', 'max_depth': 7, 'learning_rate': 0.4})
2023-08-09 16:10:13,329:INFO:Checking exceptions
2023-08-09 16:10:13,329:INFO:Importing libraries
2023-08-09 16:10:13,329:INFO:Copying training dataset
2023-08-09 16:10:13,332:INFO:Defining folds
2023-08-09 16:10:13,332:INFO:Declaring metric variables
2023-08-09 16:10:13,334:INFO:Importing untrained model
2023-08-09 16:10:13,334:INFO:Declaring custom model
2023-08-09 16:10:13,337:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:10:13,342:INFO:Starting cross validation
2023-08-09 16:10:13,343:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:10:13,977:INFO:Calculating mean and std
2023-08-09 16:10:13,978:INFO:Creating metrics dataframe
2023-08-09 16:10:13,983:INFO:Finalizing model
2023-08-09 16:10:14,106:INFO:Uploading results into container
2023-08-09 16:10:14,108:INFO:Uploading model into container now
2023-08-09 16:10:14,108:INFO:_master_model_container: 21
2023-08-09 16:10:14,108:INFO:_display_container: 6
2023-08-09 16:10:14,109:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=123, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:10:14,109:INFO:create_model() successfully completed......................................
2023-08-09 16:10:14,462:INFO:SubProcess create_model() end ==================================
2023-08-09 16:10:14,462:INFO:choose_better activated
2023-08-09 16:10:14,464:INFO:SubProcess create_model() called ==================================
2023-08-09 16:10:14,465:INFO:Initializing create_model()
2023-08-09 16:10:14,465:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:10:14,465:INFO:Checking exceptions
2023-08-09 16:10:14,467:INFO:Importing libraries
2023-08-09 16:10:14,467:INFO:Copying training dataset
2023-08-09 16:10:14,469:INFO:Defining folds
2023-08-09 16:10:14,470:INFO:Declaring metric variables
2023-08-09 16:10:14,470:INFO:Importing untrained model
2023-08-09 16:10:14,470:INFO:Declaring custom model
2023-08-09 16:10:14,470:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:10:14,470:INFO:Starting cross validation
2023-08-09 16:10:14,471:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:10:15,018:INFO:Calculating mean and std
2023-08-09 16:10:15,018:INFO:Creating metrics dataframe
2023-08-09 16:10:15,020:INFO:Finalizing model
2023-08-09 16:10:15,141:INFO:Uploading results into container
2023-08-09 16:10:15,141:INFO:Uploading model into container now
2023-08-09 16:10:15,142:INFO:_master_model_container: 22
2023-08-09 16:10:15,142:INFO:_display_container: 7
2023-08-09 16:10:15,142:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:10:15,142:INFO:create_model() successfully completed......................................
2023-08-09 16:10:15,501:INFO:SubProcess create_model() end ==================================
2023-08-09 16:10:15,502:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.6573
2023-08-09 16:10:15,502:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=123, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.6488
2023-08-09 16:10:15,502:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-08-09 16:10:15,502:INFO:choose_better completed
2023-08-09 16:10:15,502:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-08-09 16:10:15,511:INFO:_master_model_container: 22
2023-08-09 16:10:15,511:INFO:_display_container: 6
2023-08-09 16:10:15,512:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:10:15,512:INFO:tune_model() successfully completed......................................
2023-08-09 16:10:15,904:INFO:Initializing create_model()
2023-08-09 16:10:15,904:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=catboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:10:15,904:INFO:Checking exceptions
2023-08-09 16:10:15,914:INFO:Importing libraries
2023-08-09 16:10:15,914:INFO:Copying training dataset
2023-08-09 16:10:15,916:INFO:Defining folds
2023-08-09 16:10:15,916:INFO:Declaring metric variables
2023-08-09 16:10:15,918:INFO:Importing untrained model
2023-08-09 16:10:15,921:INFO:CatBoost Classifier Imported successfully
2023-08-09 16:10:15,925:INFO:Starting cross validation
2023-08-09 16:10:15,927:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:10:16,922:INFO:Calculating mean and std
2023-08-09 16:10:16,922:INFO:Creating metrics dataframe
2023-08-09 16:10:16,926:INFO:Finalizing model
2023-08-09 16:10:19,361:INFO:Uploading results into container
2023-08-09 16:10:19,362:INFO:Uploading model into container now
2023-08-09 16:10:19,369:INFO:_master_model_container: 23
2023-08-09 16:10:19,369:INFO:_display_container: 7
2023-08-09 16:10:19,369:INFO:<catboost.core.CatBoostClassifier object at 0x00000236BD21D450>
2023-08-09 16:10:19,369:INFO:create_model() successfully completed......................................
2023-08-09 16:10:19,736:INFO:Initializing tune_model()
2023-08-09 16:10:19,736:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x00000236BD21D450>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>)
2023-08-09 16:10:19,736:INFO:Checking exceptions
2023-08-09 16:10:19,747:INFO:Copying training dataset
2023-08-09 16:10:19,750:INFO:Checking base model
2023-08-09 16:10:19,750:INFO:Base model : CatBoost Classifier
2023-08-09 16:10:19,752:INFO:Declaring metric variables
2023-08-09 16:10:19,754:INFO:Defining Hyperparameters
2023-08-09 16:10:20,123:INFO:Tuning with n_jobs=-1
2023-08-09 16:10:20,125:INFO:Initializing RandomizedSearchCV
2023-08-09 16:10:28,573:INFO:best_params: {'actual_estimator__random_strength': 0.2, 'actual_estimator__n_estimators': 270, 'actual_estimator__l2_leaf_reg': 8, 'actual_estimator__eta': 0.0005, 'actual_estimator__depth': 4}
2023-08-09 16:10:28,573:INFO:Hyperparameter search completed
2023-08-09 16:10:28,573:INFO:SubProcess create_model() called ==================================
2023-08-09 16:10:28,574:INFO:Initializing create_model()
2023-08-09 16:10:28,574:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000023706E598D0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236D68A7760>, model_only=True, return_train_score=False, kwargs={'random_strength': 0.2, 'n_estimators': 270, 'l2_leaf_reg': 8, 'eta': 0.0005, 'depth': 4})
2023-08-09 16:10:28,574:INFO:Checking exceptions
2023-08-09 16:10:28,574:INFO:Importing libraries
2023-08-09 16:10:28,574:INFO:Copying training dataset
2023-08-09 16:10:28,578:INFO:Defining folds
2023-08-09 16:10:28,578:INFO:Declaring metric variables
2023-08-09 16:10:28,580:INFO:Importing untrained model
2023-08-09 16:10:28,580:INFO:Declaring custom model
2023-08-09 16:10:28,583:INFO:CatBoost Classifier Imported successfully
2023-08-09 16:10:28,588:INFO:Starting cross validation
2023-08-09 16:10:28,589:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:10:29,257:INFO:Calculating mean and std
2023-08-09 16:10:29,258:INFO:Creating metrics dataframe
2023-08-09 16:10:29,262:INFO:Finalizing model
2023-08-09 16:10:29,807:INFO:Uploading results into container
2023-08-09 16:10:29,807:INFO:Uploading model into container now
2023-08-09 16:10:29,808:INFO:_master_model_container: 24
2023-08-09 16:10:29,808:INFO:_display_container: 8
2023-08-09 16:10:29,808:INFO:<catboost.core.CatBoostClassifier object at 0x00000236D80415A0>
2023-08-09 16:10:29,808:INFO:create_model() successfully completed......................................
2023-08-09 16:10:30,167:INFO:SubProcess create_model() end ==================================
2023-08-09 16:10:30,167:INFO:choose_better activated
2023-08-09 16:10:30,169:INFO:SubProcess create_model() called ==================================
2023-08-09 16:10:30,169:INFO:Initializing create_model()
2023-08-09 16:10:30,169:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=<catboost.core.CatBoostClassifier object at 0x00000236BD21D450>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:10:30,169:INFO:Checking exceptions
2023-08-09 16:10:30,171:INFO:Importing libraries
2023-08-09 16:10:30,171:INFO:Copying training dataset
2023-08-09 16:10:30,174:INFO:Defining folds
2023-08-09 16:10:30,174:INFO:Declaring metric variables
2023-08-09 16:10:30,174:INFO:Importing untrained model
2023-08-09 16:10:30,174:INFO:Declaring custom model
2023-08-09 16:10:30,174:INFO:CatBoost Classifier Imported successfully
2023-08-09 16:10:30,174:INFO:Starting cross validation
2023-08-09 16:10:30,175:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:10:30,839:INFO:Calculating mean and std
2023-08-09 16:10:30,839:INFO:Creating metrics dataframe
2023-08-09 16:10:30,841:INFO:Finalizing model
2023-08-09 16:10:30,979:INFO:Uploading results into container
2023-08-09 16:10:30,980:INFO:Uploading model into container now
2023-08-09 16:10:30,980:INFO:_master_model_container: 25
2023-08-09 16:10:30,980:INFO:_display_container: 9
2023-08-09 16:10:30,980:INFO:<catboost.core.CatBoostClassifier object at 0x00000237065A5150>
2023-08-09 16:10:30,980:INFO:create_model() successfully completed......................................
2023-08-09 16:10:31,324:INFO:SubProcess create_model() end ==================================
2023-08-09 16:10:31,324:INFO:<catboost.core.CatBoostClassifier object at 0x00000237065A5150> result for Accuracy is 0.6542
2023-08-09 16:10:31,324:INFO:<catboost.core.CatBoostClassifier object at 0x00000236D80415A0> result for Accuracy is 0.671
2023-08-09 16:10:31,324:INFO:<catboost.core.CatBoostClassifier object at 0x00000236D80415A0> is best model
2023-08-09 16:10:31,324:INFO:choose_better completed
2023-08-09 16:10:31,332:INFO:_master_model_container: 25
2023-08-09 16:10:31,332:INFO:_display_container: 8
2023-08-09 16:10:31,332:INFO:<catboost.core.CatBoostClassifier object at 0x00000236D80415A0>
2023-08-09 16:10:31,332:INFO:tune_model() successfully completed......................................
2023-08-09 16:10:31,735:INFO:Initializing blend_models()
2023-08-09 16:10:31,735:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), <catboost.core.CatBoostClassifier object at 0x00000236D80415A0>], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-08-09 16:10:31,735:INFO:Checking exceptions
2023-08-09 16:10:31,745:INFO:Importing libraries
2023-08-09 16:10:31,745:INFO:Copying training dataset
2023-08-09 16:10:31,749:INFO:Getting model names
2023-08-09 16:10:31,751:INFO:SubProcess create_model() called ==================================
2023-08-09 16:10:31,753:INFO:Initializing create_model()
2023-08-09 16:10:31,753:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False)),
                             ('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x00000236D80415A0>)],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236FE309B10>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:10:31,753:INFO:Checking exceptions
2023-08-09 16:10:31,753:INFO:Importing libraries
2023-08-09 16:10:31,753:INFO:Copying training dataset
2023-08-09 16:10:31,755:INFO:Defining folds
2023-08-09 16:10:31,756:INFO:Declaring metric variables
2023-08-09 16:10:31,757:INFO:Importing untrained model
2023-08-09 16:10:31,757:INFO:Declaring custom model
2023-08-09 16:10:31,760:INFO:Voting Classifier Imported successfully
2023-08-09 16:10:31,764:INFO:Starting cross validation
2023-08-09 16:10:31,765:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:10:34,000:INFO:Calculating mean and std
2023-08-09 16:10:34,001:INFO:Creating metrics dataframe
2023-08-09 16:10:34,005:INFO:Finalizing model
2023-08-09 16:10:34,893:INFO:Uploading results into container
2023-08-09 16:10:34,894:INFO:Uploading model into container now
2023-08-09 16:10:34,894:INFO:_master_model_container: 26
2023-08-09 16:10:34,894:INFO:_display_container: 9
2023-08-09 16:10:34,895:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False)),
                             ('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x00000236CDEE38B0>)],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 16:10:34,895:INFO:create_model() successfully completed......................................
2023-08-09 16:10:35,291:INFO:SubProcess create_model() end ==================================
2023-08-09 16:10:35,298:INFO:_master_model_container: 26
2023-08-09 16:10:35,299:INFO:_display_container: 9
2023-08-09 16:10:35,300:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False)),
                             ('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x00000236CDEE38B0>)],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 16:10:35,300:INFO:blend_models() successfully completed......................................
2023-08-09 16:10:35,674:INFO:Initializing compare_models()
2023-08-09 16:10:35,674:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-09 16:10:35,674:INFO:Checking exceptions
2023-08-09 16:10:35,675:INFO:Preparing display monitor
2023-08-09 16:10:35,689:INFO:Initializing Logistic Regression
2023-08-09 16:10:35,689:INFO:Total runtime is 0.0 minutes
2023-08-09 16:10:35,691:INFO:SubProcess create_model() called ==================================
2023-08-09 16:10:35,691:INFO:Initializing create_model()
2023-08-09 16:10:35,691:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236D68A73A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:10:35,691:INFO:Checking exceptions
2023-08-09 16:10:35,691:INFO:Importing libraries
2023-08-09 16:10:35,691:INFO:Copying training dataset
2023-08-09 16:10:35,694:INFO:Defining folds
2023-08-09 16:10:35,694:INFO:Declaring metric variables
2023-08-09 16:10:35,696:INFO:Importing untrained model
2023-08-09 16:10:35,699:INFO:Logistic Regression Imported successfully
2023-08-09 16:10:35,703:INFO:Starting cross validation
2023-08-09 16:10:35,704:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:10:36,454:INFO:Calculating mean and std
2023-08-09 16:10:36,454:INFO:Creating metrics dataframe
2023-08-09 16:10:36,522:INFO:Uploading results into container
2023-08-09 16:10:36,522:INFO:Uploading model into container now
2023-08-09 16:10:36,523:INFO:_master_model_container: 27
2023-08-09 16:10:36,523:INFO:_display_container: 10
2023-08-09 16:10:36,523:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-09 16:10:36,523:INFO:create_model() successfully completed......................................
2023-08-09 16:10:36,900:INFO:SubProcess create_model() end ==================================
2023-08-09 16:10:36,900:INFO:Creating metrics dataframe
2023-08-09 16:10:36,906:INFO:Initializing K Neighbors Classifier
2023-08-09 16:10:36,906:INFO:Total runtime is 0.020292297999064127 minutes
2023-08-09 16:10:36,909:INFO:SubProcess create_model() called ==================================
2023-08-09 16:10:36,909:INFO:Initializing create_model()
2023-08-09 16:10:36,909:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236D68A73A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:10:36,909:INFO:Checking exceptions
2023-08-09 16:10:36,909:INFO:Importing libraries
2023-08-09 16:10:36,909:INFO:Copying training dataset
2023-08-09 16:10:36,913:INFO:Defining folds
2023-08-09 16:10:36,913:INFO:Declaring metric variables
2023-08-09 16:10:36,915:INFO:Importing untrained model
2023-08-09 16:10:36,918:INFO:K Neighbors Classifier Imported successfully
2023-08-09 16:10:36,922:INFO:Starting cross validation
2023-08-09 16:10:36,923:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:10:37,701:INFO:Calculating mean and std
2023-08-09 16:10:37,702:INFO:Creating metrics dataframe
2023-08-09 16:10:37,776:INFO:Uploading results into container
2023-08-09 16:10:37,777:INFO:Uploading model into container now
2023-08-09 16:10:37,777:INFO:_master_model_container: 28
2023-08-09 16:10:37,777:INFO:_display_container: 10
2023-08-09 16:10:37,777:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-09 16:10:37,777:INFO:create_model() successfully completed......................................
2023-08-09 16:10:38,148:INFO:SubProcess create_model() end ==================================
2023-08-09 16:10:38,148:INFO:Creating metrics dataframe
2023-08-09 16:10:38,155:INFO:Initializing Naive Bayes
2023-08-09 16:10:38,155:INFO:Total runtime is 0.04110858837763469 minutes
2023-08-09 16:10:38,159:INFO:SubProcess create_model() called ==================================
2023-08-09 16:10:38,160:INFO:Initializing create_model()
2023-08-09 16:10:38,160:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236D68A73A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:10:38,160:INFO:Checking exceptions
2023-08-09 16:10:38,160:INFO:Importing libraries
2023-08-09 16:10:38,160:INFO:Copying training dataset
2023-08-09 16:10:38,163:INFO:Defining folds
2023-08-09 16:10:38,163:INFO:Declaring metric variables
2023-08-09 16:10:38,165:INFO:Importing untrained model
2023-08-09 16:10:38,167:INFO:Naive Bayes Imported successfully
2023-08-09 16:10:38,172:INFO:Starting cross validation
2023-08-09 16:10:38,173:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:10:38,872:INFO:Calculating mean and std
2023-08-09 16:10:38,873:INFO:Creating metrics dataframe
2023-08-09 16:10:38,948:INFO:Uploading results into container
2023-08-09 16:10:38,948:INFO:Uploading model into container now
2023-08-09 16:10:38,948:INFO:_master_model_container: 29
2023-08-09 16:10:38,948:INFO:_display_container: 10
2023-08-09 16:10:38,949:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-09 16:10:38,949:INFO:create_model() successfully completed......................................
2023-08-09 16:10:39,300:INFO:SubProcess create_model() end ==================================
2023-08-09 16:10:39,300:INFO:Creating metrics dataframe
2023-08-09 16:10:39,307:INFO:Initializing Decision Tree Classifier
2023-08-09 16:10:39,307:INFO:Total runtime is 0.06030365228652955 minutes
2023-08-09 16:10:39,310:INFO:SubProcess create_model() called ==================================
2023-08-09 16:10:39,310:INFO:Initializing create_model()
2023-08-09 16:10:39,310:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236D68A73A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:10:39,310:INFO:Checking exceptions
2023-08-09 16:10:39,310:INFO:Importing libraries
2023-08-09 16:10:39,310:INFO:Copying training dataset
2023-08-09 16:10:39,315:INFO:Defining folds
2023-08-09 16:10:39,315:INFO:Declaring metric variables
2023-08-09 16:10:39,318:INFO:Importing untrained model
2023-08-09 16:10:39,320:INFO:Decision Tree Classifier Imported successfully
2023-08-09 16:10:39,325:INFO:Starting cross validation
2023-08-09 16:10:39,326:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:10:40,040:INFO:Calculating mean and std
2023-08-09 16:10:40,041:INFO:Creating metrics dataframe
2023-08-09 16:10:40,115:INFO:Uploading results into container
2023-08-09 16:10:40,115:INFO:Uploading model into container now
2023-08-09 16:10:40,115:INFO:_master_model_container: 30
2023-08-09 16:10:40,115:INFO:_display_container: 10
2023-08-09 16:10:40,116:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-08-09 16:10:40,116:INFO:create_model() successfully completed......................................
2023-08-09 16:10:40,483:INFO:SubProcess create_model() end ==================================
2023-08-09 16:10:40,483:INFO:Creating metrics dataframe
2023-08-09 16:10:40,489:INFO:Initializing SVM - Linear Kernel
2023-08-09 16:10:40,489:INFO:Total runtime is 0.08000881671905519 minutes
2023-08-09 16:10:40,492:INFO:SubProcess create_model() called ==================================
2023-08-09 16:10:40,492:INFO:Initializing create_model()
2023-08-09 16:10:40,493:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236D68A73A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:10:40,493:INFO:Checking exceptions
2023-08-09 16:10:40,493:INFO:Importing libraries
2023-08-09 16:10:40,493:INFO:Copying training dataset
2023-08-09 16:10:40,498:INFO:Defining folds
2023-08-09 16:10:40,498:INFO:Declaring metric variables
2023-08-09 16:10:40,501:INFO:Importing untrained model
2023-08-09 16:10:40,504:INFO:SVM - Linear Kernel Imported successfully
2023-08-09 16:10:40,508:INFO:Starting cross validation
2023-08-09 16:10:40,510:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:10:40,705:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:10:40,713:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:10:40,713:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:10:40,715:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:10:40,733:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:10:40,736:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:10:40,741:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:10:40,744:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:10:40,746:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:10:40,765:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:10:41,189:INFO:Calculating mean and std
2023-08-09 16:10:41,190:INFO:Creating metrics dataframe
2023-08-09 16:10:41,261:INFO:Uploading results into container
2023-08-09 16:10:41,261:INFO:Uploading model into container now
2023-08-09 16:10:41,262:INFO:_master_model_container: 31
2023-08-09 16:10:41,262:INFO:_display_container: 10
2023-08-09 16:10:41,262:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-09 16:10:41,262:INFO:create_model() successfully completed......................................
2023-08-09 16:10:41,631:INFO:SubProcess create_model() end ==================================
2023-08-09 16:10:41,631:INFO:Creating metrics dataframe
2023-08-09 16:10:41,639:INFO:Initializing Ridge Classifier
2023-08-09 16:10:41,639:INFO:Total runtime is 0.0991677204767863 minutes
2023-08-09 16:10:41,642:INFO:SubProcess create_model() called ==================================
2023-08-09 16:10:41,642:INFO:Initializing create_model()
2023-08-09 16:10:41,642:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236D68A73A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:10:41,642:INFO:Checking exceptions
2023-08-09 16:10:41,642:INFO:Importing libraries
2023-08-09 16:10:41,642:INFO:Copying training dataset
2023-08-09 16:10:41,645:INFO:Defining folds
2023-08-09 16:10:41,645:INFO:Declaring metric variables
2023-08-09 16:10:41,647:INFO:Importing untrained model
2023-08-09 16:10:41,650:INFO:Ridge Classifier Imported successfully
2023-08-09 16:10:41,654:INFO:Starting cross validation
2023-08-09 16:10:41,655:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:10:41,811:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:10:41,828:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:10:41,829:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:10:41,841:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:10:41,843:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:10:41,843:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:10:41,846:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:10:41,851:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:10:41,853:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:10:41,858:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:10:42,314:INFO:Calculating mean and std
2023-08-09 16:10:42,315:INFO:Creating metrics dataframe
2023-08-09 16:10:42,386:INFO:Uploading results into container
2023-08-09 16:10:42,387:INFO:Uploading model into container now
2023-08-09 16:10:42,387:INFO:_master_model_container: 32
2023-08-09 16:10:42,387:INFO:_display_container: 10
2023-08-09 16:10:42,387:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-08-09 16:10:42,387:INFO:create_model() successfully completed......................................
2023-08-09 16:10:42,759:INFO:SubProcess create_model() end ==================================
2023-08-09 16:10:42,759:INFO:Creating metrics dataframe
2023-08-09 16:10:42,767:INFO:Initializing Random Forest Classifier
2023-08-09 16:10:42,767:INFO:Total runtime is 0.11797299385070802 minutes
2023-08-09 16:10:42,769:INFO:SubProcess create_model() called ==================================
2023-08-09 16:10:42,769:INFO:Initializing create_model()
2023-08-09 16:10:42,769:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236D68A73A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:10:42,769:INFO:Checking exceptions
2023-08-09 16:10:42,769:INFO:Importing libraries
2023-08-09 16:10:42,769:INFO:Copying training dataset
2023-08-09 16:10:42,773:INFO:Defining folds
2023-08-09 16:10:42,773:INFO:Declaring metric variables
2023-08-09 16:10:42,775:INFO:Importing untrained model
2023-08-09 16:10:42,778:INFO:Random Forest Classifier Imported successfully
2023-08-09 16:10:42,782:INFO:Starting cross validation
2023-08-09 16:10:42,783:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:10:43,655:INFO:Calculating mean and std
2023-08-09 16:10:43,655:INFO:Creating metrics dataframe
2023-08-09 16:10:43,731:INFO:Uploading results into container
2023-08-09 16:10:43,732:INFO:Uploading model into container now
2023-08-09 16:10:43,732:INFO:_master_model_container: 33
2023-08-09 16:10:43,732:INFO:_display_container: 10
2023-08-09 16:10:43,732:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-09 16:10:43,732:INFO:create_model() successfully completed......................................
2023-08-09 16:10:44,085:INFO:SubProcess create_model() end ==================================
2023-08-09 16:10:44,085:INFO:Creating metrics dataframe
2023-08-09 16:10:44,094:INFO:Initializing Quadratic Discriminant Analysis
2023-08-09 16:10:44,094:INFO:Total runtime is 0.14008153676986695 minutes
2023-08-09 16:10:44,096:INFO:SubProcess create_model() called ==================================
2023-08-09 16:10:44,096:INFO:Initializing create_model()
2023-08-09 16:10:44,096:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236D68A73A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:10:44,096:INFO:Checking exceptions
2023-08-09 16:10:44,096:INFO:Importing libraries
2023-08-09 16:10:44,096:INFO:Copying training dataset
2023-08-09 16:10:44,100:INFO:Defining folds
2023-08-09 16:10:44,100:INFO:Declaring metric variables
2023-08-09 16:10:44,102:INFO:Importing untrained model
2023-08-09 16:10:44,104:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-09 16:10:44,109:INFO:Starting cross validation
2023-08-09 16:10:44,110:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:10:44,219:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:10:44,227:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:10:44,231:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:10:44,237:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:10:44,240:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:10:44,241:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:10:44,248:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:10:44,251:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:10:44,259:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:10:44,263:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:10:44,807:INFO:Calculating mean and std
2023-08-09 16:10:44,808:INFO:Creating metrics dataframe
2023-08-09 16:10:44,883:INFO:Uploading results into container
2023-08-09 16:10:44,885:INFO:Uploading model into container now
2023-08-09 16:10:44,885:INFO:_master_model_container: 34
2023-08-09 16:10:44,885:INFO:_display_container: 10
2023-08-09 16:10:44,885:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-09 16:10:44,885:INFO:create_model() successfully completed......................................
2023-08-09 16:10:45,269:INFO:SubProcess create_model() end ==================================
2023-08-09 16:10:45,269:INFO:Creating metrics dataframe
2023-08-09 16:10:45,278:INFO:Initializing Ada Boost Classifier
2023-08-09 16:10:45,278:INFO:Total runtime is 0.15981328090031943 minutes
2023-08-09 16:10:45,281:INFO:SubProcess create_model() called ==================================
2023-08-09 16:10:45,281:INFO:Initializing create_model()
2023-08-09 16:10:45,281:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236D68A73A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:10:45,281:INFO:Checking exceptions
2023-08-09 16:10:45,281:INFO:Importing libraries
2023-08-09 16:10:45,281:INFO:Copying training dataset
2023-08-09 16:10:45,285:INFO:Defining folds
2023-08-09 16:10:45,285:INFO:Declaring metric variables
2023-08-09 16:10:45,289:INFO:Importing untrained model
2023-08-09 16:10:45,291:INFO:Ada Boost Classifier Imported successfully
2023-08-09 16:10:45,297:INFO:Starting cross validation
2023-08-09 16:10:45,298:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:10:46,055:INFO:Calculating mean and std
2023-08-09 16:10:46,055:INFO:Creating metrics dataframe
2023-08-09 16:10:46,123:INFO:Uploading results into container
2023-08-09 16:10:46,124:INFO:Uploading model into container now
2023-08-09 16:10:46,124:INFO:_master_model_container: 35
2023-08-09 16:10:46,124:INFO:_display_container: 10
2023-08-09 16:10:46,124:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-08-09 16:10:46,124:INFO:create_model() successfully completed......................................
2023-08-09 16:10:46,476:INFO:SubProcess create_model() end ==================================
2023-08-09 16:10:46,476:INFO:Creating metrics dataframe
2023-08-09 16:10:46,484:INFO:Initializing Gradient Boosting Classifier
2023-08-09 16:10:46,484:INFO:Total runtime is 0.17992074489593507 minutes
2023-08-09 16:10:46,487:INFO:SubProcess create_model() called ==================================
2023-08-09 16:10:46,488:INFO:Initializing create_model()
2023-08-09 16:10:46,488:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236D68A73A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:10:46,488:INFO:Checking exceptions
2023-08-09 16:10:46,488:INFO:Importing libraries
2023-08-09 16:10:46,488:INFO:Copying training dataset
2023-08-09 16:10:46,492:INFO:Defining folds
2023-08-09 16:10:46,492:INFO:Declaring metric variables
2023-08-09 16:10:46,495:INFO:Importing untrained model
2023-08-09 16:10:46,497:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:10:46,501:INFO:Starting cross validation
2023-08-09 16:10:46,502:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:10:47,256:INFO:Calculating mean and std
2023-08-09 16:10:47,256:INFO:Creating metrics dataframe
2023-08-09 16:10:47,329:INFO:Uploading results into container
2023-08-09 16:10:47,329:INFO:Uploading model into container now
2023-08-09 16:10:47,330:INFO:_master_model_container: 36
2023-08-09 16:10:47,330:INFO:_display_container: 10
2023-08-09 16:10:47,330:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:10:47,330:INFO:create_model() successfully completed......................................
2023-08-09 16:10:47,689:INFO:SubProcess create_model() end ==================================
2023-08-09 16:10:47,689:INFO:Creating metrics dataframe
2023-08-09 16:10:47,698:INFO:Initializing Linear Discriminant Analysis
2023-08-09 16:10:47,698:INFO:Total runtime is 0.20015145937601725 minutes
2023-08-09 16:10:47,701:INFO:SubProcess create_model() called ==================================
2023-08-09 16:10:47,701:INFO:Initializing create_model()
2023-08-09 16:10:47,701:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236D68A73A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:10:47,701:INFO:Checking exceptions
2023-08-09 16:10:47,701:INFO:Importing libraries
2023-08-09 16:10:47,701:INFO:Copying training dataset
2023-08-09 16:10:47,705:INFO:Defining folds
2023-08-09 16:10:47,705:INFO:Declaring metric variables
2023-08-09 16:10:47,707:INFO:Importing untrained model
2023-08-09 16:10:47,709:INFO:Linear Discriminant Analysis Imported successfully
2023-08-09 16:10:47,713:INFO:Starting cross validation
2023-08-09 16:10:47,714:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:10:48,397:INFO:Calculating mean and std
2023-08-09 16:10:48,397:INFO:Creating metrics dataframe
2023-08-09 16:10:48,469:INFO:Uploading results into container
2023-08-09 16:10:48,470:INFO:Uploading model into container now
2023-08-09 16:10:48,470:INFO:_master_model_container: 37
2023-08-09 16:10:48,470:INFO:_display_container: 10
2023-08-09 16:10:48,471:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-09 16:10:48,471:INFO:create_model() successfully completed......................................
2023-08-09 16:10:48,821:INFO:SubProcess create_model() end ==================================
2023-08-09 16:10:48,821:INFO:Creating metrics dataframe
2023-08-09 16:10:48,829:INFO:Initializing Extra Trees Classifier
2023-08-09 16:10:48,829:INFO:Total runtime is 0.21900193293889364 minutes
2023-08-09 16:10:48,832:INFO:SubProcess create_model() called ==================================
2023-08-09 16:10:48,832:INFO:Initializing create_model()
2023-08-09 16:10:48,832:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236D68A73A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:10:48,832:INFO:Checking exceptions
2023-08-09 16:10:48,832:INFO:Importing libraries
2023-08-09 16:10:48,832:INFO:Copying training dataset
2023-08-09 16:10:48,836:INFO:Defining folds
2023-08-09 16:10:48,836:INFO:Declaring metric variables
2023-08-09 16:10:48,838:INFO:Importing untrained model
2023-08-09 16:10:48,841:INFO:Extra Trees Classifier Imported successfully
2023-08-09 16:10:48,845:INFO:Starting cross validation
2023-08-09 16:10:48,847:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:10:49,798:INFO:Calculating mean and std
2023-08-09 16:10:49,799:INFO:Creating metrics dataframe
2023-08-09 16:10:49,870:INFO:Uploading results into container
2023-08-09 16:10:49,871:INFO:Uploading model into container now
2023-08-09 16:10:49,871:INFO:_master_model_container: 38
2023-08-09 16:10:49,871:INFO:_display_container: 10
2023-08-09 16:10:49,872:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-08-09 16:10:49,872:INFO:create_model() successfully completed......................................
2023-08-09 16:10:50,232:INFO:SubProcess create_model() end ==================================
2023-08-09 16:10:50,232:INFO:Creating metrics dataframe
2023-08-09 16:10:50,241:INFO:Initializing Extreme Gradient Boosting
2023-08-09 16:10:50,241:INFO:Total runtime is 0.2425412138303121 minutes
2023-08-09 16:10:50,244:INFO:SubProcess create_model() called ==================================
2023-08-09 16:10:50,245:INFO:Initializing create_model()
2023-08-09 16:10:50,245:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236D68A73A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:10:50,245:INFO:Checking exceptions
2023-08-09 16:10:50,245:INFO:Importing libraries
2023-08-09 16:10:50,245:INFO:Copying training dataset
2023-08-09 16:10:50,249:INFO:Defining folds
2023-08-09 16:10:50,249:INFO:Declaring metric variables
2023-08-09 16:10:50,252:INFO:Importing untrained model
2023-08-09 16:10:50,254:INFO:Extreme Gradient Boosting Imported successfully
2023-08-09 16:10:50,258:INFO:Starting cross validation
2023-08-09 16:10:50,260:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:10:50,948:INFO:Calculating mean and std
2023-08-09 16:10:50,949:INFO:Creating metrics dataframe
2023-08-09 16:10:51,020:INFO:Uploading results into container
2023-08-09 16:10:51,021:INFO:Uploading model into container now
2023-08-09 16:10:51,021:INFO:_master_model_container: 39
2023-08-09 16:10:51,021:INFO:_display_container: 10
2023-08-09 16:10:51,022:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-09 16:10:51,022:INFO:create_model() successfully completed......................................
2023-08-09 16:10:51,376:INFO:SubProcess create_model() end ==================================
2023-08-09 16:10:51,376:INFO:Creating metrics dataframe
2023-08-09 16:10:51,385:INFO:Initializing Light Gradient Boosting Machine
2023-08-09 16:10:51,385:INFO:Total runtime is 0.2616078058878581 minutes
2023-08-09 16:10:51,388:INFO:SubProcess create_model() called ==================================
2023-08-09 16:10:51,388:INFO:Initializing create_model()
2023-08-09 16:10:51,388:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236D68A73A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:10:51,389:INFO:Checking exceptions
2023-08-09 16:10:51,389:INFO:Importing libraries
2023-08-09 16:10:51,389:INFO:Copying training dataset
2023-08-09 16:10:51,392:INFO:Defining folds
2023-08-09 16:10:51,392:INFO:Declaring metric variables
2023-08-09 16:10:51,394:INFO:Importing untrained model
2023-08-09 16:10:51,396:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-09 16:10:51,401:INFO:Starting cross validation
2023-08-09 16:10:51,402:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:10:52,182:INFO:Calculating mean and std
2023-08-09 16:10:52,183:INFO:Creating metrics dataframe
2023-08-09 16:10:52,255:INFO:Uploading results into container
2023-08-09 16:10:52,255:INFO:Uploading model into container now
2023-08-09 16:10:52,255:INFO:_master_model_container: 40
2023-08-09 16:10:52,255:INFO:_display_container: 10
2023-08-09 16:10:52,256:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-09 16:10:52,256:INFO:create_model() successfully completed......................................
2023-08-09 16:10:52,615:INFO:SubProcess create_model() end ==================================
2023-08-09 16:10:52,615:INFO:Creating metrics dataframe
2023-08-09 16:10:52,624:INFO:Initializing CatBoost Classifier
2023-08-09 16:10:52,624:INFO:Total runtime is 0.28225826422373457 minutes
2023-08-09 16:10:52,627:INFO:SubProcess create_model() called ==================================
2023-08-09 16:10:52,627:INFO:Initializing create_model()
2023-08-09 16:10:52,627:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236D68A73A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:10:52,627:INFO:Checking exceptions
2023-08-09 16:10:52,628:INFO:Importing libraries
2023-08-09 16:10:52,628:INFO:Copying training dataset
2023-08-09 16:10:52,631:INFO:Defining folds
2023-08-09 16:10:52,631:INFO:Declaring metric variables
2023-08-09 16:10:52,634:INFO:Importing untrained model
2023-08-09 16:10:52,636:INFO:CatBoost Classifier Imported successfully
2023-08-09 16:10:52,641:INFO:Starting cross validation
2023-08-09 16:10:52,642:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:10:53,345:INFO:Calculating mean and std
2023-08-09 16:10:53,345:INFO:Creating metrics dataframe
2023-08-09 16:10:53,418:INFO:Uploading results into container
2023-08-09 16:10:53,419:INFO:Uploading model into container now
2023-08-09 16:10:53,419:INFO:_master_model_container: 41
2023-08-09 16:10:53,419:INFO:_display_container: 10
2023-08-09 16:10:53,419:INFO:<catboost.core.CatBoostClassifier object at 0x0000023706E31000>
2023-08-09 16:10:53,419:INFO:create_model() successfully completed......................................
2023-08-09 16:10:53,777:INFO:SubProcess create_model() end ==================================
2023-08-09 16:10:53,778:INFO:Creating metrics dataframe
2023-08-09 16:10:53,787:INFO:Initializing Dummy Classifier
2023-08-09 16:10:53,787:INFO:Total runtime is 0.3016303618748983 minutes
2023-08-09 16:10:53,790:INFO:SubProcess create_model() called ==================================
2023-08-09 16:10:53,790:INFO:Initializing create_model()
2023-08-09 16:10:53,790:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236D68A73A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:10:53,790:INFO:Checking exceptions
2023-08-09 16:10:53,790:INFO:Importing libraries
2023-08-09 16:10:53,791:INFO:Copying training dataset
2023-08-09 16:10:53,795:INFO:Defining folds
2023-08-09 16:10:53,795:INFO:Declaring metric variables
2023-08-09 16:10:53,798:INFO:Importing untrained model
2023-08-09 16:10:53,800:INFO:Dummy Classifier Imported successfully
2023-08-09 16:10:53,805:INFO:Starting cross validation
2023-08-09 16:10:53,807:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:10:54,472:INFO:Calculating mean and std
2023-08-09 16:10:54,473:INFO:Creating metrics dataframe
2023-08-09 16:10:54,541:INFO:Uploading results into container
2023-08-09 16:10:54,542:INFO:Uploading model into container now
2023-08-09 16:10:54,542:INFO:_master_model_container: 42
2023-08-09 16:10:54,542:INFO:_display_container: 10
2023-08-09 16:10:54,542:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-08-09 16:10:54,542:INFO:create_model() successfully completed......................................
2023-08-09 16:10:54,908:INFO:SubProcess create_model() end ==================================
2023-08-09 16:10:54,908:INFO:Creating metrics dataframe
2023-08-09 16:10:54,924:INFO:Initializing create_model()
2023-08-09 16:10:54,924:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:10:54,924:INFO:Checking exceptions
2023-08-09 16:10:54,926:INFO:Importing libraries
2023-08-09 16:10:54,926:INFO:Copying training dataset
2023-08-09 16:10:54,930:INFO:Defining folds
2023-08-09 16:10:54,930:INFO:Declaring metric variables
2023-08-09 16:10:54,930:INFO:Importing untrained model
2023-08-09 16:10:54,930:INFO:Declaring custom model
2023-08-09 16:10:54,930:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:10:54,931:INFO:Cross validation set to False
2023-08-09 16:10:54,931:INFO:Fitting Model
2023-08-09 16:10:55,047:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:10:55,047:INFO:create_model() successfully completed......................................
2023-08-09 16:10:55,411:INFO:Initializing create_model()
2023-08-09 16:10:55,411:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:10:55,411:INFO:Checking exceptions
2023-08-09 16:10:55,413:INFO:Importing libraries
2023-08-09 16:10:55,413:INFO:Copying training dataset
2023-08-09 16:10:55,416:INFO:Defining folds
2023-08-09 16:10:55,416:INFO:Declaring metric variables
2023-08-09 16:10:55,416:INFO:Importing untrained model
2023-08-09 16:10:55,417:INFO:Declaring custom model
2023-08-09 16:10:55,417:INFO:Ada Boost Classifier Imported successfully
2023-08-09 16:10:55,418:INFO:Cross validation set to False
2023-08-09 16:10:55,418:INFO:Fitting Model
2023-08-09 16:10:55,740:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-08-09 16:10:55,740:INFO:create_model() successfully completed......................................
2023-08-09 16:10:56,105:INFO:Initializing create_model()
2023-08-09 16:10:56,106:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000023706E31000>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:10:56,106:INFO:Checking exceptions
2023-08-09 16:10:56,107:INFO:Importing libraries
2023-08-09 16:10:56,107:INFO:Copying training dataset
2023-08-09 16:10:56,110:INFO:Defining folds
2023-08-09 16:10:56,110:INFO:Declaring metric variables
2023-08-09 16:10:56,110:INFO:Importing untrained model
2023-08-09 16:10:56,110:INFO:Declaring custom model
2023-08-09 16:10:56,111:INFO:CatBoost Classifier Imported successfully
2023-08-09 16:10:56,111:INFO:Cross validation set to False
2023-08-09 16:10:56,111:INFO:Fitting Model
2023-08-09 16:10:56,227:INFO:<catboost.core.CatBoostClassifier object at 0x00000236CDEE3940>
2023-08-09 16:10:56,227:INFO:create_model() successfully completed......................................
2023-08-09 16:10:56,584:INFO:Initializing create_model()
2023-08-09 16:10:56,584:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:10:56,584:INFO:Checking exceptions
2023-08-09 16:10:56,585:INFO:Importing libraries
2023-08-09 16:10:56,585:INFO:Copying training dataset
2023-08-09 16:10:56,588:INFO:Defining folds
2023-08-09 16:10:56,588:INFO:Declaring metric variables
2023-08-09 16:10:56,588:INFO:Importing untrained model
2023-08-09 16:10:56,589:INFO:Declaring custom model
2023-08-09 16:10:56,589:INFO:Random Forest Classifier Imported successfully
2023-08-09 16:10:56,590:INFO:Cross validation set to False
2023-08-09 16:10:56,590:INFO:Fitting Model
2023-08-09 16:10:56,959:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-09 16:10:56,959:INFO:create_model() successfully completed......................................
2023-08-09 16:10:57,323:INFO:Initializing create_model()
2023-08-09 16:10:57,324:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:10:57,324:INFO:Checking exceptions
2023-08-09 16:10:57,325:INFO:Importing libraries
2023-08-09 16:10:57,325:INFO:Copying training dataset
2023-08-09 16:10:57,328:INFO:Defining folds
2023-08-09 16:10:57,328:INFO:Declaring metric variables
2023-08-09 16:10:57,329:INFO:Importing untrained model
2023-08-09 16:10:57,329:INFO:Declaring custom model
2023-08-09 16:10:57,329:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-09 16:10:57,330:INFO:Cross validation set to False
2023-08-09 16:10:57,330:INFO:Fitting Model
2023-08-09 16:10:57,407:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-09 16:10:57,407:INFO:[LightGBM] [Info] Number of positive: 2870, number of negative: 1957
2023-08-09 16:10:57,408:INFO:[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000219 seconds.
2023-08-09 16:10:57,408:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-08-09 16:10:57,408:INFO:[LightGBM] [Info] Total Bins 756
2023-08-09 16:10:57,408:INFO:[LightGBM] [Info] Number of data points in the train set: 4827, number of used features: 17
2023-08-09 16:10:57,408:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.594572 -> initscore=0.382899
2023-08-09 16:10:57,408:INFO:[LightGBM] [Info] Start training from score 0.382899
2023-08-09 16:10:57,519:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-09 16:10:57,519:INFO:create_model() successfully completed......................................
2023-08-09 16:10:57,882:INFO:_master_model_container: 42
2023-08-09 16:10:57,882:INFO:_display_container: 10
2023-08-09 16:10:57,883:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), <catboost.core.CatBoostClassifier object at 0x00000236CDEE3940>, RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)]
2023-08-09 16:10:57,883:INFO:compare_models() successfully completed......................................
2023-08-09 16:10:57,884:INFO:Initializing blend_models()
2023-08-09 16:10:57,885:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), <catboost.core.CatBoostClassifier object at 0x00000236CDEE3940>, RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-08-09 16:10:57,885:INFO:Checking exceptions
2023-08-09 16:10:57,896:INFO:Importing libraries
2023-08-09 16:10:57,896:INFO:Copying training dataset
2023-08-09 16:10:57,899:INFO:Getting model names
2023-08-09 16:10:57,902:INFO:SubProcess create_model() called ==================================
2023-08-09 16:10:57,907:INFO:Initializing create_model()
2023-08-09 16:10:57,907:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236B189FD00>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:10:57,907:INFO:Checking exceptions
2023-08-09 16:10:57,908:INFO:Importing libraries
2023-08-09 16:10:57,908:INFO:Copying training dataset
2023-08-09 16:10:57,910:INFO:Defining folds
2023-08-09 16:10:57,911:INFO:Declaring metric variables
2023-08-09 16:10:57,913:INFO:Importing untrained model
2023-08-09 16:10:57,913:INFO:Declaring custom model
2023-08-09 16:10:57,917:INFO:Voting Classifier Imported successfully
2023-08-09 16:10:57,922:INFO:Starting cross validation
2023-08-09 16:10:57,923:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:11:06,177:INFO:Calculating mean and std
2023-08-09 16:11:06,178:INFO:Creating metrics dataframe
2023-08-09 16:11:06,182:INFO:Finalizing model
2023-08-09 16:11:09,450:INFO:Uploading results into container
2023-08-09 16:11:09,451:INFO:Uploading model into container now
2023-08-09 16:11:09,451:INFO:_master_model_container: 43
2023-08-09 16:11:09,451:INFO:_display_container: 11
2023-08-09 16:11:09,455:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 16:11:09,455:INFO:create_model() successfully completed......................................
2023-08-09 16:11:09,813:INFO:SubProcess create_model() end ==================================
2023-08-09 16:11:09,820:INFO:_master_model_container: 43
2023-08-09 16:11:09,820:INFO:_display_container: 11
2023-08-09 16:11:09,824:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 16:11:09,824:INFO:blend_models() successfully completed......................................
2023-08-09 16:11:10,186:INFO:Initializing finalize_model()
2023-08-09 16:11:10,186:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-08-09 16:11:10,189:INFO:Finalizing VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 16:11:10,195:INFO:Initializing create_model()
2023-08-09 16:11:10,195:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-08-09 16:11:10,195:INFO:Checking exceptions
2023-08-09 16:11:10,197:INFO:Importing libraries
2023-08-09 16:11:10,197:INFO:Copying training dataset
2023-08-09 16:11:10,197:INFO:Defining folds
2023-08-09 16:11:10,197:INFO:Declaring metric variables
2023-08-09 16:11:10,197:INFO:Importing untrained model
2023-08-09 16:11:10,197:INFO:Declaring custom model
2023-08-09 16:11:10,198:INFO:Voting Classifier Imported successfully
2023-08-09 16:11:10,199:INFO:Cross validation set to False
2023-08-09 16:11:10,199:INFO:Fitting Model
2023-08-09 16:11:13,514:INFO:Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_fea...
                                                              importance_type='split',
                                                              learning_rate=0.1,
                                                              max_depth=-1,
                                                              min_child_samples=20,
                                                              min_child_weight=0.001,
                                                              min_split_gain=0.0,
                                                              n_estimators=100,
                                                              n_jobs=-1,
                                                              num_leaves=31,
                                                              objective=None,
                                                              random_state=123,
                                                              reg_alpha=0.0,
                                                              reg_lambda=0.0,
                                                              subsample=1.0,
                                                              subsample_for_bin=200000,
                                                              subsample_freq=0))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-09 16:11:13,514:INFO:create_model() successfully completed......................................
2023-08-09 16:11:13,883:INFO:_master_model_container: 43
2023-08-09 16:11:13,883:INFO:_display_container: 11
2023-08-09 16:11:13,896:INFO:Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_fea...
                                                              importance_type='split',
                                                              learning_rate=0.1,
                                                              max_depth=-1,
                                                              min_child_samples=20,
                                                              min_child_weight=0.001,
                                                              min_split_gain=0.0,
                                                              n_estimators=100,
                                                              n_jobs=-1,
                                                              num_leaves=31,
                                                              objective=None,
                                                              random_state=123,
                                                              reg_alpha=0.0,
                                                              reg_lambda=0.0,
                                                              subsample=1.0,
                                                              subsample_for_bin=200000,
                                                              subsample_freq=0))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-09 16:11:13,897:INFO:finalize_model() successfully completed......................................
2023-08-09 16:11:14,264:INFO:Initializing predict_model()
2023-08-09 16:11:14,264:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_fea...
                                                              importance_type='split',
                                                              learning_rate=0.1,
                                                              max_depth=-1,
                                                              min_child_samples=20,
                                                              min_child_weight=0.001,
                                                              min_split_gain=0.0,
                                                              n_estimators=100,
                                                              n_jobs=-1,
                                                              num_leaves=31,
                                                              objective=None,
                                                              random_state=123,
                                                              reg_alpha=0.0,
                                                              reg_lambda=0.0,
                                                              subsample=1.0,
                                                              subsample_for_bin=200000,
                                                              subsample_freq=0))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000236B18C03A0>)
2023-08-09 16:11:14,265:INFO:Checking exceptions
2023-08-09 16:11:14,265:INFO:Preloading libraries
2023-08-09 16:11:14,266:INFO:Set up data.
2023-08-09 16:11:14,272:INFO:Set up index.
2023-08-09 16:11:48,213:INFO:Initializing create_model()
2023-08-09 16:11:48,213:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:11:48,213:INFO:Checking exceptions
2023-08-09 16:11:48,224:INFO:Importing libraries
2023-08-09 16:11:48,224:INFO:Copying training dataset
2023-08-09 16:11:48,228:INFO:Defining folds
2023-08-09 16:11:48,228:INFO:Declaring metric variables
2023-08-09 16:11:48,230:INFO:Importing untrained model
2023-08-09 16:11:48,233:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:11:48,237:INFO:Starting cross validation
2023-08-09 16:11:48,237:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:11:49,034:INFO:Calculating mean and std
2023-08-09 16:11:49,034:INFO:Creating metrics dataframe
2023-08-09 16:11:49,040:INFO:Finalizing model
2023-08-09 16:11:49,195:INFO:Uploading results into container
2023-08-09 16:11:49,195:INFO:Uploading model into container now
2023-08-09 16:11:49,202:INFO:_master_model_container: 44
2023-08-09 16:11:49,202:INFO:_display_container: 12
2023-08-09 16:11:49,203:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:11:49,203:INFO:create_model() successfully completed......................................
2023-08-09 16:11:49,610:INFO:Initializing tune_model()
2023-08-09 16:11:49,610:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>)
2023-08-09 16:11:49,610:INFO:Checking exceptions
2023-08-09 16:11:49,620:INFO:Copying training dataset
2023-08-09 16:11:49,623:INFO:Checking base model
2023-08-09 16:11:49,623:INFO:Base model : Gradient Boosting Classifier
2023-08-09 16:11:49,626:INFO:Declaring metric variables
2023-08-09 16:11:49,629:INFO:Defining Hyperparameters
2023-08-09 16:11:50,005:INFO:Tuning with n_jobs=-1
2023-08-09 16:11:50,005:INFO:Initializing RandomizedSearchCV
2023-08-09 16:11:56,447:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.4}
2023-08-09 16:11:56,448:INFO:Hyperparameter search completed
2023-08-09 16:11:56,448:INFO:SubProcess create_model() called ==================================
2023-08-09 16:11:56,449:INFO:Initializing create_model()
2023-08-09 16:11:56,449:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236AE538AF0>, model_only=True, return_train_score=False, kwargs={'subsample': 0.7, 'n_estimators': 190, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.3, 'max_features': 'sqrt', 'max_depth': 7, 'learning_rate': 0.4})
2023-08-09 16:11:56,449:INFO:Checking exceptions
2023-08-09 16:11:56,449:INFO:Importing libraries
2023-08-09 16:11:56,449:INFO:Copying training dataset
2023-08-09 16:11:56,452:INFO:Defining folds
2023-08-09 16:11:56,452:INFO:Declaring metric variables
2023-08-09 16:11:56,455:INFO:Importing untrained model
2023-08-09 16:11:56,455:INFO:Declaring custom model
2023-08-09 16:11:56,457:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:11:56,463:INFO:Starting cross validation
2023-08-09 16:11:56,464:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:11:57,294:INFO:Calculating mean and std
2023-08-09 16:11:57,295:INFO:Creating metrics dataframe
2023-08-09 16:11:57,299:INFO:Finalizing model
2023-08-09 16:11:57,455:INFO:Uploading results into container
2023-08-09 16:11:57,455:INFO:Uploading model into container now
2023-08-09 16:11:57,455:INFO:_master_model_container: 45
2023-08-09 16:11:57,455:INFO:_display_container: 13
2023-08-09 16:11:57,456:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=123, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:11:57,456:INFO:create_model() successfully completed......................................
2023-08-09 16:11:57,831:INFO:SubProcess create_model() end ==================================
2023-08-09 16:11:57,832:INFO:choose_better activated
2023-08-09 16:11:57,834:INFO:SubProcess create_model() called ==================================
2023-08-09 16:11:57,834:INFO:Initializing create_model()
2023-08-09 16:11:57,834:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:11:57,834:INFO:Checking exceptions
2023-08-09 16:11:57,836:INFO:Importing libraries
2023-08-09 16:11:57,836:INFO:Copying training dataset
2023-08-09 16:11:57,838:INFO:Defining folds
2023-08-09 16:11:57,838:INFO:Declaring metric variables
2023-08-09 16:11:57,838:INFO:Importing untrained model
2023-08-09 16:11:57,839:INFO:Declaring custom model
2023-08-09 16:11:57,839:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:11:57,839:INFO:Starting cross validation
2023-08-09 16:11:57,840:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:11:58,607:INFO:Calculating mean and std
2023-08-09 16:11:58,607:INFO:Creating metrics dataframe
2023-08-09 16:11:58,609:INFO:Finalizing model
2023-08-09 16:11:58,753:INFO:Uploading results into container
2023-08-09 16:11:58,753:INFO:Uploading model into container now
2023-08-09 16:11:58,754:INFO:_master_model_container: 46
2023-08-09 16:11:58,754:INFO:_display_container: 14
2023-08-09 16:11:58,754:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:11:58,754:INFO:create_model() successfully completed......................................
2023-08-09 16:11:59,138:INFO:SubProcess create_model() end ==================================
2023-08-09 16:11:59,139:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.6573
2023-08-09 16:11:59,139:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=123, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.6488
2023-08-09 16:11:59,139:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-08-09 16:11:59,139:INFO:choose_better completed
2023-08-09 16:11:59,139:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-08-09 16:11:59,145:INFO:_master_model_container: 46
2023-08-09 16:11:59,147:INFO:_display_container: 13
2023-08-09 16:11:59,147:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:11:59,147:INFO:tune_model() successfully completed......................................
2023-08-09 16:11:59,579:INFO:Initializing create_model()
2023-08-09 16:11:59,579:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=catboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:11:59,579:INFO:Checking exceptions
2023-08-09 16:11:59,589:INFO:Importing libraries
2023-08-09 16:11:59,589:INFO:Copying training dataset
2023-08-09 16:11:59,592:INFO:Defining folds
2023-08-09 16:11:59,592:INFO:Declaring metric variables
2023-08-09 16:11:59,595:INFO:Importing untrained model
2023-08-09 16:11:59,597:INFO:CatBoost Classifier Imported successfully
2023-08-09 16:11:59,601:INFO:Starting cross validation
2023-08-09 16:11:59,602:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:12:00,313:INFO:Calculating mean and std
2023-08-09 16:12:00,314:INFO:Creating metrics dataframe
2023-08-09 16:12:00,318:INFO:Finalizing model
2023-08-09 16:12:00,461:INFO:Uploading results into container
2023-08-09 16:12:00,462:INFO:Uploading model into container now
2023-08-09 16:12:00,468:INFO:_master_model_container: 47
2023-08-09 16:12:00,469:INFO:_display_container: 14
2023-08-09 16:12:00,469:INFO:<catboost.core.CatBoostClassifier object at 0x00000236D8430B80>
2023-08-09 16:12:00,469:INFO:create_model() successfully completed......................................
2023-08-09 16:12:00,863:INFO:Initializing tune_model()
2023-08-09 16:12:00,864:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x00000236D8430B80>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>)
2023-08-09 16:12:00,864:INFO:Checking exceptions
2023-08-09 16:12:00,874:INFO:Copying training dataset
2023-08-09 16:12:00,877:INFO:Checking base model
2023-08-09 16:12:00,877:INFO:Base model : CatBoost Classifier
2023-08-09 16:12:00,880:INFO:Declaring metric variables
2023-08-09 16:12:00,882:INFO:Defining Hyperparameters
2023-08-09 16:12:01,267:INFO:Tuning with n_jobs=-1
2023-08-09 16:12:01,267:INFO:Initializing RandomizedSearchCV
2023-08-09 16:12:07,341:INFO:best_params: {'actual_estimator__random_strength': 0.2, 'actual_estimator__n_estimators': 270, 'actual_estimator__l2_leaf_reg': 8, 'actual_estimator__eta': 0.0005, 'actual_estimator__depth': 4}
2023-08-09 16:12:07,342:INFO:Hyperparameter search completed
2023-08-09 16:12:07,342:INFO:SubProcess create_model() called ==================================
2023-08-09 16:12:07,342:INFO:Initializing create_model()
2023-08-09 16:12:07,343:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=<catboost.core.CatBoostClassifier object at 0x00000237070FFA60>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237070E2BC0>, model_only=True, return_train_score=False, kwargs={'random_strength': 0.2, 'n_estimators': 270, 'l2_leaf_reg': 8, 'eta': 0.0005, 'depth': 4})
2023-08-09 16:12:07,343:INFO:Checking exceptions
2023-08-09 16:12:07,343:INFO:Importing libraries
2023-08-09 16:12:07,343:INFO:Copying training dataset
2023-08-09 16:12:07,345:INFO:Defining folds
2023-08-09 16:12:07,345:INFO:Declaring metric variables
2023-08-09 16:12:07,349:INFO:Importing untrained model
2023-08-09 16:12:07,349:INFO:Declaring custom model
2023-08-09 16:12:07,351:INFO:CatBoost Classifier Imported successfully
2023-08-09 16:12:07,355:INFO:Starting cross validation
2023-08-09 16:12:07,357:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:12:08,080:INFO:Calculating mean and std
2023-08-09 16:12:08,081:INFO:Creating metrics dataframe
2023-08-09 16:12:08,085:INFO:Finalizing model
2023-08-09 16:12:08,235:INFO:Uploading results into container
2023-08-09 16:12:08,235:INFO:Uploading model into container now
2023-08-09 16:12:08,236:INFO:_master_model_container: 48
2023-08-09 16:12:08,236:INFO:_display_container: 15
2023-08-09 16:12:08,236:INFO:<catboost.core.CatBoostClassifier object at 0x000002370EA7F7F0>
2023-08-09 16:12:08,236:INFO:create_model() successfully completed......................................
2023-08-09 16:12:08,610:INFO:SubProcess create_model() end ==================================
2023-08-09 16:12:08,610:INFO:choose_better activated
2023-08-09 16:12:08,613:INFO:SubProcess create_model() called ==================================
2023-08-09 16:12:08,613:INFO:Initializing create_model()
2023-08-09 16:12:08,613:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=<catboost.core.CatBoostClassifier object at 0x00000236D8430B80>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:12:08,614:INFO:Checking exceptions
2023-08-09 16:12:08,615:INFO:Importing libraries
2023-08-09 16:12:08,615:INFO:Copying training dataset
2023-08-09 16:12:08,618:INFO:Defining folds
2023-08-09 16:12:08,618:INFO:Declaring metric variables
2023-08-09 16:12:08,618:INFO:Importing untrained model
2023-08-09 16:12:08,618:INFO:Declaring custom model
2023-08-09 16:12:08,618:INFO:CatBoost Classifier Imported successfully
2023-08-09 16:12:08,618:INFO:Starting cross validation
2023-08-09 16:12:08,619:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:12:09,314:INFO:Calculating mean and std
2023-08-09 16:12:09,314:INFO:Creating metrics dataframe
2023-08-09 16:12:09,315:INFO:Finalizing model
2023-08-09 16:12:09,459:INFO:Uploading results into container
2023-08-09 16:12:09,460:INFO:Uploading model into container now
2023-08-09 16:12:09,460:INFO:_master_model_container: 49
2023-08-09 16:12:09,460:INFO:_display_container: 16
2023-08-09 16:12:09,460:INFO:<catboost.core.CatBoostClassifier object at 0x000002370FC782E0>
2023-08-09 16:12:09,460:INFO:create_model() successfully completed......................................
2023-08-09 16:12:09,827:INFO:SubProcess create_model() end ==================================
2023-08-09 16:12:09,827:INFO:<catboost.core.CatBoostClassifier object at 0x000002370FC782E0> result for Accuracy is 0.6542
2023-08-09 16:12:09,827:INFO:<catboost.core.CatBoostClassifier object at 0x000002370EA7F7F0> result for Accuracy is 0.671
2023-08-09 16:12:09,827:INFO:<catboost.core.CatBoostClassifier object at 0x000002370EA7F7F0> is best model
2023-08-09 16:12:09,827:INFO:choose_better completed
2023-08-09 16:12:09,834:INFO:_master_model_container: 49
2023-08-09 16:12:09,834:INFO:_display_container: 15
2023-08-09 16:12:09,834:INFO:<catboost.core.CatBoostClassifier object at 0x000002370EA7F7F0>
2023-08-09 16:12:09,835:INFO:tune_model() successfully completed......................................
2023-08-09 16:12:10,291:INFO:Initializing blend_models()
2023-08-09 16:12:10,291:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), <catboost.core.CatBoostClassifier object at 0x000002370EA7F7F0>], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-08-09 16:12:10,291:INFO:Checking exceptions
2023-08-09 16:12:10,302:INFO:Importing libraries
2023-08-09 16:12:10,302:INFO:Copying training dataset
2023-08-09 16:12:10,304:INFO:Getting model names
2023-08-09 16:12:10,306:INFO:SubProcess create_model() called ==================================
2023-08-09 16:12:10,307:INFO:Initializing create_model()
2023-08-09 16:12:10,307:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False)),
                             ('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x000002370EA7F7F0>)],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023706CAED70>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:12:10,308:INFO:Checking exceptions
2023-08-09 16:12:10,308:INFO:Importing libraries
2023-08-09 16:12:10,308:INFO:Copying training dataset
2023-08-09 16:12:10,310:INFO:Defining folds
2023-08-09 16:12:10,310:INFO:Declaring metric variables
2023-08-09 16:12:10,312:INFO:Importing untrained model
2023-08-09 16:12:10,312:INFO:Declaring custom model
2023-08-09 16:12:10,315:INFO:Voting Classifier Imported successfully
2023-08-09 16:12:10,320:INFO:Starting cross validation
2023-08-09 16:12:10,320:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:12:11,112:INFO:Calculating mean and std
2023-08-09 16:12:11,113:INFO:Creating metrics dataframe
2023-08-09 16:12:11,117:INFO:Finalizing model
2023-08-09 16:12:11,278:INFO:Uploading results into container
2023-08-09 16:12:11,279:INFO:Uploading model into container now
2023-08-09 16:12:11,279:INFO:_master_model_container: 50
2023-08-09 16:12:11,279:INFO:_display_container: 16
2023-08-09 16:12:11,280:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False)),
                             ('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x000002370FC7AFB0>)],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 16:12:11,280:INFO:create_model() successfully completed......................................
2023-08-09 16:12:11,660:INFO:SubProcess create_model() end ==================================
2023-08-09 16:12:11,667:INFO:_master_model_container: 50
2023-08-09 16:12:11,667:INFO:_display_container: 16
2023-08-09 16:12:11,668:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False)),
                             ('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x000002370FC7AFB0>)],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 16:12:11,668:INFO:blend_models() successfully completed......................................
2023-08-09 16:12:12,079:INFO:Initializing finalize_model()
2023-08-09 16:12:12,079:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-08-09 16:12:12,082:INFO:Finalizing VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 16:12:12,089:INFO:Initializing create_model()
2023-08-09 16:12:12,089:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=Non...
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambda=0.0, subsample=1.0,
                                             subsample_for_bin=200000,
                                             subsample_freq=0))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-08-09 16:12:12,089:INFO:Checking exceptions
2023-08-09 16:12:12,090:INFO:Importing libraries
2023-08-09 16:12:12,090:INFO:Copying training dataset
2023-08-09 16:12:12,090:INFO:Defining folds
2023-08-09 16:12:12,090:INFO:Declaring metric variables
2023-08-09 16:12:12,090:INFO:Importing untrained model
2023-08-09 16:12:12,090:INFO:Declaring custom model
2023-08-09 16:12:12,092:INFO:Voting Classifier Imported successfully
2023-08-09 16:12:12,092:INFO:Cross validation set to False
2023-08-09 16:12:12,092:INFO:Fitting Model
2023-08-09 16:12:12,261:INFO:Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_fea...
                                                              importance_type='split',
                                                              learning_rate=0.1,
                                                              max_depth=-1,
                                                              min_child_samples=20,
                                                              min_child_weight=0.001,
                                                              min_split_gain=0.0,
                                                              n_estimators=100,
                                                              n_jobs=-1,
                                                              num_leaves=31,
                                                              objective=None,
                                                              random_state=123,
                                                              reg_alpha=0.0,
                                                              reg_lambda=0.0,
                                                              subsample=1.0,
                                                              subsample_for_bin=200000,
                                                              subsample_freq=0))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-09 16:12:12,261:INFO:create_model() successfully completed......................................
2023-08-09 16:12:12,659:INFO:_master_model_container: 50
2023-08-09 16:12:12,659:INFO:_display_container: 16
2023-08-09 16:12:12,673:INFO:Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_fea...
                                                              importance_type='split',
                                                              learning_rate=0.1,
                                                              max_depth=-1,
                                                              min_child_samples=20,
                                                              min_child_weight=0.001,
                                                              min_split_gain=0.0,
                                                              n_estimators=100,
                                                              n_jobs=-1,
                                                              num_leaves=31,
                                                              objective=None,
                                                              random_state=123,
                                                              reg_alpha=0.0,
                                                              reg_lambda=0.0,
                                                              subsample=1.0,
                                                              subsample_for_bin=200000,
                                                              subsample_freq=0))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-09 16:12:12,673:INFO:finalize_model() successfully completed......................................
2023-08-09 16:12:13,073:INFO:Initializing predict_model()
2023-08-09 16:12:13,074:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_fea...
                                                              importance_type='split',
                                                              learning_rate=0.1,
                                                              max_depth=-1,
                                                              min_child_samples=20,
                                                              min_child_weight=0.001,
                                                              min_split_gain=0.0,
                                                              n_estimators=100,
                                                              n_jobs=-1,
                                                              num_leaves=31,
                                                              objective=None,
                                                              random_state=123,
                                                              reg_alpha=0.0,
                                                              reg_lambda=0.0,
                                                              subsample=1.0,
                                                              subsample_for_bin=200000,
                                                              subsample_freq=0))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002370E9CC280>)
2023-08-09 16:12:13,074:INFO:Checking exceptions
2023-08-09 16:12:13,074:INFO:Preloading libraries
2023-08-09 16:12:13,075:INFO:Set up data.
2023-08-09 16:12:13,080:INFO:Set up index.
2023-08-09 16:12:39,509:INFO:Initializing create_model()
2023-08-09 16:12:39,509:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:12:39,509:INFO:Checking exceptions
2023-08-09 16:12:39,520:INFO:Importing libraries
2023-08-09 16:12:39,521:INFO:Copying training dataset
2023-08-09 16:12:39,524:INFO:Defining folds
2023-08-09 16:12:39,524:INFO:Declaring metric variables
2023-08-09 16:12:39,526:INFO:Importing untrained model
2023-08-09 16:12:39,528:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:12:39,533:INFO:Starting cross validation
2023-08-09 16:12:39,534:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:12:40,321:INFO:Calculating mean and std
2023-08-09 16:12:40,321:INFO:Creating metrics dataframe
2023-08-09 16:12:40,325:INFO:Finalizing model
2023-08-09 16:12:40,473:INFO:Uploading results into container
2023-08-09 16:12:40,474:INFO:Uploading model into container now
2023-08-09 16:12:40,482:INFO:_master_model_container: 51
2023-08-09 16:12:40,482:INFO:_display_container: 17
2023-08-09 16:12:40,482:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:12:40,482:INFO:create_model() successfully completed......................................
2023-08-09 16:12:40,919:INFO:Initializing tune_model()
2023-08-09 16:12:40,919:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>)
2023-08-09 16:12:40,919:INFO:Checking exceptions
2023-08-09 16:12:40,929:INFO:Copying training dataset
2023-08-09 16:12:40,931:INFO:Checking base model
2023-08-09 16:12:40,931:INFO:Base model : Gradient Boosting Classifier
2023-08-09 16:12:40,934:INFO:Declaring metric variables
2023-08-09 16:12:40,936:INFO:Defining Hyperparameters
2023-08-09 16:12:41,327:INFO:Tuning with n_jobs=-1
2023-08-09 16:12:41,327:INFO:Initializing RandomizedSearchCV
2023-08-09 16:12:47,678:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.4}
2023-08-09 16:12:47,679:INFO:Hyperparameter search completed
2023-08-09 16:12:47,679:INFO:SubProcess create_model() called ==================================
2023-08-09 16:12:47,679:INFO:Initializing create_model()
2023-08-09 16:12:47,679:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023708C41DE0>, model_only=True, return_train_score=False, kwargs={'subsample': 0.7, 'n_estimators': 190, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.3, 'max_features': 'sqrt', 'max_depth': 7, 'learning_rate': 0.4})
2023-08-09 16:12:47,680:INFO:Checking exceptions
2023-08-09 16:12:47,680:INFO:Importing libraries
2023-08-09 16:12:47,680:INFO:Copying training dataset
2023-08-09 16:12:47,683:INFO:Defining folds
2023-08-09 16:12:47,684:INFO:Declaring metric variables
2023-08-09 16:12:47,686:INFO:Importing untrained model
2023-08-09 16:12:47,686:INFO:Declaring custom model
2023-08-09 16:12:47,690:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:12:47,694:INFO:Starting cross validation
2023-08-09 16:12:47,695:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:12:48,516:INFO:Calculating mean and std
2023-08-09 16:12:48,517:INFO:Creating metrics dataframe
2023-08-09 16:12:48,522:INFO:Finalizing model
2023-08-09 16:12:48,679:INFO:Uploading results into container
2023-08-09 16:12:48,680:INFO:Uploading model into container now
2023-08-09 16:12:48,681:INFO:_master_model_container: 52
2023-08-09 16:12:48,681:INFO:_display_container: 18
2023-08-09 16:12:48,681:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=123, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:12:48,681:INFO:create_model() successfully completed......................................
2023-08-09 16:12:49,070:INFO:SubProcess create_model() end ==================================
2023-08-09 16:12:49,070:INFO:choose_better activated
2023-08-09 16:12:49,074:INFO:SubProcess create_model() called ==================================
2023-08-09 16:12:49,074:INFO:Initializing create_model()
2023-08-09 16:12:49,074:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:12:49,074:INFO:Checking exceptions
2023-08-09 16:12:49,075:INFO:Importing libraries
2023-08-09 16:12:49,075:INFO:Copying training dataset
2023-08-09 16:12:49,078:INFO:Defining folds
2023-08-09 16:12:49,078:INFO:Declaring metric variables
2023-08-09 16:12:49,078:INFO:Importing untrained model
2023-08-09 16:12:49,078:INFO:Declaring custom model
2023-08-09 16:12:49,079:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:12:49,079:INFO:Starting cross validation
2023-08-09 16:12:49,080:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:12:49,851:INFO:Calculating mean and std
2023-08-09 16:12:49,851:INFO:Creating metrics dataframe
2023-08-09 16:12:49,853:INFO:Finalizing model
2023-08-09 16:12:49,996:INFO:Uploading results into container
2023-08-09 16:12:49,996:INFO:Uploading model into container now
2023-08-09 16:12:49,996:INFO:_master_model_container: 53
2023-08-09 16:12:49,996:INFO:_display_container: 19
2023-08-09 16:12:49,998:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:12:49,998:INFO:create_model() successfully completed......................................
2023-08-09 16:12:50,383:INFO:SubProcess create_model() end ==================================
2023-08-09 16:12:50,384:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.6573
2023-08-09 16:12:50,384:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=123, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.6488
2023-08-09 16:12:50,385:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-08-09 16:12:50,385:INFO:choose_better completed
2023-08-09 16:12:50,385:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-08-09 16:12:50,391:INFO:_master_model_container: 53
2023-08-09 16:12:50,391:INFO:_display_container: 18
2023-08-09 16:12:50,391:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:12:50,391:INFO:tune_model() successfully completed......................................
2023-08-09 16:12:50,830:INFO:Initializing create_model()
2023-08-09 16:12:50,830:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=catboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:12:50,830:INFO:Checking exceptions
2023-08-09 16:12:50,839:INFO:Importing libraries
2023-08-09 16:12:50,840:INFO:Copying training dataset
2023-08-09 16:12:50,843:INFO:Defining folds
2023-08-09 16:12:50,843:INFO:Declaring metric variables
2023-08-09 16:12:50,845:INFO:Importing untrained model
2023-08-09 16:12:50,847:INFO:CatBoost Classifier Imported successfully
2023-08-09 16:12:50,857:INFO:Starting cross validation
2023-08-09 16:12:50,858:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:12:51,566:INFO:Calculating mean and std
2023-08-09 16:12:51,566:INFO:Creating metrics dataframe
2023-08-09 16:12:51,570:INFO:Finalizing model
2023-08-09 16:12:51,719:INFO:Uploading results into container
2023-08-09 16:12:51,720:INFO:Uploading model into container now
2023-08-09 16:12:51,727:INFO:_master_model_container: 54
2023-08-09 16:12:51,727:INFO:_display_container: 19
2023-08-09 16:12:51,727:INFO:<catboost.core.CatBoostClassifier object at 0x0000023706596050>
2023-08-09 16:12:51,727:INFO:create_model() successfully completed......................................
2023-08-09 16:12:52,115:INFO:Initializing tune_model()
2023-08-09 16:12:52,115:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x0000023706596050>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>)
2023-08-09 16:12:52,115:INFO:Checking exceptions
2023-08-09 16:12:52,127:INFO:Copying training dataset
2023-08-09 16:12:52,130:INFO:Checking base model
2023-08-09 16:12:52,130:INFO:Base model : CatBoost Classifier
2023-08-09 16:12:52,132:INFO:Declaring metric variables
2023-08-09 16:12:52,134:INFO:Defining Hyperparameters
2023-08-09 16:12:52,521:INFO:Tuning with n_jobs=-1
2023-08-09 16:12:52,521:INFO:Initializing RandomizedSearchCV
2023-08-09 16:12:58,616:INFO:best_params: {'actual_estimator__random_strength': 0.2, 'actual_estimator__n_estimators': 270, 'actual_estimator__l2_leaf_reg': 8, 'actual_estimator__eta': 0.0005, 'actual_estimator__depth': 4}
2023-08-09 16:12:58,617:INFO:Hyperparameter search completed
2023-08-09 16:12:58,617:INFO:SubProcess create_model() called ==================================
2023-08-09 16:12:58,617:INFO:Initializing create_model()
2023-08-09 16:12:58,617:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=<catboost.core.CatBoostClassifier object at 0x000002370FC781F0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002370EAB95A0>, model_only=True, return_train_score=False, kwargs={'random_strength': 0.2, 'n_estimators': 270, 'l2_leaf_reg': 8, 'eta': 0.0005, 'depth': 4})
2023-08-09 16:12:58,617:INFO:Checking exceptions
2023-08-09 16:12:58,617:INFO:Importing libraries
2023-08-09 16:12:58,617:INFO:Copying training dataset
2023-08-09 16:12:58,622:INFO:Defining folds
2023-08-09 16:12:58,622:INFO:Declaring metric variables
2023-08-09 16:12:58,624:INFO:Importing untrained model
2023-08-09 16:12:58,624:INFO:Declaring custom model
2023-08-09 16:12:58,626:INFO:CatBoost Classifier Imported successfully
2023-08-09 16:12:58,630:INFO:Starting cross validation
2023-08-09 16:12:58,631:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:12:59,321:INFO:Calculating mean and std
2023-08-09 16:12:59,323:INFO:Creating metrics dataframe
2023-08-09 16:12:59,327:INFO:Finalizing model
2023-08-09 16:12:59,472:INFO:Uploading results into container
2023-08-09 16:12:59,472:INFO:Uploading model into container now
2023-08-09 16:12:59,472:INFO:_master_model_container: 55
2023-08-09 16:12:59,472:INFO:_display_container: 20
2023-08-09 16:12:59,472:INFO:<catboost.core.CatBoostClassifier object at 0x0000023706546B30>
2023-08-09 16:12:59,473:INFO:create_model() successfully completed......................................
2023-08-09 16:12:59,844:INFO:SubProcess create_model() end ==================================
2023-08-09 16:12:59,844:INFO:choose_better activated
2023-08-09 16:12:59,847:INFO:SubProcess create_model() called ==================================
2023-08-09 16:12:59,847:INFO:Initializing create_model()
2023-08-09 16:12:59,847:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=<catboost.core.CatBoostClassifier object at 0x0000023706596050>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:12:59,847:INFO:Checking exceptions
2023-08-09 16:12:59,848:INFO:Importing libraries
2023-08-09 16:12:59,848:INFO:Copying training dataset
2023-08-09 16:12:59,851:INFO:Defining folds
2023-08-09 16:12:59,851:INFO:Declaring metric variables
2023-08-09 16:12:59,852:INFO:Importing untrained model
2023-08-09 16:12:59,852:INFO:Declaring custom model
2023-08-09 16:12:59,852:INFO:CatBoost Classifier Imported successfully
2023-08-09 16:12:59,852:INFO:Starting cross validation
2023-08-09 16:12:59,853:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:13:00,552:INFO:Calculating mean and std
2023-08-09 16:13:00,552:INFO:Creating metrics dataframe
2023-08-09 16:13:00,554:INFO:Finalizing model
2023-08-09 16:13:00,693:INFO:Uploading results into container
2023-08-09 16:13:00,693:INFO:Uploading model into container now
2023-08-09 16:13:00,694:INFO:_master_model_container: 56
2023-08-09 16:13:00,695:INFO:_display_container: 21
2023-08-09 16:13:00,695:INFO:<catboost.core.CatBoostClassifier object at 0x00000237061E0160>
2023-08-09 16:13:00,695:INFO:create_model() successfully completed......................................
2023-08-09 16:13:01,068:INFO:SubProcess create_model() end ==================================
2023-08-09 16:13:01,068:INFO:<catboost.core.CatBoostClassifier object at 0x00000237061E0160> result for Accuracy is 0.6542
2023-08-09 16:13:01,068:INFO:<catboost.core.CatBoostClassifier object at 0x0000023706546B30> result for Accuracy is 0.671
2023-08-09 16:13:01,068:INFO:<catboost.core.CatBoostClassifier object at 0x0000023706546B30> is best model
2023-08-09 16:13:01,068:INFO:choose_better completed
2023-08-09 16:13:01,077:INFO:_master_model_container: 56
2023-08-09 16:13:01,077:INFO:_display_container: 20
2023-08-09 16:13:01,077:INFO:<catboost.core.CatBoostClassifier object at 0x0000023706546B30>
2023-08-09 16:13:01,077:INFO:tune_model() successfully completed......................................
2023-08-09 16:13:01,504:INFO:Initializing blend_models()
2023-08-09 16:13:01,504:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator_list=[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), <catboost.core.CatBoostClassifier object at 0x0000023706546B30>], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-08-09 16:13:01,504:INFO:Checking exceptions
2023-08-09 16:13:01,515:INFO:Importing libraries
2023-08-09 16:13:01,515:INFO:Copying training dataset
2023-08-09 16:13:01,518:INFO:Getting model names
2023-08-09 16:13:01,520:INFO:SubProcess create_model() called ==================================
2023-08-09 16:13:01,522:INFO:Initializing create_model()
2023-08-09 16:13:01,522:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False)),
                             ('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000023706546B30>)],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237070E2BC0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:13:01,522:INFO:Checking exceptions
2023-08-09 16:13:01,522:INFO:Importing libraries
2023-08-09 16:13:01,522:INFO:Copying training dataset
2023-08-09 16:13:01,525:INFO:Defining folds
2023-08-09 16:13:01,525:INFO:Declaring metric variables
2023-08-09 16:13:01,528:INFO:Importing untrained model
2023-08-09 16:13:01,528:INFO:Declaring custom model
2023-08-09 16:13:01,531:INFO:Voting Classifier Imported successfully
2023-08-09 16:13:01,535:INFO:Starting cross validation
2023-08-09 16:13:01,537:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:13:02,330:INFO:Calculating mean and std
2023-08-09 16:13:02,330:INFO:Creating metrics dataframe
2023-08-09 16:13:02,334:INFO:Finalizing model
2023-08-09 16:13:02,478:INFO:Uploading results into container
2023-08-09 16:13:02,479:INFO:Uploading model into container now
2023-08-09 16:13:02,479:INFO:_master_model_container: 57
2023-08-09 16:13:02,479:INFO:_display_container: 21
2023-08-09 16:13:02,481:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False)),
                             ('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000023706597FD0>)],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 16:13:02,481:INFO:create_model() successfully completed......................................
2023-08-09 16:13:02,851:INFO:SubProcess create_model() end ==================================
2023-08-09 16:13:02,858:INFO:_master_model_container: 57
2023-08-09 16:13:02,859:INFO:_display_container: 21
2023-08-09 16:13:02,860:INFO:VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False)),
                             ('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000023706597FD0>)],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 16:13:02,860:INFO:blend_models() successfully completed......................................
2023-08-09 16:13:03,247:INFO:Initializing finalize_model()
2023-08-09 16:13:03,247:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False)),
                             ('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000023706597FD0>)],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-08-09 16:13:03,248:INFO:Finalizing VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False)),
                             ('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000023706597FD0>)],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 16:13:03,251:INFO:Initializing create_model()
2023-08-09 16:13:03,251:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=VotingClassifier(estimators=[('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False)),
                             ('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x0000023706597FD0>)],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-08-09 16:13:03,251:INFO:Checking exceptions
2023-08-09 16:13:03,253:INFO:Importing libraries
2023-08-09 16:13:03,253:INFO:Copying training dataset
2023-08-09 16:13:03,253:INFO:Defining folds
2023-08-09 16:13:03,253:INFO:Declaring metric variables
2023-08-09 16:13:03,253:INFO:Importing untrained model
2023-08-09 16:13:03,253:INFO:Declaring custom model
2023-08-09 16:13:03,254:INFO:Voting Classifier Imported successfully
2023-08-09 16:13:03,255:INFO:Cross validation set to False
2023-08-09 16:13:03,255:INFO:Fitting Model
2023-08-09 16:13:04,246:INFO:Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_fea...
                                                                          min_samples_split=2,
                                                                          min_weight_fraction_leaf=0.0,
                                                                          n_estimators=100,
                                                                          n_iter_no_change=None,
                                                                          random_state=123,
                                                                          subsample=1.0,
                                                                          tol=0.0001,
                                                                          validation_fraction=0.1,
                                                                          verbose=0,
                                                                          warm_start=False)),
                                              ('CatBoost Classifier',
                                               <catboost.core.CatBoostClassifier object at 0x000002370EA65F60>)],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-09 16:13:04,246:INFO:create_model() successfully completed......................................
2023-08-09 16:13:04,628:INFO:_master_model_container: 57
2023-08-09 16:13:04,628:INFO:_display_container: 21
2023-08-09 16:13:04,635:INFO:Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_fea...
                                                                          min_samples_split=2,
                                                                          min_weight_fraction_leaf=0.0,
                                                                          n_estimators=100,
                                                                          n_iter_no_change=None,
                                                                          random_state=123,
                                                                          subsample=1.0,
                                                                          tol=0.0001,
                                                                          validation_fraction=0.1,
                                                                          verbose=0,
                                                                          warm_start=False)),
                                              ('CatBoost Classifier',
                                               <catboost.core.CatBoostClassifier object at 0x000002370EA65F60>)],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-09 16:13:04,637:INFO:finalize_model() successfully completed......................................
2023-08-09 16:13:05,018:INFO:Initializing predict_model()
2023-08-09 16:13:05,018:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000237065470A0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_fea...
                                                                          min_samples_split=2,
                                                                          min_weight_fraction_leaf=0.0,
                                                                          n_estimators=100,
                                                                          n_iter_no_change=None,
                                                                          random_state=123,
                                                                          subsample=1.0,
                                                                          tol=0.0001,
                                                                          validation_fraction=0.1,
                                                                          verbose=0,
                                                                          warm_start=False)),
                                              ('CatBoost Classifier',
                                               <catboost.core.CatBoostClassifier object at 0x000002370EA65F60>)],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000023706CDAC20>)
2023-08-09 16:13:05,018:INFO:Checking exceptions
2023-08-09 16:13:05,018:INFO:Preloading libraries
2023-08-09 16:13:05,020:INFO:Set up data.
2023-08-09 16:13:05,024:INFO:Set up index.
2023-08-09 16:14:59,630:INFO:PyCaret ClassificationExperiment
2023-08-09 16:14:59,630:INFO:Logging name: clf-default-name
2023-08-09 16:14:59,630:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-09 16:14:59,630:INFO:version 3.0.4
2023-08-09 16:14:59,630:INFO:Initializing setup()
2023-08-09 16:14:59,630:INFO:self.USI: a0ad
2023-08-09 16:14:59,630:INFO:self._variable_keys: {'data', 'y_train', 'USI', 'html_param', 'seed', 'target_param', 'exp_name_log', 'fold_groups_param', 'y', 'gpu_param', '_available_plots', 'gpu_n_jobs_param', 'fold_shuffle_param', 'pipeline', 'memory', 'X', 'fix_imbalance', 'fold_generator', 'is_multiclass', '_ml_usecase', 'log_plots_param', 'X_test', 'y_test', 'logging_param', 'n_jobs_param', 'exp_id', 'X_train', 'idx'}
2023-08-09 16:14:59,630:INFO:Checking environment
2023-08-09 16:14:59,630:INFO:python_version: 3.10.12
2023-08-09 16:14:59,630:INFO:python_build: ('main', 'Jul  5 2023 19:09:20')
2023-08-09 16:14:59,630:INFO:machine: AMD64
2023-08-09 16:14:59,630:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-09 16:14:59,630:INFO:Memory: svmem(total=16828977152, available=3738771456, percent=77.8, used=13090205696, free=3738771456)
2023-08-09 16:14:59,630:INFO:Physical Core: 14
2023-08-09 16:14:59,630:INFO:Logical Core: 20
2023-08-09 16:14:59,630:INFO:Checking libraries
2023-08-09 16:14:59,630:INFO:System:
2023-08-09 16:14:59,630:INFO:    python: 3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:09:20) [MSC v.1916 64 bit (AMD64)]
2023-08-09 16:14:59,630:INFO:executable: C:\Users\user21\anaconda3\python.exe
2023-08-09 16:14:59,630:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-09 16:14:59,630:INFO:PyCaret required dependencies:
2023-08-09 16:14:59,630:INFO:                 pip: 23.2.1
2023-08-09 16:14:59,630:INFO:          setuptools: 68.0.0
2023-08-09 16:14:59,630:INFO:             pycaret: 3.0.4
2023-08-09 16:14:59,630:INFO:             IPython: 8.12.0
2023-08-09 16:14:59,630:INFO:          ipywidgets: 8.1.0
2023-08-09 16:14:59,631:INFO:                tqdm: 4.65.0
2023-08-09 16:14:59,631:INFO:               numpy: 1.23.5
2023-08-09 16:14:59,631:INFO:              pandas: 1.5.3
2023-08-09 16:14:59,631:INFO:              jinja2: 3.1.2
2023-08-09 16:14:59,631:INFO:               scipy: 1.11.1
2023-08-09 16:14:59,631:INFO:              joblib: 1.3.1
2023-08-09 16:14:59,631:INFO:             sklearn: 1.2.2
2023-08-09 16:14:59,631:INFO:                pyod: 1.1.0
2023-08-09 16:14:59,631:INFO:            imblearn: 0.11.0
2023-08-09 16:14:59,631:INFO:   category_encoders: 2.6.1
2023-08-09 16:14:59,631:INFO:            lightgbm: 4.0.0
2023-08-09 16:14:59,631:INFO:               numba: 0.57.1
2023-08-09 16:14:59,631:INFO:            requests: 2.31.0
2023-08-09 16:14:59,631:INFO:          matplotlib: 3.7.2
2023-08-09 16:14:59,631:INFO:          scikitplot: 0.3.7
2023-08-09 16:14:59,631:INFO:         yellowbrick: 1.5
2023-08-09 16:14:59,631:INFO:              plotly: 5.15.0
2023-08-09 16:14:59,631:INFO:    plotly-resampler: Not installed
2023-08-09 16:14:59,631:INFO:             kaleido: 0.2.1
2023-08-09 16:14:59,631:INFO:           schemdraw: 0.15
2023-08-09 16:14:59,631:INFO:         statsmodels: 0.14.0
2023-08-09 16:14:59,631:INFO:              sktime: 0.21.0
2023-08-09 16:14:59,631:INFO:               tbats: 1.1.3
2023-08-09 16:14:59,631:INFO:            pmdarima: 2.0.3
2023-08-09 16:14:59,631:INFO:              psutil: 5.9.0
2023-08-09 16:14:59,631:INFO:          markupsafe: 2.1.1
2023-08-09 16:14:59,631:INFO:             pickle5: Not installed
2023-08-09 16:14:59,631:INFO:         cloudpickle: 2.2.1
2023-08-09 16:14:59,631:INFO:         deprecation: 2.1.0
2023-08-09 16:14:59,631:INFO:              xxhash: 3.3.0
2023-08-09 16:14:59,631:INFO:           wurlitzer: Not installed
2023-08-09 16:14:59,631:INFO:PyCaret optional dependencies:
2023-08-09 16:14:59,631:INFO:                shap: Not installed
2023-08-09 16:14:59,631:INFO:           interpret: Not installed
2023-08-09 16:14:59,631:INFO:                umap: Not installed
2023-08-09 16:14:59,631:INFO:    pandas_profiling: Not installed
2023-08-09 16:14:59,631:INFO:  explainerdashboard: Not installed
2023-08-09 16:14:59,631:INFO:             autoviz: Not installed
2023-08-09 16:14:59,631:INFO:           fairlearn: Not installed
2023-08-09 16:14:59,631:INFO:          deepchecks: Not installed
2023-08-09 16:14:59,632:INFO:             xgboost: 1.7.6
2023-08-09 16:14:59,632:INFO:            catboost: 1.2
2023-08-09 16:14:59,632:INFO:              kmodes: Not installed
2023-08-09 16:14:59,632:INFO:             mlxtend: Not installed
2023-08-09 16:14:59,632:INFO:       statsforecast: Not installed
2023-08-09 16:14:59,632:INFO:        tune_sklearn: Not installed
2023-08-09 16:14:59,632:INFO:                 ray: Not installed
2023-08-09 16:14:59,632:INFO:            hyperopt: Not installed
2023-08-09 16:14:59,632:INFO:              optuna: 3.2.0
2023-08-09 16:14:59,632:INFO:               skopt: Not installed
2023-08-09 16:14:59,632:INFO:              mlflow: Not installed
2023-08-09 16:14:59,632:INFO:              gradio: Not installed
2023-08-09 16:14:59,632:INFO:             fastapi: Not installed
2023-08-09 16:14:59,632:INFO:             uvicorn: Not installed
2023-08-09 16:14:59,632:INFO:              m2cgen: Not installed
2023-08-09 16:14:59,632:INFO:           evidently: Not installed
2023-08-09 16:14:59,632:INFO:               fugue: Not installed
2023-08-09 16:14:59,632:INFO:           streamlit: Not installed
2023-08-09 16:14:59,632:INFO:             prophet: Not installed
2023-08-09 16:14:59,632:INFO:None
2023-08-09 16:14:59,632:INFO:Set up data.
2023-08-09 16:14:59,639:INFO:Set up train/test split.
2023-08-09 16:14:59,642:INFO:Set up index.
2023-08-09 16:14:59,642:INFO:Set up folding strategy.
2023-08-09 16:14:59,642:INFO:Assigning column types.
2023-08-09 16:14:59,645:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-09 16:14:59,672:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-09 16:14:59,673:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 16:14:59,690:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:14:59,692:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:14:59,720:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-09 16:14:59,721:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 16:14:59,738:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:14:59,741:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:14:59,741:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-09 16:14:59,769:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 16:14:59,787:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:14:59,788:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:14:59,817:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 16:14:59,835:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:14:59,837:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:14:59,837:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-09 16:14:59,884:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:14:59,885:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:14:59,934:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:14:59,936:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:14:59,937:INFO:Preparing preprocessing pipeline...
2023-08-09 16:14:59,937:INFO:Set up simple imputation.
2023-08-09 16:14:59,937:INFO:Set up column name cleaning.
2023-08-09 16:14:59,953:INFO:Finished creating preprocessing pipeline.
2023-08-09 16:14:59,957:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Discount_offered',
                                             'Weight_in_gms',
                                             'Warehouse_block_A',
                                             'Warehouse_block_B',
                                             'Warehouse_block_C',
                                             'Warehouse_block_D',
                                             'Wareho...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-09 16:14:59,957:INFO:Creating final display dataframe.
2023-08-09 16:15:00,017:INFO:Setup _display_container:                     Description                Value
0                    Session id                  123
1                        Target  Reached.on.Time_Y.N
2                   Target type               Binary
3           Original data shape           (4827, 18)
4        Transformed data shape           (4827, 18)
5   Transformed train set shape           (3378, 18)
6    Transformed test set shape           (1449, 18)
7              Numeric features                   17
8                    Preprocess                 True
9               Imputation type               simple
10           Numeric imputation                 mean
11       Categorical imputation                 mode
12               Fold Generator      StratifiedKFold
13                  Fold Number                   10
14                     CPU Jobs                   -1
15                      Use GPU                False
16               Log Experiment                False
17              Experiment Name     clf-default-name
18                          USI                 a0ad
2023-08-09 16:15:00,069:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:15:00,071:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:15:00,120:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:15:00,121:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:15:00,122:INFO:setup() successfully completed in 0.54s...............
2023-08-09 16:15:00,122:INFO:Initializing compare_models()
2023-08-09 16:15:00,122:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-09 16:15:00,122:INFO:Checking exceptions
2023-08-09 16:15:00,125:INFO:Preparing display monitor
2023-08-09 16:15:00,138:INFO:Initializing Logistic Regression
2023-08-09 16:15:00,138:INFO:Total runtime is 0.0 minutes
2023-08-09 16:15:00,141:INFO:SubProcess create_model() called ==================================
2023-08-09 16:15:00,141:INFO:Initializing create_model()
2023-08-09 16:15:00,141:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237100679D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:15:00,141:INFO:Checking exceptions
2023-08-09 16:15:00,141:INFO:Importing libraries
2023-08-09 16:15:00,141:INFO:Copying training dataset
2023-08-09 16:15:00,144:INFO:Defining folds
2023-08-09 16:15:00,144:INFO:Declaring metric variables
2023-08-09 16:15:00,145:INFO:Importing untrained model
2023-08-09 16:15:00,148:INFO:Logistic Regression Imported successfully
2023-08-09 16:15:00,151:INFO:Starting cross validation
2023-08-09 16:15:00,152:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:15:00,768:INFO:Calculating mean and std
2023-08-09 16:15:00,768:INFO:Creating metrics dataframe
2023-08-09 16:15:00,841:INFO:Uploading results into container
2023-08-09 16:15:00,842:INFO:Uploading model into container now
2023-08-09 16:15:00,842:INFO:_master_model_container: 1
2023-08-09 16:15:00,842:INFO:_display_container: 2
2023-08-09 16:15:00,842:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-09 16:15:00,842:INFO:create_model() successfully completed......................................
2023-08-09 16:15:01,292:INFO:SubProcess create_model() end ==================================
2023-08-09 16:15:01,292:INFO:Creating metrics dataframe
2023-08-09 16:15:01,298:INFO:Initializing K Neighbors Classifier
2023-08-09 16:15:01,298:INFO:Total runtime is 0.019324688116709392 minutes
2023-08-09 16:15:01,301:INFO:SubProcess create_model() called ==================================
2023-08-09 16:15:01,301:INFO:Initializing create_model()
2023-08-09 16:15:01,301:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237100679D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:15:01,301:INFO:Checking exceptions
2023-08-09 16:15:01,301:INFO:Importing libraries
2023-08-09 16:15:01,301:INFO:Copying training dataset
2023-08-09 16:15:01,305:INFO:Defining folds
2023-08-09 16:15:01,305:INFO:Declaring metric variables
2023-08-09 16:15:01,307:INFO:Importing untrained model
2023-08-09 16:15:01,309:INFO:K Neighbors Classifier Imported successfully
2023-08-09 16:15:01,314:INFO:Starting cross validation
2023-08-09 16:15:01,315:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:15:02,049:INFO:Calculating mean and std
2023-08-09 16:15:02,050:INFO:Creating metrics dataframe
2023-08-09 16:15:02,129:INFO:Uploading results into container
2023-08-09 16:15:02,129:INFO:Uploading model into container now
2023-08-09 16:15:02,129:INFO:_master_model_container: 2
2023-08-09 16:15:02,130:INFO:_display_container: 2
2023-08-09 16:15:02,130:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-09 16:15:02,130:INFO:create_model() successfully completed......................................
2023-08-09 16:15:02,513:INFO:SubProcess create_model() end ==================================
2023-08-09 16:15:02,513:INFO:Creating metrics dataframe
2023-08-09 16:15:02,520:INFO:Initializing Naive Bayes
2023-08-09 16:15:02,520:INFO:Total runtime is 0.039694778124491376 minutes
2023-08-09 16:15:02,522:INFO:SubProcess create_model() called ==================================
2023-08-09 16:15:02,522:INFO:Initializing create_model()
2023-08-09 16:15:02,522:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237100679D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:15:02,522:INFO:Checking exceptions
2023-08-09 16:15:02,524:INFO:Importing libraries
2023-08-09 16:15:02,524:INFO:Copying training dataset
2023-08-09 16:15:02,526:INFO:Defining folds
2023-08-09 16:15:02,526:INFO:Declaring metric variables
2023-08-09 16:15:02,529:INFO:Importing untrained model
2023-08-09 16:15:02,531:INFO:Naive Bayes Imported successfully
2023-08-09 16:15:02,535:INFO:Starting cross validation
2023-08-09 16:15:02,537:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:15:03,109:INFO:Calculating mean and std
2023-08-09 16:15:03,110:INFO:Creating metrics dataframe
2023-08-09 16:15:03,188:INFO:Uploading results into container
2023-08-09 16:15:03,188:INFO:Uploading model into container now
2023-08-09 16:15:03,189:INFO:_master_model_container: 3
2023-08-09 16:15:03,189:INFO:_display_container: 2
2023-08-09 16:15:03,189:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-09 16:15:03,189:INFO:create_model() successfully completed......................................
2023-08-09 16:15:03,565:INFO:SubProcess create_model() end ==================================
2023-08-09 16:15:03,565:INFO:Creating metrics dataframe
2023-08-09 16:15:03,572:INFO:Initializing Decision Tree Classifier
2023-08-09 16:15:03,572:INFO:Total runtime is 0.057225330670674646 minutes
2023-08-09 16:15:03,574:INFO:SubProcess create_model() called ==================================
2023-08-09 16:15:03,574:INFO:Initializing create_model()
2023-08-09 16:15:03,574:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237100679D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:15:03,574:INFO:Checking exceptions
2023-08-09 16:15:03,575:INFO:Importing libraries
2023-08-09 16:15:03,575:INFO:Copying training dataset
2023-08-09 16:15:03,578:INFO:Defining folds
2023-08-09 16:15:03,579:INFO:Declaring metric variables
2023-08-09 16:15:03,581:INFO:Importing untrained model
2023-08-09 16:15:03,583:INFO:Decision Tree Classifier Imported successfully
2023-08-09 16:15:03,590:INFO:Starting cross validation
2023-08-09 16:15:03,590:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:15:04,185:INFO:Calculating mean and std
2023-08-09 16:15:04,185:INFO:Creating metrics dataframe
2023-08-09 16:15:04,259:INFO:Uploading results into container
2023-08-09 16:15:04,260:INFO:Uploading model into container now
2023-08-09 16:15:04,260:INFO:_master_model_container: 4
2023-08-09 16:15:04,260:INFO:_display_container: 2
2023-08-09 16:15:04,260:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-08-09 16:15:04,260:INFO:create_model() successfully completed......................................
2023-08-09 16:15:04,643:INFO:SubProcess create_model() end ==================================
2023-08-09 16:15:04,643:INFO:Creating metrics dataframe
2023-08-09 16:15:04,649:INFO:Initializing SVM - Linear Kernel
2023-08-09 16:15:04,650:INFO:Total runtime is 0.07519968748092652 minutes
2023-08-09 16:15:04,652:INFO:SubProcess create_model() called ==================================
2023-08-09 16:15:04,653:INFO:Initializing create_model()
2023-08-09 16:15:04,653:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237100679D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:15:04,653:INFO:Checking exceptions
2023-08-09 16:15:04,653:INFO:Importing libraries
2023-08-09 16:15:04,653:INFO:Copying training dataset
2023-08-09 16:15:04,655:INFO:Defining folds
2023-08-09 16:15:04,657:INFO:Declaring metric variables
2023-08-09 16:15:04,659:INFO:Importing untrained model
2023-08-09 16:15:04,661:INFO:SVM - Linear Kernel Imported successfully
2023-08-09 16:15:04,664:INFO:Starting cross validation
2023-08-09 16:15:04,665:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:15:04,728:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:15:04,737:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:15:04,743:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:15:04,746:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:15:04,749:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:15:04,752:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:15:04,759:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:15:04,764:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:15:04,766:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:15:04,773:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:15:05,226:INFO:Calculating mean and std
2023-08-09 16:15:05,226:INFO:Creating metrics dataframe
2023-08-09 16:15:05,303:INFO:Uploading results into container
2023-08-09 16:15:05,304:INFO:Uploading model into container now
2023-08-09 16:15:05,304:INFO:_master_model_container: 5
2023-08-09 16:15:05,304:INFO:_display_container: 2
2023-08-09 16:15:05,305:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-09 16:15:05,305:INFO:create_model() successfully completed......................................
2023-08-09 16:15:05,675:INFO:SubProcess create_model() end ==================================
2023-08-09 16:15:05,675:INFO:Creating metrics dataframe
2023-08-09 16:15:05,683:INFO:Initializing Ridge Classifier
2023-08-09 16:15:05,683:INFO:Total runtime is 0.09240875244140626 minutes
2023-08-09 16:15:05,685:INFO:SubProcess create_model() called ==================================
2023-08-09 16:15:05,685:INFO:Initializing create_model()
2023-08-09 16:15:05,685:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237100679D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:15:05,685:INFO:Checking exceptions
2023-08-09 16:15:05,685:INFO:Importing libraries
2023-08-09 16:15:05,685:INFO:Copying training dataset
2023-08-09 16:15:05,689:INFO:Defining folds
2023-08-09 16:15:05,689:INFO:Declaring metric variables
2023-08-09 16:15:05,691:INFO:Importing untrained model
2023-08-09 16:15:05,694:INFO:Ridge Classifier Imported successfully
2023-08-09 16:15:05,699:INFO:Starting cross validation
2023-08-09 16:15:05,700:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:15:05,750:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:15:05,755:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:15:05,758:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:15:05,765:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:15:05,773:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:15:05,777:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:15:05,778:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:15:05,785:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:15:05,785:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:15:05,789:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:15:06,259:INFO:Calculating mean and std
2023-08-09 16:15:06,260:INFO:Creating metrics dataframe
2023-08-09 16:15:06,335:INFO:Uploading results into container
2023-08-09 16:15:06,335:INFO:Uploading model into container now
2023-08-09 16:15:06,336:INFO:_master_model_container: 6
2023-08-09 16:15:06,336:INFO:_display_container: 2
2023-08-09 16:15:06,336:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-08-09 16:15:06,336:INFO:create_model() successfully completed......................................
2023-08-09 16:15:06,703:INFO:SubProcess create_model() end ==================================
2023-08-09 16:15:06,703:INFO:Creating metrics dataframe
2023-08-09 16:15:06,711:INFO:Initializing Random Forest Classifier
2023-08-09 16:15:06,711:INFO:Total runtime is 0.1095355272293091 minutes
2023-08-09 16:15:06,714:INFO:SubProcess create_model() called ==================================
2023-08-09 16:15:06,714:INFO:Initializing create_model()
2023-08-09 16:15:06,714:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237100679D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:15:06,714:INFO:Checking exceptions
2023-08-09 16:15:06,714:INFO:Importing libraries
2023-08-09 16:15:06,714:INFO:Copying training dataset
2023-08-09 16:15:06,718:INFO:Defining folds
2023-08-09 16:15:06,718:INFO:Declaring metric variables
2023-08-09 16:15:06,721:INFO:Importing untrained model
2023-08-09 16:15:06,723:INFO:Random Forest Classifier Imported successfully
2023-08-09 16:15:06,727:INFO:Starting cross validation
2023-08-09 16:15:06,728:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:15:07,892:INFO:Calculating mean and std
2023-08-09 16:15:07,893:INFO:Creating metrics dataframe
2023-08-09 16:15:07,972:INFO:Uploading results into container
2023-08-09 16:15:07,973:INFO:Uploading model into container now
2023-08-09 16:15:07,973:INFO:_master_model_container: 7
2023-08-09 16:15:07,973:INFO:_display_container: 2
2023-08-09 16:15:07,973:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-09 16:15:07,973:INFO:create_model() successfully completed......................................
2023-08-09 16:15:08,357:INFO:SubProcess create_model() end ==================================
2023-08-09 16:15:08,357:INFO:Creating metrics dataframe
2023-08-09 16:15:08,365:INFO:Initializing Quadratic Discriminant Analysis
2023-08-09 16:15:08,365:INFO:Total runtime is 0.13710147539774578 minutes
2023-08-09 16:15:08,366:INFO:SubProcess create_model() called ==================================
2023-08-09 16:15:08,367:INFO:Initializing create_model()
2023-08-09 16:15:08,367:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237100679D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:15:08,367:INFO:Checking exceptions
2023-08-09 16:15:08,367:INFO:Importing libraries
2023-08-09 16:15:08,367:INFO:Copying training dataset
2023-08-09 16:15:08,370:INFO:Defining folds
2023-08-09 16:15:08,370:INFO:Declaring metric variables
2023-08-09 16:15:08,374:INFO:Importing untrained model
2023-08-09 16:15:08,376:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-09 16:15:08,380:INFO:Starting cross validation
2023-08-09 16:15:08,381:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:15:08,417:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:15:08,419:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:15:08,430:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:15:08,432:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:15:08,432:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:15:08,437:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:15:08,438:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:15:08,442:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:15:08,445:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:15:08,456:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:15:08,964:INFO:Calculating mean and std
2023-08-09 16:15:08,965:INFO:Creating metrics dataframe
2023-08-09 16:15:09,042:INFO:Uploading results into container
2023-08-09 16:15:09,043:INFO:Uploading model into container now
2023-08-09 16:15:09,043:INFO:_master_model_container: 8
2023-08-09 16:15:09,043:INFO:_display_container: 2
2023-08-09 16:15:09,043:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-09 16:15:09,043:INFO:create_model() successfully completed......................................
2023-08-09 16:15:09,413:INFO:SubProcess create_model() end ==================================
2023-08-09 16:15:09,413:INFO:Creating metrics dataframe
2023-08-09 16:15:09,422:INFO:Initializing Ada Boost Classifier
2023-08-09 16:15:09,422:INFO:Total runtime is 0.15472511847813925 minutes
2023-08-09 16:15:09,424:INFO:SubProcess create_model() called ==================================
2023-08-09 16:15:09,425:INFO:Initializing create_model()
2023-08-09 16:15:09,425:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237100679D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:15:09,425:INFO:Checking exceptions
2023-08-09 16:15:09,425:INFO:Importing libraries
2023-08-09 16:15:09,425:INFO:Copying training dataset
2023-08-09 16:15:09,429:INFO:Defining folds
2023-08-09 16:15:09,429:INFO:Declaring metric variables
2023-08-09 16:15:09,431:INFO:Importing untrained model
2023-08-09 16:15:09,433:INFO:Ada Boost Classifier Imported successfully
2023-08-09 16:15:09,437:INFO:Starting cross validation
2023-08-09 16:15:09,438:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:15:10,288:INFO:Calculating mean and std
2023-08-09 16:15:10,289:INFO:Creating metrics dataframe
2023-08-09 16:15:10,367:INFO:Uploading results into container
2023-08-09 16:15:10,367:INFO:Uploading model into container now
2023-08-09 16:15:10,368:INFO:_master_model_container: 9
2023-08-09 16:15:10,368:INFO:_display_container: 2
2023-08-09 16:15:10,368:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-08-09 16:15:10,368:INFO:create_model() successfully completed......................................
2023-08-09 16:15:10,731:INFO:SubProcess create_model() end ==================================
2023-08-09 16:15:10,731:INFO:Creating metrics dataframe
2023-08-09 16:15:10,738:INFO:Initializing Gradient Boosting Classifier
2023-08-09 16:15:10,738:INFO:Total runtime is 0.17666553258895873 minutes
2023-08-09 16:15:10,742:INFO:SubProcess create_model() called ==================================
2023-08-09 16:15:10,743:INFO:Initializing create_model()
2023-08-09 16:15:10,743:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237100679D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:15:10,743:INFO:Checking exceptions
2023-08-09 16:15:10,743:INFO:Importing libraries
2023-08-09 16:15:10,743:INFO:Copying training dataset
2023-08-09 16:15:10,747:INFO:Defining folds
2023-08-09 16:15:10,747:INFO:Declaring metric variables
2023-08-09 16:15:10,750:INFO:Importing untrained model
2023-08-09 16:15:10,752:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:15:10,757:INFO:Starting cross validation
2023-08-09 16:15:10,758:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:15:11,917:INFO:Calculating mean and std
2023-08-09 16:15:11,918:INFO:Creating metrics dataframe
2023-08-09 16:15:12,003:INFO:Uploading results into container
2023-08-09 16:15:12,004:INFO:Uploading model into container now
2023-08-09 16:15:12,004:INFO:_master_model_container: 10
2023-08-09 16:15:12,004:INFO:_display_container: 2
2023-08-09 16:15:12,004:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:15:12,004:INFO:create_model() successfully completed......................................
2023-08-09 16:15:12,377:INFO:SubProcess create_model() end ==================================
2023-08-09 16:15:12,377:INFO:Creating metrics dataframe
2023-08-09 16:15:12,385:INFO:Initializing Linear Discriminant Analysis
2023-08-09 16:15:12,385:INFO:Total runtime is 0.20410832166671752 minutes
2023-08-09 16:15:12,388:INFO:SubProcess create_model() called ==================================
2023-08-09 16:15:12,388:INFO:Initializing create_model()
2023-08-09 16:15:12,388:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237100679D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:15:12,388:INFO:Checking exceptions
2023-08-09 16:15:12,388:INFO:Importing libraries
2023-08-09 16:15:12,388:INFO:Copying training dataset
2023-08-09 16:15:12,392:INFO:Defining folds
2023-08-09 16:15:12,392:INFO:Declaring metric variables
2023-08-09 16:15:12,394:INFO:Importing untrained model
2023-08-09 16:15:12,396:INFO:Linear Discriminant Analysis Imported successfully
2023-08-09 16:15:12,403:INFO:Starting cross validation
2023-08-09 16:15:12,404:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:15:13,038:INFO:Calculating mean and std
2023-08-09 16:15:13,039:INFO:Creating metrics dataframe
2023-08-09 16:15:13,114:INFO:Uploading results into container
2023-08-09 16:15:13,115:INFO:Uploading model into container now
2023-08-09 16:15:13,115:INFO:_master_model_container: 11
2023-08-09 16:15:13,116:INFO:_display_container: 2
2023-08-09 16:15:13,116:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-09 16:15:13,116:INFO:create_model() successfully completed......................................
2023-08-09 16:15:13,510:INFO:SubProcess create_model() end ==================================
2023-08-09 16:15:13,510:INFO:Creating metrics dataframe
2023-08-09 16:15:13,519:INFO:Initializing Extra Trees Classifier
2023-08-09 16:15:13,519:INFO:Total runtime is 0.22300500472386678 minutes
2023-08-09 16:15:13,521:INFO:SubProcess create_model() called ==================================
2023-08-09 16:15:13,522:INFO:Initializing create_model()
2023-08-09 16:15:13,522:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237100679D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:15:13,522:INFO:Checking exceptions
2023-08-09 16:15:13,522:INFO:Importing libraries
2023-08-09 16:15:13,522:INFO:Copying training dataset
2023-08-09 16:15:13,525:INFO:Defining folds
2023-08-09 16:15:13,525:INFO:Declaring metric variables
2023-08-09 16:15:13,528:INFO:Importing untrained model
2023-08-09 16:15:13,529:INFO:Extra Trees Classifier Imported successfully
2023-08-09 16:15:13,534:INFO:Starting cross validation
2023-08-09 16:15:13,535:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:15:14,722:INFO:Calculating mean and std
2023-08-09 16:15:14,723:INFO:Creating metrics dataframe
2023-08-09 16:15:14,807:INFO:Uploading results into container
2023-08-09 16:15:14,807:INFO:Uploading model into container now
2023-08-09 16:15:14,808:INFO:_master_model_container: 12
2023-08-09 16:15:14,808:INFO:_display_container: 2
2023-08-09 16:15:14,808:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-08-09 16:15:14,808:INFO:create_model() successfully completed......................................
2023-08-09 16:15:15,186:INFO:SubProcess create_model() end ==================================
2023-08-09 16:15:15,186:INFO:Creating metrics dataframe
2023-08-09 16:15:15,196:INFO:Initializing Extreme Gradient Boosting
2023-08-09 16:15:15,196:INFO:Total runtime is 0.2509515364964803 minutes
2023-08-09 16:15:15,198:INFO:SubProcess create_model() called ==================================
2023-08-09 16:15:15,198:INFO:Initializing create_model()
2023-08-09 16:15:15,199:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237100679D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:15:15,199:INFO:Checking exceptions
2023-08-09 16:15:15,199:INFO:Importing libraries
2023-08-09 16:15:15,199:INFO:Copying training dataset
2023-08-09 16:15:15,202:INFO:Defining folds
2023-08-09 16:15:15,202:INFO:Declaring metric variables
2023-08-09 16:15:15,204:INFO:Importing untrained model
2023-08-09 16:15:15,207:INFO:Extreme Gradient Boosting Imported successfully
2023-08-09 16:15:15,211:INFO:Starting cross validation
2023-08-09 16:15:15,212:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:15:16,376:INFO:Calculating mean and std
2023-08-09 16:15:16,377:INFO:Creating metrics dataframe
2023-08-09 16:15:16,460:INFO:Uploading results into container
2023-08-09 16:15:16,461:INFO:Uploading model into container now
2023-08-09 16:15:16,461:INFO:_master_model_container: 13
2023-08-09 16:15:16,461:INFO:_display_container: 2
2023-08-09 16:15:16,462:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-09 16:15:16,462:INFO:create_model() successfully completed......................................
2023-08-09 16:15:16,835:INFO:SubProcess create_model() end ==================================
2023-08-09 16:15:16,835:INFO:Creating metrics dataframe
2023-08-09 16:15:16,845:INFO:Initializing Light Gradient Boosting Machine
2023-08-09 16:15:16,845:INFO:Total runtime is 0.2784368872642517 minutes
2023-08-09 16:15:16,846:INFO:SubProcess create_model() called ==================================
2023-08-09 16:15:16,847:INFO:Initializing create_model()
2023-08-09 16:15:16,847:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237100679D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:15:16,847:INFO:Checking exceptions
2023-08-09 16:15:16,847:INFO:Importing libraries
2023-08-09 16:15:16,847:INFO:Copying training dataset
2023-08-09 16:15:16,850:INFO:Defining folds
2023-08-09 16:15:16,850:INFO:Declaring metric variables
2023-08-09 16:15:16,854:INFO:Importing untrained model
2023-08-09 16:15:16,856:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-09 16:15:16,861:INFO:Starting cross validation
2023-08-09 16:15:16,861:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:15:18,561:INFO:Calculating mean and std
2023-08-09 16:15:18,562:INFO:Creating metrics dataframe
2023-08-09 16:15:18,652:INFO:Uploading results into container
2023-08-09 16:15:18,653:INFO:Uploading model into container now
2023-08-09 16:15:18,653:INFO:_master_model_container: 14
2023-08-09 16:15:18,653:INFO:_display_container: 2
2023-08-09 16:15:18,654:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-09 16:15:18,654:INFO:create_model() successfully completed......................................
2023-08-09 16:15:19,034:INFO:SubProcess create_model() end ==================================
2023-08-09 16:15:19,034:INFO:Creating metrics dataframe
2023-08-09 16:15:19,043:INFO:Initializing CatBoost Classifier
2023-08-09 16:15:19,043:INFO:Total runtime is 0.31506926616032915 minutes
2023-08-09 16:15:19,045:INFO:SubProcess create_model() called ==================================
2023-08-09 16:15:19,045:INFO:Initializing create_model()
2023-08-09 16:15:19,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237100679D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:15:19,045:INFO:Checking exceptions
2023-08-09 16:15:19,045:INFO:Importing libraries
2023-08-09 16:15:19,045:INFO:Copying training dataset
2023-08-09 16:15:19,050:INFO:Defining folds
2023-08-09 16:15:19,050:INFO:Declaring metric variables
2023-08-09 16:15:19,053:INFO:Importing untrained model
2023-08-09 16:15:19,055:INFO:CatBoost Classifier Imported successfully
2023-08-09 16:15:19,058:INFO:Starting cross validation
2023-08-09 16:15:19,060:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:15:23,174:INFO:Calculating mean and std
2023-08-09 16:15:23,175:INFO:Creating metrics dataframe
2023-08-09 16:15:23,269:INFO:Uploading results into container
2023-08-09 16:15:23,269:INFO:Uploading model into container now
2023-08-09 16:15:23,269:INFO:_master_model_container: 15
2023-08-09 16:15:23,269:INFO:_display_container: 2
2023-08-09 16:15:23,269:INFO:<catboost.core.CatBoostClassifier object at 0x0000023710076230>
2023-08-09 16:15:23,269:INFO:create_model() successfully completed......................................
2023-08-09 16:15:23,639:INFO:SubProcess create_model() end ==================================
2023-08-09 16:15:23,639:INFO:Creating metrics dataframe
2023-08-09 16:15:23,649:INFO:Initializing Dummy Classifier
2023-08-09 16:15:23,649:INFO:Total runtime is 0.3918401519457499 minutes
2023-08-09 16:15:23,651:INFO:SubProcess create_model() called ==================================
2023-08-09 16:15:23,652:INFO:Initializing create_model()
2023-08-09 16:15:23,652:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237100679D0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:15:23,652:INFO:Checking exceptions
2023-08-09 16:15:23,652:INFO:Importing libraries
2023-08-09 16:15:23,652:INFO:Copying training dataset
2023-08-09 16:15:23,655:INFO:Defining folds
2023-08-09 16:15:23,655:INFO:Declaring metric variables
2023-08-09 16:15:23,658:INFO:Importing untrained model
2023-08-09 16:15:23,661:INFO:Dummy Classifier Imported successfully
2023-08-09 16:15:23,665:INFO:Starting cross validation
2023-08-09 16:15:23,665:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:15:24,360:INFO:Calculating mean and std
2023-08-09 16:15:24,360:INFO:Creating metrics dataframe
2023-08-09 16:15:24,450:INFO:Uploading results into container
2023-08-09 16:15:24,451:INFO:Uploading model into container now
2023-08-09 16:15:24,451:INFO:_master_model_container: 16
2023-08-09 16:15:24,451:INFO:_display_container: 2
2023-08-09 16:15:24,451:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-08-09 16:15:24,452:INFO:create_model() successfully completed......................................
2023-08-09 16:15:24,830:INFO:SubProcess create_model() end ==================================
2023-08-09 16:15:24,830:INFO:Creating metrics dataframe
2023-08-09 16:15:24,846:INFO:Initializing create_model()
2023-08-09 16:15:24,846:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:15:24,846:INFO:Checking exceptions
2023-08-09 16:15:24,847:INFO:Importing libraries
2023-08-09 16:15:24,848:INFO:Copying training dataset
2023-08-09 16:15:24,852:INFO:Defining folds
2023-08-09 16:15:24,852:INFO:Declaring metric variables
2023-08-09 16:15:24,852:INFO:Importing untrained model
2023-08-09 16:15:24,852:INFO:Declaring custom model
2023-08-09 16:15:24,852:INFO:Random Forest Classifier Imported successfully
2023-08-09 16:15:24,853:INFO:Cross validation set to False
2023-08-09 16:15:24,853:INFO:Fitting Model
2023-08-09 16:15:25,152:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-09 16:15:25,152:INFO:create_model() successfully completed......................................
2023-08-09 16:15:25,542:INFO:_master_model_container: 16
2023-08-09 16:15:25,542:INFO:_display_container: 2
2023-08-09 16:15:25,543:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-09 16:15:25,543:INFO:compare_models() successfully completed......................................
2023-08-09 16:15:25,543:INFO:Initializing create_model()
2023-08-09 16:15:25,543:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:15:25,543:INFO:Checking exceptions
2023-08-09 16:15:25,553:INFO:Importing libraries
2023-08-09 16:15:25,553:INFO:Copying training dataset
2023-08-09 16:15:25,556:INFO:Defining folds
2023-08-09 16:15:25,556:INFO:Declaring metric variables
2023-08-09 16:15:25,558:INFO:Importing untrained model
2023-08-09 16:15:25,560:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:15:25,565:INFO:Starting cross validation
2023-08-09 16:15:25,565:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:15:26,336:INFO:Calculating mean and std
2023-08-09 16:15:26,336:INFO:Creating metrics dataframe
2023-08-09 16:15:26,343:INFO:Finalizing model
2023-08-09 16:15:26,904:INFO:Uploading results into container
2023-08-09 16:15:26,906:INFO:Uploading model into container now
2023-08-09 16:15:26,911:INFO:_master_model_container: 17
2023-08-09 16:15:26,911:INFO:_display_container: 3
2023-08-09 16:15:26,912:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:15:26,912:INFO:create_model() successfully completed......................................
2023-08-09 16:15:27,294:INFO:Initializing tune_model()
2023-08-09 16:15:27,294:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>)
2023-08-09 16:15:27,294:INFO:Checking exceptions
2023-08-09 16:15:27,307:INFO:Copying training dataset
2023-08-09 16:15:27,309:INFO:Checking base model
2023-08-09 16:15:27,310:INFO:Base model : Gradient Boosting Classifier
2023-08-09 16:15:27,312:INFO:Declaring metric variables
2023-08-09 16:15:27,314:INFO:Defining Hyperparameters
2023-08-09 16:15:27,699:INFO:Tuning with n_jobs=-1
2023-08-09 16:15:27,700:INFO:Initializing RandomizedSearchCV
2023-08-09 16:15:39,288:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 140, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.05, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.01}
2023-08-09 16:15:39,288:INFO:Hyperparameter search completed
2023-08-09 16:15:39,288:INFO:SubProcess create_model() called ==================================
2023-08-09 16:15:39,289:INFO:Initializing create_model()
2023-08-09 16:15:39,289:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023706F1D750>, model_only=True, return_train_score=False, kwargs={'subsample': 0.35, 'n_estimators': 140, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.05, 'max_features': 'sqrt', 'max_depth': 7, 'learning_rate': 0.01})
2023-08-09 16:15:39,289:INFO:Checking exceptions
2023-08-09 16:15:39,289:INFO:Importing libraries
2023-08-09 16:15:39,289:INFO:Copying training dataset
2023-08-09 16:15:39,292:INFO:Defining folds
2023-08-09 16:15:39,293:INFO:Declaring metric variables
2023-08-09 16:15:39,296:INFO:Importing untrained model
2023-08-09 16:15:39,296:INFO:Declaring custom model
2023-08-09 16:15:39,300:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:15:39,305:INFO:Starting cross validation
2023-08-09 16:15:39,305:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:15:40,229:INFO:Calculating mean and std
2023-08-09 16:15:40,230:INFO:Creating metrics dataframe
2023-08-09 16:15:40,234:INFO:Finalizing model
2023-08-09 16:15:40,788:INFO:Uploading results into container
2023-08-09 16:15:40,789:INFO:Uploading model into container now
2023-08-09 16:15:40,789:INFO:_master_model_container: 18
2023-08-09 16:15:40,789:INFO:_display_container: 4
2023-08-09 16:15:40,790:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:15:40,790:INFO:create_model() successfully completed......................................
2023-08-09 16:15:41,181:INFO:SubProcess create_model() end ==================================
2023-08-09 16:15:41,181:INFO:choose_better activated
2023-08-09 16:15:41,184:INFO:SubProcess create_model() called ==================================
2023-08-09 16:15:41,184:INFO:Initializing create_model()
2023-08-09 16:15:41,184:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:15:41,184:INFO:Checking exceptions
2023-08-09 16:15:41,186:INFO:Importing libraries
2023-08-09 16:15:41,186:INFO:Copying training dataset
2023-08-09 16:15:41,190:INFO:Defining folds
2023-08-09 16:15:41,190:INFO:Declaring metric variables
2023-08-09 16:15:41,190:INFO:Importing untrained model
2023-08-09 16:15:41,190:INFO:Declaring custom model
2023-08-09 16:15:41,190:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:15:41,191:INFO:Starting cross validation
2023-08-09 16:15:41,191:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:15:42,098:INFO:Calculating mean and std
2023-08-09 16:15:42,098:INFO:Creating metrics dataframe
2023-08-09 16:15:42,100:INFO:Finalizing model
2023-08-09 16:15:42,237:INFO:Uploading results into container
2023-08-09 16:15:42,237:INFO:Uploading model into container now
2023-08-09 16:15:42,239:INFO:_master_model_container: 19
2023-08-09 16:15:42,239:INFO:_display_container: 5
2023-08-09 16:15:42,239:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:15:42,239:INFO:create_model() successfully completed......................................
2023-08-09 16:15:42,622:INFO:SubProcess create_model() end ==================================
2023-08-09 16:15:42,622:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.6539
2023-08-09 16:15:42,624:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.6548
2023-08-09 16:15:42,624:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-08-09 16:15:42,624:INFO:choose_better completed
2023-08-09 16:15:42,632:INFO:_master_model_container: 19
2023-08-09 16:15:42,632:INFO:_display_container: 4
2023-08-09 16:15:42,632:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:15:42,632:INFO:tune_model() successfully completed......................................
2023-08-09 16:16:20,920:INFO:Initializing create_model()
2023-08-09 16:16:20,920:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:16:20,920:INFO:Checking exceptions
2023-08-09 16:16:20,930:INFO:Importing libraries
2023-08-09 16:16:20,930:INFO:Copying training dataset
2023-08-09 16:16:20,933:INFO:Defining folds
2023-08-09 16:16:20,933:INFO:Declaring metric variables
2023-08-09 16:16:20,935:INFO:Importing untrained model
2023-08-09 16:16:20,939:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-09 16:16:20,943:INFO:Starting cross validation
2023-08-09 16:16:20,944:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:16:21,907:INFO:Calculating mean and std
2023-08-09 16:16:21,907:INFO:Creating metrics dataframe
2023-08-09 16:16:21,912:INFO:Finalizing model
2023-08-09 16:16:21,935:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-09 16:16:21,936:INFO:[LightGBM] [Info] Number of positive: 2004, number of negative: 1374
2023-08-09 16:16:21,936:INFO:[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000308 seconds.
2023-08-09 16:16:21,937:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-08-09 16:16:21,937:INFO:[LightGBM] [Info] Total Bins 748
2023-08-09 16:16:21,937:INFO:[LightGBM] [Info] Number of data points in the train set: 3378, number of used features: 17
2023-08-09 16:16:21,937:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.593250 -> initscore=0.377419
2023-08-09 16:16:21,937:INFO:[LightGBM] [Info] Start training from score 0.377419
2023-08-09 16:16:22,171:INFO:Uploading results into container
2023-08-09 16:16:22,171:INFO:Uploading model into container now
2023-08-09 16:16:22,179:INFO:_master_model_container: 20
2023-08-09 16:16:22,179:INFO:_display_container: 5
2023-08-09 16:16:22,179:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-09 16:16:22,179:INFO:create_model() successfully completed......................................
2023-08-09 16:16:22,563:INFO:Initializing tune_model()
2023-08-09 16:16:22,565:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>)
2023-08-09 16:16:22,565:INFO:Checking exceptions
2023-08-09 16:16:22,575:INFO:Copying training dataset
2023-08-09 16:16:22,578:INFO:Checking base model
2023-08-09 16:16:22,578:INFO:Base model : Light Gradient Boosting Machine
2023-08-09 16:16:22,581:INFO:Declaring metric variables
2023-08-09 16:16:22,583:INFO:Defining Hyperparameters
2023-08-09 16:16:22,973:INFO:Tuning with n_jobs=-1
2023-08-09 16:16:22,973:INFO:Initializing RandomizedSearchCV
2023-08-09 16:16:36,729:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.0001, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 180, 'actual_estimator__min_split_gain': 0.7, 'actual_estimator__min_child_samples': 96, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 4, 'actual_estimator__bagging_fraction': 0.6}
2023-08-09 16:16:36,729:INFO:Hyperparameter search completed
2023-08-09 16:16:36,730:INFO:SubProcess create_model() called ==================================
2023-08-09 16:16:36,730:INFO:Initializing create_model()
2023-08-09 16:16:36,730:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002370651E1A0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.0001, 'num_leaves': 10, 'n_estimators': 180, 'min_split_gain': 0.7, 'min_child_samples': 96, 'learning_rate': 0.05, 'feature_fraction': 0.9, 'bagging_freq': 4, 'bagging_fraction': 0.6})
2023-08-09 16:16:36,730:INFO:Checking exceptions
2023-08-09 16:16:36,730:INFO:Importing libraries
2023-08-09 16:16:36,730:INFO:Copying training dataset
2023-08-09 16:16:36,733:INFO:Defining folds
2023-08-09 16:16:36,733:INFO:Declaring metric variables
2023-08-09 16:16:36,735:INFO:Importing untrained model
2023-08-09 16:16:36,736:INFO:Declaring custom model
2023-08-09 16:16:36,739:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-09 16:16:36,745:INFO:Starting cross validation
2023-08-09 16:16:36,745:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:16:37,824:INFO:Calculating mean and std
2023-08-09 16:16:37,825:INFO:Creating metrics dataframe
2023-08-09 16:16:37,829:INFO:Finalizing model
2023-08-09 16:16:37,849:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-08-09 16:16:37,849:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-08-09 16:16:37,849:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-08-09 16:16:37,851:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-09 16:16:37,851:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-08-09 16:16:37,851:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-08-09 16:16:37,851:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-08-09 16:16:37,852:INFO:[LightGBM] [Info] Number of positive: 2004, number of negative: 1374
2023-08-09 16:16:37,852:INFO:[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000279 seconds.
2023-08-09 16:16:37,852:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-08-09 16:16:37,852:INFO:[LightGBM] [Info] Total Bins 748
2023-08-09 16:16:37,852:INFO:[LightGBM] [Info] Number of data points in the train set: 3378, number of used features: 17
2023-08-09 16:16:37,853:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.593250 -> initscore=0.377419
2023-08-09 16:16:37,853:INFO:[LightGBM] [Info] Start training from score 0.377419
2023-08-09 16:16:37,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:16:37,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:16:37,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:16:37,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:16:38,050:INFO:Uploading results into container
2023-08-09 16:16:38,051:INFO:Uploading model into container now
2023-08-09 16:16:38,051:INFO:_master_model_container: 21
2023-08-09 16:16:38,051:INFO:_display_container: 6
2023-08-09 16:16:38,052:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-08-09 16:16:38,052:INFO:create_model() successfully completed......................................
2023-08-09 16:16:38,419:INFO:SubProcess create_model() end ==================================
2023-08-09 16:16:38,419:INFO:choose_better activated
2023-08-09 16:16:38,422:INFO:SubProcess create_model() called ==================================
2023-08-09 16:16:38,423:INFO:Initializing create_model()
2023-08-09 16:16:38,423:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:16:38,423:INFO:Checking exceptions
2023-08-09 16:16:38,424:INFO:Importing libraries
2023-08-09 16:16:38,424:INFO:Copying training dataset
2023-08-09 16:16:38,427:INFO:Defining folds
2023-08-09 16:16:38,427:INFO:Declaring metric variables
2023-08-09 16:16:38,427:INFO:Importing untrained model
2023-08-09 16:16:38,427:INFO:Declaring custom model
2023-08-09 16:16:38,428:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-09 16:16:38,428:INFO:Starting cross validation
2023-08-09 16:16:38,428:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:16:39,445:INFO:Calculating mean and std
2023-08-09 16:16:39,445:INFO:Creating metrics dataframe
2023-08-09 16:16:39,447:INFO:Finalizing model
2023-08-09 16:16:39,620:INFO:Uploading results into container
2023-08-09 16:16:39,621:INFO:Uploading model into container now
2023-08-09 16:16:39,621:INFO:_master_model_container: 22
2023-08-09 16:16:39,621:INFO:_display_container: 7
2023-08-09 16:16:39,621:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-09 16:16:39,621:INFO:create_model() successfully completed......................................
2023-08-09 16:16:39,976:INFO:SubProcess create_model() end ==================================
2023-08-09 16:16:39,977:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.6587
2023-08-09 16:16:39,977:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.6536
2023-08-09 16:16:39,978:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2023-08-09 16:16:39,978:INFO:choose_better completed
2023-08-09 16:16:39,978:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-08-09 16:16:39,985:INFO:_master_model_container: 22
2023-08-09 16:16:39,985:INFO:_display_container: 6
2023-08-09 16:16:39,985:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-09 16:16:39,985:INFO:tune_model() successfully completed......................................
2023-08-09 16:16:40,453:INFO:Initializing create_model()
2023-08-09 16:16:40,453:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:16:40,453:INFO:Checking exceptions
2023-08-09 16:16:40,463:INFO:Importing libraries
2023-08-09 16:16:40,463:INFO:Copying training dataset
2023-08-09 16:16:40,466:INFO:Defining folds
2023-08-09 16:16:40,466:INFO:Declaring metric variables
2023-08-09 16:16:40,468:INFO:Importing untrained model
2023-08-09 16:16:40,470:INFO:Random Forest Classifier Imported successfully
2023-08-09 16:16:40,475:INFO:Starting cross validation
2023-08-09 16:16:40,475:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:16:41,649:INFO:Calculating mean and std
2023-08-09 16:16:41,650:INFO:Creating metrics dataframe
2023-08-09 16:16:41,654:INFO:Finalizing model
2023-08-09 16:16:41,838:INFO:Uploading results into container
2023-08-09 16:16:41,838:INFO:Uploading model into container now
2023-08-09 16:16:41,844:INFO:_master_model_container: 23
2023-08-09 16:16:41,845:INFO:_display_container: 7
2023-08-09 16:16:41,845:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-09 16:16:41,845:INFO:create_model() successfully completed......................................
2023-08-09 16:16:42,216:INFO:Initializing tune_model()
2023-08-09 16:16:42,216:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>)
2023-08-09 16:16:42,216:INFO:Checking exceptions
2023-08-09 16:16:42,228:INFO:Copying training dataset
2023-08-09 16:16:42,231:INFO:Checking base model
2023-08-09 16:16:42,231:INFO:Base model : Random Forest Classifier
2023-08-09 16:16:42,238:INFO:Declaring metric variables
2023-08-09 16:16:42,240:INFO:Defining Hyperparameters
2023-08-09 16:16:42,624:INFO:Tuning with n_jobs=-1
2023-08-09 16:16:42,624:INFO:Initializing RandomizedSearchCV
2023-08-09 16:16:58,025:INFO:best_params: {'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.001, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 6, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2023-08-09 16:16:58,026:INFO:Hyperparameter search completed
2023-08-09 16:16:58,027:INFO:SubProcess create_model() called ==================================
2023-08-09 16:16:58,027:INFO:Initializing create_model()
2023-08-09 16:16:58,027:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236C9C39210>, model_only=True, return_train_score=False, kwargs={'n_estimators': 190, 'min_samples_split': 9, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.001, 'max_features': 'log2', 'max_depth': 6, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2023-08-09 16:16:58,027:INFO:Checking exceptions
2023-08-09 16:16:58,027:INFO:Importing libraries
2023-08-09 16:16:58,027:INFO:Copying training dataset
2023-08-09 16:16:58,030:INFO:Defining folds
2023-08-09 16:16:58,030:INFO:Declaring metric variables
2023-08-09 16:16:58,033:INFO:Importing untrained model
2023-08-09 16:16:58,033:INFO:Declaring custom model
2023-08-09 16:16:58,035:INFO:Random Forest Classifier Imported successfully
2023-08-09 16:16:58,040:INFO:Starting cross validation
2023-08-09 16:16:58,041:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:16:59,548:INFO:Calculating mean and std
2023-08-09 16:16:59,549:INFO:Creating metrics dataframe
2023-08-09 16:16:59,554:INFO:Finalizing model
2023-08-09 16:17:00,045:INFO:Uploading results into container
2023-08-09 16:17:00,047:INFO:Uploading model into container now
2023-08-09 16:17:00,047:INFO:_master_model_container: 24
2023-08-09 16:17:00,047:INFO:_display_container: 8
2023-08-09 16:17:00,047:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=190,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2023-08-09 16:17:00,047:INFO:create_model() successfully completed......................................
2023-08-09 16:17:00,451:INFO:SubProcess create_model() end ==================================
2023-08-09 16:17:00,451:INFO:choose_better activated
2023-08-09 16:17:00,453:INFO:SubProcess create_model() called ==================================
2023-08-09 16:17:00,454:INFO:Initializing create_model()
2023-08-09 16:17:00,454:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:17:00,454:INFO:Checking exceptions
2023-08-09 16:17:00,455:INFO:Importing libraries
2023-08-09 16:17:00,455:INFO:Copying training dataset
2023-08-09 16:17:00,458:INFO:Defining folds
2023-08-09 16:17:00,458:INFO:Declaring metric variables
2023-08-09 16:17:00,458:INFO:Importing untrained model
2023-08-09 16:17:00,458:INFO:Declaring custom model
2023-08-09 16:17:00,458:INFO:Random Forest Classifier Imported successfully
2023-08-09 16:17:00,458:INFO:Starting cross validation
2023-08-09 16:17:00,459:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:17:01,833:INFO:Calculating mean and std
2023-08-09 16:17:01,833:INFO:Creating metrics dataframe
2023-08-09 16:17:01,835:INFO:Finalizing model
2023-08-09 16:17:02,035:INFO:Uploading results into container
2023-08-09 16:17:02,036:INFO:Uploading model into container now
2023-08-09 16:17:02,036:INFO:_master_model_container: 25
2023-08-09 16:17:02,036:INFO:_display_container: 9
2023-08-09 16:17:02,037:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-09 16:17:02,037:INFO:create_model() successfully completed......................................
2023-08-09 16:17:02,406:INFO:SubProcess create_model() end ==================================
2023-08-09 16:17:02,406:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) result for Accuracy is 0.6616
2023-08-09 16:17:02,406:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=190,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for Accuracy is 0.6729
2023-08-09 16:17:02,406:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=190,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False) is best model
2023-08-09 16:17:02,406:INFO:choose_better completed
2023-08-09 16:17:02,410:INFO:_master_model_container: 25
2023-08-09 16:17:02,410:INFO:_display_container: 8
2023-08-09 16:17:02,410:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=190,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2023-08-09 16:17:02,410:INFO:tune_model() successfully completed......................................
2023-08-09 16:17:02,903:INFO:Initializing blend_models()
2023-08-09 16:17:02,903:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=190,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-08-09 16:17:02,903:INFO:Checking exceptions
2023-08-09 16:17:02,914:INFO:Importing libraries
2023-08-09 16:17:02,914:INFO:Copying training dataset
2023-08-09 16:17:02,916:INFO:Getting model names
2023-08-09 16:17:02,918:INFO:SubProcess create_model() called ==================================
2023-08-09 16:17:02,920:INFO:Initializing create_model()
2023-08-09 16:17:02,921:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                                                     class_weight='balanced_subsample',
                                                     criterion='gini',
                                                     max_depth=6,
                                                     max_features='log2',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.001,
                                                     min_samples_leaf=6,
                                                     min_samples_split=9,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=190,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=123,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236FF92A140>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:17:02,921:INFO:Checking exceptions
2023-08-09 16:17:02,921:INFO:Importing libraries
2023-08-09 16:17:02,921:INFO:Copying training dataset
2023-08-09 16:17:02,924:INFO:Defining folds
2023-08-09 16:17:02,924:INFO:Declaring metric variables
2023-08-09 16:17:02,925:INFO:Importing untrained model
2023-08-09 16:17:02,925:INFO:Declaring custom model
2023-08-09 16:17:02,929:INFO:Voting Classifier Imported successfully
2023-08-09 16:17:02,933:INFO:Starting cross validation
2023-08-09 16:17:02,934:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:17:06,412:INFO:Calculating mean and std
2023-08-09 16:17:06,413:INFO:Creating metrics dataframe
2023-08-09 16:17:06,417:INFO:Finalizing model
2023-08-09 16:17:07,118:INFO:Uploading results into container
2023-08-09 16:17:07,118:INFO:Uploading model into container now
2023-08-09 16:17:07,119:INFO:_master_model_container: 26
2023-08-09 16:17:07,119:INFO:_display_container: 9
2023-08-09 16:17:07,121:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                                                     class_weight='balanced_subsample',
                                                     criterion='gini',
                                                     max_depth=6,
                                                     max_features='log2',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.001,
                                                     min_samples_leaf=6,
                                                     min_samples_split=9,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=190,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=123,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 16:17:07,121:INFO:create_model() successfully completed......................................
2023-08-09 16:17:07,497:INFO:SubProcess create_model() end ==================================
2023-08-09 16:17:07,504:INFO:_master_model_container: 26
2023-08-09 16:17:07,504:INFO:_display_container: 9
2023-08-09 16:17:07,506:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                                                     class_weight='balanced_subsample',
                                                     criterion='gini',
                                                     max_depth=6,
                                                     max_features='log2',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.001,
                                                     min_samples_leaf=6,
                                                     min_samples_split=9,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=190,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=123,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 16:17:07,506:INFO:blend_models() successfully completed......................................
2023-08-09 16:17:07,881:INFO:Initializing finalize_model()
2023-08-09 16:17:07,881:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                                                     class_weight='balanced_subsample',
                                                     criterion='gini',
                                                     max_depth=6,
                                                     max_features='log2',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.001,
                                                     min_samples_leaf=6,
                                                     min_samples_split=9,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=190,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=123,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-08-09 16:17:07,883:INFO:Finalizing VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                                                     class_weight='balanced_subsample',
                                                     criterion='gini',
                                                     max_depth=6,
                                                     max_features='log2',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.001,
                                                     min_samples_leaf=6,
                                                     min_samples_split=9,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=190,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=123,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 16:17:07,888:INFO:Initializing create_model()
2023-08-09 16:17:07,888:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                                                     class_weight='balanced_subsample',
                                                     criterion='gini',
                                                     max_depth=6,
                                                     max_features='log2',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.001,
                                                     min_samples_leaf=6,
                                                     min_samples_split=9,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=190,
                                                     n_jobs=-1, oob_score=False,
                                                     random_state=123,
                                                     verbose=0,
                                                     warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-08-09 16:17:07,888:INFO:Checking exceptions
2023-08-09 16:17:07,889:INFO:Importing libraries
2023-08-09 16:17:07,889:INFO:Copying training dataset
2023-08-09 16:17:07,889:INFO:Defining folds
2023-08-09 16:17:07,889:INFO:Declaring metric variables
2023-08-09 16:17:07,889:INFO:Importing untrained model
2023-08-09 16:17:07,889:INFO:Declaring custom model
2023-08-09 16:17:07,890:INFO:Voting Classifier Imported successfully
2023-08-09 16:17:07,891:INFO:Cross validation set to False
2023-08-09 16:17:07,891:INFO:Fitting Model
2023-08-09 16:17:08,385:INFO:Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Discount_offered',
                                             'Weight_in_gms',
                                             'Warehouse_block_A',
                                             'Warehouse_block_B',
                                             'Warehouse_block_C',
                                             'Warehouse_block_D',
                                             'Wareho...
                                                                      criterion='gini',
                                                                      max_depth=6,
                                                                      max_features='log2',
                                                                      max_leaf_nodes=None,
                                                                      max_samples=None,
                                                                      min_impurity_decrease=0.001,
                                                                      min_samples_leaf=6,
                                                                      min_samples_split=9,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      n_estimators=190,
                                                                      n_jobs=-1,
                                                                      oob_score=False,
                                                                      random_state=123,
                                                                      verbose=0,
                                                                      warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-09 16:17:08,385:INFO:create_model() successfully completed......................................
2023-08-09 16:17:08,746:INFO:_master_model_container: 26
2023-08-09 16:17:08,746:INFO:_display_container: 9
2023-08-09 16:17:08,757:INFO:Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Discount_offered',
                                             'Weight_in_gms',
                                             'Warehouse_block_A',
                                             'Warehouse_block_B',
                                             'Warehouse_block_C',
                                             'Warehouse_block_D',
                                             'Wareho...
                                                                      criterion='gini',
                                                                      max_depth=6,
                                                                      max_features='log2',
                                                                      max_leaf_nodes=None,
                                                                      max_samples=None,
                                                                      min_impurity_decrease=0.001,
                                                                      min_samples_leaf=6,
                                                                      min_samples_split=9,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      n_estimators=190,
                                                                      n_jobs=-1,
                                                                      oob_score=False,
                                                                      random_state=123,
                                                                      verbose=0,
                                                                      warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-09 16:17:08,757:INFO:finalize_model() successfully completed......................................
2023-08-09 16:17:09,142:INFO:Initializing predict_model()
2023-08-09 16:17:09,142:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Discount_offered',
                                             'Weight_in_gms',
                                             'Warehouse_block_A',
                                             'Warehouse_block_B',
                                             'Warehouse_block_C',
                                             'Warehouse_block_D',
                                             'Wareho...
                                                                      criterion='gini',
                                                                      max_depth=6,
                                                                      max_features='log2',
                                                                      max_leaf_nodes=None,
                                                                      max_samples=None,
                                                                      min_impurity_decrease=0.001,
                                                                      min_samples_leaf=6,
                                                                      min_samples_split=9,
                                                                      min_weight_fraction_leaf=0.0,
                                                                      n_estimators=190,
                                                                      n_jobs=-1,
                                                                      oob_score=False,
                                                                      random_state=123,
                                                                      verbose=0,
                                                                      warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000023706CD8F70>)
2023-08-09 16:17:09,142:INFO:Checking exceptions
2023-08-09 16:17:09,142:INFO:Preloading libraries
2023-08-09 16:17:09,144:INFO:Set up data.
2023-08-09 16:17:09,148:INFO:Set up index.
2023-08-09 16:21:26,648:INFO:Initializing create_model()
2023-08-09 16:21:26,648:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:21:26,648:INFO:Checking exceptions
2023-08-09 16:21:26,658:INFO:Importing libraries
2023-08-09 16:21:26,658:INFO:Copying training dataset
2023-08-09 16:21:26,662:INFO:Defining folds
2023-08-09 16:21:26,662:INFO:Declaring metric variables
2023-08-09 16:21:26,664:INFO:Importing untrained model
2023-08-09 16:21:26,667:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-09 16:21:26,671:INFO:Starting cross validation
2023-08-09 16:21:26,672:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:21:27,986:INFO:Calculating mean and std
2023-08-09 16:21:27,987:INFO:Creating metrics dataframe
2023-08-09 16:21:27,991:INFO:Finalizing model
2023-08-09 16:21:28,192:INFO:Uploading results into container
2023-08-09 16:21:28,193:INFO:Uploading model into container now
2023-08-09 16:21:28,199:INFO:_master_model_container: 27
2023-08-09 16:21:28,199:INFO:_display_container: 10
2023-08-09 16:21:28,199:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-09 16:21:28,200:INFO:create_model() successfully completed......................................
2023-08-09 16:21:28,853:INFO:Initializing tune_model()
2023-08-09 16:21:28,853:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>)
2023-08-09 16:21:28,853:INFO:Checking exceptions
2023-08-09 16:21:28,864:INFO:Copying training dataset
2023-08-09 16:21:28,866:INFO:Checking base model
2023-08-09 16:21:28,867:INFO:Base model : Light Gradient Boosting Machine
2023-08-09 16:21:28,869:INFO:Declaring metric variables
2023-08-09 16:21:28,872:INFO:Defining Hyperparameters
2023-08-09 16:21:29,247:INFO:Tuning with n_jobs=-1
2023-08-09 16:21:29,247:INFO:Initializing RandomizedSearchCV
2023-08-09 16:21:43,406:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.0001, 'actual_estimator__num_leaves': 10, 'actual_estimator__n_estimators': 180, 'actual_estimator__min_split_gain': 0.7, 'actual_estimator__min_child_samples': 96, 'actual_estimator__learning_rate': 0.05, 'actual_estimator__feature_fraction': 0.9, 'actual_estimator__bagging_freq': 4, 'actual_estimator__bagging_fraction': 0.6}
2023-08-09 16:21:43,407:INFO:Hyperparameter search completed
2023-08-09 16:21:43,407:INFO:SubProcess create_model() called ==================================
2023-08-09 16:21:43,408:INFO:Initializing create_model()
2023-08-09 16:21:43,408:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237100D4100>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.0001, 'num_leaves': 10, 'n_estimators': 180, 'min_split_gain': 0.7, 'min_child_samples': 96, 'learning_rate': 0.05, 'feature_fraction': 0.9, 'bagging_freq': 4, 'bagging_fraction': 0.6})
2023-08-09 16:21:43,408:INFO:Checking exceptions
2023-08-09 16:21:43,408:INFO:Importing libraries
2023-08-09 16:21:43,408:INFO:Copying training dataset
2023-08-09 16:21:43,411:INFO:Defining folds
2023-08-09 16:21:43,411:INFO:Declaring metric variables
2023-08-09 16:21:43,413:INFO:Importing untrained model
2023-08-09 16:21:43,413:INFO:Declaring custom model
2023-08-09 16:21:43,416:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-09 16:21:43,420:INFO:Starting cross validation
2023-08-09 16:21:43,421:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:21:44,711:INFO:Calculating mean and std
2023-08-09 16:21:44,712:INFO:Creating metrics dataframe
2023-08-09 16:21:44,717:INFO:Finalizing model
2023-08-09 16:21:44,736:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-08-09 16:21:44,736:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-08-09 16:21:44,736:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-08-09 16:21:44,738:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-09 16:21:44,739:INFO:[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
2023-08-09 16:21:44,739:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-08-09 16:21:44,739:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-08-09 16:21:44,739:INFO:[LightGBM] [Info] Number of positive: 2004, number of negative: 1374
2023-08-09 16:21:44,740:INFO:[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000538 seconds.
2023-08-09 16:21:44,740:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-08-09 16:21:44,740:INFO:[LightGBM] [Info] Total Bins 748
2023-08-09 16:21:44,740:INFO:[LightGBM] [Info] Number of data points in the train set: 3378, number of used features: 17
2023-08-09 16:21:44,740:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.593250 -> initscore=0.377419
2023-08-09 16:21:44,740:INFO:[LightGBM] [Info] Start training from score 0.377419
2023-08-09 16:21:44,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:21:44,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:21:44,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:21:44,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:21:44,979:INFO:Uploading results into container
2023-08-09 16:21:44,980:INFO:Uploading model into container now
2023-08-09 16:21:44,980:INFO:_master_model_container: 28
2023-08-09 16:21:44,980:INFO:_display_container: 11
2023-08-09 16:21:44,981:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-08-09 16:21:44,981:INFO:create_model() successfully completed......................................
2023-08-09 16:21:45,386:INFO:SubProcess create_model() end ==================================
2023-08-09 16:21:45,386:INFO:choose_better activated
2023-08-09 16:21:45,388:INFO:SubProcess create_model() called ==================================
2023-08-09 16:21:45,389:INFO:Initializing create_model()
2023-08-09 16:21:45,389:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:21:45,389:INFO:Checking exceptions
2023-08-09 16:21:45,390:INFO:Importing libraries
2023-08-09 16:21:45,390:INFO:Copying training dataset
2023-08-09 16:21:45,394:INFO:Defining folds
2023-08-09 16:21:45,394:INFO:Declaring metric variables
2023-08-09 16:21:45,394:INFO:Importing untrained model
2023-08-09 16:21:45,394:INFO:Declaring custom model
2023-08-09 16:21:45,394:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-09 16:21:45,394:INFO:Starting cross validation
2023-08-09 16:21:45,395:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:21:46,663:INFO:Calculating mean and std
2023-08-09 16:21:46,664:INFO:Creating metrics dataframe
2023-08-09 16:21:46,665:INFO:Finalizing model
2023-08-09 16:21:46,870:INFO:Uploading results into container
2023-08-09 16:21:46,870:INFO:Uploading model into container now
2023-08-09 16:21:46,871:INFO:_master_model_container: 29
2023-08-09 16:21:46,871:INFO:_display_container: 12
2023-08-09 16:21:46,871:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-09 16:21:46,871:INFO:create_model() successfully completed......................................
2023-08-09 16:21:47,275:INFO:SubProcess create_model() end ==================================
2023-08-09 16:21:47,275:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.6587
2023-08-09 16:21:47,276:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.9,
               importance_type='split', learning_rate=0.05, max_depth=-1,
               min_child_samples=96, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=180, n_jobs=-1, num_leaves=10, objective=None,
               random_state=123, reg_alpha=0.0001, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.6536
2023-08-09 16:21:47,276:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2023-08-09 16:21:47,276:INFO:choose_better completed
2023-08-09 16:21:47,276:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-08-09 16:21:47,283:INFO:_master_model_container: 29
2023-08-09 16:21:47,283:INFO:_display_container: 11
2023-08-09 16:21:47,284:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-09 16:21:47,284:INFO:tune_model() successfully completed......................................
2023-08-09 16:21:47,795:INFO:Initializing create_model()
2023-08-09 16:21:47,795:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:21:47,795:INFO:Checking exceptions
2023-08-09 16:21:47,807:INFO:Importing libraries
2023-08-09 16:21:47,807:INFO:Copying training dataset
2023-08-09 16:21:47,811:INFO:Defining folds
2023-08-09 16:21:47,811:INFO:Declaring metric variables
2023-08-09 16:21:47,813:INFO:Importing untrained model
2023-08-09 16:21:47,816:INFO:Random Forest Classifier Imported successfully
2023-08-09 16:21:47,822:INFO:Starting cross validation
2023-08-09 16:21:47,822:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:21:49,215:INFO:Calculating mean and std
2023-08-09 16:21:49,216:INFO:Creating metrics dataframe
2023-08-09 16:21:49,219:INFO:Finalizing model
2023-08-09 16:21:49,432:INFO:Uploading results into container
2023-08-09 16:21:49,433:INFO:Uploading model into container now
2023-08-09 16:21:49,441:INFO:_master_model_container: 30
2023-08-09 16:21:49,441:INFO:_display_container: 12
2023-08-09 16:21:49,441:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-09 16:21:49,441:INFO:create_model() successfully completed......................................
2023-08-09 16:21:49,818:INFO:Initializing tune_model()
2023-08-09 16:21:49,818:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>)
2023-08-09 16:21:49,818:INFO:Checking exceptions
2023-08-09 16:21:49,829:INFO:Copying training dataset
2023-08-09 16:21:49,831:INFO:Checking base model
2023-08-09 16:21:49,831:INFO:Base model : Random Forest Classifier
2023-08-09 16:21:49,834:INFO:Declaring metric variables
2023-08-09 16:21:49,836:INFO:Defining Hyperparameters
2023-08-09 16:21:50,246:INFO:Tuning with n_jobs=-1
2023-08-09 16:21:50,246:INFO:Initializing RandomizedSearchCV
2023-08-09 16:22:02,977:INFO:best_params: {'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.001, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 6, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2023-08-09 16:22:02,977:INFO:Hyperparameter search completed
2023-08-09 16:22:02,978:INFO:SubProcess create_model() called ==================================
2023-08-09 16:22:02,978:INFO:Initializing create_model()
2023-08-09 16:22:02,978:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236D00CFA30>, model_only=True, return_train_score=False, kwargs={'n_estimators': 190, 'min_samples_split': 9, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.001, 'max_features': 'log2', 'max_depth': 6, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2023-08-09 16:22:02,978:INFO:Checking exceptions
2023-08-09 16:22:02,979:INFO:Importing libraries
2023-08-09 16:22:02,979:INFO:Copying training dataset
2023-08-09 16:22:02,982:INFO:Defining folds
2023-08-09 16:22:02,982:INFO:Declaring metric variables
2023-08-09 16:22:02,984:INFO:Importing untrained model
2023-08-09 16:22:02,984:INFO:Declaring custom model
2023-08-09 16:22:02,988:INFO:Random Forest Classifier Imported successfully
2023-08-09 16:22:02,992:INFO:Starting cross validation
2023-08-09 16:22:02,993:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:22:04,469:INFO:Calculating mean and std
2023-08-09 16:22:04,469:INFO:Creating metrics dataframe
2023-08-09 16:22:04,474:INFO:Finalizing model
2023-08-09 16:22:04,699:INFO:Uploading results into container
2023-08-09 16:22:04,699:INFO:Uploading model into container now
2023-08-09 16:22:04,700:INFO:_master_model_container: 31
2023-08-09 16:22:04,700:INFO:_display_container: 13
2023-08-09 16:22:04,700:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=190,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2023-08-09 16:22:04,700:INFO:create_model() successfully completed......................................
2023-08-09 16:22:05,079:INFO:SubProcess create_model() end ==================================
2023-08-09 16:22:05,079:INFO:choose_better activated
2023-08-09 16:22:05,082:INFO:SubProcess create_model() called ==================================
2023-08-09 16:22:05,082:INFO:Initializing create_model()
2023-08-09 16:22:05,082:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:22:05,083:INFO:Checking exceptions
2023-08-09 16:22:05,084:INFO:Importing libraries
2023-08-09 16:22:05,084:INFO:Copying training dataset
2023-08-09 16:22:05,088:INFO:Defining folds
2023-08-09 16:22:05,088:INFO:Declaring metric variables
2023-08-09 16:22:05,088:INFO:Importing untrained model
2023-08-09 16:22:05,088:INFO:Declaring custom model
2023-08-09 16:22:05,088:INFO:Random Forest Classifier Imported successfully
2023-08-09 16:22:05,088:INFO:Starting cross validation
2023-08-09 16:22:05,089:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:22:06,431:INFO:Calculating mean and std
2023-08-09 16:22:06,431:INFO:Creating metrics dataframe
2023-08-09 16:22:06,433:INFO:Finalizing model
2023-08-09 16:22:06,639:INFO:Uploading results into container
2023-08-09 16:22:06,640:INFO:Uploading model into container now
2023-08-09 16:22:06,640:INFO:_master_model_container: 32
2023-08-09 16:22:06,640:INFO:_display_container: 14
2023-08-09 16:22:06,640:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-09 16:22:06,641:INFO:create_model() successfully completed......................................
2023-08-09 16:22:07,013:INFO:SubProcess create_model() end ==================================
2023-08-09 16:22:07,014:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) result for Accuracy is 0.6616
2023-08-09 16:22:07,014:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=190,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for Accuracy is 0.6729
2023-08-09 16:22:07,015:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=190,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False) is best model
2023-08-09 16:22:07,015:INFO:choose_better completed
2023-08-09 16:22:07,022:INFO:_master_model_container: 32
2023-08-09 16:22:07,022:INFO:_display_container: 13
2023-08-09 16:22:07,022:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=190,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2023-08-09 16:22:07,022:INFO:tune_model() successfully completed......................................
2023-08-09 16:22:07,525:INFO:Initializing create_model()
2023-08-09 16:22:07,525:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:22:07,525:INFO:Checking exceptions
2023-08-09 16:22:07,535:INFO:Importing libraries
2023-08-09 16:22:07,535:INFO:Copying training dataset
2023-08-09 16:22:07,538:INFO:Defining folds
2023-08-09 16:22:07,538:INFO:Declaring metric variables
2023-08-09 16:22:07,540:INFO:Importing untrained model
2023-08-09 16:22:07,542:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:22:07,546:INFO:Starting cross validation
2023-08-09 16:22:07,546:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:22:08,775:INFO:Calculating mean and std
2023-08-09 16:22:08,776:INFO:Creating metrics dataframe
2023-08-09 16:22:08,782:INFO:Finalizing model
2023-08-09 16:22:08,970:INFO:Uploading results into container
2023-08-09 16:22:08,971:INFO:Uploading model into container now
2023-08-09 16:22:08,977:INFO:_master_model_container: 33
2023-08-09 16:22:08,977:INFO:_display_container: 14
2023-08-09 16:22:08,978:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:22:08,978:INFO:create_model() successfully completed......................................
2023-08-09 16:22:09,382:INFO:Initializing tune_model()
2023-08-09 16:22:09,382:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>)
2023-08-09 16:22:09,382:INFO:Checking exceptions
2023-08-09 16:22:09,393:INFO:Copying training dataset
2023-08-09 16:22:09,395:INFO:Checking base model
2023-08-09 16:22:09,395:INFO:Base model : Gradient Boosting Classifier
2023-08-09 16:22:09,397:INFO:Declaring metric variables
2023-08-09 16:22:09,400:INFO:Defining Hyperparameters
2023-08-09 16:22:09,805:INFO:Tuning with n_jobs=-1
2023-08-09 16:22:09,805:INFO:Initializing RandomizedSearchCV
2023-08-09 16:22:22,319:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 140, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.05, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.01}
2023-08-09 16:22:22,320:INFO:Hyperparameter search completed
2023-08-09 16:22:22,320:INFO:SubProcess create_model() called ==================================
2023-08-09 16:22:22,321:INFO:Initializing create_model()
2023-08-09 16:22:22,321:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236CE236A70>, model_only=True, return_train_score=False, kwargs={'subsample': 0.35, 'n_estimators': 140, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.05, 'max_features': 'sqrt', 'max_depth': 7, 'learning_rate': 0.01})
2023-08-09 16:22:22,321:INFO:Checking exceptions
2023-08-09 16:22:22,321:INFO:Importing libraries
2023-08-09 16:22:22,321:INFO:Copying training dataset
2023-08-09 16:22:22,322:INFO:Defining folds
2023-08-09 16:22:22,322:INFO:Declaring metric variables
2023-08-09 16:22:22,327:INFO:Importing untrained model
2023-08-09 16:22:22,328:INFO:Declaring custom model
2023-08-09 16:22:22,330:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:22:22,335:INFO:Starting cross validation
2023-08-09 16:22:22,335:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:22:23,658:INFO:Calculating mean and std
2023-08-09 16:22:23,659:INFO:Creating metrics dataframe
2023-08-09 16:22:23,664:INFO:Finalizing model
2023-08-09 16:22:23,860:INFO:Uploading results into container
2023-08-09 16:22:23,860:INFO:Uploading model into container now
2023-08-09 16:22:23,861:INFO:_master_model_container: 34
2023-08-09 16:22:23,861:INFO:_display_container: 15
2023-08-09 16:22:23,861:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:22:23,861:INFO:create_model() successfully completed......................................
2023-08-09 16:22:24,271:INFO:SubProcess create_model() end ==================================
2023-08-09 16:22:24,271:INFO:choose_better activated
2023-08-09 16:22:24,273:INFO:SubProcess create_model() called ==================================
2023-08-09 16:22:24,274:INFO:Initializing create_model()
2023-08-09 16:22:24,274:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:22:24,274:INFO:Checking exceptions
2023-08-09 16:22:24,275:INFO:Importing libraries
2023-08-09 16:22:24,275:INFO:Copying training dataset
2023-08-09 16:22:24,278:INFO:Defining folds
2023-08-09 16:22:24,278:INFO:Declaring metric variables
2023-08-09 16:22:24,278:INFO:Importing untrained model
2023-08-09 16:22:24,278:INFO:Declaring custom model
2023-08-09 16:22:24,278:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:22:24,279:INFO:Starting cross validation
2023-08-09 16:22:24,279:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:22:25,524:INFO:Calculating mean and std
2023-08-09 16:22:25,524:INFO:Creating metrics dataframe
2023-08-09 16:22:25,525:INFO:Finalizing model
2023-08-09 16:22:25,705:INFO:Uploading results into container
2023-08-09 16:22:25,707:INFO:Uploading model into container now
2023-08-09 16:22:25,707:INFO:_master_model_container: 35
2023-08-09 16:22:25,707:INFO:_display_container: 16
2023-08-09 16:22:25,708:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:22:25,708:INFO:create_model() successfully completed......................................
2023-08-09 16:22:26,076:INFO:SubProcess create_model() end ==================================
2023-08-09 16:22:26,077:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.6539
2023-08-09 16:22:26,077:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.6548
2023-08-09 16:22:26,078:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-08-09 16:22:26,078:INFO:choose_better completed
2023-08-09 16:22:26,085:INFO:_master_model_container: 35
2023-08-09 16:22:26,085:INFO:_display_container: 15
2023-08-09 16:22:26,085:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:22:26,085:INFO:tune_model() successfully completed......................................
2023-08-09 16:22:26,581:INFO:Initializing blend_models()
2023-08-09 16:22:26,581:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=190,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-08-09 16:22:26,581:INFO:Checking exceptions
2023-08-09 16:22:26,592:INFO:Importing libraries
2023-08-09 16:22:26,592:INFO:Copying training dataset
2023-08-09 16:22:26,594:INFO:Getting model names
2023-08-09 16:22:26,597:INFO:SubProcess create_model() called ==================================
2023-08-09 16:22:26,600:INFO:Initializing create_model()
2023-08-09 16:22:26,600:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                                                         max_depth=7,
                                                         max_features='sqrt',
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.05,
                                                         min_samples_leaf=2,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=140,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=0.35,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023708C41DE0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:22:26,600:INFO:Checking exceptions
2023-08-09 16:22:26,600:INFO:Importing libraries
2023-08-09 16:22:26,600:INFO:Copying training dataset
2023-08-09 16:22:26,603:INFO:Defining folds
2023-08-09 16:22:26,603:INFO:Declaring metric variables
2023-08-09 16:22:26,605:INFO:Importing untrained model
2023-08-09 16:22:26,605:INFO:Declaring custom model
2023-08-09 16:22:26,608:INFO:Voting Classifier Imported successfully
2023-08-09 16:22:26,612:INFO:Starting cross validation
2023-08-09 16:22:26,612:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:22:30,848:INFO:Calculating mean and std
2023-08-09 16:22:30,849:INFO:Creating metrics dataframe
2023-08-09 16:22:30,853:INFO:Finalizing model
2023-08-09 16:22:31,814:INFO:Uploading results into container
2023-08-09 16:22:31,815:INFO:Uploading model into container now
2023-08-09 16:22:31,815:INFO:_master_model_container: 36
2023-08-09 16:22:31,815:INFO:_display_container: 16
2023-08-09 16:22:31,819:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                                                         max_depth=7,
                                                         max_features='sqrt',
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.05,
                                                         min_samples_leaf=2,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=140,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=0.35,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 16:22:31,819:INFO:create_model() successfully completed......................................
2023-08-09 16:22:32,199:INFO:SubProcess create_model() end ==================================
2023-08-09 16:22:32,206:INFO:_master_model_container: 36
2023-08-09 16:22:32,206:INFO:_display_container: 16
2023-08-09 16:22:32,209:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                                                         max_depth=7,
                                                         max_features='sqrt',
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.05,
                                                         min_samples_leaf=2,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=140,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=0.35,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 16:22:32,209:INFO:blend_models() successfully completed......................................
2023-08-09 16:22:32,595:INFO:Initializing finalize_model()
2023-08-09 16:22:32,595:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                                                         max_depth=7,
                                                         max_features='sqrt',
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.05,
                                                         min_samples_leaf=2,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=140,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=0.35,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-08-09 16:22:32,599:INFO:Finalizing VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                                                         max_depth=7,
                                                         max_features='sqrt',
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.05,
                                                         min_samples_leaf=2,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=140,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=0.35,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 16:22:32,605:INFO:Initializing create_model()
2023-08-09 16:22:32,605:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                                                         max_depth=7,
                                                         max_features='sqrt',
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.05,
                                                         min_samples_leaf=2,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=140,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=0.35,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-08-09 16:22:32,605:INFO:Checking exceptions
2023-08-09 16:22:32,605:INFO:Importing libraries
2023-08-09 16:22:32,606:INFO:Copying training dataset
2023-08-09 16:22:32,606:INFO:Defining folds
2023-08-09 16:22:32,606:INFO:Declaring metric variables
2023-08-09 16:22:32,606:INFO:Importing untrained model
2023-08-09 16:22:32,606:INFO:Declaring custom model
2023-08-09 16:22:32,607:INFO:Voting Classifier Imported successfully
2023-08-09 16:22:32,607:INFO:Cross validation set to False
2023-08-09 16:22:32,608:INFO:Fitting Model
2023-08-09 16:22:33,408:INFO:Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Discount_offered',
                                             'Weight_in_gms',
                                             'Warehouse_block_A',
                                             'Warehouse_block_B',
                                             'Warehouse_block_C',
                                             'Warehouse_block_D',
                                             'Wareho...
                                                                          max_features='sqrt',
                                                                          max_leaf_nodes=None,
                                                                          min_impurity_decrease=0.05,
                                                                          min_samples_leaf=2,
                                                                          min_samples_split=2,
                                                                          min_weight_fraction_leaf=0.0,
                                                                          n_estimators=140,
                                                                          n_iter_no_change=None,
                                                                          random_state=123,
                                                                          subsample=0.35,
                                                                          tol=0.0001,
                                                                          validation_fraction=0.1,
                                                                          verbose=0,
                                                                          warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-09 16:22:33,409:INFO:create_model() successfully completed......................................
2023-08-09 16:22:33,795:INFO:_master_model_container: 36
2023-08-09 16:22:33,795:INFO:_display_container: 16
2023-08-09 16:22:33,807:INFO:Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Discount_offered',
                                             'Weight_in_gms',
                                             'Warehouse_block_A',
                                             'Warehouse_block_B',
                                             'Warehouse_block_C',
                                             'Warehouse_block_D',
                                             'Wareho...
                                                                          max_features='sqrt',
                                                                          max_leaf_nodes=None,
                                                                          min_impurity_decrease=0.05,
                                                                          min_samples_leaf=2,
                                                                          min_samples_split=2,
                                                                          min_weight_fraction_leaf=0.0,
                                                                          n_estimators=140,
                                                                          n_iter_no_change=None,
                                                                          random_state=123,
                                                                          subsample=0.35,
                                                                          tol=0.0001,
                                                                          validation_fraction=0.1,
                                                                          verbose=0,
                                                                          warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-09 16:22:33,807:INFO:finalize_model() successfully completed......................................
2023-08-09 16:22:34,315:INFO:Initializing predict_model()
2023-08-09 16:22:34,322:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000236D7F07CA0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Discount_offered',
                                             'Weight_in_gms',
                                             'Warehouse_block_A',
                                             'Warehouse_block_B',
                                             'Warehouse_block_C',
                                             'Warehouse_block_D',
                                             'Wareho...
                                                                          max_features='sqrt',
                                                                          max_leaf_nodes=None,
                                                                          min_impurity_decrease=0.05,
                                                                          min_samples_leaf=2,
                                                                          min_samples_split=2,
                                                                          min_weight_fraction_leaf=0.0,
                                                                          n_estimators=140,
                                                                          n_iter_no_change=None,
                                                                          random_state=123,
                                                                          subsample=0.35,
                                                                          tol=0.0001,
                                                                          validation_fraction=0.1,
                                                                          verbose=0,
                                                                          warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000236CFE2D750>)
2023-08-09 16:22:34,322:INFO:Checking exceptions
2023-08-09 16:22:34,322:INFO:Preloading libraries
2023-08-09 16:22:34,325:INFO:Set up data.
2023-08-09 16:22:34,328:INFO:Set up index.
2023-08-09 16:24:00,973:INFO:PyCaret ClassificationExperiment
2023-08-09 16:24:00,973:INFO:Logging name: clf-default-name
2023-08-09 16:24:00,973:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-09 16:24:00,973:INFO:version 3.0.4
2023-08-09 16:24:00,973:INFO:Initializing setup()
2023-08-09 16:24:00,973:INFO:self.USI: 78c6
2023-08-09 16:24:00,973:INFO:self._variable_keys: {'data', 'y_train', 'USI', 'html_param', 'seed', 'target_param', 'exp_name_log', 'fold_groups_param', 'y', 'gpu_param', '_available_plots', 'gpu_n_jobs_param', 'fold_shuffle_param', 'pipeline', 'memory', 'X', 'fix_imbalance', 'fold_generator', 'is_multiclass', '_ml_usecase', 'log_plots_param', 'X_test', 'y_test', 'logging_param', 'n_jobs_param', 'exp_id', 'X_train', 'idx'}
2023-08-09 16:24:00,973:INFO:Checking environment
2023-08-09 16:24:00,973:INFO:python_version: 3.10.12
2023-08-09 16:24:00,973:INFO:python_build: ('main', 'Jul  5 2023 19:09:20')
2023-08-09 16:24:00,973:INFO:machine: AMD64
2023-08-09 16:24:00,973:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-09 16:24:00,973:INFO:Memory: svmem(total=16828977152, available=3803443200, percent=77.4, used=13025533952, free=3803443200)
2023-08-09 16:24:00,973:INFO:Physical Core: 14
2023-08-09 16:24:00,973:INFO:Logical Core: 20
2023-08-09 16:24:00,973:INFO:Checking libraries
2023-08-09 16:24:00,973:INFO:System:
2023-08-09 16:24:00,973:INFO:    python: 3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:09:20) [MSC v.1916 64 bit (AMD64)]
2023-08-09 16:24:00,973:INFO:executable: C:\Users\user21\anaconda3\python.exe
2023-08-09 16:24:00,973:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-09 16:24:00,973:INFO:PyCaret required dependencies:
2023-08-09 16:24:00,974:INFO:                 pip: 23.2.1
2023-08-09 16:24:00,974:INFO:          setuptools: 68.0.0
2023-08-09 16:24:00,974:INFO:             pycaret: 3.0.4
2023-08-09 16:24:00,974:INFO:             IPython: 8.12.0
2023-08-09 16:24:00,974:INFO:          ipywidgets: 8.1.0
2023-08-09 16:24:00,974:INFO:                tqdm: 4.65.0
2023-08-09 16:24:00,974:INFO:               numpy: 1.23.5
2023-08-09 16:24:00,974:INFO:              pandas: 1.5.3
2023-08-09 16:24:00,974:INFO:              jinja2: 3.1.2
2023-08-09 16:24:00,974:INFO:               scipy: 1.11.1
2023-08-09 16:24:00,974:INFO:              joblib: 1.3.1
2023-08-09 16:24:00,974:INFO:             sklearn: 1.2.2
2023-08-09 16:24:00,974:INFO:                pyod: 1.1.0
2023-08-09 16:24:00,974:INFO:            imblearn: 0.11.0
2023-08-09 16:24:00,974:INFO:   category_encoders: 2.6.1
2023-08-09 16:24:00,974:INFO:            lightgbm: 4.0.0
2023-08-09 16:24:00,974:INFO:               numba: 0.57.1
2023-08-09 16:24:00,974:INFO:            requests: 2.31.0
2023-08-09 16:24:00,974:INFO:          matplotlib: 3.7.2
2023-08-09 16:24:00,974:INFO:          scikitplot: 0.3.7
2023-08-09 16:24:00,974:INFO:         yellowbrick: 1.5
2023-08-09 16:24:00,974:INFO:              plotly: 5.15.0
2023-08-09 16:24:00,974:INFO:    plotly-resampler: Not installed
2023-08-09 16:24:00,974:INFO:             kaleido: 0.2.1
2023-08-09 16:24:00,974:INFO:           schemdraw: 0.15
2023-08-09 16:24:00,974:INFO:         statsmodels: 0.14.0
2023-08-09 16:24:00,974:INFO:              sktime: 0.21.0
2023-08-09 16:24:00,974:INFO:               tbats: 1.1.3
2023-08-09 16:24:00,974:INFO:            pmdarima: 2.0.3
2023-08-09 16:24:00,974:INFO:              psutil: 5.9.0
2023-08-09 16:24:00,974:INFO:          markupsafe: 2.1.1
2023-08-09 16:24:00,974:INFO:             pickle5: Not installed
2023-08-09 16:24:00,974:INFO:         cloudpickle: 2.2.1
2023-08-09 16:24:00,974:INFO:         deprecation: 2.1.0
2023-08-09 16:24:00,974:INFO:              xxhash: 3.3.0
2023-08-09 16:24:00,974:INFO:           wurlitzer: Not installed
2023-08-09 16:24:00,974:INFO:PyCaret optional dependencies:
2023-08-09 16:24:00,974:INFO:                shap: Not installed
2023-08-09 16:24:00,974:INFO:           interpret: Not installed
2023-08-09 16:24:00,974:INFO:                umap: Not installed
2023-08-09 16:24:00,974:INFO:    pandas_profiling: Not installed
2023-08-09 16:24:00,974:INFO:  explainerdashboard: Not installed
2023-08-09 16:24:00,974:INFO:             autoviz: Not installed
2023-08-09 16:24:00,974:INFO:           fairlearn: Not installed
2023-08-09 16:24:00,974:INFO:          deepchecks: Not installed
2023-08-09 16:24:00,974:INFO:             xgboost: 1.7.6
2023-08-09 16:24:00,974:INFO:            catboost: 1.2
2023-08-09 16:24:00,974:INFO:              kmodes: Not installed
2023-08-09 16:24:00,974:INFO:             mlxtend: Not installed
2023-08-09 16:24:00,974:INFO:       statsforecast: Not installed
2023-08-09 16:24:00,974:INFO:        tune_sklearn: Not installed
2023-08-09 16:24:00,975:INFO:                 ray: Not installed
2023-08-09 16:24:00,975:INFO:            hyperopt: Not installed
2023-08-09 16:24:00,975:INFO:              optuna: 3.2.0
2023-08-09 16:24:00,975:INFO:               skopt: Not installed
2023-08-09 16:24:00,975:INFO:              mlflow: Not installed
2023-08-09 16:24:00,975:INFO:              gradio: Not installed
2023-08-09 16:24:00,975:INFO:             fastapi: Not installed
2023-08-09 16:24:00,975:INFO:             uvicorn: Not installed
2023-08-09 16:24:00,975:INFO:              m2cgen: Not installed
2023-08-09 16:24:00,975:INFO:           evidently: Not installed
2023-08-09 16:24:00,975:INFO:               fugue: Not installed
2023-08-09 16:24:00,975:INFO:           streamlit: Not installed
2023-08-09 16:24:00,975:INFO:             prophet: Not installed
2023-08-09 16:24:00,975:INFO:None
2023-08-09 16:24:00,975:INFO:Set up data.
2023-08-09 16:24:00,979:INFO:Set up train/test split.
2023-08-09 16:24:00,984:INFO:Set up index.
2023-08-09 16:24:00,984:INFO:Set up folding strategy.
2023-08-09 16:24:00,984:INFO:Assigning column types.
2023-08-09 16:24:00,987:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-09 16:24:01,015:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-09 16:24:01,015:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 16:24:01,034:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:24:01,035:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:24:01,064:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-09 16:24:01,065:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 16:24:01,082:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:24:01,084:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:24:01,085:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-09 16:24:01,113:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 16:24:01,131:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:24:01,132:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:24:01,161:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 16:24:01,180:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:24:01,181:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:24:01,181:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-09 16:24:01,227:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:24:01,229:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:24:01,277:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:24:01,279:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:24:01,280:INFO:Preparing preprocessing pipeline...
2023-08-09 16:24:01,281:INFO:Set up simple imputation.
2023-08-09 16:24:01,282:INFO:Set up encoding of categorical features.
2023-08-09 16:24:01,284:INFO:Set up column name cleaning.
2023-08-09 16:24:01,347:INFO:Finished creating preprocessing pipeline.
2023-08-09 16:24:01,351:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_fea...
                                    transformer=OneHotEncoder(cols=['Warehouse_block',
                                                                    'Mode_of_Shipment',
                                                                    'Product_importance'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-09 16:24:01,351:INFO:Creating final display dataframe.
2023-08-09 16:24:01,510:INFO:Setup _display_container:                     Description                Value
0                    Session id                  123
1                        Target  Reached.on.Time_Y.N
2                   Target type               Binary
3           Original data shape           (6897, 10)
4        Transformed data shape           (6897, 18)
5   Transformed train set shape           (4827, 18)
6    Transformed test set shape           (2070, 18)
7              Numeric features                    6
8          Categorical features                    3
9                    Preprocess                 True
10              Imputation type               simple
11           Numeric imputation                 mean
12       Categorical imputation                 mode
13     Maximum one-hot encoding                   25
14              Encoding method                 None
15               Fold Generator      StratifiedKFold
16                  Fold Number                   10
17                     CPU Jobs                   -1
18                      Use GPU                False
19               Log Experiment                False
20              Experiment Name     clf-default-name
21                          USI                 78c6
2023-08-09 16:24:01,562:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:24:01,564:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:24:01,610:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:24:01,611:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:24:01,612:INFO:setup() successfully completed in 0.76s...............
2023-08-09 16:24:01,737:INFO:Initializing compare_models()
2023-08-09 16:24:01,737:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-09 16:24:01,737:INFO:Checking exceptions
2023-08-09 16:24:01,740:INFO:Preparing display monitor
2023-08-09 16:24:01,756:INFO:Initializing Logistic Regression
2023-08-09 16:24:01,756:INFO:Total runtime is 0.0 minutes
2023-08-09 16:24:01,758:INFO:SubProcess create_model() called ==================================
2023-08-09 16:24:01,758:INFO:Initializing create_model()
2023-08-09 16:24:01,759:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237061E3910>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:24:01,759:INFO:Checking exceptions
2023-08-09 16:24:01,759:INFO:Importing libraries
2023-08-09 16:24:01,759:INFO:Copying training dataset
2023-08-09 16:24:01,762:INFO:Defining folds
2023-08-09 16:24:01,762:INFO:Declaring metric variables
2023-08-09 16:24:01,764:INFO:Importing untrained model
2023-08-09 16:24:01,766:INFO:Logistic Regression Imported successfully
2023-08-09 16:24:01,771:INFO:Starting cross validation
2023-08-09 16:24:01,771:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:24:03,180:INFO:Calculating mean and std
2023-08-09 16:24:03,181:INFO:Creating metrics dataframe
2023-08-09 16:24:03,348:INFO:Uploading results into container
2023-08-09 16:24:03,349:INFO:Uploading model into container now
2023-08-09 16:24:03,351:INFO:_master_model_container: 1
2023-08-09 16:24:03,351:INFO:_display_container: 2
2023-08-09 16:24:03,351:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-09 16:24:03,351:INFO:create_model() successfully completed......................................
2023-08-09 16:24:03,747:INFO:SubProcess create_model() end ==================================
2023-08-09 16:24:03,748:INFO:Creating metrics dataframe
2023-08-09 16:24:03,753:INFO:Initializing K Neighbors Classifier
2023-08-09 16:24:03,753:INFO:Total runtime is 0.03328544696172078 minutes
2023-08-09 16:24:03,756:INFO:SubProcess create_model() called ==================================
2023-08-09 16:24:03,756:INFO:Initializing create_model()
2023-08-09 16:24:03,756:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237061E3910>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:24:03,756:INFO:Checking exceptions
2023-08-09 16:24:03,756:INFO:Importing libraries
2023-08-09 16:24:03,756:INFO:Copying training dataset
2023-08-09 16:24:03,760:INFO:Defining folds
2023-08-09 16:24:03,760:INFO:Declaring metric variables
2023-08-09 16:24:03,763:INFO:Importing untrained model
2023-08-09 16:24:03,766:INFO:K Neighbors Classifier Imported successfully
2023-08-09 16:24:03,769:INFO:Starting cross validation
2023-08-09 16:24:03,770:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:24:05,283:INFO:Calculating mean and std
2023-08-09 16:24:05,284:INFO:Creating metrics dataframe
2023-08-09 16:24:05,450:INFO:Uploading results into container
2023-08-09 16:24:05,450:INFO:Uploading model into container now
2023-08-09 16:24:05,451:INFO:_master_model_container: 2
2023-08-09 16:24:05,451:INFO:_display_container: 2
2023-08-09 16:24:05,451:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-09 16:24:05,451:INFO:create_model() successfully completed......................................
2023-08-09 16:24:05,831:INFO:SubProcess create_model() end ==================================
2023-08-09 16:24:05,831:INFO:Creating metrics dataframe
2023-08-09 16:24:05,837:INFO:Initializing Naive Bayes
2023-08-09 16:24:05,837:INFO:Total runtime is 0.06801547606786092 minutes
2023-08-09 16:24:05,839:INFO:SubProcess create_model() called ==================================
2023-08-09 16:24:05,839:INFO:Initializing create_model()
2023-08-09 16:24:05,839:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237061E3910>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:24:05,839:INFO:Checking exceptions
2023-08-09 16:24:05,840:INFO:Importing libraries
2023-08-09 16:24:05,840:INFO:Copying training dataset
2023-08-09 16:24:05,844:INFO:Defining folds
2023-08-09 16:24:05,844:INFO:Declaring metric variables
2023-08-09 16:24:05,847:INFO:Importing untrained model
2023-08-09 16:24:05,848:INFO:Naive Bayes Imported successfully
2023-08-09 16:24:05,853:INFO:Starting cross validation
2023-08-09 16:24:05,854:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:24:07,157:INFO:Calculating mean and std
2023-08-09 16:24:07,158:INFO:Creating metrics dataframe
2023-08-09 16:24:07,331:INFO:Uploading results into container
2023-08-09 16:24:07,331:INFO:Uploading model into container now
2023-08-09 16:24:07,332:INFO:_master_model_container: 3
2023-08-09 16:24:07,332:INFO:_display_container: 2
2023-08-09 16:24:07,332:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-09 16:24:07,332:INFO:create_model() successfully completed......................................
2023-08-09 16:24:07,712:INFO:SubProcess create_model() end ==================================
2023-08-09 16:24:07,712:INFO:Creating metrics dataframe
2023-08-09 16:24:07,720:INFO:Initializing Decision Tree Classifier
2023-08-09 16:24:07,721:INFO:Total runtime is 0.09941808382670084 minutes
2023-08-09 16:24:07,723:INFO:SubProcess create_model() called ==================================
2023-08-09 16:24:07,723:INFO:Initializing create_model()
2023-08-09 16:24:07,723:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237061E3910>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:24:07,724:INFO:Checking exceptions
2023-08-09 16:24:07,724:INFO:Importing libraries
2023-08-09 16:24:07,724:INFO:Copying training dataset
2023-08-09 16:24:07,728:INFO:Defining folds
2023-08-09 16:24:07,728:INFO:Declaring metric variables
2023-08-09 16:24:07,730:INFO:Importing untrained model
2023-08-09 16:24:07,733:INFO:Decision Tree Classifier Imported successfully
2023-08-09 16:24:07,736:INFO:Starting cross validation
2023-08-09 16:24:07,738:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:24:09,055:INFO:Calculating mean and std
2023-08-09 16:24:09,056:INFO:Creating metrics dataframe
2023-08-09 16:24:09,223:INFO:Uploading results into container
2023-08-09 16:24:09,224:INFO:Uploading model into container now
2023-08-09 16:24:09,224:INFO:_master_model_container: 4
2023-08-09 16:24:09,224:INFO:_display_container: 2
2023-08-09 16:24:09,225:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-08-09 16:24:09,225:INFO:create_model() successfully completed......................................
2023-08-09 16:24:09,597:INFO:SubProcess create_model() end ==================================
2023-08-09 16:24:09,598:INFO:Creating metrics dataframe
2023-08-09 16:24:09,605:INFO:Initializing SVM - Linear Kernel
2023-08-09 16:24:09,605:INFO:Total runtime is 0.13081065813700357 minutes
2023-08-09 16:24:09,607:INFO:SubProcess create_model() called ==================================
2023-08-09 16:24:09,607:INFO:Initializing create_model()
2023-08-09 16:24:09,607:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237061E3910>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:24:09,607:INFO:Checking exceptions
2023-08-09 16:24:09,607:INFO:Importing libraries
2023-08-09 16:24:09,607:INFO:Copying training dataset
2023-08-09 16:24:09,611:INFO:Defining folds
2023-08-09 16:24:09,612:INFO:Declaring metric variables
2023-08-09 16:24:09,614:INFO:Importing untrained model
2023-08-09 16:24:09,617:INFO:SVM - Linear Kernel Imported successfully
2023-08-09 16:24:09,621:INFO:Starting cross validation
2023-08-09 16:24:09,622:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:24:09,801:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:24:09,807:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:24:09,812:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:24:09,813:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:24:09,816:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:24:09,818:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:24:09,821:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:24:09,824:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:24:09,835:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:24:09,837:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:24:10,910:INFO:Calculating mean and std
2023-08-09 16:24:10,911:INFO:Creating metrics dataframe
2023-08-09 16:24:11,075:INFO:Uploading results into container
2023-08-09 16:24:11,075:INFO:Uploading model into container now
2023-08-09 16:24:11,075:INFO:_master_model_container: 5
2023-08-09 16:24:11,075:INFO:_display_container: 2
2023-08-09 16:24:11,076:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-09 16:24:11,076:INFO:create_model() successfully completed......................................
2023-08-09 16:24:11,475:INFO:SubProcess create_model() end ==================================
2023-08-09 16:24:11,475:INFO:Creating metrics dataframe
2023-08-09 16:24:11,483:INFO:Initializing Ridge Classifier
2023-08-09 16:24:11,483:INFO:Total runtime is 0.16210814317067462 minutes
2023-08-09 16:24:11,485:INFO:SubProcess create_model() called ==================================
2023-08-09 16:24:11,485:INFO:Initializing create_model()
2023-08-09 16:24:11,485:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237061E3910>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:24:11,485:INFO:Checking exceptions
2023-08-09 16:24:11,485:INFO:Importing libraries
2023-08-09 16:24:11,485:INFO:Copying training dataset
2023-08-09 16:24:11,489:INFO:Defining folds
2023-08-09 16:24:11,489:INFO:Declaring metric variables
2023-08-09 16:24:11,492:INFO:Importing untrained model
2023-08-09 16:24:11,494:INFO:Ridge Classifier Imported successfully
2023-08-09 16:24:11,499:INFO:Starting cross validation
2023-08-09 16:24:11,500:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:24:11,660:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:24:11,673:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:24:11,675:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:24:11,678:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:24:11,682:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:24:11,686:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:24:11,686:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:24:11,699:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:24:11,707:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:24:11,726:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:24:12,795:INFO:Calculating mean and std
2023-08-09 16:24:12,796:INFO:Creating metrics dataframe
2023-08-09 16:24:12,971:INFO:Uploading results into container
2023-08-09 16:24:12,972:INFO:Uploading model into container now
2023-08-09 16:24:12,972:INFO:_master_model_container: 6
2023-08-09 16:24:12,972:INFO:_display_container: 2
2023-08-09 16:24:12,972:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-08-09 16:24:12,972:INFO:create_model() successfully completed......................................
2023-08-09 16:24:13,357:INFO:SubProcess create_model() end ==================================
2023-08-09 16:24:13,357:INFO:Creating metrics dataframe
2023-08-09 16:24:13,364:INFO:Initializing Random Forest Classifier
2023-08-09 16:24:13,364:INFO:Total runtime is 0.1934643467267354 minutes
2023-08-09 16:24:13,367:INFO:SubProcess create_model() called ==================================
2023-08-09 16:24:13,367:INFO:Initializing create_model()
2023-08-09 16:24:13,367:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237061E3910>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:24:13,367:INFO:Checking exceptions
2023-08-09 16:24:13,367:INFO:Importing libraries
2023-08-09 16:24:13,367:INFO:Copying training dataset
2023-08-09 16:24:13,370:INFO:Defining folds
2023-08-09 16:24:13,371:INFO:Declaring metric variables
2023-08-09 16:24:13,373:INFO:Importing untrained model
2023-08-09 16:24:13,375:INFO:Random Forest Classifier Imported successfully
2023-08-09 16:24:13,380:INFO:Starting cross validation
2023-08-09 16:24:13,381:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:24:14,924:INFO:Calculating mean and std
2023-08-09 16:24:14,926:INFO:Creating metrics dataframe
2023-08-09 16:24:15,100:INFO:Uploading results into container
2023-08-09 16:24:15,101:INFO:Uploading model into container now
2023-08-09 16:24:15,101:INFO:_master_model_container: 7
2023-08-09 16:24:15,101:INFO:_display_container: 2
2023-08-09 16:24:15,101:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-09 16:24:15,102:INFO:create_model() successfully completed......................................
2023-08-09 16:24:15,480:INFO:SubProcess create_model() end ==================================
2023-08-09 16:24:15,481:INFO:Creating metrics dataframe
2023-08-09 16:24:15,489:INFO:Initializing Quadratic Discriminant Analysis
2023-08-09 16:24:15,489:INFO:Total runtime is 0.2288731535275777 minutes
2023-08-09 16:24:15,491:INFO:SubProcess create_model() called ==================================
2023-08-09 16:24:15,491:INFO:Initializing create_model()
2023-08-09 16:24:15,492:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237061E3910>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:24:15,492:INFO:Checking exceptions
2023-08-09 16:24:15,492:INFO:Importing libraries
2023-08-09 16:24:15,492:INFO:Copying training dataset
2023-08-09 16:24:15,495:INFO:Defining folds
2023-08-09 16:24:15,495:INFO:Declaring metric variables
2023-08-09 16:24:15,497:INFO:Importing untrained model
2023-08-09 16:24:15,500:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-09 16:24:15,504:INFO:Starting cross validation
2023-08-09 16:24:15,505:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:24:15,607:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:24:15,609:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:24:15,611:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:24:15,616:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:24:15,632:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:24:15,635:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:24:15,636:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:24:15,641:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:24:15,642:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:24:15,642:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:24:16,828:INFO:Calculating mean and std
2023-08-09 16:24:16,829:INFO:Creating metrics dataframe
2023-08-09 16:24:16,995:INFO:Uploading results into container
2023-08-09 16:24:16,996:INFO:Uploading model into container now
2023-08-09 16:24:16,996:INFO:_master_model_container: 8
2023-08-09 16:24:16,996:INFO:_display_container: 2
2023-08-09 16:24:16,997:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-09 16:24:16,997:INFO:create_model() successfully completed......................................
2023-08-09 16:24:17,372:INFO:SubProcess create_model() end ==================================
2023-08-09 16:24:17,373:INFO:Creating metrics dataframe
2023-08-09 16:24:17,380:INFO:Initializing Ada Boost Classifier
2023-08-09 16:24:17,380:INFO:Total runtime is 0.26039940913518267 minutes
2023-08-09 16:24:17,384:INFO:SubProcess create_model() called ==================================
2023-08-09 16:24:17,384:INFO:Initializing create_model()
2023-08-09 16:24:17,384:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237061E3910>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:24:17,384:INFO:Checking exceptions
2023-08-09 16:24:17,384:INFO:Importing libraries
2023-08-09 16:24:17,384:INFO:Copying training dataset
2023-08-09 16:24:17,387:INFO:Defining folds
2023-08-09 16:24:17,388:INFO:Declaring metric variables
2023-08-09 16:24:17,391:INFO:Importing untrained model
2023-08-09 16:24:17,394:INFO:Ada Boost Classifier Imported successfully
2023-08-09 16:24:17,398:INFO:Starting cross validation
2023-08-09 16:24:17,399:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:24:18,743:INFO:Calculating mean and std
2023-08-09 16:24:18,744:INFO:Creating metrics dataframe
2023-08-09 16:24:18,914:INFO:Uploading results into container
2023-08-09 16:24:18,914:INFO:Uploading model into container now
2023-08-09 16:24:18,914:INFO:_master_model_container: 9
2023-08-09 16:24:18,915:INFO:_display_container: 2
2023-08-09 16:24:18,915:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-08-09 16:24:18,915:INFO:create_model() successfully completed......................................
2023-08-09 16:24:19,287:INFO:SubProcess create_model() end ==================================
2023-08-09 16:24:19,288:INFO:Creating metrics dataframe
2023-08-09 16:24:19,297:INFO:Initializing Gradient Boosting Classifier
2023-08-09 16:24:19,297:INFO:Total runtime is 0.292355195681254 minutes
2023-08-09 16:24:19,300:INFO:SubProcess create_model() called ==================================
2023-08-09 16:24:19,300:INFO:Initializing create_model()
2023-08-09 16:24:19,300:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237061E3910>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:24:19,300:INFO:Checking exceptions
2023-08-09 16:24:19,300:INFO:Importing libraries
2023-08-09 16:24:19,300:INFO:Copying training dataset
2023-08-09 16:24:19,303:INFO:Defining folds
2023-08-09 16:24:19,303:INFO:Declaring metric variables
2023-08-09 16:24:19,306:INFO:Importing untrained model
2023-08-09 16:24:19,309:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:24:19,314:INFO:Starting cross validation
2023-08-09 16:24:19,315:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:24:20,693:INFO:Calculating mean and std
2023-08-09 16:24:20,694:INFO:Creating metrics dataframe
2023-08-09 16:24:20,856:INFO:Uploading results into container
2023-08-09 16:24:20,857:INFO:Uploading model into container now
2023-08-09 16:24:20,857:INFO:_master_model_container: 10
2023-08-09 16:24:20,857:INFO:_display_container: 2
2023-08-09 16:24:20,857:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:24:20,857:INFO:create_model() successfully completed......................................
2023-08-09 16:24:21,229:INFO:SubProcess create_model() end ==================================
2023-08-09 16:24:21,229:INFO:Creating metrics dataframe
2023-08-09 16:24:21,240:INFO:Initializing Linear Discriminant Analysis
2023-08-09 16:24:21,240:INFO:Total runtime is 0.324728504816691 minutes
2023-08-09 16:24:21,242:INFO:SubProcess create_model() called ==================================
2023-08-09 16:24:21,243:INFO:Initializing create_model()
2023-08-09 16:24:21,243:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237061E3910>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:24:21,243:INFO:Checking exceptions
2023-08-09 16:24:21,243:INFO:Importing libraries
2023-08-09 16:24:21,243:INFO:Copying training dataset
2023-08-09 16:24:21,246:INFO:Defining folds
2023-08-09 16:24:21,246:INFO:Declaring metric variables
2023-08-09 16:24:21,248:INFO:Importing untrained model
2023-08-09 16:24:21,251:INFO:Linear Discriminant Analysis Imported successfully
2023-08-09 16:24:21,256:INFO:Starting cross validation
2023-08-09 16:24:21,256:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:24:22,535:INFO:Calculating mean and std
2023-08-09 16:24:22,536:INFO:Creating metrics dataframe
2023-08-09 16:24:22,715:INFO:Uploading results into container
2023-08-09 16:24:22,716:INFO:Uploading model into container now
2023-08-09 16:24:22,717:INFO:_master_model_container: 11
2023-08-09 16:24:22,717:INFO:_display_container: 2
2023-08-09 16:24:22,717:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-09 16:24:22,717:INFO:create_model() successfully completed......................................
2023-08-09 16:24:23,100:INFO:SubProcess create_model() end ==================================
2023-08-09 16:24:23,100:INFO:Creating metrics dataframe
2023-08-09 16:24:23,109:INFO:Initializing Extra Trees Classifier
2023-08-09 16:24:23,109:INFO:Total runtime is 0.3558737277984619 minutes
2023-08-09 16:24:23,111:INFO:SubProcess create_model() called ==================================
2023-08-09 16:24:23,111:INFO:Initializing create_model()
2023-08-09 16:24:23,111:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237061E3910>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:24:23,111:INFO:Checking exceptions
2023-08-09 16:24:23,112:INFO:Importing libraries
2023-08-09 16:24:23,112:INFO:Copying training dataset
2023-08-09 16:24:23,115:INFO:Defining folds
2023-08-09 16:24:23,115:INFO:Declaring metric variables
2023-08-09 16:24:23,118:INFO:Importing untrained model
2023-08-09 16:24:23,120:INFO:Extra Trees Classifier Imported successfully
2023-08-09 16:24:23,125:INFO:Starting cross validation
2023-08-09 16:24:23,125:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:24:24,704:INFO:Calculating mean and std
2023-08-09 16:24:24,705:INFO:Creating metrics dataframe
2023-08-09 16:24:24,870:INFO:Uploading results into container
2023-08-09 16:24:24,870:INFO:Uploading model into container now
2023-08-09 16:24:24,870:INFO:_master_model_container: 12
2023-08-09 16:24:24,870:INFO:_display_container: 2
2023-08-09 16:24:24,871:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-08-09 16:24:24,871:INFO:create_model() successfully completed......................................
2023-08-09 16:24:25,251:INFO:SubProcess create_model() end ==================================
2023-08-09 16:24:25,251:INFO:Creating metrics dataframe
2023-08-09 16:24:25,259:INFO:Initializing Extreme Gradient Boosting
2023-08-09 16:24:25,259:INFO:Total runtime is 0.39172253211339314 minutes
2023-08-09 16:24:25,262:INFO:SubProcess create_model() called ==================================
2023-08-09 16:24:25,262:INFO:Initializing create_model()
2023-08-09 16:24:25,263:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237061E3910>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:24:25,263:INFO:Checking exceptions
2023-08-09 16:24:25,263:INFO:Importing libraries
2023-08-09 16:24:25,263:INFO:Copying training dataset
2023-08-09 16:24:25,266:INFO:Defining folds
2023-08-09 16:24:25,267:INFO:Declaring metric variables
2023-08-09 16:24:25,269:INFO:Importing untrained model
2023-08-09 16:24:25,272:INFO:Extreme Gradient Boosting Imported successfully
2023-08-09 16:24:25,275:INFO:Starting cross validation
2023-08-09 16:24:25,276:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:24:26,667:INFO:Calculating mean and std
2023-08-09 16:24:26,667:INFO:Creating metrics dataframe
2023-08-09 16:24:26,835:INFO:Uploading results into container
2023-08-09 16:24:26,835:INFO:Uploading model into container now
2023-08-09 16:24:26,836:INFO:_master_model_container: 13
2023-08-09 16:24:26,836:INFO:_display_container: 2
2023-08-09 16:24:26,836:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-09 16:24:26,836:INFO:create_model() successfully completed......................................
2023-08-09 16:24:27,218:INFO:SubProcess create_model() end ==================================
2023-08-09 16:24:27,219:INFO:Creating metrics dataframe
2023-08-09 16:24:27,229:INFO:Initializing Light Gradient Boosting Machine
2023-08-09 16:24:27,229:INFO:Total runtime is 0.4245440562566121 minutes
2023-08-09 16:24:27,232:INFO:SubProcess create_model() called ==================================
2023-08-09 16:24:27,233:INFO:Initializing create_model()
2023-08-09 16:24:27,233:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237061E3910>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:24:27,233:INFO:Checking exceptions
2023-08-09 16:24:27,233:INFO:Importing libraries
2023-08-09 16:24:27,233:INFO:Copying training dataset
2023-08-09 16:24:27,236:INFO:Defining folds
2023-08-09 16:24:27,236:INFO:Declaring metric variables
2023-08-09 16:24:27,239:INFO:Importing untrained model
2023-08-09 16:24:27,241:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-09 16:24:27,245:INFO:Starting cross validation
2023-08-09 16:24:27,246:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:24:28,637:INFO:Calculating mean and std
2023-08-09 16:24:28,637:INFO:Creating metrics dataframe
2023-08-09 16:24:28,806:INFO:Uploading results into container
2023-08-09 16:24:28,806:INFO:Uploading model into container now
2023-08-09 16:24:28,806:INFO:_master_model_container: 14
2023-08-09 16:24:28,807:INFO:_display_container: 2
2023-08-09 16:24:28,807:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-09 16:24:28,807:INFO:create_model() successfully completed......................................
2023-08-09 16:24:29,183:INFO:SubProcess create_model() end ==================================
2023-08-09 16:24:29,183:INFO:Creating metrics dataframe
2023-08-09 16:24:29,193:INFO:Initializing CatBoost Classifier
2023-08-09 16:24:29,193:INFO:Total runtime is 0.4572874148686727 minutes
2023-08-09 16:24:29,196:INFO:SubProcess create_model() called ==================================
2023-08-09 16:24:29,196:INFO:Initializing create_model()
2023-08-09 16:24:29,196:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237061E3910>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:24:29,196:INFO:Checking exceptions
2023-08-09 16:24:29,196:INFO:Importing libraries
2023-08-09 16:24:29,196:INFO:Copying training dataset
2023-08-09 16:24:29,200:INFO:Defining folds
2023-08-09 16:24:29,200:INFO:Declaring metric variables
2023-08-09 16:24:29,203:INFO:Importing untrained model
2023-08-09 16:24:29,206:INFO:CatBoost Classifier Imported successfully
2023-08-09 16:24:29,210:INFO:Starting cross validation
2023-08-09 16:24:29,211:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:24:30,502:INFO:Calculating mean and std
2023-08-09 16:24:30,503:INFO:Creating metrics dataframe
2023-08-09 16:24:30,674:INFO:Uploading results into container
2023-08-09 16:24:30,674:INFO:Uploading model into container now
2023-08-09 16:24:30,674:INFO:_master_model_container: 15
2023-08-09 16:24:30,674:INFO:_display_container: 2
2023-08-09 16:24:30,675:INFO:<catboost.core.CatBoostClassifier object at 0x00000237065BB520>
2023-08-09 16:24:30,675:INFO:create_model() successfully completed......................................
2023-08-09 16:24:31,045:INFO:SubProcess create_model() end ==================================
2023-08-09 16:24:31,045:INFO:Creating metrics dataframe
2023-08-09 16:24:31,054:INFO:Initializing Dummy Classifier
2023-08-09 16:24:31,054:INFO:Total runtime is 0.48830350637435915 minutes
2023-08-09 16:24:31,057:INFO:SubProcess create_model() called ==================================
2023-08-09 16:24:31,057:INFO:Initializing create_model()
2023-08-09 16:24:31,057:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237061E3910>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:24:31,057:INFO:Checking exceptions
2023-08-09 16:24:31,057:INFO:Importing libraries
2023-08-09 16:24:31,057:INFO:Copying training dataset
2023-08-09 16:24:31,060:INFO:Defining folds
2023-08-09 16:24:31,060:INFO:Declaring metric variables
2023-08-09 16:24:31,063:INFO:Importing untrained model
2023-08-09 16:24:31,065:INFO:Dummy Classifier Imported successfully
2023-08-09 16:24:31,069:INFO:Starting cross validation
2023-08-09 16:24:31,071:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:24:32,384:INFO:Calculating mean and std
2023-08-09 16:24:32,385:INFO:Creating metrics dataframe
2023-08-09 16:24:32,552:INFO:Uploading results into container
2023-08-09 16:24:32,553:INFO:Uploading model into container now
2023-08-09 16:24:32,553:INFO:_master_model_container: 16
2023-08-09 16:24:32,554:INFO:_display_container: 2
2023-08-09 16:24:32,554:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-08-09 16:24:32,554:INFO:create_model() successfully completed......................................
2023-08-09 16:24:32,929:INFO:SubProcess create_model() end ==================================
2023-08-09 16:24:32,929:INFO:Creating metrics dataframe
2023-08-09 16:24:32,945:INFO:Initializing create_model()
2023-08-09 16:24:32,945:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:24:32,945:INFO:Checking exceptions
2023-08-09 16:24:32,947:INFO:Importing libraries
2023-08-09 16:24:32,947:INFO:Copying training dataset
2023-08-09 16:24:32,951:INFO:Defining folds
2023-08-09 16:24:32,951:INFO:Declaring metric variables
2023-08-09 16:24:32,952:INFO:Importing untrained model
2023-08-09 16:24:32,952:INFO:Declaring custom model
2023-08-09 16:24:32,952:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:24:32,953:INFO:Cross validation set to False
2023-08-09 16:24:32,953:INFO:Fitting Model
2023-08-09 16:24:33,143:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:24:33,144:INFO:create_model() successfully completed......................................
2023-08-09 16:24:33,554:INFO:_master_model_container: 16
2023-08-09 16:24:33,554:INFO:_display_container: 2
2023-08-09 16:24:33,555:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:24:33,555:INFO:compare_models() successfully completed......................................
2023-08-09 16:24:33,556:INFO:Initializing create_model()
2023-08-09 16:24:33,556:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:24:33,556:INFO:Checking exceptions
2023-08-09 16:24:33,566:INFO:Importing libraries
2023-08-09 16:24:33,566:INFO:Copying training dataset
2023-08-09 16:24:33,570:INFO:Defining folds
2023-08-09 16:24:33,570:INFO:Declaring metric variables
2023-08-09 16:24:33,572:INFO:Importing untrained model
2023-08-09 16:24:33,575:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:24:33,580:INFO:Starting cross validation
2023-08-09 16:24:33,581:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:24:34,966:INFO:Calculating mean and std
2023-08-09 16:24:34,967:INFO:Creating metrics dataframe
2023-08-09 16:24:34,972:INFO:Finalizing model
2023-08-09 16:24:35,209:INFO:Uploading results into container
2023-08-09 16:24:35,210:INFO:Uploading model into container now
2023-08-09 16:24:35,217:INFO:_master_model_container: 17
2023-08-09 16:24:35,219:INFO:_display_container: 3
2023-08-09 16:24:35,219:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:24:35,219:INFO:create_model() successfully completed......................................
2023-08-09 16:24:35,594:INFO:Initializing tune_model()
2023-08-09 16:24:35,594:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>)
2023-08-09 16:24:35,594:INFO:Checking exceptions
2023-08-09 16:24:35,608:INFO:Copying training dataset
2023-08-09 16:24:35,611:INFO:Checking base model
2023-08-09 16:24:35,612:INFO:Base model : Gradient Boosting Classifier
2023-08-09 16:24:35,614:INFO:Declaring metric variables
2023-08-09 16:24:35,616:INFO:Defining Hyperparameters
2023-08-09 16:24:35,991:INFO:Tuning with n_jobs=-1
2023-08-09 16:24:35,991:INFO:Initializing RandomizedSearchCV
2023-08-09 16:24:48,951:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.4}
2023-08-09 16:24:48,951:INFO:Hyperparameter search completed
2023-08-09 16:24:48,952:INFO:SubProcess create_model() called ==================================
2023-08-09 16:24:48,952:INFO:Initializing create_model()
2023-08-09 16:24:48,952:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237061E2F50>, model_only=True, return_train_score=False, kwargs={'subsample': 0.7, 'n_estimators': 190, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.3, 'max_features': 'sqrt', 'max_depth': 7, 'learning_rate': 0.4})
2023-08-09 16:24:48,952:INFO:Checking exceptions
2023-08-09 16:24:48,952:INFO:Importing libraries
2023-08-09 16:24:48,952:INFO:Copying training dataset
2023-08-09 16:24:48,957:INFO:Defining folds
2023-08-09 16:24:48,957:INFO:Declaring metric variables
2023-08-09 16:24:48,958:INFO:Importing untrained model
2023-08-09 16:24:48,958:INFO:Declaring custom model
2023-08-09 16:24:48,961:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:24:48,965:INFO:Starting cross validation
2023-08-09 16:24:48,966:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:24:50,406:INFO:Calculating mean and std
2023-08-09 16:24:50,407:INFO:Creating metrics dataframe
2023-08-09 16:24:50,411:INFO:Finalizing model
2023-08-09 16:24:50,654:INFO:Uploading results into container
2023-08-09 16:24:50,655:INFO:Uploading model into container now
2023-08-09 16:24:50,655:INFO:_master_model_container: 18
2023-08-09 16:24:50,655:INFO:_display_container: 4
2023-08-09 16:24:50,655:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=123, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:24:50,655:INFO:create_model() successfully completed......................................
2023-08-09 16:24:51,029:INFO:SubProcess create_model() end ==================================
2023-08-09 16:24:51,029:INFO:choose_better activated
2023-08-09 16:24:51,031:INFO:SubProcess create_model() called ==================================
2023-08-09 16:24:51,032:INFO:Initializing create_model()
2023-08-09 16:24:51,032:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:24:51,032:INFO:Checking exceptions
2023-08-09 16:24:51,033:INFO:Importing libraries
2023-08-09 16:24:51,033:INFO:Copying training dataset
2023-08-09 16:24:51,036:INFO:Defining folds
2023-08-09 16:24:51,036:INFO:Declaring metric variables
2023-08-09 16:24:51,036:INFO:Importing untrained model
2023-08-09 16:24:51,036:INFO:Declaring custom model
2023-08-09 16:24:51,037:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:24:51,037:INFO:Starting cross validation
2023-08-09 16:24:51,038:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:24:52,408:INFO:Calculating mean and std
2023-08-09 16:24:52,408:INFO:Creating metrics dataframe
2023-08-09 16:24:52,410:INFO:Finalizing model
2023-08-09 16:24:52,651:INFO:Uploading results into container
2023-08-09 16:24:52,652:INFO:Uploading model into container now
2023-08-09 16:24:52,652:INFO:_master_model_container: 19
2023-08-09 16:24:52,652:INFO:_display_container: 5
2023-08-09 16:24:52,654:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:24:52,654:INFO:create_model() successfully completed......................................
2023-08-09 16:24:53,026:INFO:SubProcess create_model() end ==================================
2023-08-09 16:24:53,027:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.6573
2023-08-09 16:24:53,027:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=123, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.6488
2023-08-09 16:24:53,027:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-08-09 16:24:53,028:INFO:choose_better completed
2023-08-09 16:24:53,028:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-08-09 16:24:53,035:INFO:_master_model_container: 19
2023-08-09 16:24:53,035:INFO:_display_container: 4
2023-08-09 16:24:53,035:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:24:53,035:INFO:tune_model() successfully completed......................................
2023-08-09 16:25:44,636:INFO:Initializing create_model()
2023-08-09 16:25:44,636:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>, estimator=ada, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:25:44,636:INFO:Checking exceptions
2023-08-09 16:25:44,646:INFO:Importing libraries
2023-08-09 16:25:44,647:INFO:Copying training dataset
2023-08-09 16:25:44,651:INFO:Defining folds
2023-08-09 16:25:44,651:INFO:Declaring metric variables
2023-08-09 16:25:44,653:INFO:Importing untrained model
2023-08-09 16:25:44,655:INFO:Ada Boost Classifier Imported successfully
2023-08-09 16:25:44,660:INFO:Starting cross validation
2023-08-09 16:25:44,661:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:25:46,090:INFO:Calculating mean and std
2023-08-09 16:25:46,091:INFO:Creating metrics dataframe
2023-08-09 16:25:46,095:INFO:Finalizing model
2023-08-09 16:25:46,354:INFO:Uploading results into container
2023-08-09 16:25:46,355:INFO:Uploading model into container now
2023-08-09 16:25:46,362:INFO:_master_model_container: 20
2023-08-09 16:25:46,362:INFO:_display_container: 5
2023-08-09 16:25:46,362:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-08-09 16:25:46,362:INFO:create_model() successfully completed......................................
2023-08-09 16:25:46,743:INFO:Initializing tune_model()
2023-08-09 16:25:46,743:INFO:tune_model(estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>)
2023-08-09 16:25:46,743:INFO:Checking exceptions
2023-08-09 16:25:46,754:INFO:Copying training dataset
2023-08-09 16:25:46,758:INFO:Checking base model
2023-08-09 16:25:46,758:INFO:Base model : Ada Boost Classifier
2023-08-09 16:25:46,760:INFO:Declaring metric variables
2023-08-09 16:25:46,763:INFO:Defining Hyperparameters
2023-08-09 16:25:47,148:INFO:Tuning with n_jobs=-1
2023-08-09 16:25:47,148:INFO:Initializing RandomizedSearchCV
2023-08-09 16:26:04,401:INFO:best_params: {'actual_estimator__n_estimators': 260, 'actual_estimator__learning_rate': 0.0005, 'actual_estimator__algorithm': 'SAMME.R'}
2023-08-09 16:26:04,401:INFO:Hyperparameter search completed
2023-08-09 16:26:04,402:INFO:SubProcess create_model() called ==================================
2023-08-09 16:26:04,402:INFO:Initializing create_model()
2023-08-09 16:26:04,402:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236B189E050>, model_only=True, return_train_score=False, kwargs={'n_estimators': 260, 'learning_rate': 0.0005, 'algorithm': 'SAMME.R'})
2023-08-09 16:26:04,402:INFO:Checking exceptions
2023-08-09 16:26:04,402:INFO:Importing libraries
2023-08-09 16:26:04,402:INFO:Copying training dataset
2023-08-09 16:26:04,407:INFO:Defining folds
2023-08-09 16:26:04,407:INFO:Declaring metric variables
2023-08-09 16:26:04,409:INFO:Importing untrained model
2023-08-09 16:26:04,409:INFO:Declaring custom model
2023-08-09 16:26:04,412:INFO:Ada Boost Classifier Imported successfully
2023-08-09 16:26:04,416:INFO:Starting cross validation
2023-08-09 16:26:04,417:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:26:06,248:INFO:Calculating mean and std
2023-08-09 16:26:06,249:INFO:Creating metrics dataframe
2023-08-09 16:26:06,253:INFO:Finalizing model
2023-08-09 16:26:07,520:INFO:Uploading results into container
2023-08-09 16:26:07,521:INFO:Uploading model into container now
2023-08-09 16:26:07,521:INFO:_master_model_container: 21
2023-08-09 16:26:07,521:INFO:_display_container: 6
2023-08-09 16:26:07,521:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=0.0005, n_estimators=260,
                   random_state=123)
2023-08-09 16:26:07,521:INFO:create_model() successfully completed......................................
2023-08-09 16:26:07,892:INFO:SubProcess create_model() end ==================================
2023-08-09 16:26:07,892:INFO:choose_better activated
2023-08-09 16:26:07,895:INFO:SubProcess create_model() called ==================================
2023-08-09 16:26:07,895:INFO:Initializing create_model()
2023-08-09 16:26:07,895:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:26:07,895:INFO:Checking exceptions
2023-08-09 16:26:07,897:INFO:Importing libraries
2023-08-09 16:26:07,897:INFO:Copying training dataset
2023-08-09 16:26:07,900:INFO:Defining folds
2023-08-09 16:26:07,900:INFO:Declaring metric variables
2023-08-09 16:26:07,900:INFO:Importing untrained model
2023-08-09 16:26:07,900:INFO:Declaring custom model
2023-08-09 16:26:07,901:INFO:Ada Boost Classifier Imported successfully
2023-08-09 16:26:07,901:INFO:Starting cross validation
2023-08-09 16:26:07,902:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:26:09,447:INFO:Calculating mean and std
2023-08-09 16:26:09,447:INFO:Creating metrics dataframe
2023-08-09 16:26:09,449:INFO:Finalizing model
2023-08-09 16:26:09,707:INFO:Uploading results into container
2023-08-09 16:26:09,707:INFO:Uploading model into container now
2023-08-09 16:26:09,707:INFO:_master_model_container: 22
2023-08-09 16:26:09,707:INFO:_display_container: 7
2023-08-09 16:26:09,708:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-08-09 16:26:09,708:INFO:create_model() successfully completed......................................
2023-08-09 16:26:10,076:INFO:SubProcess create_model() end ==================================
2023-08-09 16:26:10,077:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123) result for Accuracy is 0.6542
2023-08-09 16:26:10,077:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=0.0005, n_estimators=260,
                   random_state=123) result for Accuracy is 0.6658
2023-08-09 16:26:10,077:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=0.0005, n_estimators=260,
                   random_state=123) is best model
2023-08-09 16:26:10,077:INFO:choose_better completed
2023-08-09 16:26:10,084:INFO:_master_model_container: 22
2023-08-09 16:26:10,084:INFO:_display_container: 6
2023-08-09 16:26:10,084:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=0.0005, n_estimators=260,
                   random_state=123)
2023-08-09 16:26:10,084:INFO:tune_model() successfully completed......................................
2023-08-09 16:26:10,587:INFO:Initializing create_model()
2023-08-09 16:26:10,587:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:26:10,587:INFO:Checking exceptions
2023-08-09 16:26:10,596:INFO:Importing libraries
2023-08-09 16:26:10,596:INFO:Copying training dataset
2023-08-09 16:26:10,599:INFO:Defining folds
2023-08-09 16:26:10,599:INFO:Declaring metric variables
2023-08-09 16:26:10,602:INFO:Importing untrained model
2023-08-09 16:26:10,604:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:26:10,609:INFO:Starting cross validation
2023-08-09 16:26:10,610:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:26:12,161:INFO:Calculating mean and std
2023-08-09 16:26:12,162:INFO:Creating metrics dataframe
2023-08-09 16:26:12,166:INFO:Finalizing model
2023-08-09 16:26:12,427:INFO:Uploading results into container
2023-08-09 16:26:12,428:INFO:Uploading model into container now
2023-08-09 16:26:12,434:INFO:_master_model_container: 23
2023-08-09 16:26:12,434:INFO:_display_container: 7
2023-08-09 16:26:12,434:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:26:12,435:INFO:create_model() successfully completed......................................
2023-08-09 16:26:12,818:INFO:Initializing tune_model()
2023-08-09 16:26:12,818:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>)
2023-08-09 16:26:12,819:INFO:Checking exceptions
2023-08-09 16:26:12,830:INFO:Copying training dataset
2023-08-09 16:26:12,832:INFO:Checking base model
2023-08-09 16:26:12,833:INFO:Base model : Gradient Boosting Classifier
2023-08-09 16:26:12,835:INFO:Declaring metric variables
2023-08-09 16:26:12,836:INFO:Defining Hyperparameters
2023-08-09 16:26:13,258:INFO:Tuning with n_jobs=-1
2023-08-09 16:26:13,258:INFO:Initializing RandomizedSearchCV
2023-08-09 16:26:28,155:INFO:best_params: {'actual_estimator__subsample': 0.7, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.3, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.4}
2023-08-09 16:26:28,155:INFO:Hyperparameter search completed
2023-08-09 16:26:28,155:INFO:SubProcess create_model() called ==================================
2023-08-09 16:26:28,156:INFO:Initializing create_model()
2023-08-09 16:26:28,156:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236CE236A70>, model_only=True, return_train_score=False, kwargs={'subsample': 0.7, 'n_estimators': 190, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.3, 'max_features': 'sqrt', 'max_depth': 7, 'learning_rate': 0.4})
2023-08-09 16:26:28,156:INFO:Checking exceptions
2023-08-09 16:26:28,156:INFO:Importing libraries
2023-08-09 16:26:28,156:INFO:Copying training dataset
2023-08-09 16:26:28,159:INFO:Defining folds
2023-08-09 16:26:28,159:INFO:Declaring metric variables
2023-08-09 16:26:28,161:INFO:Importing untrained model
2023-08-09 16:26:28,161:INFO:Declaring custom model
2023-08-09 16:26:28,163:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:26:28,168:INFO:Starting cross validation
2023-08-09 16:26:28,168:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:26:29,818:INFO:Calculating mean and std
2023-08-09 16:26:29,820:INFO:Creating metrics dataframe
2023-08-09 16:26:29,824:INFO:Finalizing model
2023-08-09 16:26:30,088:INFO:Uploading results into container
2023-08-09 16:26:30,090:INFO:Uploading model into container now
2023-08-09 16:26:30,090:INFO:_master_model_container: 24
2023-08-09 16:26:30,090:INFO:_display_container: 8
2023-08-09 16:26:30,091:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=123, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:26:30,091:INFO:create_model() successfully completed......................................
2023-08-09 16:26:30,463:INFO:SubProcess create_model() end ==================================
2023-08-09 16:26:30,463:INFO:choose_better activated
2023-08-09 16:26:30,466:INFO:SubProcess create_model() called ==================================
2023-08-09 16:26:30,466:INFO:Initializing create_model()
2023-08-09 16:26:30,467:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:26:30,467:INFO:Checking exceptions
2023-08-09 16:26:30,468:INFO:Importing libraries
2023-08-09 16:26:30,468:INFO:Copying training dataset
2023-08-09 16:26:30,472:INFO:Defining folds
2023-08-09 16:26:30,472:INFO:Declaring metric variables
2023-08-09 16:26:30,472:INFO:Importing untrained model
2023-08-09 16:26:30,472:INFO:Declaring custom model
2023-08-09 16:26:30,472:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:26:30,472:INFO:Starting cross validation
2023-08-09 16:26:30,473:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:26:31,997:INFO:Calculating mean and std
2023-08-09 16:26:31,998:INFO:Creating metrics dataframe
2023-08-09 16:26:32,000:INFO:Finalizing model
2023-08-09 16:26:32,257:INFO:Uploading results into container
2023-08-09 16:26:32,257:INFO:Uploading model into container now
2023-08-09 16:26:32,257:INFO:_master_model_container: 25
2023-08-09 16:26:32,257:INFO:_display_container: 9
2023-08-09 16:26:32,257:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:26:32,257:INFO:create_model() successfully completed......................................
2023-08-09 16:26:32,630:INFO:SubProcess create_model() end ==================================
2023-08-09 16:26:32,631:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.6573
2023-08-09 16:26:32,631:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.4, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.3, min_samples_leaf=4,
                           min_samples_split=10, min_weight_fraction_leaf=0.0,
                           n_estimators=190, n_iter_no_change=None,
                           random_state=123, subsample=0.7, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.6488
2023-08-09 16:26:32,632:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-08-09 16:26:32,632:INFO:choose_better completed
2023-08-09 16:26:32,632:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-08-09 16:26:32,639:INFO:_master_model_container: 25
2023-08-09 16:26:32,639:INFO:_display_container: 8
2023-08-09 16:26:32,639:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:26:32,639:INFO:tune_model() successfully completed......................................
2023-08-09 16:26:33,149:INFO:Initializing blend_models()
2023-08-09 16:26:33,149:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>, estimator_list=[AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=0.0005, n_estimators=260,
                   random_state=123), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-08-09 16:26:33,150:INFO:Checking exceptions
2023-08-09 16:26:33,162:INFO:Importing libraries
2023-08-09 16:26:33,162:INFO:Copying training dataset
2023-08-09 16:26:33,165:INFO:Getting model names
2023-08-09 16:26:33,166:INFO:SubProcess create_model() called ==================================
2023-08-09 16:26:33,168:INFO:Initializing create_model()
2023-08-09 16:26:33,169:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>, estimator=VotingClassifier(estimators=[('Ada Boost Classifier',
                              AdaBoostClassifier(algorithm='SAMME.R',
                                                 base_estimator='deprecated',
                                                 estimator=None,
                                                 learning_rate=0.0005,
                                                 n_estimators=260,
                                                 random_state=123)),
                             ('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236CDEB06A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:26:33,169:INFO:Checking exceptions
2023-08-09 16:26:33,169:INFO:Importing libraries
2023-08-09 16:26:33,169:INFO:Copying training dataset
2023-08-09 16:26:33,172:INFO:Defining folds
2023-08-09 16:26:33,172:INFO:Declaring metric variables
2023-08-09 16:26:33,174:INFO:Importing untrained model
2023-08-09 16:26:33,174:INFO:Declaring custom model
2023-08-09 16:26:33,177:INFO:Voting Classifier Imported successfully
2023-08-09 16:26:33,181:INFO:Starting cross validation
2023-08-09 16:26:33,182:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:26:36,771:INFO:Calculating mean and std
2023-08-09 16:26:36,772:INFO:Creating metrics dataframe
2023-08-09 16:26:36,776:INFO:Finalizing model
2023-08-09 16:26:38,217:INFO:Uploading results into container
2023-08-09 16:26:38,218:INFO:Uploading model into container now
2023-08-09 16:26:38,218:INFO:_master_model_container: 26
2023-08-09 16:26:38,218:INFO:_display_container: 9
2023-08-09 16:26:38,220:INFO:VotingClassifier(estimators=[('Ada Boost Classifier',
                              AdaBoostClassifier(algorithm='SAMME.R',
                                                 base_estimator='deprecated',
                                                 estimator=None,
                                                 learning_rate=0.0005,
                                                 n_estimators=260,
                                                 random_state=123)),
                             ('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 16:26:38,220:INFO:create_model() successfully completed......................................
2023-08-09 16:26:38,610:INFO:SubProcess create_model() end ==================================
2023-08-09 16:26:38,617:INFO:_master_model_container: 26
2023-08-09 16:26:38,617:INFO:_display_container: 9
2023-08-09 16:26:38,618:INFO:VotingClassifier(estimators=[('Ada Boost Classifier',
                              AdaBoostClassifier(algorithm='SAMME.R',
                                                 base_estimator='deprecated',
                                                 estimator=None,
                                                 learning_rate=0.0005,
                                                 n_estimators=260,
                                                 random_state=123)),
                             ('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 16:26:38,618:INFO:blend_models() successfully completed......................................
2023-08-09 16:26:39,003:INFO:Initializing finalize_model()
2023-08-09 16:26:39,003:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>, estimator=VotingClassifier(estimators=[('Ada Boost Classifier',
                              AdaBoostClassifier(algorithm='SAMME.R',
                                                 base_estimator='deprecated',
                                                 estimator=None,
                                                 learning_rate=0.0005,
                                                 n_estimators=260,
                                                 random_state=123)),
                             ('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-08-09 16:26:39,005:INFO:Finalizing VotingClassifier(estimators=[('Ada Boost Classifier',
                              AdaBoostClassifier(algorithm='SAMME.R',
                                                 base_estimator='deprecated',
                                                 estimator=None,
                                                 learning_rate=0.0005,
                                                 n_estimators=260,
                                                 random_state=123)),
                             ('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 16:26:39,008:INFO:Initializing create_model()
2023-08-09 16:26:39,008:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>, estimator=VotingClassifier(estimators=[('Ada Boost Classifier',
                              AdaBoostClassifier(algorithm='SAMME.R',
                                                 base_estimator='deprecated',
                                                 estimator=None,
                                                 learning_rate=0.0005,
                                                 n_estimators=260,
                                                 random_state=123)),
                             ('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-08-09 16:26:39,008:INFO:Checking exceptions
2023-08-09 16:26:39,009:INFO:Importing libraries
2023-08-09 16:26:39,009:INFO:Copying training dataset
2023-08-09 16:26:39,010:INFO:Defining folds
2023-08-09 16:26:39,010:INFO:Declaring metric variables
2023-08-09 16:26:39,010:INFO:Importing untrained model
2023-08-09 16:26:39,010:INFO:Declaring custom model
2023-08-09 16:26:39,010:INFO:Voting Classifier Imported successfully
2023-08-09 16:26:39,011:INFO:Cross validation set to False
2023-08-09 16:26:39,011:INFO:Fitting Model
2023-08-09 16:26:40,503:INFO:Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_fea...
                                                                          max_features=None,
                                                                          max_leaf_nodes=None,
                                                                          min_impurity_decrease=0.0,
                                                                          min_samples_leaf=1,
                                                                          min_samples_split=2,
                                                                          min_weight_fraction_leaf=0.0,
                                                                          n_estimators=100,
                                                                          n_iter_no_change=None,
                                                                          random_state=123,
                                                                          subsample=1.0,
                                                                          tol=0.0001,
                                                                          validation_fraction=0.1,
                                                                          verbose=0,
                                                                          warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-09 16:26:40,503:INFO:create_model() successfully completed......................................
2023-08-09 16:26:40,883:INFO:_master_model_container: 26
2023-08-09 16:26:40,884:INFO:_display_container: 9
2023-08-09 16:26:40,893:INFO:Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_fea...
                                                                          max_features=None,
                                                                          max_leaf_nodes=None,
                                                                          min_impurity_decrease=0.0,
                                                                          min_samples_leaf=1,
                                                                          min_samples_split=2,
                                                                          min_weight_fraction_leaf=0.0,
                                                                          n_estimators=100,
                                                                          n_iter_no_change=None,
                                                                          random_state=123,
                                                                          subsample=1.0,
                                                                          tol=0.0001,
                                                                          validation_fraction=0.1,
                                                                          verbose=0,
                                                                          warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-09 16:26:40,893:INFO:finalize_model() successfully completed......................................
2023-08-09 16:27:53,342:INFO:Initializing predict_model()
2023-08-09 16:27:53,342:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>, estimator=      Customer_care_calls  Customer_rating  Cost_of_the_Product  \
0                       3                1                  274   
1                       3                4                  136   
2                       3                5                  140   
3                       3                1                  291   
4                       4                2                  147   
...                   ...              ...                  ...   
3995                    4                1                  204   
3996                    4                3                  195   
3997                    4                3                  206   
3998                    6                4                  255   
3999                    5                1                  252   

      Prior_purchases  Discount_offered  Weight_in_gms  Warehouse_block_A  \
0                 3.0          6.567113           4352                  0   
1                 2.0         27.881276           1056                  0   
2                 3.0          7.000000           5383                  1   
3                 4.0         15.082298           1880                  0   
4                 3.0          5.000000           5174                  0   
...               ...               ...            ...                ...   
3995              4.0         21.300414           1667                  1   
3996              2.0         13.334436           3869                  0   
3997              2.0          7.000000           4531                  0   
3998              4.0          7.000000           1869                  0   
3999              5.0          4.000000           1308                  0   

      Warehouse_block_B  Warehouse_block_C  Warehouse_block_D  \
0                     0                  0                  0   
1                     0                  0                  0   
2                     0                  0                  0   
3                     0                  1                  0   
4                     0                  0                  0   
...                 ...                ...                ...   
3995                  0                  0                  0   
3996                  0                  1                  0   
3997                  1                  0                  0   
3998                  0                  1                  0   
3999                  0                  0                  1   

      Warehouse_block_F  Mode_of_Shipment_ Flight  Mode_of_Shipment_ Road  \
0                     1                         0                       0   
1                     1                         0                       0   
2                     0                         1                       0   
3                     0                         0                       0   
4                     1                         0                       0   
...                 ...                       ...                     ...   
3995                  0                         0                       0   
3996                  0                         0                       0   
3997                  0                         1                       0   
3998                  0                         0                       0   
3999                  0                         0                       0   

      Mode_of_Shipment_ Ship  Product_importance_high  Product_importance_low  \
0                          1                        1                       0   
1                          1                        0                       0   
2                          0                        0                       1   
3                          1                        0                       1   
4                          1                        0                       1   
...                      ...                      ...                     ...   
3995                       1                        0                       1   
3996                       1                        0                       0   
3997                       0                        0                       0   
3998                       1                        0                       1   
3999                       1                        0                       1   

      Product_importance_medium  
0                             0  
1                             1  
2                             0  
3                             0  
4                             0  
...                         ...  
3995                          0  
3996                          1  
3997                          1  
3998                          0  
3999                          0  

[4000 rows x 17 columns], probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002370FC3BD90>)
2023-08-09 16:27:53,342:INFO:Checking exceptions
2023-08-09 16:27:53,342:INFO:Preloading libraries
2023-08-09 16:28:16,321:INFO:Initializing predict_model()
2023-08-09 16:28:16,321:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706E33490>, estimator=Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_fea...
                                                                          max_features=None,
                                                                          max_leaf_nodes=None,
                                                                          min_impurity_decrease=0.0,
                                                                          min_samples_leaf=1,
                                                                          min_samples_split=2,
                                                                          min_weight_fraction_leaf=0.0,
                                                                          n_estimators=100,
                                                                          n_iter_no_change=None,
                                                                          random_state=123,
                                                                          subsample=1.0,
                                                                          tol=0.0001,
                                                                          validation_fraction=0.1,
                                                                          verbose=0,
                                                                          warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000237124B2CB0>)
2023-08-09 16:28:16,321:INFO:Checking exceptions
2023-08-09 16:28:16,322:INFO:Preloading libraries
2023-08-09 16:28:16,324:INFO:Set up data.
2023-08-09 16:28:16,329:INFO:Set up index.
2023-08-09 16:29:13,938:INFO:PyCaret ClassificationExperiment
2023-08-09 16:29:13,938:INFO:Logging name: clf-default-name
2023-08-09 16:29:13,938:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-09 16:29:13,938:INFO:version 3.0.4
2023-08-09 16:29:13,938:INFO:Initializing setup()
2023-08-09 16:29:13,938:INFO:self.USI: 5f9a
2023-08-09 16:29:13,938:INFO:self._variable_keys: {'data', 'y_train', 'USI', 'html_param', 'seed', 'target_param', 'exp_name_log', 'fold_groups_param', 'y', 'gpu_param', '_available_plots', 'gpu_n_jobs_param', 'fold_shuffle_param', 'pipeline', 'memory', 'X', 'fix_imbalance', 'fold_generator', 'is_multiclass', '_ml_usecase', 'log_plots_param', 'X_test', 'y_test', 'logging_param', 'n_jobs_param', 'exp_id', 'X_train', 'idx'}
2023-08-09 16:29:13,938:INFO:Checking environment
2023-08-09 16:29:13,938:INFO:python_version: 3.10.12
2023-08-09 16:29:13,938:INFO:python_build: ('main', 'Jul  5 2023 19:09:20')
2023-08-09 16:29:13,938:INFO:machine: AMD64
2023-08-09 16:29:13,938:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-09 16:29:13,938:INFO:Memory: svmem(total=16828977152, available=3694190592, percent=78.0, used=13134786560, free=3694190592)
2023-08-09 16:29:13,939:INFO:Physical Core: 14
2023-08-09 16:29:13,939:INFO:Logical Core: 20
2023-08-09 16:29:13,939:INFO:Checking libraries
2023-08-09 16:29:13,939:INFO:System:
2023-08-09 16:29:13,939:INFO:    python: 3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:09:20) [MSC v.1916 64 bit (AMD64)]
2023-08-09 16:29:13,939:INFO:executable: C:\Users\user21\anaconda3\python.exe
2023-08-09 16:29:13,939:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-09 16:29:13,939:INFO:PyCaret required dependencies:
2023-08-09 16:29:13,939:INFO:                 pip: 23.2.1
2023-08-09 16:29:13,939:INFO:          setuptools: 68.0.0
2023-08-09 16:29:13,939:INFO:             pycaret: 3.0.4
2023-08-09 16:29:13,939:INFO:             IPython: 8.12.0
2023-08-09 16:29:13,939:INFO:          ipywidgets: 8.1.0
2023-08-09 16:29:13,939:INFO:                tqdm: 4.65.0
2023-08-09 16:29:13,939:INFO:               numpy: 1.23.5
2023-08-09 16:29:13,939:INFO:              pandas: 1.5.3
2023-08-09 16:29:13,939:INFO:              jinja2: 3.1.2
2023-08-09 16:29:13,939:INFO:               scipy: 1.11.1
2023-08-09 16:29:13,939:INFO:              joblib: 1.3.1
2023-08-09 16:29:13,939:INFO:             sklearn: 1.2.2
2023-08-09 16:29:13,939:INFO:                pyod: 1.1.0
2023-08-09 16:29:13,939:INFO:            imblearn: 0.11.0
2023-08-09 16:29:13,939:INFO:   category_encoders: 2.6.1
2023-08-09 16:29:13,939:INFO:            lightgbm: 4.0.0
2023-08-09 16:29:13,939:INFO:               numba: 0.57.1
2023-08-09 16:29:13,939:INFO:            requests: 2.31.0
2023-08-09 16:29:13,939:INFO:          matplotlib: 3.7.2
2023-08-09 16:29:13,939:INFO:          scikitplot: 0.3.7
2023-08-09 16:29:13,939:INFO:         yellowbrick: 1.5
2023-08-09 16:29:13,939:INFO:              plotly: 5.15.0
2023-08-09 16:29:13,939:INFO:    plotly-resampler: Not installed
2023-08-09 16:29:13,939:INFO:             kaleido: 0.2.1
2023-08-09 16:29:13,939:INFO:           schemdraw: 0.15
2023-08-09 16:29:13,939:INFO:         statsmodels: 0.14.0
2023-08-09 16:29:13,939:INFO:              sktime: 0.21.0
2023-08-09 16:29:13,939:INFO:               tbats: 1.1.3
2023-08-09 16:29:13,939:INFO:            pmdarima: 2.0.3
2023-08-09 16:29:13,939:INFO:              psutil: 5.9.0
2023-08-09 16:29:13,939:INFO:          markupsafe: 2.1.1
2023-08-09 16:29:13,939:INFO:             pickle5: Not installed
2023-08-09 16:29:13,939:INFO:         cloudpickle: 2.2.1
2023-08-09 16:29:13,939:INFO:         deprecation: 2.1.0
2023-08-09 16:29:13,939:INFO:              xxhash: 3.3.0
2023-08-09 16:29:13,939:INFO:           wurlitzer: Not installed
2023-08-09 16:29:13,939:INFO:PyCaret optional dependencies:
2023-08-09 16:29:13,939:INFO:                shap: Not installed
2023-08-09 16:29:13,939:INFO:           interpret: Not installed
2023-08-09 16:29:13,939:INFO:                umap: Not installed
2023-08-09 16:29:13,939:INFO:    pandas_profiling: Not installed
2023-08-09 16:29:13,939:INFO:  explainerdashboard: Not installed
2023-08-09 16:29:13,939:INFO:             autoviz: Not installed
2023-08-09 16:29:13,940:INFO:           fairlearn: Not installed
2023-08-09 16:29:13,940:INFO:          deepchecks: Not installed
2023-08-09 16:29:13,940:INFO:             xgboost: 1.7.6
2023-08-09 16:29:13,940:INFO:            catboost: 1.2
2023-08-09 16:29:13,940:INFO:              kmodes: Not installed
2023-08-09 16:29:13,940:INFO:             mlxtend: Not installed
2023-08-09 16:29:13,940:INFO:       statsforecast: Not installed
2023-08-09 16:29:13,940:INFO:        tune_sklearn: Not installed
2023-08-09 16:29:13,940:INFO:                 ray: Not installed
2023-08-09 16:29:13,940:INFO:            hyperopt: Not installed
2023-08-09 16:29:13,940:INFO:              optuna: 3.2.0
2023-08-09 16:29:13,940:INFO:               skopt: Not installed
2023-08-09 16:29:13,940:INFO:              mlflow: Not installed
2023-08-09 16:29:13,940:INFO:              gradio: Not installed
2023-08-09 16:29:13,940:INFO:             fastapi: Not installed
2023-08-09 16:29:13,940:INFO:             uvicorn: Not installed
2023-08-09 16:29:13,940:INFO:              m2cgen: Not installed
2023-08-09 16:29:13,940:INFO:           evidently: Not installed
2023-08-09 16:29:13,940:INFO:               fugue: Not installed
2023-08-09 16:29:13,940:INFO:           streamlit: Not installed
2023-08-09 16:29:13,940:INFO:             prophet: Not installed
2023-08-09 16:29:13,940:INFO:None
2023-08-09 16:29:13,940:INFO:Set up data.
2023-08-09 16:29:13,946:INFO:Set up train/test split.
2023-08-09 16:29:13,950:INFO:Set up index.
2023-08-09 16:29:13,950:INFO:Set up folding strategy.
2023-08-09 16:29:13,950:INFO:Assigning column types.
2023-08-09 16:29:13,952:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-09 16:29:13,981:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-09 16:29:13,982:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 16:29:13,999:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:29:14,000:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:29:14,030:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-09 16:29:14,031:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 16:29:14,048:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:29:14,050:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:29:14,050:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-09 16:29:14,080:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 16:29:14,098:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:29:14,100:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:29:14,129:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 16:29:14,147:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:29:14,148:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:29:14,149:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-09 16:29:14,196:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:29:14,197:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:29:14,246:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:29:14,248:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:29:14,248:INFO:Preparing preprocessing pipeline...
2023-08-09 16:29:14,249:INFO:Set up simple imputation.
2023-08-09 16:29:14,251:INFO:Set up encoding of categorical features.
2023-08-09 16:29:14,251:INFO:Set up column name cleaning.
2023-08-09 16:29:14,316:INFO:Finished creating preprocessing pipeline.
2023-08-09 16:29:14,320:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing...
                                    transformer=OneHotEncoder(cols=['Warehouse_block',
                                                                    'Mode_of_Shipment',
                                                                    'Product_importance'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-09 16:29:14,320:INFO:Creating final display dataframe.
2023-08-09 16:29:14,480:INFO:Setup _display_container:                     Description                Value
0                    Session id                  123
1                        Target  Reached.on.Time_Y.N
2                   Target type               Binary
3           Original data shape            (6897, 9)
4        Transformed data shape           (6897, 17)
5   Transformed train set shape           (4827, 17)
6    Transformed test set shape           (2070, 17)
7              Numeric features                    5
8          Categorical features                    3
9                    Preprocess                 True
10              Imputation type               simple
11           Numeric imputation                 mean
12       Categorical imputation                 mode
13     Maximum one-hot encoding                   25
14              Encoding method                 None
15               Fold Generator      StratifiedKFold
16                  Fold Number                   10
17                     CPU Jobs                   -1
18                      Use GPU                False
19               Log Experiment                False
20              Experiment Name     clf-default-name
21                          USI                 5f9a
2023-08-09 16:29:14,531:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:29:14,533:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:29:14,579:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:29:14,581:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:29:14,583:INFO:setup() successfully completed in 0.78s...............
2023-08-09 16:29:14,583:INFO:Initializing compare_models()
2023-08-09 16:29:14,583:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706EACE80>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000023706EACE80>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-09 16:29:14,583:INFO:Checking exceptions
2023-08-09 16:29:14,586:INFO:Preparing display monitor
2023-08-09 16:29:14,601:INFO:Initializing Logistic Regression
2023-08-09 16:29:14,602:INFO:Total runtime is 1.661380132039388e-05 minutes
2023-08-09 16:29:14,604:INFO:SubProcess create_model() called ==================================
2023-08-09 16:29:14,604:INFO:Initializing create_model()
2023-08-09 16:29:14,604:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706EACE80>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002370FC4C6A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:29:14,604:INFO:Checking exceptions
2023-08-09 16:29:14,604:INFO:Importing libraries
2023-08-09 16:29:14,604:INFO:Copying training dataset
2023-08-09 16:29:14,606:INFO:Defining folds
2023-08-09 16:29:14,606:INFO:Declaring metric variables
2023-08-09 16:29:14,609:INFO:Importing untrained model
2023-08-09 16:29:14,611:INFO:Logistic Regression Imported successfully
2023-08-09 16:29:14,616:INFO:Starting cross validation
2023-08-09 16:29:14,616:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:29:16,231:INFO:Calculating mean and std
2023-08-09 16:29:16,232:INFO:Creating metrics dataframe
2023-08-09 16:29:16,422:INFO:Uploading results into container
2023-08-09 16:29:16,424:INFO:Uploading model into container now
2023-08-09 16:29:16,424:INFO:_master_model_container: 1
2023-08-09 16:29:16,424:INFO:_display_container: 2
2023-08-09 16:29:16,424:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-09 16:29:16,424:INFO:create_model() successfully completed......................................
2023-08-09 16:29:16,825:INFO:SubProcess create_model() end ==================================
2023-08-09 16:29:16,825:INFO:Creating metrics dataframe
2023-08-09 16:29:16,831:INFO:Initializing K Neighbors Classifier
2023-08-09 16:29:16,831:INFO:Total runtime is 0.037173577149709064 minutes
2023-08-09 16:29:16,835:INFO:SubProcess create_model() called ==================================
2023-08-09 16:29:16,835:INFO:Initializing create_model()
2023-08-09 16:29:16,835:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706EACE80>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002370FC4C6A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:29:16,835:INFO:Checking exceptions
2023-08-09 16:29:16,835:INFO:Importing libraries
2023-08-09 16:29:16,835:INFO:Copying training dataset
2023-08-09 16:29:16,837:INFO:Defining folds
2023-08-09 16:29:16,838:INFO:Declaring metric variables
2023-08-09 16:29:16,840:INFO:Importing untrained model
2023-08-09 16:29:16,842:INFO:K Neighbors Classifier Imported successfully
2023-08-09 16:29:16,846:INFO:Starting cross validation
2023-08-09 16:29:16,847:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:29:18,467:INFO:Calculating mean and std
2023-08-09 16:29:18,468:INFO:Creating metrics dataframe
2023-08-09 16:29:18,657:INFO:Uploading results into container
2023-08-09 16:29:18,657:INFO:Uploading model into container now
2023-08-09 16:29:18,659:INFO:_master_model_container: 2
2023-08-09 16:29:18,659:INFO:_display_container: 2
2023-08-09 16:29:18,659:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-09 16:29:18,659:INFO:create_model() successfully completed......................................
2023-08-09 16:29:19,030:INFO:SubProcess create_model() end ==================================
2023-08-09 16:29:19,030:INFO:Creating metrics dataframe
2023-08-09 16:29:19,037:INFO:Initializing Naive Bayes
2023-08-09 16:29:19,038:INFO:Total runtime is 0.07396007776260376 minutes
2023-08-09 16:29:19,040:INFO:SubProcess create_model() called ==================================
2023-08-09 16:29:19,041:INFO:Initializing create_model()
2023-08-09 16:29:19,041:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706EACE80>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002370FC4C6A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:29:19,041:INFO:Checking exceptions
2023-08-09 16:29:19,041:INFO:Importing libraries
2023-08-09 16:29:19,041:INFO:Copying training dataset
2023-08-09 16:29:19,044:INFO:Defining folds
2023-08-09 16:29:19,044:INFO:Declaring metric variables
2023-08-09 16:29:19,047:INFO:Importing untrained model
2023-08-09 16:29:19,050:INFO:Naive Bayes Imported successfully
2023-08-09 16:29:19,054:INFO:Starting cross validation
2023-08-09 16:29:19,055:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:29:20,525:INFO:Calculating mean and std
2023-08-09 16:29:20,526:INFO:Creating metrics dataframe
2023-08-09 16:29:20,717:INFO:Uploading results into container
2023-08-09 16:29:20,717:INFO:Uploading model into container now
2023-08-09 16:29:20,718:INFO:_master_model_container: 3
2023-08-09 16:29:20,718:INFO:_display_container: 2
2023-08-09 16:29:20,718:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-09 16:29:20,718:INFO:create_model() successfully completed......................................
2023-08-09 16:29:21,088:INFO:SubProcess create_model() end ==================================
2023-08-09 16:29:21,088:INFO:Creating metrics dataframe
2023-08-09 16:29:21,096:INFO:Initializing Decision Tree Classifier
2023-08-09 16:29:21,096:INFO:Total runtime is 0.10825539032618205 minutes
2023-08-09 16:29:21,100:INFO:SubProcess create_model() called ==================================
2023-08-09 16:29:21,100:INFO:Initializing create_model()
2023-08-09 16:29:21,100:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706EACE80>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002370FC4C6A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:29:21,100:INFO:Checking exceptions
2023-08-09 16:29:21,101:INFO:Importing libraries
2023-08-09 16:29:21,101:INFO:Copying training dataset
2023-08-09 16:29:21,105:INFO:Defining folds
2023-08-09 16:29:21,105:INFO:Declaring metric variables
2023-08-09 16:29:21,107:INFO:Importing untrained model
2023-08-09 16:29:21,110:INFO:Decision Tree Classifier Imported successfully
2023-08-09 16:29:21,115:INFO:Starting cross validation
2023-08-09 16:29:21,116:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:29:22,596:INFO:Calculating mean and std
2023-08-09 16:29:22,598:INFO:Creating metrics dataframe
2023-08-09 16:29:22,794:INFO:Uploading results into container
2023-08-09 16:29:22,794:INFO:Uploading model into container now
2023-08-09 16:29:22,796:INFO:_master_model_container: 4
2023-08-09 16:29:22,796:INFO:_display_container: 2
2023-08-09 16:29:22,796:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-08-09 16:29:22,796:INFO:create_model() successfully completed......................................
2023-08-09 16:29:23,174:INFO:SubProcess create_model() end ==================================
2023-08-09 16:29:23,175:INFO:Creating metrics dataframe
2023-08-09 16:29:23,182:INFO:Initializing SVM - Linear Kernel
2023-08-09 16:29:23,182:INFO:Total runtime is 0.143024476369222 minutes
2023-08-09 16:29:23,185:INFO:SubProcess create_model() called ==================================
2023-08-09 16:29:23,185:INFO:Initializing create_model()
2023-08-09 16:29:23,185:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706EACE80>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002370FC4C6A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:29:23,185:INFO:Checking exceptions
2023-08-09 16:29:23,185:INFO:Importing libraries
2023-08-09 16:29:23,185:INFO:Copying training dataset
2023-08-09 16:29:23,189:INFO:Defining folds
2023-08-09 16:29:23,190:INFO:Declaring metric variables
2023-08-09 16:29:23,192:INFO:Importing untrained model
2023-08-09 16:29:23,194:INFO:SVM - Linear Kernel Imported successfully
2023-08-09 16:29:23,198:INFO:Starting cross validation
2023-08-09 16:29:23,198:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:29:23,376:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:29:23,386:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:29:23,388:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:29:23,392:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:29:23,394:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:29:23,399:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-09 16:29:23,401:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:29:23,403:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:29:23,404:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:29:23,407:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-09 16:29:23,413:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:29:23,420:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:29:24,668:INFO:Calculating mean and std
2023-08-09 16:29:24,668:INFO:Creating metrics dataframe
2023-08-09 16:29:24,863:INFO:Uploading results into container
2023-08-09 16:29:24,863:INFO:Uploading model into container now
2023-08-09 16:29:24,865:INFO:_master_model_container: 5
2023-08-09 16:29:24,865:INFO:_display_container: 2
2023-08-09 16:29:24,865:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-09 16:29:24,865:INFO:create_model() successfully completed......................................
2023-08-09 16:29:25,242:INFO:SubProcess create_model() end ==================================
2023-08-09 16:29:25,242:INFO:Creating metrics dataframe
2023-08-09 16:29:25,249:INFO:Initializing Ridge Classifier
2023-08-09 16:29:25,249:INFO:Total runtime is 0.17746665080388385 minutes
2023-08-09 16:29:25,251:INFO:SubProcess create_model() called ==================================
2023-08-09 16:29:25,252:INFO:Initializing create_model()
2023-08-09 16:29:25,252:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706EACE80>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002370FC4C6A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:29:25,252:INFO:Checking exceptions
2023-08-09 16:29:25,252:INFO:Importing libraries
2023-08-09 16:29:25,252:INFO:Copying training dataset
2023-08-09 16:29:25,255:INFO:Defining folds
2023-08-09 16:29:25,255:INFO:Declaring metric variables
2023-08-09 16:29:25,257:INFO:Importing untrained model
2023-08-09 16:29:25,260:INFO:Ridge Classifier Imported successfully
2023-08-09 16:29:25,264:INFO:Starting cross validation
2023-08-09 16:29:25,264:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:29:25,421:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:29:25,425:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:29:25,432:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:29:25,433:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:29:25,433:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:29:25,439:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:29:25,439:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:29:25,442:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:29:25,444:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:29:25,446:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:29:26,707:INFO:Calculating mean and std
2023-08-09 16:29:26,707:INFO:Creating metrics dataframe
2023-08-09 16:29:26,896:INFO:Uploading results into container
2023-08-09 16:29:26,896:INFO:Uploading model into container now
2023-08-09 16:29:26,897:INFO:_master_model_container: 6
2023-08-09 16:29:26,897:INFO:_display_container: 2
2023-08-09 16:29:26,897:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-08-09 16:29:26,897:INFO:create_model() successfully completed......................................
2023-08-09 16:29:27,295:INFO:SubProcess create_model() end ==================================
2023-08-09 16:29:27,296:INFO:Creating metrics dataframe
2023-08-09 16:29:27,304:INFO:Initializing Random Forest Classifier
2023-08-09 16:29:27,304:INFO:Total runtime is 0.2117143670717875 minutes
2023-08-09 16:29:27,305:INFO:SubProcess create_model() called ==================================
2023-08-09 16:29:27,306:INFO:Initializing create_model()
2023-08-09 16:29:27,306:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706EACE80>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002370FC4C6A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:29:27,306:INFO:Checking exceptions
2023-08-09 16:29:27,306:INFO:Importing libraries
2023-08-09 16:29:27,306:INFO:Copying training dataset
2023-08-09 16:29:27,309:INFO:Defining folds
2023-08-09 16:29:27,310:INFO:Declaring metric variables
2023-08-09 16:29:27,312:INFO:Importing untrained model
2023-08-09 16:29:27,316:INFO:Random Forest Classifier Imported successfully
2023-08-09 16:29:27,321:INFO:Starting cross validation
2023-08-09 16:29:27,322:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:29:29,492:INFO:Calculating mean and std
2023-08-09 16:29:29,493:INFO:Creating metrics dataframe
2023-08-09 16:29:29,690:INFO:Uploading results into container
2023-08-09 16:29:29,691:INFO:Uploading model into container now
2023-08-09 16:29:29,691:INFO:_master_model_container: 7
2023-08-09 16:29:29,691:INFO:_display_container: 2
2023-08-09 16:29:29,692:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-09 16:29:29,692:INFO:create_model() successfully completed......................................
2023-08-09 16:29:30,078:INFO:SubProcess create_model() end ==================================
2023-08-09 16:29:30,078:INFO:Creating metrics dataframe
2023-08-09 16:29:30,086:INFO:Initializing Quadratic Discriminant Analysis
2023-08-09 16:29:30,086:INFO:Total runtime is 0.25809584856033324 minutes
2023-08-09 16:29:30,089:INFO:SubProcess create_model() called ==================================
2023-08-09 16:29:30,089:INFO:Initializing create_model()
2023-08-09 16:29:30,090:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706EACE80>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002370FC4C6A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:29:30,090:INFO:Checking exceptions
2023-08-09 16:29:30,090:INFO:Importing libraries
2023-08-09 16:29:30,090:INFO:Copying training dataset
2023-08-09 16:29:30,094:INFO:Defining folds
2023-08-09 16:29:30,094:INFO:Declaring metric variables
2023-08-09 16:29:30,097:INFO:Importing untrained model
2023-08-09 16:29:30,099:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-09 16:29:30,104:INFO:Starting cross validation
2023-08-09 16:29:30,106:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:29:30,202:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:29:30,220:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:29:30,221:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:29:30,225:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:29:30,229:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:29:30,236:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:29:30,239:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:29:30,243:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:29:30,251:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:29:30,254:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:29:31,597:INFO:Calculating mean and std
2023-08-09 16:29:31,598:INFO:Creating metrics dataframe
2023-08-09 16:29:31,797:INFO:Uploading results into container
2023-08-09 16:29:31,797:INFO:Uploading model into container now
2023-08-09 16:29:31,798:INFO:_master_model_container: 8
2023-08-09 16:29:31,798:INFO:_display_container: 2
2023-08-09 16:29:31,798:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-09 16:29:31,798:INFO:create_model() successfully completed......................................
2023-08-09 16:29:32,173:INFO:SubProcess create_model() end ==================================
2023-08-09 16:29:32,173:INFO:Creating metrics dataframe
2023-08-09 16:29:32,181:INFO:Initializing Ada Boost Classifier
2023-08-09 16:29:32,181:INFO:Total runtime is 0.2930096308390299 minutes
2023-08-09 16:29:32,184:INFO:SubProcess create_model() called ==================================
2023-08-09 16:29:32,184:INFO:Initializing create_model()
2023-08-09 16:29:32,184:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706EACE80>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002370FC4C6A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:29:32,184:INFO:Checking exceptions
2023-08-09 16:29:32,184:INFO:Importing libraries
2023-08-09 16:29:32,184:INFO:Copying training dataset
2023-08-09 16:29:32,188:INFO:Defining folds
2023-08-09 16:29:32,188:INFO:Declaring metric variables
2023-08-09 16:29:32,191:INFO:Importing untrained model
2023-08-09 16:29:32,193:INFO:Ada Boost Classifier Imported successfully
2023-08-09 16:29:32,197:INFO:Starting cross validation
2023-08-09 16:29:32,197:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:29:34,028:INFO:Calculating mean and std
2023-08-09 16:29:34,029:INFO:Creating metrics dataframe
2023-08-09 16:29:34,225:INFO:Uploading results into container
2023-08-09 16:29:34,225:INFO:Uploading model into container now
2023-08-09 16:29:34,226:INFO:_master_model_container: 9
2023-08-09 16:29:34,226:INFO:_display_container: 2
2023-08-09 16:29:34,226:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-08-09 16:29:34,226:INFO:create_model() successfully completed......................................
2023-08-09 16:29:34,600:INFO:SubProcess create_model() end ==================================
2023-08-09 16:29:34,600:INFO:Creating metrics dataframe
2023-08-09 16:29:34,609:INFO:Initializing Gradient Boosting Classifier
2023-08-09 16:29:34,609:INFO:Total runtime is 0.3334653218587239 minutes
2023-08-09 16:29:34,612:INFO:SubProcess create_model() called ==================================
2023-08-09 16:29:34,612:INFO:Initializing create_model()
2023-08-09 16:29:34,612:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706EACE80>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002370FC4C6A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:29:34,612:INFO:Checking exceptions
2023-08-09 16:29:34,612:INFO:Importing libraries
2023-08-09 16:29:34,612:INFO:Copying training dataset
2023-08-09 16:29:34,615:INFO:Defining folds
2023-08-09 16:29:34,615:INFO:Declaring metric variables
2023-08-09 16:29:34,618:INFO:Importing untrained model
2023-08-09 16:29:34,620:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:29:34,625:INFO:Starting cross validation
2023-08-09 16:29:34,626:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:29:36,766:INFO:Calculating mean and std
2023-08-09 16:29:36,766:INFO:Creating metrics dataframe
2023-08-09 16:29:36,966:INFO:Uploading results into container
2023-08-09 16:29:36,966:INFO:Uploading model into container now
2023-08-09 16:29:36,967:INFO:_master_model_container: 10
2023-08-09 16:29:36,967:INFO:_display_container: 2
2023-08-09 16:29:36,967:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:29:36,967:INFO:create_model() successfully completed......................................
2023-08-09 16:29:37,338:INFO:SubProcess create_model() end ==================================
2023-08-09 16:29:37,338:INFO:Creating metrics dataframe
2023-08-09 16:29:37,348:INFO:Initializing Linear Discriminant Analysis
2023-08-09 16:29:37,348:INFO:Total runtime is 0.37911578814188635 minutes
2023-08-09 16:29:37,350:INFO:SubProcess create_model() called ==================================
2023-08-09 16:29:37,350:INFO:Initializing create_model()
2023-08-09 16:29:37,350:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706EACE80>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002370FC4C6A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:29:37,350:INFO:Checking exceptions
2023-08-09 16:29:37,350:INFO:Importing libraries
2023-08-09 16:29:37,351:INFO:Copying training dataset
2023-08-09 16:29:37,354:INFO:Defining folds
2023-08-09 16:29:37,354:INFO:Declaring metric variables
2023-08-09 16:29:37,356:INFO:Importing untrained model
2023-08-09 16:29:37,359:INFO:Linear Discriminant Analysis Imported successfully
2023-08-09 16:29:37,363:INFO:Starting cross validation
2023-08-09 16:29:37,364:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:29:38,914:INFO:Calculating mean and std
2023-08-09 16:29:38,916:INFO:Creating metrics dataframe
2023-08-09 16:29:39,113:INFO:Uploading results into container
2023-08-09 16:29:39,114:INFO:Uploading model into container now
2023-08-09 16:29:39,114:INFO:_master_model_container: 11
2023-08-09 16:29:39,114:INFO:_display_container: 2
2023-08-09 16:29:39,114:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-09 16:29:39,114:INFO:create_model() successfully completed......................................
2023-08-09 16:29:39,495:INFO:SubProcess create_model() end ==================================
2023-08-09 16:29:39,495:INFO:Creating metrics dataframe
2023-08-09 16:29:39,505:INFO:Initializing Extra Trees Classifier
2023-08-09 16:29:39,505:INFO:Total runtime is 0.4150725166002909 minutes
2023-08-09 16:29:39,507:INFO:SubProcess create_model() called ==================================
2023-08-09 16:29:39,508:INFO:Initializing create_model()
2023-08-09 16:29:39,508:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706EACE80>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002370FC4C6A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:29:39,508:INFO:Checking exceptions
2023-08-09 16:29:39,508:INFO:Importing libraries
2023-08-09 16:29:39,508:INFO:Copying training dataset
2023-08-09 16:29:39,512:INFO:Defining folds
2023-08-09 16:29:39,512:INFO:Declaring metric variables
2023-08-09 16:29:39,515:INFO:Importing untrained model
2023-08-09 16:29:39,518:INFO:Extra Trees Classifier Imported successfully
2023-08-09 16:29:39,522:INFO:Starting cross validation
2023-08-09 16:29:39,523:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:29:41,734:INFO:Calculating mean and std
2023-08-09 16:29:41,734:INFO:Creating metrics dataframe
2023-08-09 16:29:41,940:INFO:Uploading results into container
2023-08-09 16:29:41,941:INFO:Uploading model into container now
2023-08-09 16:29:41,942:INFO:_master_model_container: 12
2023-08-09 16:29:41,942:INFO:_display_container: 2
2023-08-09 16:29:41,942:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-08-09 16:29:41,942:INFO:create_model() successfully completed......................................
2023-08-09 16:29:42,313:INFO:SubProcess create_model() end ==================================
2023-08-09 16:29:42,313:INFO:Creating metrics dataframe
2023-08-09 16:29:42,321:INFO:Initializing Extreme Gradient Boosting
2023-08-09 16:29:42,322:INFO:Total runtime is 0.4620218515396117 minutes
2023-08-09 16:29:42,324:INFO:SubProcess create_model() called ==================================
2023-08-09 16:29:42,324:INFO:Initializing create_model()
2023-08-09 16:29:42,324:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706EACE80>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002370FC4C6A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:29:42,324:INFO:Checking exceptions
2023-08-09 16:29:42,324:INFO:Importing libraries
2023-08-09 16:29:42,324:INFO:Copying training dataset
2023-08-09 16:29:42,328:INFO:Defining folds
2023-08-09 16:29:42,328:INFO:Declaring metric variables
2023-08-09 16:29:42,330:INFO:Importing untrained model
2023-08-09 16:29:42,333:INFO:Extreme Gradient Boosting Imported successfully
2023-08-09 16:29:42,338:INFO:Starting cross validation
2023-08-09 16:29:42,339:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:29:44,519:INFO:Calculating mean and std
2023-08-09 16:29:44,520:INFO:Creating metrics dataframe
2023-08-09 16:29:44,724:INFO:Uploading results into container
2023-08-09 16:29:44,725:INFO:Uploading model into container now
2023-08-09 16:29:44,725:INFO:_master_model_container: 13
2023-08-09 16:29:44,725:INFO:_display_container: 2
2023-08-09 16:29:44,726:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-09 16:29:44,726:INFO:create_model() successfully completed......................................
2023-08-09 16:29:45,105:INFO:SubProcess create_model() end ==================================
2023-08-09 16:29:45,105:INFO:Creating metrics dataframe
2023-08-09 16:29:45,114:INFO:Initializing Light Gradient Boosting Machine
2023-08-09 16:29:45,114:INFO:Total runtime is 0.5085529446601866 minutes
2023-08-09 16:29:45,116:INFO:SubProcess create_model() called ==================================
2023-08-09 16:29:45,117:INFO:Initializing create_model()
2023-08-09 16:29:45,117:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706EACE80>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002370FC4C6A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:29:45,117:INFO:Checking exceptions
2023-08-09 16:29:45,117:INFO:Importing libraries
2023-08-09 16:29:45,117:INFO:Copying training dataset
2023-08-09 16:29:45,121:INFO:Defining folds
2023-08-09 16:29:45,121:INFO:Declaring metric variables
2023-08-09 16:29:45,123:INFO:Importing untrained model
2023-08-09 16:29:45,126:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-09 16:29:45,130:INFO:Starting cross validation
2023-08-09 16:29:45,130:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:29:47,766:INFO:Calculating mean and std
2023-08-09 16:29:47,767:INFO:Creating metrics dataframe
2023-08-09 16:29:47,974:INFO:Uploading results into container
2023-08-09 16:29:47,974:INFO:Uploading model into container now
2023-08-09 16:29:47,974:INFO:_master_model_container: 14
2023-08-09 16:29:47,974:INFO:_display_container: 2
2023-08-09 16:29:47,976:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-09 16:29:47,976:INFO:create_model() successfully completed......................................
2023-08-09 16:29:48,348:INFO:SubProcess create_model() end ==================================
2023-08-09 16:29:48,348:INFO:Creating metrics dataframe
2023-08-09 16:29:48,357:INFO:Initializing CatBoost Classifier
2023-08-09 16:29:48,357:INFO:Total runtime is 0.5625971635182697 minutes
2023-08-09 16:29:48,359:INFO:SubProcess create_model() called ==================================
2023-08-09 16:29:48,360:INFO:Initializing create_model()
2023-08-09 16:29:48,360:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706EACE80>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002370FC4C6A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:29:48,360:INFO:Checking exceptions
2023-08-09 16:29:48,360:INFO:Importing libraries
2023-08-09 16:29:48,360:INFO:Copying training dataset
2023-08-09 16:29:48,363:INFO:Defining folds
2023-08-09 16:29:48,363:INFO:Declaring metric variables
2023-08-09 16:29:48,365:INFO:Importing untrained model
2023-08-09 16:29:48,367:INFO:CatBoost Classifier Imported successfully
2023-08-09 16:29:48,372:INFO:Starting cross validation
2023-08-09 16:29:48,373:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:29:53,966:INFO:Calculating mean and std
2023-08-09 16:29:53,967:INFO:Creating metrics dataframe
2023-08-09 16:29:54,176:INFO:Uploading results into container
2023-08-09 16:29:54,177:INFO:Uploading model into container now
2023-08-09 16:29:54,177:INFO:_master_model_container: 15
2023-08-09 16:29:54,177:INFO:_display_container: 2
2023-08-09 16:29:54,177:INFO:<catboost.core.CatBoostClassifier object at 0x00000237065A59C0>
2023-08-09 16:29:54,177:INFO:create_model() successfully completed......................................
2023-08-09 16:29:54,557:INFO:SubProcess create_model() end ==================================
2023-08-09 16:29:54,557:INFO:Creating metrics dataframe
2023-08-09 16:29:54,568:INFO:Initializing Dummy Classifier
2023-08-09 16:29:54,568:INFO:Total runtime is 0.6661161144574482 minutes
2023-08-09 16:29:54,570:INFO:SubProcess create_model() called ==================================
2023-08-09 16:29:54,571:INFO:Initializing create_model()
2023-08-09 16:29:54,571:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706EACE80>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002370FC4C6A0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:29:54,571:INFO:Checking exceptions
2023-08-09 16:29:54,571:INFO:Importing libraries
2023-08-09 16:29:54,571:INFO:Copying training dataset
2023-08-09 16:29:54,575:INFO:Defining folds
2023-08-09 16:29:54,575:INFO:Declaring metric variables
2023-08-09 16:29:54,577:INFO:Importing untrained model
2023-08-09 16:29:54,579:INFO:Dummy Classifier Imported successfully
2023-08-09 16:29:54,584:INFO:Starting cross validation
2023-08-09 16:29:54,585:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:29:56,178:INFO:Calculating mean and std
2023-08-09 16:29:56,179:INFO:Creating metrics dataframe
2023-08-09 16:29:56,388:INFO:Uploading results into container
2023-08-09 16:29:56,388:INFO:Uploading model into container now
2023-08-09 16:29:56,389:INFO:_master_model_container: 16
2023-08-09 16:29:56,389:INFO:_display_container: 2
2023-08-09 16:29:56,389:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-08-09 16:29:56,389:INFO:create_model() successfully completed......................................
2023-08-09 16:29:56,775:INFO:SubProcess create_model() end ==================================
2023-08-09 16:29:56,775:INFO:Creating metrics dataframe
2023-08-09 16:29:56,791:INFO:Initializing create_model()
2023-08-09 16:29:56,791:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706EACE80>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:29:56,791:INFO:Checking exceptions
2023-08-09 16:29:56,792:INFO:Importing libraries
2023-08-09 16:29:56,792:INFO:Copying training dataset
2023-08-09 16:29:56,795:INFO:Defining folds
2023-08-09 16:29:56,795:INFO:Declaring metric variables
2023-08-09 16:29:56,795:INFO:Importing untrained model
2023-08-09 16:29:56,795:INFO:Declaring custom model
2023-08-09 16:29:56,796:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:29:56,797:INFO:Cross validation set to False
2023-08-09 16:29:56,797:INFO:Fitting Model
2023-08-09 16:29:57,503:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:29:57,503:INFO:create_model() successfully completed......................................
2023-08-09 16:29:57,896:INFO:_master_model_container: 16
2023-08-09 16:29:57,896:INFO:_display_container: 2
2023-08-09 16:29:57,896:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:29:57,896:INFO:compare_models() successfully completed......................................
2023-08-09 16:30:14,438:INFO:Initializing create_model()
2023-08-09 16:30:14,439:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706EACE80>, estimator=catboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:30:14,439:INFO:Checking exceptions
2023-08-09 16:30:14,449:INFO:Importing libraries
2023-08-09 16:30:14,449:INFO:Copying training dataset
2023-08-09 16:30:14,452:INFO:Defining folds
2023-08-09 16:30:14,452:INFO:Declaring metric variables
2023-08-09 16:30:14,454:INFO:Importing untrained model
2023-08-09 16:30:14,457:INFO:CatBoost Classifier Imported successfully
2023-08-09 16:30:14,462:INFO:Starting cross validation
2023-08-09 16:30:14,463:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:30:16,151:INFO:Calculating mean and std
2023-08-09 16:30:16,152:INFO:Creating metrics dataframe
2023-08-09 16:30:16,158:INFO:Finalizing model
2023-08-09 16:30:18,579:INFO:Uploading results into container
2023-08-09 16:30:18,580:INFO:Uploading model into container now
2023-08-09 16:30:18,588:INFO:_master_model_container: 17
2023-08-09 16:30:18,588:INFO:_display_container: 3
2023-08-09 16:30:18,588:INFO:<catboost.core.CatBoostClassifier object at 0x0000023712596440>
2023-08-09 16:30:18,588:INFO:create_model() successfully completed......................................
2023-08-09 16:30:18,973:INFO:Initializing tune_model()
2023-08-09 16:30:18,974:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x0000023712596440>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706EACE80>)
2023-08-09 16:30:18,974:INFO:Checking exceptions
2023-08-09 16:30:18,987:INFO:Copying training dataset
2023-08-09 16:30:18,990:INFO:Checking base model
2023-08-09 16:30:18,990:INFO:Base model : CatBoost Classifier
2023-08-09 16:30:18,992:INFO:Declaring metric variables
2023-08-09 16:30:18,994:INFO:Defining Hyperparameters
2023-08-09 16:30:19,382:INFO:Tuning with n_jobs=-1
2023-08-09 16:30:19,382:INFO:Initializing RandomizedSearchCV
2023-08-09 16:30:40,386:INFO:best_params: {'actual_estimator__random_strength': 0.2, 'actual_estimator__n_estimators': 270, 'actual_estimator__l2_leaf_reg': 8, 'actual_estimator__eta': 0.0005, 'actual_estimator__depth': 4}
2023-08-09 16:30:40,387:INFO:Hyperparameter search completed
2023-08-09 16:30:40,387:INFO:SubProcess create_model() called ==================================
2023-08-09 16:30:40,387:INFO:Initializing create_model()
2023-08-09 16:30:40,388:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706EACE80>, estimator=<catboost.core.CatBoostClassifier object at 0x0000023708E0EFE0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002370EAB97B0>, model_only=True, return_train_score=False, kwargs={'random_strength': 0.2, 'n_estimators': 270, 'l2_leaf_reg': 8, 'eta': 0.0005, 'depth': 4})
2023-08-09 16:30:40,388:INFO:Checking exceptions
2023-08-09 16:30:40,388:INFO:Importing libraries
2023-08-09 16:30:40,388:INFO:Copying training dataset
2023-08-09 16:30:40,392:INFO:Defining folds
2023-08-09 16:30:40,392:INFO:Declaring metric variables
2023-08-09 16:30:40,394:INFO:Importing untrained model
2023-08-09 16:30:40,394:INFO:Declaring custom model
2023-08-09 16:30:40,396:INFO:CatBoost Classifier Imported successfully
2023-08-09 16:30:40,402:INFO:Starting cross validation
2023-08-09 16:30:40,403:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:30:42,156:INFO:Calculating mean and std
2023-08-09 16:30:42,156:INFO:Creating metrics dataframe
2023-08-09 16:30:42,161:INFO:Finalizing model
2023-08-09 16:30:42,832:INFO:Uploading results into container
2023-08-09 16:30:42,832:INFO:Uploading model into container now
2023-08-09 16:30:42,833:INFO:_master_model_container: 18
2023-08-09 16:30:42,833:INFO:_display_container: 4
2023-08-09 16:30:42,833:INFO:<catboost.core.CatBoostClassifier object at 0x00000237100559F0>
2023-08-09 16:30:42,833:INFO:create_model() successfully completed......................................
2023-08-09 16:30:43,214:INFO:SubProcess create_model() end ==================================
2023-08-09 16:30:43,214:INFO:choose_better activated
2023-08-09 16:30:43,217:INFO:SubProcess create_model() called ==================================
2023-08-09 16:30:43,217:INFO:Initializing create_model()
2023-08-09 16:30:43,217:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706EACE80>, estimator=<catboost.core.CatBoostClassifier object at 0x0000023712596440>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:30:43,217:INFO:Checking exceptions
2023-08-09 16:30:43,219:INFO:Importing libraries
2023-08-09 16:30:43,219:INFO:Copying training dataset
2023-08-09 16:30:43,222:INFO:Defining folds
2023-08-09 16:30:43,222:INFO:Declaring metric variables
2023-08-09 16:30:43,222:INFO:Importing untrained model
2023-08-09 16:30:43,223:INFO:Declaring custom model
2023-08-09 16:30:43,223:INFO:CatBoost Classifier Imported successfully
2023-08-09 16:30:43,223:INFO:Starting cross validation
2023-08-09 16:30:43,224:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:30:44,979:INFO:Calculating mean and std
2023-08-09 16:30:44,979:INFO:Creating metrics dataframe
2023-08-09 16:30:44,981:INFO:Finalizing model
2023-08-09 16:30:45,276:INFO:Uploading results into container
2023-08-09 16:30:45,277:INFO:Uploading model into container now
2023-08-09 16:30:45,277:INFO:_master_model_container: 19
2023-08-09 16:30:45,277:INFO:_display_container: 5
2023-08-09 16:30:45,277:INFO:<catboost.core.CatBoostClassifier object at 0x00000237100AEEC0>
2023-08-09 16:30:45,277:INFO:create_model() successfully completed......................................
2023-08-09 16:30:45,647:INFO:SubProcess create_model() end ==================================
2023-08-09 16:30:45,648:INFO:<catboost.core.CatBoostClassifier object at 0x00000237100AEEC0> result for Accuracy is 0.6453
2023-08-09 16:30:45,648:INFO:<catboost.core.CatBoostClassifier object at 0x00000237100559F0> result for Accuracy is 0.6721
2023-08-09 16:30:45,648:INFO:<catboost.core.CatBoostClassifier object at 0x00000237100559F0> is best model
2023-08-09 16:30:45,648:INFO:choose_better completed
2023-08-09 16:30:45,655:INFO:_master_model_container: 19
2023-08-09 16:30:45,655:INFO:_display_container: 4
2023-08-09 16:30:45,655:INFO:<catboost.core.CatBoostClassifier object at 0x00000237100559F0>
2023-08-09 16:30:45,655:INFO:tune_model() successfully completed......................................
2023-08-09 16:30:46,204:INFO:Initializing create_model()
2023-08-09 16:30:46,204:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706EACE80>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:30:46,204:INFO:Checking exceptions
2023-08-09 16:30:46,215:INFO:Importing libraries
2023-08-09 16:30:46,215:INFO:Copying training dataset
2023-08-09 16:30:46,218:INFO:Defining folds
2023-08-09 16:30:46,218:INFO:Declaring metric variables
2023-08-09 16:30:46,220:INFO:Importing untrained model
2023-08-09 16:30:46,223:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:30:46,228:INFO:Starting cross validation
2023-08-09 16:30:46,229:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:30:48,073:INFO:Calculating mean and std
2023-08-09 16:30:48,074:INFO:Creating metrics dataframe
2023-08-09 16:30:48,077:INFO:Finalizing model
2023-08-09 16:30:48,400:INFO:Uploading results into container
2023-08-09 16:30:48,400:INFO:Uploading model into container now
2023-08-09 16:30:48,406:INFO:_master_model_container: 20
2023-08-09 16:30:48,406:INFO:_display_container: 5
2023-08-09 16:30:48,406:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:30:48,406:INFO:create_model() successfully completed......................................
2023-08-09 16:30:48,812:INFO:Initializing tune_model()
2023-08-09 16:30:48,812:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706EACE80>)
2023-08-09 16:30:48,812:INFO:Checking exceptions
2023-08-09 16:30:48,822:INFO:Copying training dataset
2023-08-09 16:30:48,826:INFO:Checking base model
2023-08-09 16:30:48,826:INFO:Base model : Gradient Boosting Classifier
2023-08-09 16:30:48,827:INFO:Declaring metric variables
2023-08-09 16:30:48,829:INFO:Defining Hyperparameters
2023-08-09 16:30:49,221:INFO:Tuning with n_jobs=-1
2023-08-09 16:30:49,223:INFO:Initializing RandomizedSearchCV
2023-08-09 16:31:14,497:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 140, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.05, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.01}
2023-08-09 16:31:14,498:INFO:Hyperparameter search completed
2023-08-09 16:31:14,498:INFO:SubProcess create_model() called ==================================
2023-08-09 16:31:14,498:INFO:Initializing create_model()
2023-08-09 16:31:14,498:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706EACE80>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023706F777C0>, model_only=True, return_train_score=False, kwargs={'subsample': 0.35, 'n_estimators': 140, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.05, 'max_features': 'sqrt', 'max_depth': 7, 'learning_rate': 0.01})
2023-08-09 16:31:14,498:INFO:Checking exceptions
2023-08-09 16:31:14,498:INFO:Importing libraries
2023-08-09 16:31:14,500:INFO:Copying training dataset
2023-08-09 16:31:14,502:INFO:Defining folds
2023-08-09 16:31:14,502:INFO:Declaring metric variables
2023-08-09 16:31:14,504:INFO:Importing untrained model
2023-08-09 16:31:14,504:INFO:Declaring custom model
2023-08-09 16:31:14,507:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:31:14,511:INFO:Starting cross validation
2023-08-09 16:31:14,512:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:31:16,524:INFO:Calculating mean and std
2023-08-09 16:31:16,525:INFO:Creating metrics dataframe
2023-08-09 16:31:16,529:INFO:Finalizing model
2023-08-09 16:31:17,348:INFO:Uploading results into container
2023-08-09 16:31:17,348:INFO:Uploading model into container now
2023-08-09 16:31:17,349:INFO:_master_model_container: 21
2023-08-09 16:31:17,349:INFO:_display_container: 6
2023-08-09 16:31:17,349:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:31:17,349:INFO:create_model() successfully completed......................................
2023-08-09 16:31:17,739:INFO:SubProcess create_model() end ==================================
2023-08-09 16:31:17,739:INFO:choose_better activated
2023-08-09 16:31:17,742:INFO:SubProcess create_model() called ==================================
2023-08-09 16:31:17,743:INFO:Initializing create_model()
2023-08-09 16:31:17,743:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706EACE80>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:31:17,743:INFO:Checking exceptions
2023-08-09 16:31:17,744:INFO:Importing libraries
2023-08-09 16:31:17,744:INFO:Copying training dataset
2023-08-09 16:31:17,746:INFO:Defining folds
2023-08-09 16:31:17,746:INFO:Declaring metric variables
2023-08-09 16:31:17,746:INFO:Importing untrained model
2023-08-09 16:31:17,746:INFO:Declaring custom model
2023-08-09 16:31:17,748:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:31:17,748:INFO:Starting cross validation
2023-08-09 16:31:17,748:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:31:19,716:INFO:Calculating mean and std
2023-08-09 16:31:19,716:INFO:Creating metrics dataframe
2023-08-09 16:31:19,718:INFO:Finalizing model
2023-08-09 16:31:20,033:INFO:Uploading results into container
2023-08-09 16:31:20,034:INFO:Uploading model into container now
2023-08-09 16:31:20,034:INFO:_master_model_container: 22
2023-08-09 16:31:20,034:INFO:_display_container: 7
2023-08-09 16:31:20,034:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:31:20,034:INFO:create_model() successfully completed......................................
2023-08-09 16:31:20,432:INFO:SubProcess create_model() end ==================================
2023-08-09 16:31:20,432:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.6561
2023-08-09 16:31:20,433:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.646
2023-08-09 16:31:20,433:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-08-09 16:31:20,433:INFO:choose_better completed
2023-08-09 16:31:20,433:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-08-09 16:31:20,442:INFO:_master_model_container: 22
2023-08-09 16:31:20,442:INFO:_display_container: 6
2023-08-09 16:31:20,442:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:31:20,442:INFO:tune_model() successfully completed......................................
2023-08-09 16:31:20,998:INFO:Initializing blend_models()
2023-08-09 16:31:20,998:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706EACE80>, estimator_list=[<catboost.core.CatBoostClassifier object at 0x00000237100559F0>, GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-08-09 16:31:20,998:INFO:Checking exceptions
2023-08-09 16:31:21,008:INFO:Importing libraries
2023-08-09 16:31:21,008:INFO:Copying training dataset
2023-08-09 16:31:21,010:INFO:Getting model names
2023-08-09 16:31:21,012:INFO:SubProcess create_model() called ==================================
2023-08-09 16:31:21,012:INFO:Initializing create_model()
2023-08-09 16:31:21,012:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706EACE80>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x00000237100559F0>),
                             ('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236FF92AA10>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:31:21,012:INFO:Checking exceptions
2023-08-09 16:31:21,012:INFO:Importing libraries
2023-08-09 16:31:21,012:INFO:Copying training dataset
2023-08-09 16:31:21,018:INFO:Defining folds
2023-08-09 16:31:21,018:INFO:Declaring metric variables
2023-08-09 16:31:21,020:INFO:Importing untrained model
2023-08-09 16:31:21,020:INFO:Declaring custom model
2023-08-09 16:31:21,024:INFO:Voting Classifier Imported successfully
2023-08-09 16:31:21,028:INFO:Starting cross validation
2023-08-09 16:31:21,029:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:31:24,050:INFO:Calculating mean and std
2023-08-09 16:31:24,051:INFO:Creating metrics dataframe
2023-08-09 16:31:24,054:INFO:Finalizing model
2023-08-09 16:31:25,022:INFO:Uploading results into container
2023-08-09 16:31:25,023:INFO:Uploading model into container now
2023-08-09 16:31:25,023:INFO:_master_model_container: 23
2023-08-09 16:31:25,023:INFO:_display_container: 7
2023-08-09 16:31:25,025:INFO:VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x000002370FCD4070>),
                             ('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 16:31:25,025:INFO:create_model() successfully completed......................................
2023-08-09 16:31:25,418:INFO:SubProcess create_model() end ==================================
2023-08-09 16:31:25,425:INFO:_master_model_container: 23
2023-08-09 16:31:25,425:INFO:_display_container: 7
2023-08-09 16:31:25,426:INFO:VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x000002370FCD4070>),
                             ('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 16:31:25,426:INFO:blend_models() successfully completed......................................
2023-08-09 16:31:25,817:INFO:Initializing finalize_model()
2023-08-09 16:31:25,817:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706EACE80>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x000002370FCD4070>),
                             ('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-08-09 16:31:25,818:INFO:Finalizing VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x000002370FCD4070>),
                             ('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 16:31:25,821:INFO:Initializing create_model()
2023-08-09 16:31:25,821:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023706EACE80>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x000002370FCD4070>),
                             ('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-08-09 16:31:25,821:INFO:Checking exceptions
2023-08-09 16:31:25,822:INFO:Importing libraries
2023-08-09 16:31:25,822:INFO:Copying training dataset
2023-08-09 16:31:25,822:INFO:Defining folds
2023-08-09 16:31:25,822:INFO:Declaring metric variables
2023-08-09 16:31:25,822:INFO:Importing untrained model
2023-08-09 16:31:25,822:INFO:Declaring custom model
2023-08-09 16:31:25,824:INFO:Voting Classifier Imported successfully
2023-08-09 16:31:25,824:INFO:Cross validation set to False
2023-08-09 16:31:25,824:INFO:Fitting Model
2023-08-09 16:31:26,623:INFO:Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing...
                                                                          max_features=None,
                                                                          max_leaf_nodes=None,
                                                                          min_impurity_decrease=0.0,
                                                                          min_samples_leaf=1,
                                                                          min_samples_split=2,
                                                                          min_weight_fraction_leaf=0.0,
                                                                          n_estimators=100,
                                                                          n_iter_no_change=None,
                                                                          random_state=123,
                                                                          subsample=1.0,
                                                                          tol=0.0001,
                                                                          validation_fraction=0.1,
                                                                          verbose=0,
                                                                          warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-09 16:31:26,623:INFO:create_model() successfully completed......................................
2023-08-09 16:31:27,008:INFO:_master_model_container: 23
2023-08-09 16:31:27,008:INFO:_display_container: 7
2023-08-09 16:31:27,015:INFO:Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing...
                                                                          max_features=None,
                                                                          max_leaf_nodes=None,
                                                                          min_impurity_decrease=0.0,
                                                                          min_samples_leaf=1,
                                                                          min_samples_split=2,
                                                                          min_weight_fraction_leaf=0.0,
                                                                          n_estimators=100,
                                                                          n_iter_no_change=None,
                                                                          random_state=123,
                                                                          subsample=1.0,
                                                                          tol=0.0001,
                                                                          validation_fraction=0.1,
                                                                          verbose=0,
                                                                          warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-09 16:31:27,015:INFO:finalize_model() successfully completed......................................
2023-08-09 16:34:47,819:INFO:PyCaret ClassificationExperiment
2023-08-09 16:34:47,819:INFO:Logging name: clf-default-name
2023-08-09 16:34:47,819:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-09 16:34:47,819:INFO:version 3.0.4
2023-08-09 16:34:47,819:INFO:Initializing setup()
2023-08-09 16:34:47,819:INFO:self.USI: 3659
2023-08-09 16:34:47,820:INFO:self._variable_keys: {'data', 'y_train', 'USI', 'html_param', 'seed', 'target_param', 'exp_name_log', 'fold_groups_param', 'y', 'gpu_param', '_available_plots', 'gpu_n_jobs_param', 'fold_shuffle_param', 'pipeline', 'memory', 'X', 'fix_imbalance', 'fold_generator', 'is_multiclass', '_ml_usecase', 'log_plots_param', 'X_test', 'y_test', 'logging_param', 'n_jobs_param', 'exp_id', 'X_train', 'idx'}
2023-08-09 16:34:47,820:INFO:Checking environment
2023-08-09 16:34:47,820:INFO:python_version: 3.10.12
2023-08-09 16:34:47,820:INFO:python_build: ('main', 'Jul  5 2023 19:09:20')
2023-08-09 16:34:47,820:INFO:machine: AMD64
2023-08-09 16:34:47,820:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-09 16:34:47,820:INFO:Memory: svmem(total=16828977152, available=3279912960, percent=80.5, used=13549064192, free=3279912960)
2023-08-09 16:34:47,820:INFO:Physical Core: 14
2023-08-09 16:34:47,820:INFO:Logical Core: 20
2023-08-09 16:34:47,820:INFO:Checking libraries
2023-08-09 16:34:47,820:INFO:System:
2023-08-09 16:34:47,820:INFO:    python: 3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:09:20) [MSC v.1916 64 bit (AMD64)]
2023-08-09 16:34:47,820:INFO:executable: C:\Users\user21\anaconda3\python.exe
2023-08-09 16:34:47,820:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-09 16:34:47,820:INFO:PyCaret required dependencies:
2023-08-09 16:34:47,820:INFO:                 pip: 23.2.1
2023-08-09 16:34:47,820:INFO:          setuptools: 68.0.0
2023-08-09 16:34:47,820:INFO:             pycaret: 3.0.4
2023-08-09 16:34:47,820:INFO:             IPython: 8.12.0
2023-08-09 16:34:47,820:INFO:          ipywidgets: 8.1.0
2023-08-09 16:34:47,820:INFO:                tqdm: 4.65.0
2023-08-09 16:34:47,820:INFO:               numpy: 1.23.5
2023-08-09 16:34:47,820:INFO:              pandas: 1.5.3
2023-08-09 16:34:47,820:INFO:              jinja2: 3.1.2
2023-08-09 16:34:47,820:INFO:               scipy: 1.11.1
2023-08-09 16:34:47,820:INFO:              joblib: 1.3.1
2023-08-09 16:34:47,820:INFO:             sklearn: 1.2.2
2023-08-09 16:34:47,820:INFO:                pyod: 1.1.0
2023-08-09 16:34:47,820:INFO:            imblearn: 0.11.0
2023-08-09 16:34:47,820:INFO:   category_encoders: 2.6.1
2023-08-09 16:34:47,820:INFO:            lightgbm: 4.0.0
2023-08-09 16:34:47,820:INFO:               numba: 0.57.1
2023-08-09 16:34:47,820:INFO:            requests: 2.31.0
2023-08-09 16:34:47,820:INFO:          matplotlib: 3.7.2
2023-08-09 16:34:47,820:INFO:          scikitplot: 0.3.7
2023-08-09 16:34:47,820:INFO:         yellowbrick: 1.5
2023-08-09 16:34:47,820:INFO:              plotly: 5.15.0
2023-08-09 16:34:47,820:INFO:    plotly-resampler: Not installed
2023-08-09 16:34:47,820:INFO:             kaleido: 0.2.1
2023-08-09 16:34:47,820:INFO:           schemdraw: 0.15
2023-08-09 16:34:47,821:INFO:         statsmodels: 0.14.0
2023-08-09 16:34:47,821:INFO:              sktime: 0.21.0
2023-08-09 16:34:47,821:INFO:               tbats: 1.1.3
2023-08-09 16:34:47,821:INFO:            pmdarima: 2.0.3
2023-08-09 16:34:47,821:INFO:              psutil: 5.9.0
2023-08-09 16:34:47,821:INFO:          markupsafe: 2.1.1
2023-08-09 16:34:47,821:INFO:             pickle5: Not installed
2023-08-09 16:34:47,821:INFO:         cloudpickle: 2.2.1
2023-08-09 16:34:47,821:INFO:         deprecation: 2.1.0
2023-08-09 16:34:47,821:INFO:              xxhash: 3.3.0
2023-08-09 16:34:47,821:INFO:           wurlitzer: Not installed
2023-08-09 16:34:47,821:INFO:PyCaret optional dependencies:
2023-08-09 16:34:47,821:INFO:                shap: Not installed
2023-08-09 16:34:47,821:INFO:           interpret: Not installed
2023-08-09 16:34:47,821:INFO:                umap: Not installed
2023-08-09 16:34:47,821:INFO:    pandas_profiling: Not installed
2023-08-09 16:34:47,821:INFO:  explainerdashboard: Not installed
2023-08-09 16:34:47,821:INFO:             autoviz: Not installed
2023-08-09 16:34:47,821:INFO:           fairlearn: Not installed
2023-08-09 16:34:47,821:INFO:          deepchecks: Not installed
2023-08-09 16:34:47,821:INFO:             xgboost: 1.7.6
2023-08-09 16:34:47,821:INFO:            catboost: 1.2
2023-08-09 16:34:47,821:INFO:              kmodes: Not installed
2023-08-09 16:34:47,821:INFO:             mlxtend: Not installed
2023-08-09 16:34:47,821:INFO:       statsforecast: Not installed
2023-08-09 16:34:47,821:INFO:        tune_sklearn: Not installed
2023-08-09 16:34:47,821:INFO:                 ray: Not installed
2023-08-09 16:34:47,821:INFO:            hyperopt: Not installed
2023-08-09 16:34:47,821:INFO:              optuna: 3.2.0
2023-08-09 16:34:47,821:INFO:               skopt: Not installed
2023-08-09 16:34:47,821:INFO:              mlflow: Not installed
2023-08-09 16:34:47,821:INFO:              gradio: Not installed
2023-08-09 16:34:47,821:INFO:             fastapi: Not installed
2023-08-09 16:34:47,821:INFO:             uvicorn: Not installed
2023-08-09 16:34:47,821:INFO:              m2cgen: Not installed
2023-08-09 16:34:47,821:INFO:           evidently: Not installed
2023-08-09 16:34:47,821:INFO:               fugue: Not installed
2023-08-09 16:34:47,821:INFO:           streamlit: Not installed
2023-08-09 16:34:47,821:INFO:             prophet: Not installed
2023-08-09 16:34:47,821:INFO:None
2023-08-09 16:34:47,821:INFO:Set up data.
2023-08-09 16:36:14,089:INFO:PyCaret ClassificationExperiment
2023-08-09 16:36:14,090:INFO:Logging name: clf-default-name
2023-08-09 16:36:14,090:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-09 16:36:14,091:INFO:version 3.0.4
2023-08-09 16:36:14,091:INFO:Initializing setup()
2023-08-09 16:36:14,091:INFO:self.USI: be51
2023-08-09 16:36:14,091:INFO:self._variable_keys: {'data', 'y_train', 'USI', 'html_param', 'seed', 'target_param', 'exp_name_log', 'fold_groups_param', 'y', 'gpu_param', '_available_plots', 'gpu_n_jobs_param', 'fold_shuffle_param', 'pipeline', 'memory', 'X', 'fix_imbalance', 'fold_generator', 'is_multiclass', '_ml_usecase', 'log_plots_param', 'X_test', 'y_test', 'logging_param', 'n_jobs_param', 'exp_id', 'X_train', 'idx'}
2023-08-09 16:36:14,091:INFO:Checking environment
2023-08-09 16:36:14,091:INFO:python_version: 3.10.12
2023-08-09 16:36:14,091:INFO:python_build: ('main', 'Jul  5 2023 19:09:20')
2023-08-09 16:36:14,091:INFO:machine: AMD64
2023-08-09 16:36:14,091:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-09 16:36:14,091:INFO:Memory: svmem(total=16828977152, available=3277836288, percent=80.5, used=13551140864, free=3277836288)
2023-08-09 16:36:14,091:INFO:Physical Core: 14
2023-08-09 16:36:14,091:INFO:Logical Core: 20
2023-08-09 16:36:14,091:INFO:Checking libraries
2023-08-09 16:36:14,091:INFO:System:
2023-08-09 16:36:14,091:INFO:    python: 3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:09:20) [MSC v.1916 64 bit (AMD64)]
2023-08-09 16:36:14,091:INFO:executable: C:\Users\user21\anaconda3\python.exe
2023-08-09 16:36:14,091:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-09 16:36:14,091:INFO:PyCaret required dependencies:
2023-08-09 16:36:14,091:INFO:                 pip: 23.2.1
2023-08-09 16:36:14,091:INFO:          setuptools: 68.0.0
2023-08-09 16:36:14,091:INFO:             pycaret: 3.0.4
2023-08-09 16:36:14,091:INFO:             IPython: 8.12.0
2023-08-09 16:36:14,091:INFO:          ipywidgets: 8.1.0
2023-08-09 16:36:14,091:INFO:                tqdm: 4.65.0
2023-08-09 16:36:14,091:INFO:               numpy: 1.23.5
2023-08-09 16:36:14,091:INFO:              pandas: 1.5.3
2023-08-09 16:36:14,091:INFO:              jinja2: 3.1.2
2023-08-09 16:36:14,091:INFO:               scipy: 1.11.1
2023-08-09 16:36:14,091:INFO:              joblib: 1.3.1
2023-08-09 16:36:14,091:INFO:             sklearn: 1.2.2
2023-08-09 16:36:14,091:INFO:                pyod: 1.1.0
2023-08-09 16:36:14,091:INFO:            imblearn: 0.11.0
2023-08-09 16:36:14,091:INFO:   category_encoders: 2.6.1
2023-08-09 16:36:14,091:INFO:            lightgbm: 4.0.0
2023-08-09 16:36:14,091:INFO:               numba: 0.57.1
2023-08-09 16:36:14,091:INFO:            requests: 2.31.0
2023-08-09 16:36:14,092:INFO:          matplotlib: 3.7.2
2023-08-09 16:36:14,092:INFO:          scikitplot: 0.3.7
2023-08-09 16:36:14,092:INFO:         yellowbrick: 1.5
2023-08-09 16:36:14,092:INFO:              plotly: 5.15.0
2023-08-09 16:36:14,092:INFO:    plotly-resampler: Not installed
2023-08-09 16:36:14,092:INFO:             kaleido: 0.2.1
2023-08-09 16:36:14,092:INFO:           schemdraw: 0.15
2023-08-09 16:36:14,092:INFO:         statsmodels: 0.14.0
2023-08-09 16:36:14,092:INFO:              sktime: 0.21.0
2023-08-09 16:36:14,092:INFO:               tbats: 1.1.3
2023-08-09 16:36:14,092:INFO:            pmdarima: 2.0.3
2023-08-09 16:36:14,092:INFO:              psutil: 5.9.0
2023-08-09 16:36:14,092:INFO:          markupsafe: 2.1.1
2023-08-09 16:36:14,092:INFO:             pickle5: Not installed
2023-08-09 16:36:14,092:INFO:         cloudpickle: 2.2.1
2023-08-09 16:36:14,092:INFO:         deprecation: 2.1.0
2023-08-09 16:36:14,092:INFO:              xxhash: 3.3.0
2023-08-09 16:36:14,092:INFO:           wurlitzer: Not installed
2023-08-09 16:36:14,092:INFO:PyCaret optional dependencies:
2023-08-09 16:36:14,092:INFO:                shap: Not installed
2023-08-09 16:36:14,092:INFO:           interpret: Not installed
2023-08-09 16:36:14,092:INFO:                umap: Not installed
2023-08-09 16:36:14,092:INFO:    pandas_profiling: Not installed
2023-08-09 16:36:14,092:INFO:  explainerdashboard: Not installed
2023-08-09 16:36:14,092:INFO:             autoviz: Not installed
2023-08-09 16:36:14,092:INFO:           fairlearn: Not installed
2023-08-09 16:36:14,092:INFO:          deepchecks: Not installed
2023-08-09 16:36:14,092:INFO:             xgboost: 1.7.6
2023-08-09 16:36:14,092:INFO:            catboost: 1.2
2023-08-09 16:36:14,092:INFO:              kmodes: Not installed
2023-08-09 16:36:14,092:INFO:             mlxtend: Not installed
2023-08-09 16:36:14,092:INFO:       statsforecast: Not installed
2023-08-09 16:36:14,092:INFO:        tune_sklearn: Not installed
2023-08-09 16:36:14,092:INFO:                 ray: Not installed
2023-08-09 16:36:14,092:INFO:            hyperopt: Not installed
2023-08-09 16:36:14,092:INFO:              optuna: 3.2.0
2023-08-09 16:36:14,092:INFO:               skopt: Not installed
2023-08-09 16:36:14,092:INFO:              mlflow: Not installed
2023-08-09 16:36:14,092:INFO:              gradio: Not installed
2023-08-09 16:36:14,092:INFO:             fastapi: Not installed
2023-08-09 16:36:14,092:INFO:             uvicorn: Not installed
2023-08-09 16:36:14,092:INFO:              m2cgen: Not installed
2023-08-09 16:36:14,092:INFO:           evidently: Not installed
2023-08-09 16:36:14,092:INFO:               fugue: Not installed
2023-08-09 16:36:14,092:INFO:           streamlit: Not installed
2023-08-09 16:36:14,092:INFO:             prophet: Not installed
2023-08-09 16:36:14,092:INFO:None
2023-08-09 16:36:14,092:INFO:Set up data.
2023-08-09 16:38:14,312:INFO:PyCaret ClassificationExperiment
2023-08-09 16:38:14,312:INFO:Logging name: clf-default-name
2023-08-09 16:38:14,312:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-09 16:38:14,312:INFO:version 3.0.4
2023-08-09 16:38:14,312:INFO:Initializing setup()
2023-08-09 16:38:14,312:INFO:self.USI: ced0
2023-08-09 16:38:14,312:INFO:self._variable_keys: {'data', 'y_train', 'USI', 'html_param', 'seed', 'target_param', 'exp_name_log', 'fold_groups_param', 'y', 'gpu_param', '_available_plots', 'gpu_n_jobs_param', 'fold_shuffle_param', 'pipeline', 'memory', 'X', 'fix_imbalance', 'fold_generator', 'is_multiclass', '_ml_usecase', 'log_plots_param', 'X_test', 'y_test', 'logging_param', 'n_jobs_param', 'exp_id', 'X_train', 'idx'}
2023-08-09 16:38:14,312:INFO:Checking environment
2023-08-09 16:38:14,312:INFO:python_version: 3.10.12
2023-08-09 16:38:14,312:INFO:python_build: ('main', 'Jul  5 2023 19:09:20')
2023-08-09 16:38:14,312:INFO:machine: AMD64
2023-08-09 16:38:14,312:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-09 16:38:14,312:INFO:Memory: svmem(total=16828977152, available=5803630592, percent=65.5, used=11025346560, free=5803630592)
2023-08-09 16:38:14,312:INFO:Physical Core: 14
2023-08-09 16:38:14,312:INFO:Logical Core: 20
2023-08-09 16:38:14,312:INFO:Checking libraries
2023-08-09 16:38:14,312:INFO:System:
2023-08-09 16:38:14,312:INFO:    python: 3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:09:20) [MSC v.1916 64 bit (AMD64)]
2023-08-09 16:38:14,312:INFO:executable: C:\Users\user21\anaconda3\python.exe
2023-08-09 16:38:14,312:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-09 16:38:14,312:INFO:PyCaret required dependencies:
2023-08-09 16:38:14,312:INFO:                 pip: 23.2.1
2023-08-09 16:38:14,312:INFO:          setuptools: 68.0.0
2023-08-09 16:38:14,312:INFO:             pycaret: 3.0.4
2023-08-09 16:38:14,312:INFO:             IPython: 8.12.0
2023-08-09 16:38:14,313:INFO:          ipywidgets: 8.1.0
2023-08-09 16:38:14,313:INFO:                tqdm: 4.65.0
2023-08-09 16:38:14,313:INFO:               numpy: 1.23.5
2023-08-09 16:38:14,313:INFO:              pandas: 1.5.3
2023-08-09 16:38:14,313:INFO:              jinja2: 3.1.2
2023-08-09 16:38:14,313:INFO:               scipy: 1.11.1
2023-08-09 16:38:14,313:INFO:              joblib: 1.3.1
2023-08-09 16:38:14,313:INFO:             sklearn: 1.2.2
2023-08-09 16:38:14,313:INFO:                pyod: 1.1.0
2023-08-09 16:38:14,313:INFO:            imblearn: 0.11.0
2023-08-09 16:38:14,313:INFO:   category_encoders: 2.6.1
2023-08-09 16:38:14,313:INFO:            lightgbm: 4.0.0
2023-08-09 16:38:14,313:INFO:               numba: 0.57.1
2023-08-09 16:38:14,313:INFO:            requests: 2.31.0
2023-08-09 16:38:14,313:INFO:          matplotlib: 3.7.2
2023-08-09 16:38:14,313:INFO:          scikitplot: 0.3.7
2023-08-09 16:38:14,313:INFO:         yellowbrick: 1.5
2023-08-09 16:38:14,313:INFO:              plotly: 5.15.0
2023-08-09 16:38:14,313:INFO:    plotly-resampler: Not installed
2023-08-09 16:38:14,313:INFO:             kaleido: 0.2.1
2023-08-09 16:38:14,313:INFO:           schemdraw: 0.15
2023-08-09 16:38:14,313:INFO:         statsmodels: 0.14.0
2023-08-09 16:38:14,313:INFO:              sktime: 0.21.0
2023-08-09 16:38:14,313:INFO:               tbats: 1.1.3
2023-08-09 16:38:14,313:INFO:            pmdarima: 2.0.3
2023-08-09 16:38:14,313:INFO:              psutil: 5.9.0
2023-08-09 16:38:14,313:INFO:          markupsafe: 2.1.1
2023-08-09 16:38:14,313:INFO:             pickle5: Not installed
2023-08-09 16:38:14,313:INFO:         cloudpickle: 2.2.1
2023-08-09 16:38:14,313:INFO:         deprecation: 2.1.0
2023-08-09 16:38:14,313:INFO:              xxhash: 3.3.0
2023-08-09 16:38:14,313:INFO:           wurlitzer: Not installed
2023-08-09 16:38:14,313:INFO:PyCaret optional dependencies:
2023-08-09 16:38:14,313:INFO:                shap: Not installed
2023-08-09 16:38:14,313:INFO:           interpret: Not installed
2023-08-09 16:38:14,313:INFO:                umap: Not installed
2023-08-09 16:38:14,313:INFO:    pandas_profiling: Not installed
2023-08-09 16:38:14,313:INFO:  explainerdashboard: Not installed
2023-08-09 16:38:14,313:INFO:             autoviz: Not installed
2023-08-09 16:38:14,313:INFO:           fairlearn: Not installed
2023-08-09 16:38:14,313:INFO:          deepchecks: Not installed
2023-08-09 16:38:14,313:INFO:             xgboost: 1.7.6
2023-08-09 16:38:14,313:INFO:            catboost: 1.2
2023-08-09 16:38:14,313:INFO:              kmodes: Not installed
2023-08-09 16:38:14,313:INFO:             mlxtend: Not installed
2023-08-09 16:38:14,313:INFO:       statsforecast: Not installed
2023-08-09 16:38:14,313:INFO:        tune_sklearn: Not installed
2023-08-09 16:38:14,313:INFO:                 ray: Not installed
2023-08-09 16:38:14,314:INFO:            hyperopt: Not installed
2023-08-09 16:38:14,314:INFO:              optuna: 3.2.0
2023-08-09 16:38:14,314:INFO:               skopt: Not installed
2023-08-09 16:38:14,314:INFO:              mlflow: Not installed
2023-08-09 16:38:14,314:INFO:              gradio: Not installed
2023-08-09 16:38:14,314:INFO:             fastapi: Not installed
2023-08-09 16:38:14,314:INFO:             uvicorn: Not installed
2023-08-09 16:38:14,314:INFO:              m2cgen: Not installed
2023-08-09 16:38:14,314:INFO:           evidently: Not installed
2023-08-09 16:38:14,314:INFO:               fugue: Not installed
2023-08-09 16:38:14,314:INFO:           streamlit: Not installed
2023-08-09 16:38:14,314:INFO:             prophet: Not installed
2023-08-09 16:38:14,314:INFO:None
2023-08-09 16:38:14,314:INFO:Set up data.
2023-08-09 16:38:31,410:INFO:PyCaret ClassificationExperiment
2023-08-09 16:38:31,410:INFO:Logging name: clf-default-name
2023-08-09 16:38:31,410:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-09 16:38:31,410:INFO:version 3.0.4
2023-08-09 16:38:31,410:INFO:Initializing setup()
2023-08-09 16:38:31,410:INFO:self.USI: d082
2023-08-09 16:38:31,410:INFO:self._variable_keys: {'data', 'y_train', 'USI', 'html_param', 'seed', 'target_param', 'exp_name_log', 'fold_groups_param', 'y', 'gpu_param', '_available_plots', 'gpu_n_jobs_param', 'fold_shuffle_param', 'pipeline', 'memory', 'X', 'fix_imbalance', 'fold_generator', 'is_multiclass', '_ml_usecase', 'log_plots_param', 'X_test', 'y_test', 'logging_param', 'n_jobs_param', 'exp_id', 'X_train', 'idx'}
2023-08-09 16:38:31,410:INFO:Checking environment
2023-08-09 16:38:31,410:INFO:python_version: 3.10.12
2023-08-09 16:38:31,411:INFO:python_build: ('main', 'Jul  5 2023 19:09:20')
2023-08-09 16:38:31,411:INFO:machine: AMD64
2023-08-09 16:38:31,411:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-09 16:38:31,411:INFO:Memory: svmem(total=16828977152, available=5959098368, percent=64.6, used=10869878784, free=5959098368)
2023-08-09 16:38:31,411:INFO:Physical Core: 14
2023-08-09 16:38:31,411:INFO:Logical Core: 20
2023-08-09 16:38:31,411:INFO:Checking libraries
2023-08-09 16:38:31,411:INFO:System:
2023-08-09 16:38:31,411:INFO:    python: 3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:09:20) [MSC v.1916 64 bit (AMD64)]
2023-08-09 16:38:31,411:INFO:executable: C:\Users\user21\anaconda3\python.exe
2023-08-09 16:38:31,411:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-09 16:38:31,411:INFO:PyCaret required dependencies:
2023-08-09 16:38:31,411:INFO:                 pip: 23.2.1
2023-08-09 16:38:31,411:INFO:          setuptools: 68.0.0
2023-08-09 16:38:31,411:INFO:             pycaret: 3.0.4
2023-08-09 16:38:31,411:INFO:             IPython: 8.12.0
2023-08-09 16:38:31,411:INFO:          ipywidgets: 8.1.0
2023-08-09 16:38:31,411:INFO:                tqdm: 4.65.0
2023-08-09 16:38:31,411:INFO:               numpy: 1.23.5
2023-08-09 16:38:31,411:INFO:              pandas: 1.5.3
2023-08-09 16:38:31,411:INFO:              jinja2: 3.1.2
2023-08-09 16:38:31,411:INFO:               scipy: 1.11.1
2023-08-09 16:38:31,411:INFO:              joblib: 1.3.1
2023-08-09 16:38:31,411:INFO:             sklearn: 1.2.2
2023-08-09 16:38:31,411:INFO:                pyod: 1.1.0
2023-08-09 16:38:31,411:INFO:            imblearn: 0.11.0
2023-08-09 16:38:31,411:INFO:   category_encoders: 2.6.1
2023-08-09 16:38:31,411:INFO:            lightgbm: 4.0.0
2023-08-09 16:38:31,411:INFO:               numba: 0.57.1
2023-08-09 16:38:31,411:INFO:            requests: 2.31.0
2023-08-09 16:38:31,411:INFO:          matplotlib: 3.7.2
2023-08-09 16:38:31,411:INFO:          scikitplot: 0.3.7
2023-08-09 16:38:31,411:INFO:         yellowbrick: 1.5
2023-08-09 16:38:31,411:INFO:              plotly: 5.15.0
2023-08-09 16:38:31,411:INFO:    plotly-resampler: Not installed
2023-08-09 16:38:31,411:INFO:             kaleido: 0.2.1
2023-08-09 16:38:31,411:INFO:           schemdraw: 0.15
2023-08-09 16:38:31,411:INFO:         statsmodels: 0.14.0
2023-08-09 16:38:31,411:INFO:              sktime: 0.21.0
2023-08-09 16:38:31,412:INFO:               tbats: 1.1.3
2023-08-09 16:38:31,412:INFO:            pmdarima: 2.0.3
2023-08-09 16:38:31,412:INFO:              psutil: 5.9.0
2023-08-09 16:38:31,412:INFO:          markupsafe: 2.1.1
2023-08-09 16:38:31,412:INFO:             pickle5: Not installed
2023-08-09 16:38:31,412:INFO:         cloudpickle: 2.2.1
2023-08-09 16:38:31,412:INFO:         deprecation: 2.1.0
2023-08-09 16:38:31,412:INFO:              xxhash: 3.3.0
2023-08-09 16:38:31,412:INFO:           wurlitzer: Not installed
2023-08-09 16:38:31,412:INFO:PyCaret optional dependencies:
2023-08-09 16:38:31,412:INFO:                shap: Not installed
2023-08-09 16:38:31,412:INFO:           interpret: Not installed
2023-08-09 16:38:31,412:INFO:                umap: Not installed
2023-08-09 16:38:31,412:INFO:    pandas_profiling: Not installed
2023-08-09 16:38:31,412:INFO:  explainerdashboard: Not installed
2023-08-09 16:38:31,412:INFO:             autoviz: Not installed
2023-08-09 16:38:31,412:INFO:           fairlearn: Not installed
2023-08-09 16:38:31,412:INFO:          deepchecks: Not installed
2023-08-09 16:38:31,412:INFO:             xgboost: 1.7.6
2023-08-09 16:38:31,412:INFO:            catboost: 1.2
2023-08-09 16:38:31,412:INFO:              kmodes: Not installed
2023-08-09 16:38:31,412:INFO:             mlxtend: Not installed
2023-08-09 16:38:31,412:INFO:       statsforecast: Not installed
2023-08-09 16:38:31,412:INFO:        tune_sklearn: Not installed
2023-08-09 16:38:31,412:INFO:                 ray: Not installed
2023-08-09 16:38:31,412:INFO:            hyperopt: Not installed
2023-08-09 16:38:31,412:INFO:              optuna: 3.2.0
2023-08-09 16:38:31,412:INFO:               skopt: Not installed
2023-08-09 16:38:31,412:INFO:              mlflow: Not installed
2023-08-09 16:38:31,412:INFO:              gradio: Not installed
2023-08-09 16:38:31,412:INFO:             fastapi: Not installed
2023-08-09 16:38:31,412:INFO:             uvicorn: Not installed
2023-08-09 16:38:31,412:INFO:              m2cgen: Not installed
2023-08-09 16:38:31,412:INFO:           evidently: Not installed
2023-08-09 16:38:31,412:INFO:               fugue: Not installed
2023-08-09 16:38:31,412:INFO:           streamlit: Not installed
2023-08-09 16:38:31,412:INFO:             prophet: Not installed
2023-08-09 16:38:31,412:INFO:None
2023-08-09 16:38:31,412:INFO:Set up data.
2023-08-09 16:38:31,418:INFO:Set up train/test split.
2023-08-09 16:38:31,422:INFO:Set up index.
2023-08-09 16:38:31,422:INFO:Set up folding strategy.
2023-08-09 16:38:31,422:INFO:Assigning column types.
2023-08-09 16:38:31,424:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-09 16:38:31,452:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-09 16:38:31,453:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 16:38:31,470:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:38:31,472:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:38:31,501:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-09 16:38:31,501:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 16:38:31,520:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:38:31,522:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:38:31,523:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-09 16:38:31,550:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 16:38:31,567:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:38:31,569:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:38:31,597:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 16:38:31,614:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:38:31,615:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:38:31,616:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-09 16:38:31,661:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:38:31,663:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:38:31,710:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:38:31,711:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:38:31,712:INFO:Preparing preprocessing pipeline...
2023-08-09 16:38:31,713:INFO:Set up simple imputation.
2023-08-09 16:38:31,713:INFO:Set up column name cleaning.
2023-08-09 16:38:31,729:INFO:Finished creating preprocessing pipeline.
2023-08-09 16:38:31,732:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases', 'Weight_in_gms',
                                             'Warehouse_block_A',
                                             'Warehouse_block_B',
                                             'Warehouse_block_C',
                                             'Warehouse_block_D',
                                             'Warehouse_block_F',
                                             'Mode_...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-09 16:38:31,732:INFO:Creating final display dataframe.
2023-08-09 16:38:31,790:INFO:Setup _display_container:                     Description                Value
0                    Session id                  123
1                        Target  Reached.on.Time_Y.N
2                   Target type               Binary
3           Original data shape           (6897, 17)
4        Transformed data shape           (6897, 17)
5   Transformed train set shape           (4827, 17)
6    Transformed test set shape           (2070, 17)
7              Numeric features                   16
8                    Preprocess                 True
9               Imputation type               simple
10           Numeric imputation                 mean
11       Categorical imputation                 mode
12               Fold Generator      StratifiedKFold
13                  Fold Number                   10
14                     CPU Jobs                   -1
15                      Use GPU                False
16               Log Experiment                False
17              Experiment Name     clf-default-name
18                          USI                 d082
2023-08-09 16:38:31,839:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:38:31,841:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:38:31,896:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:38:31,898:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:38:31,898:INFO:setup() successfully completed in 0.66s...............
2023-08-09 16:38:31,898:INFO:Initializing compare_models()
2023-08-09 16:38:31,898:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712F3F2B0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000023712F3F2B0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-09 16:38:31,898:INFO:Checking exceptions
2023-08-09 16:38:31,901:INFO:Preparing display monitor
2023-08-09 16:38:31,916:INFO:Initializing Logistic Regression
2023-08-09 16:38:31,916:INFO:Total runtime is 0.0 minutes
2023-08-09 16:38:31,920:INFO:SubProcess create_model() called ==================================
2023-08-09 16:38:31,920:INFO:Initializing create_model()
2023-08-09 16:38:31,920:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712F3F2B0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002371306B040>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:38:31,920:INFO:Checking exceptions
2023-08-09 16:38:31,920:INFO:Importing libraries
2023-08-09 16:38:31,920:INFO:Copying training dataset
2023-08-09 16:38:31,923:INFO:Defining folds
2023-08-09 16:38:31,923:INFO:Declaring metric variables
2023-08-09 16:38:31,925:INFO:Importing untrained model
2023-08-09 16:38:31,928:INFO:Logistic Regression Imported successfully
2023-08-09 16:38:31,933:INFO:Starting cross validation
2023-08-09 16:38:31,934:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:38:35,524:INFO:Calculating mean and std
2023-08-09 16:38:35,525:INFO:Creating metrics dataframe
2023-08-09 16:38:35,774:INFO:Uploading results into container
2023-08-09 16:38:35,774:INFO:Uploading model into container now
2023-08-09 16:38:35,776:INFO:_master_model_container: 1
2023-08-09 16:38:35,776:INFO:_display_container: 2
2023-08-09 16:38:35,776:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-09 16:38:35,776:INFO:create_model() successfully completed......................................
2023-08-09 16:38:36,886:INFO:SubProcess create_model() end ==================================
2023-08-09 16:38:36,886:INFO:Creating metrics dataframe
2023-08-09 16:38:36,892:INFO:Initializing K Neighbors Classifier
2023-08-09 16:38:36,892:INFO:Total runtime is 0.08294057846069336 minutes
2023-08-09 16:38:36,894:INFO:SubProcess create_model() called ==================================
2023-08-09 16:38:36,894:INFO:Initializing create_model()
2023-08-09 16:38:36,894:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712F3F2B0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002371306B040>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:38:36,894:INFO:Checking exceptions
2023-08-09 16:38:36,894:INFO:Importing libraries
2023-08-09 16:38:36,894:INFO:Copying training dataset
2023-08-09 16:38:36,899:INFO:Defining folds
2023-08-09 16:38:36,899:INFO:Declaring metric variables
2023-08-09 16:38:36,902:INFO:Importing untrained model
2023-08-09 16:38:36,904:INFO:K Neighbors Classifier Imported successfully
2023-08-09 16:38:36,908:INFO:Starting cross validation
2023-08-09 16:38:36,908:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:38:40,533:INFO:Calculating mean and std
2023-08-09 16:38:40,534:INFO:Creating metrics dataframe
2023-08-09 16:38:40,791:INFO:Uploading results into container
2023-08-09 16:38:40,792:INFO:Uploading model into container now
2023-08-09 16:38:40,792:INFO:_master_model_container: 2
2023-08-09 16:38:40,792:INFO:_display_container: 2
2023-08-09 16:38:40,792:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-09 16:38:40,792:INFO:create_model() successfully completed......................................
2023-08-09 16:38:41,177:INFO:SubProcess create_model() end ==================================
2023-08-09 16:38:41,179:INFO:Creating metrics dataframe
2023-08-09 16:38:41,186:INFO:Initializing Naive Bayes
2023-08-09 16:38:41,186:INFO:Total runtime is 0.15450835227966309 minutes
2023-08-09 16:38:41,189:INFO:SubProcess create_model() called ==================================
2023-08-09 16:38:41,190:INFO:Initializing create_model()
2023-08-09 16:38:41,190:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712F3F2B0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002371306B040>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:38:41,190:INFO:Checking exceptions
2023-08-09 16:38:41,190:INFO:Importing libraries
2023-08-09 16:38:41,190:INFO:Copying training dataset
2023-08-09 16:38:41,195:INFO:Defining folds
2023-08-09 16:38:41,195:INFO:Declaring metric variables
2023-08-09 16:38:41,199:INFO:Importing untrained model
2023-08-09 16:38:41,201:INFO:Naive Bayes Imported successfully
2023-08-09 16:38:41,206:INFO:Starting cross validation
2023-08-09 16:38:41,207:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:38:42,979:INFO:Calculating mean and std
2023-08-09 16:38:42,980:INFO:Creating metrics dataframe
2023-08-09 16:38:43,235:INFO:Uploading results into container
2023-08-09 16:38:43,235:INFO:Uploading model into container now
2023-08-09 16:38:43,236:INFO:_master_model_container: 3
2023-08-09 16:38:43,236:INFO:_display_container: 2
2023-08-09 16:38:43,236:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-09 16:38:43,236:INFO:create_model() successfully completed......................................
2023-08-09 16:38:43,631:INFO:SubProcess create_model() end ==================================
2023-08-09 16:38:43,631:INFO:Creating metrics dataframe
2023-08-09 16:38:43,639:INFO:Initializing Decision Tree Classifier
2023-08-09 16:38:43,639:INFO:Total runtime is 0.19537726640701295 minutes
2023-08-09 16:38:43,641:INFO:SubProcess create_model() called ==================================
2023-08-09 16:38:43,641:INFO:Initializing create_model()
2023-08-09 16:38:43,641:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712F3F2B0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002371306B040>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:38:43,641:INFO:Checking exceptions
2023-08-09 16:38:43,641:INFO:Importing libraries
2023-08-09 16:38:43,641:INFO:Copying training dataset
2023-08-09 16:38:43,645:INFO:Defining folds
2023-08-09 16:38:43,645:INFO:Declaring metric variables
2023-08-09 16:38:43,648:INFO:Importing untrained model
2023-08-09 16:38:43,650:INFO:Decision Tree Classifier Imported successfully
2023-08-09 16:38:43,656:INFO:Starting cross validation
2023-08-09 16:38:43,656:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:38:45,440:INFO:Calculating mean and std
2023-08-09 16:38:45,441:INFO:Creating metrics dataframe
2023-08-09 16:38:45,700:INFO:Uploading results into container
2023-08-09 16:38:45,701:INFO:Uploading model into container now
2023-08-09 16:38:45,701:INFO:_master_model_container: 4
2023-08-09 16:38:45,701:INFO:_display_container: 2
2023-08-09 16:38:45,702:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-08-09 16:38:45,702:INFO:create_model() successfully completed......................................
2023-08-09 16:38:46,082:INFO:SubProcess create_model() end ==================================
2023-08-09 16:38:46,082:INFO:Creating metrics dataframe
2023-08-09 16:38:46,090:INFO:Initializing SVM - Linear Kernel
2023-08-09 16:38:46,090:INFO:Total runtime is 0.23623679876327514 minutes
2023-08-09 16:38:46,093:INFO:SubProcess create_model() called ==================================
2023-08-09 16:38:46,094:INFO:Initializing create_model()
2023-08-09 16:38:46,094:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712F3F2B0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002371306B040>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:38:46,094:INFO:Checking exceptions
2023-08-09 16:38:46,094:INFO:Importing libraries
2023-08-09 16:38:46,094:INFO:Copying training dataset
2023-08-09 16:38:46,098:INFO:Defining folds
2023-08-09 16:38:46,098:INFO:Declaring metric variables
2023-08-09 16:38:46,101:INFO:Importing untrained model
2023-08-09 16:38:46,104:INFO:SVM - Linear Kernel Imported successfully
2023-08-09 16:38:46,108:INFO:Starting cross validation
2023-08-09 16:38:46,109:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:38:46,200:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:38:46,200:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:38:46,211:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:38:46,212:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:38:46,215:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-09 16:38:46,220:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:38:46,221:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:38:46,221:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:38:46,223:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:38:46,227:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:38:46,230:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-09 16:38:46,234:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:38:47,895:INFO:Calculating mean and std
2023-08-09 16:38:47,896:INFO:Creating metrics dataframe
2023-08-09 16:38:48,149:INFO:Uploading results into container
2023-08-09 16:38:48,150:INFO:Uploading model into container now
2023-08-09 16:38:48,150:INFO:_master_model_container: 5
2023-08-09 16:38:48,150:INFO:_display_container: 2
2023-08-09 16:38:48,150:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-09 16:38:48,150:INFO:create_model() successfully completed......................................
2023-08-09 16:38:48,543:INFO:SubProcess create_model() end ==================================
2023-08-09 16:38:48,543:INFO:Creating metrics dataframe
2023-08-09 16:38:48,550:INFO:Initializing Ridge Classifier
2023-08-09 16:38:48,550:INFO:Total runtime is 0.27723646958669024 minutes
2023-08-09 16:38:48,553:INFO:SubProcess create_model() called ==================================
2023-08-09 16:38:48,553:INFO:Initializing create_model()
2023-08-09 16:38:48,553:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712F3F2B0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002371306B040>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:38:48,553:INFO:Checking exceptions
2023-08-09 16:38:48,553:INFO:Importing libraries
2023-08-09 16:38:48,553:INFO:Copying training dataset
2023-08-09 16:38:48,557:INFO:Defining folds
2023-08-09 16:38:48,557:INFO:Declaring metric variables
2023-08-09 16:38:48,559:INFO:Importing untrained model
2023-08-09 16:38:48,561:INFO:Ridge Classifier Imported successfully
2023-08-09 16:38:48,566:INFO:Starting cross validation
2023-08-09 16:38:48,567:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:38:48,621:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:38:48,625:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:38:48,626:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:38:48,630:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:38:48,640:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:38:48,645:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:38:48,646:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:38:48,647:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:38:48,649:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:38:48,657:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:38:50,328:INFO:Calculating mean and std
2023-08-09 16:38:50,329:INFO:Creating metrics dataframe
2023-08-09 16:38:50,581:INFO:Uploading results into container
2023-08-09 16:38:50,581:INFO:Uploading model into container now
2023-08-09 16:38:50,582:INFO:_master_model_container: 6
2023-08-09 16:38:50,582:INFO:_display_container: 2
2023-08-09 16:38:50,582:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-08-09 16:38:50,582:INFO:create_model() successfully completed......................................
2023-08-09 16:38:50,962:INFO:SubProcess create_model() end ==================================
2023-08-09 16:38:50,962:INFO:Creating metrics dataframe
2023-08-09 16:38:50,969:INFO:Initializing Random Forest Classifier
2023-08-09 16:38:50,970:INFO:Total runtime is 0.3175711989402771 minutes
2023-08-09 16:38:50,972:INFO:SubProcess create_model() called ==================================
2023-08-09 16:38:50,972:INFO:Initializing create_model()
2023-08-09 16:38:50,972:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712F3F2B0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002371306B040>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:38:50,972:INFO:Checking exceptions
2023-08-09 16:38:50,972:INFO:Importing libraries
2023-08-09 16:38:50,972:INFO:Copying training dataset
2023-08-09 16:38:50,976:INFO:Defining folds
2023-08-09 16:38:50,977:INFO:Declaring metric variables
2023-08-09 16:38:50,979:INFO:Importing untrained model
2023-08-09 16:38:50,981:INFO:Random Forest Classifier Imported successfully
2023-08-09 16:38:50,988:INFO:Starting cross validation
2023-08-09 16:38:50,989:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:38:53,401:INFO:Calculating mean and std
2023-08-09 16:38:53,402:INFO:Creating metrics dataframe
2023-08-09 16:38:53,655:INFO:Uploading results into container
2023-08-09 16:38:53,656:INFO:Uploading model into container now
2023-08-09 16:38:53,656:INFO:_master_model_container: 7
2023-08-09 16:38:53,656:INFO:_display_container: 2
2023-08-09 16:38:53,656:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-09 16:38:53,657:INFO:create_model() successfully completed......................................
2023-08-09 16:38:54,048:INFO:SubProcess create_model() end ==================================
2023-08-09 16:38:54,048:INFO:Creating metrics dataframe
2023-08-09 16:38:54,056:INFO:Initializing Quadratic Discriminant Analysis
2023-08-09 16:38:54,056:INFO:Total runtime is 0.36899865865707393 minutes
2023-08-09 16:38:54,058:INFO:SubProcess create_model() called ==================================
2023-08-09 16:38:54,058:INFO:Initializing create_model()
2023-08-09 16:38:54,058:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712F3F2B0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002371306B040>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:38:54,058:INFO:Checking exceptions
2023-08-09 16:38:54,058:INFO:Importing libraries
2023-08-09 16:38:54,058:INFO:Copying training dataset
2023-08-09 16:38:54,064:INFO:Defining folds
2023-08-09 16:38:54,064:INFO:Declaring metric variables
2023-08-09 16:38:54,066:INFO:Importing untrained model
2023-08-09 16:38:54,070:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-09 16:38:54,073:INFO:Starting cross validation
2023-08-09 16:38:54,074:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:38:54,111:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:38:54,119:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:38:54,128:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:38:54,129:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:38:54,129:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:38:54,131:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:38:54,136:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:38:54,142:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:38:54,144:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:38:54,148:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 16:38:55,841:INFO:Calculating mean and std
2023-08-09 16:38:55,842:INFO:Creating metrics dataframe
2023-08-09 16:38:56,097:INFO:Uploading results into container
2023-08-09 16:38:56,099:INFO:Uploading model into container now
2023-08-09 16:38:56,099:INFO:_master_model_container: 8
2023-08-09 16:38:56,099:INFO:_display_container: 2
2023-08-09 16:38:56,099:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-09 16:38:56,099:INFO:create_model() successfully completed......................................
2023-08-09 16:38:56,481:INFO:SubProcess create_model() end ==================================
2023-08-09 16:38:56,481:INFO:Creating metrics dataframe
2023-08-09 16:38:56,489:INFO:Initializing Ada Boost Classifier
2023-08-09 16:38:56,489:INFO:Total runtime is 0.4095512549082438 minutes
2023-08-09 16:38:56,492:INFO:SubProcess create_model() called ==================================
2023-08-09 16:38:56,492:INFO:Initializing create_model()
2023-08-09 16:38:56,492:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712F3F2B0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002371306B040>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:38:56,492:INFO:Checking exceptions
2023-08-09 16:38:56,492:INFO:Importing libraries
2023-08-09 16:38:56,492:INFO:Copying training dataset
2023-08-09 16:38:56,497:INFO:Defining folds
2023-08-09 16:38:56,497:INFO:Declaring metric variables
2023-08-09 16:38:56,499:INFO:Importing untrained model
2023-08-09 16:38:56,501:INFO:Ada Boost Classifier Imported successfully
2023-08-09 16:38:56,507:INFO:Starting cross validation
2023-08-09 16:38:56,508:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:38:58,560:INFO:Calculating mean and std
2023-08-09 16:38:58,561:INFO:Creating metrics dataframe
2023-08-09 16:38:58,817:INFO:Uploading results into container
2023-08-09 16:38:58,818:INFO:Uploading model into container now
2023-08-09 16:38:58,818:INFO:_master_model_container: 9
2023-08-09 16:38:58,819:INFO:_display_container: 2
2023-08-09 16:38:58,819:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-08-09 16:38:58,820:INFO:create_model() successfully completed......................................
2023-08-09 16:38:59,208:INFO:SubProcess create_model() end ==================================
2023-08-09 16:38:59,208:INFO:Creating metrics dataframe
2023-08-09 16:38:59,216:INFO:Initializing Gradient Boosting Classifier
2023-08-09 16:38:59,216:INFO:Total runtime is 0.4549994309743245 minutes
2023-08-09 16:38:59,219:INFO:SubProcess create_model() called ==================================
2023-08-09 16:38:59,219:INFO:Initializing create_model()
2023-08-09 16:38:59,219:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712F3F2B0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002371306B040>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:38:59,219:INFO:Checking exceptions
2023-08-09 16:38:59,219:INFO:Importing libraries
2023-08-09 16:38:59,219:INFO:Copying training dataset
2023-08-09 16:38:59,223:INFO:Defining folds
2023-08-09 16:38:59,223:INFO:Declaring metric variables
2023-08-09 16:38:59,226:INFO:Importing untrained model
2023-08-09 16:38:59,229:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:38:59,235:INFO:Starting cross validation
2023-08-09 16:38:59,235:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:39:01,688:INFO:Calculating mean and std
2023-08-09 16:39:01,689:INFO:Creating metrics dataframe
2023-08-09 16:39:01,943:INFO:Uploading results into container
2023-08-09 16:39:01,944:INFO:Uploading model into container now
2023-08-09 16:39:01,944:INFO:_master_model_container: 10
2023-08-09 16:39:01,944:INFO:_display_container: 2
2023-08-09 16:39:01,944:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:39:01,944:INFO:create_model() successfully completed......................................
2023-08-09 16:39:02,330:INFO:SubProcess create_model() end ==================================
2023-08-09 16:39:02,330:INFO:Creating metrics dataframe
2023-08-09 16:39:02,339:INFO:Initializing Linear Discriminant Analysis
2023-08-09 16:39:02,339:INFO:Total runtime is 0.5070584734280904 minutes
2023-08-09 16:39:02,343:INFO:SubProcess create_model() called ==================================
2023-08-09 16:39:02,343:INFO:Initializing create_model()
2023-08-09 16:39:02,343:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712F3F2B0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002371306B040>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:39:02,343:INFO:Checking exceptions
2023-08-09 16:39:02,343:INFO:Importing libraries
2023-08-09 16:39:02,343:INFO:Copying training dataset
2023-08-09 16:39:02,347:INFO:Defining folds
2023-08-09 16:39:02,348:INFO:Declaring metric variables
2023-08-09 16:39:02,350:INFO:Importing untrained model
2023-08-09 16:39:02,352:INFO:Linear Discriminant Analysis Imported successfully
2023-08-09 16:39:02,356:INFO:Starting cross validation
2023-08-09 16:39:02,356:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:39:04,140:INFO:Calculating mean and std
2023-08-09 16:39:04,141:INFO:Creating metrics dataframe
2023-08-09 16:39:04,397:INFO:Uploading results into container
2023-08-09 16:39:04,398:INFO:Uploading model into container now
2023-08-09 16:39:04,398:INFO:_master_model_container: 11
2023-08-09 16:39:04,398:INFO:_display_container: 2
2023-08-09 16:39:04,398:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-09 16:39:04,398:INFO:create_model() successfully completed......................................
2023-08-09 16:39:04,795:INFO:SubProcess create_model() end ==================================
2023-08-09 16:39:04,795:INFO:Creating metrics dataframe
2023-08-09 16:39:04,804:INFO:Initializing Extra Trees Classifier
2023-08-09 16:39:04,804:INFO:Total runtime is 0.548141626516978 minutes
2023-08-09 16:39:04,807:INFO:SubProcess create_model() called ==================================
2023-08-09 16:39:04,807:INFO:Initializing create_model()
2023-08-09 16:39:04,807:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712F3F2B0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002371306B040>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:39:04,807:INFO:Checking exceptions
2023-08-09 16:39:04,807:INFO:Importing libraries
2023-08-09 16:39:04,807:INFO:Copying training dataset
2023-08-09 16:39:04,811:INFO:Defining folds
2023-08-09 16:39:04,812:INFO:Declaring metric variables
2023-08-09 16:39:04,814:INFO:Importing untrained model
2023-08-09 16:39:04,818:INFO:Extra Trees Classifier Imported successfully
2023-08-09 16:39:04,823:INFO:Starting cross validation
2023-08-09 16:39:04,823:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:39:07,351:INFO:Calculating mean and std
2023-08-09 16:39:07,352:INFO:Creating metrics dataframe
2023-08-09 16:39:07,623:INFO:Uploading results into container
2023-08-09 16:39:07,623:INFO:Uploading model into container now
2023-08-09 16:39:07,624:INFO:_master_model_container: 12
2023-08-09 16:39:07,624:INFO:_display_container: 2
2023-08-09 16:39:07,625:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-08-09 16:39:07,625:INFO:create_model() successfully completed......................................
2023-08-09 16:39:08,009:INFO:SubProcess create_model() end ==================================
2023-08-09 16:39:08,009:INFO:Creating metrics dataframe
2023-08-09 16:39:08,017:INFO:Initializing Extreme Gradient Boosting
2023-08-09 16:39:08,017:INFO:Total runtime is 0.6016788681348165 minutes
2023-08-09 16:39:08,019:INFO:SubProcess create_model() called ==================================
2023-08-09 16:39:08,020:INFO:Initializing create_model()
2023-08-09 16:39:08,020:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712F3F2B0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002371306B040>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:39:08,020:INFO:Checking exceptions
2023-08-09 16:39:08,020:INFO:Importing libraries
2023-08-09 16:39:08,020:INFO:Copying training dataset
2023-08-09 16:39:08,023:INFO:Defining folds
2023-08-09 16:39:08,024:INFO:Declaring metric variables
2023-08-09 16:39:08,026:INFO:Importing untrained model
2023-08-09 16:39:08,028:INFO:Extreme Gradient Boosting Imported successfully
2023-08-09 16:39:08,032:INFO:Starting cross validation
2023-08-09 16:39:08,033:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:39:10,598:INFO:Calculating mean and std
2023-08-09 16:39:10,599:INFO:Creating metrics dataframe
2023-08-09 16:39:10,866:INFO:Uploading results into container
2023-08-09 16:39:10,866:INFO:Uploading model into container now
2023-08-09 16:39:10,867:INFO:_master_model_container: 13
2023-08-09 16:39:10,867:INFO:_display_container: 2
2023-08-09 16:39:10,868:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-09 16:39:10,868:INFO:create_model() successfully completed......................................
2023-08-09 16:39:11,251:INFO:SubProcess create_model() end ==================================
2023-08-09 16:39:11,251:INFO:Creating metrics dataframe
2023-08-09 16:39:11,259:INFO:Initializing Light Gradient Boosting Machine
2023-08-09 16:39:11,259:INFO:Total runtime is 0.6557174960772196 minutes
2023-08-09 16:39:11,261:INFO:SubProcess create_model() called ==================================
2023-08-09 16:39:11,262:INFO:Initializing create_model()
2023-08-09 16:39:11,262:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712F3F2B0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002371306B040>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:39:11,262:INFO:Checking exceptions
2023-08-09 16:39:11,262:INFO:Importing libraries
2023-08-09 16:39:11,262:INFO:Copying training dataset
2023-08-09 16:39:11,264:INFO:Defining folds
2023-08-09 16:39:11,264:INFO:Declaring metric variables
2023-08-09 16:39:11,267:INFO:Importing untrained model
2023-08-09 16:39:11,270:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-09 16:39:11,274:INFO:Starting cross validation
2023-08-09 16:39:11,275:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:39:14,322:INFO:Calculating mean and std
2023-08-09 16:39:14,323:INFO:Creating metrics dataframe
2023-08-09 16:39:14,595:INFO:Uploading results into container
2023-08-09 16:39:14,595:INFO:Uploading model into container now
2023-08-09 16:39:14,595:INFO:_master_model_container: 14
2023-08-09 16:39:14,595:INFO:_display_container: 2
2023-08-09 16:39:14,596:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-09 16:39:14,596:INFO:create_model() successfully completed......................................
2023-08-09 16:39:14,977:INFO:SubProcess create_model() end ==================================
2023-08-09 16:39:14,977:INFO:Creating metrics dataframe
2023-08-09 16:39:14,986:INFO:Initializing CatBoost Classifier
2023-08-09 16:39:14,988:INFO:Total runtime is 0.7178593158721923 minutes
2023-08-09 16:39:14,990:INFO:SubProcess create_model() called ==================================
2023-08-09 16:39:14,990:INFO:Initializing create_model()
2023-08-09 16:39:14,990:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712F3F2B0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002371306B040>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:39:14,990:INFO:Checking exceptions
2023-08-09 16:39:14,990:INFO:Importing libraries
2023-08-09 16:39:14,990:INFO:Copying training dataset
2023-08-09 16:39:14,993:INFO:Defining folds
2023-08-09 16:39:14,994:INFO:Declaring metric variables
2023-08-09 16:39:14,996:INFO:Importing untrained model
2023-08-09 16:39:14,998:INFO:CatBoost Classifier Imported successfully
2023-08-09 16:39:15,002:INFO:Starting cross validation
2023-08-09 16:39:15,003:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:39:20,704:INFO:Calculating mean and std
2023-08-09 16:39:20,705:INFO:Creating metrics dataframe
2023-08-09 16:39:20,972:INFO:Uploading results into container
2023-08-09 16:39:20,973:INFO:Uploading model into container now
2023-08-09 16:39:20,974:INFO:_master_model_container: 15
2023-08-09 16:39:20,974:INFO:_display_container: 2
2023-08-09 16:39:20,974:INFO:<catboost.core.CatBoostClassifier object at 0x00000236CDEE3EE0>
2023-08-09 16:39:20,974:INFO:create_model() successfully completed......................................
2023-08-09 16:39:21,362:INFO:SubProcess create_model() end ==================================
2023-08-09 16:39:21,362:INFO:Creating metrics dataframe
2023-08-09 16:39:21,371:INFO:Initializing Dummy Classifier
2023-08-09 16:39:21,371:INFO:Total runtime is 0.8242539803187052 minutes
2023-08-09 16:39:21,373:INFO:SubProcess create_model() called ==================================
2023-08-09 16:39:21,374:INFO:Initializing create_model()
2023-08-09 16:39:21,374:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712F3F2B0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002371306B040>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:39:21,374:INFO:Checking exceptions
2023-08-09 16:39:21,374:INFO:Importing libraries
2023-08-09 16:39:21,374:INFO:Copying training dataset
2023-08-09 16:39:21,378:INFO:Defining folds
2023-08-09 16:39:21,378:INFO:Declaring metric variables
2023-08-09 16:39:21,380:INFO:Importing untrained model
2023-08-09 16:39:21,382:INFO:Dummy Classifier Imported successfully
2023-08-09 16:39:21,386:INFO:Starting cross validation
2023-08-09 16:39:21,387:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:39:23,257:INFO:Calculating mean and std
2023-08-09 16:39:23,258:INFO:Creating metrics dataframe
2023-08-09 16:39:23,522:INFO:Uploading results into container
2023-08-09 16:39:23,523:INFO:Uploading model into container now
2023-08-09 16:39:23,523:INFO:_master_model_container: 16
2023-08-09 16:39:23,523:INFO:_display_container: 2
2023-08-09 16:39:23,525:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-08-09 16:39:23,525:INFO:create_model() successfully completed......................................
2023-08-09 16:39:23,901:INFO:SubProcess create_model() end ==================================
2023-08-09 16:39:23,901:INFO:Creating metrics dataframe
2023-08-09 16:39:23,919:INFO:Initializing create_model()
2023-08-09 16:39:23,919:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712F3F2B0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:39:23,920:INFO:Checking exceptions
2023-08-09 16:39:23,922:INFO:Importing libraries
2023-08-09 16:39:23,922:INFO:Copying training dataset
2023-08-09 16:39:23,925:INFO:Defining folds
2023-08-09 16:39:23,925:INFO:Declaring metric variables
2023-08-09 16:39:23,925:INFO:Importing untrained model
2023-08-09 16:39:23,925:INFO:Declaring custom model
2023-08-09 16:39:23,926:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:39:23,926:INFO:Cross validation set to False
2023-08-09 16:39:23,926:INFO:Fitting Model
2023-08-09 16:39:24,621:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:39:24,621:INFO:create_model() successfully completed......................................
2023-08-09 16:39:25,038:INFO:_master_model_container: 16
2023-08-09 16:39:25,040:INFO:_display_container: 2
2023-08-09 16:39:25,040:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:39:25,040:INFO:compare_models() successfully completed......................................
2023-08-09 16:39:59,960:INFO:Initializing create_model()
2023-08-09 16:39:59,960:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712F3F2B0>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:39:59,960:INFO:Checking exceptions
2023-08-09 16:39:59,970:INFO:Importing libraries
2023-08-09 16:39:59,971:INFO:Copying training dataset
2023-08-09 16:39:59,974:INFO:Defining folds
2023-08-09 16:39:59,974:INFO:Declaring metric variables
2023-08-09 16:39:59,976:INFO:Importing untrained model
2023-08-09 16:39:59,979:INFO:Random Forest Classifier Imported successfully
2023-08-09 16:39:59,983:INFO:Starting cross validation
2023-08-09 16:39:59,984:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:40:02,183:INFO:Calculating mean and std
2023-08-09 16:40:02,183:INFO:Creating metrics dataframe
2023-08-09 16:40:02,189:INFO:Finalizing model
2023-08-09 16:40:02,729:INFO:Uploading results into container
2023-08-09 16:40:02,730:INFO:Uploading model into container now
2023-08-09 16:40:02,736:INFO:_master_model_container: 17
2023-08-09 16:40:02,736:INFO:_display_container: 3
2023-08-09 16:40:02,737:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-09 16:40:02,737:INFO:create_model() successfully completed......................................
2023-08-09 16:40:03,129:INFO:Initializing tune_model()
2023-08-09 16:40:03,129:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712F3F2B0>)
2023-08-09 16:40:03,129:INFO:Checking exceptions
2023-08-09 16:40:03,142:INFO:Copying training dataset
2023-08-09 16:40:03,145:INFO:Checking base model
2023-08-09 16:40:03,145:INFO:Base model : Random Forest Classifier
2023-08-09 16:40:03,148:INFO:Declaring metric variables
2023-08-09 16:40:03,150:INFO:Defining Hyperparameters
2023-08-09 16:40:03,551:INFO:Tuning with n_jobs=-1
2023-08-09 16:40:03,551:INFO:Initializing RandomizedSearchCV
2023-08-09 16:40:28,492:INFO:best_params: {'actual_estimator__n_estimators': 190, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.001, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 6, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2023-08-09 16:40:28,493:INFO:Hyperparameter search completed
2023-08-09 16:40:28,493:INFO:SubProcess create_model() called ==================================
2023-08-09 16:40:28,493:INFO:Initializing create_model()
2023-08-09 16:40:28,493:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712F3F2B0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237070F28F0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 190, 'min_samples_split': 9, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.001, 'max_features': 'log2', 'max_depth': 6, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2023-08-09 16:40:28,493:INFO:Checking exceptions
2023-08-09 16:40:28,493:INFO:Importing libraries
2023-08-09 16:40:28,493:INFO:Copying training dataset
2023-08-09 16:40:28,498:INFO:Defining folds
2023-08-09 16:40:28,498:INFO:Declaring metric variables
2023-08-09 16:40:28,500:INFO:Importing untrained model
2023-08-09 16:40:28,500:INFO:Declaring custom model
2023-08-09 16:40:28,503:INFO:Random Forest Classifier Imported successfully
2023-08-09 16:40:28,507:INFO:Starting cross validation
2023-08-09 16:40:28,507:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:40:30,886:INFO:Calculating mean and std
2023-08-09 16:40:30,887:INFO:Creating metrics dataframe
2023-08-09 16:40:30,892:INFO:Finalizing model
2023-08-09 16:40:31,518:INFO:Uploading results into container
2023-08-09 16:40:31,519:INFO:Uploading model into container now
2023-08-09 16:40:31,519:INFO:_master_model_container: 18
2023-08-09 16:40:31,519:INFO:_display_container: 4
2023-08-09 16:40:31,519:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=190,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2023-08-09 16:40:31,519:INFO:create_model() successfully completed......................................
2023-08-09 16:40:31,927:INFO:SubProcess create_model() end ==================================
2023-08-09 16:40:31,927:INFO:choose_better activated
2023-08-09 16:40:31,930:INFO:SubProcess create_model() called ==================================
2023-08-09 16:40:31,931:INFO:Initializing create_model()
2023-08-09 16:40:31,931:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712F3F2B0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:40:31,931:INFO:Checking exceptions
2023-08-09 16:40:31,932:INFO:Importing libraries
2023-08-09 16:40:31,932:INFO:Copying training dataset
2023-08-09 16:40:31,936:INFO:Defining folds
2023-08-09 16:40:31,936:INFO:Declaring metric variables
2023-08-09 16:40:31,937:INFO:Importing untrained model
2023-08-09 16:40:31,937:INFO:Declaring custom model
2023-08-09 16:40:31,937:INFO:Random Forest Classifier Imported successfully
2023-08-09 16:40:31,937:INFO:Starting cross validation
2023-08-09 16:40:31,938:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:40:34,202:INFO:Calculating mean and std
2023-08-09 16:40:34,202:INFO:Creating metrics dataframe
2023-08-09 16:40:34,203:INFO:Finalizing model
2023-08-09 16:40:34,561:INFO:Uploading results into container
2023-08-09 16:40:34,562:INFO:Uploading model into container now
2023-08-09 16:40:34,562:INFO:_master_model_container: 19
2023-08-09 16:40:34,562:INFO:_display_container: 5
2023-08-09 16:40:34,563:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-09 16:40:34,563:INFO:create_model() successfully completed......................................
2023-08-09 16:40:34,957:INFO:SubProcess create_model() end ==================================
2023-08-09 16:40:34,959:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) result for Accuracy is 0.6445
2023-08-09 16:40:34,959:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=190,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for Accuracy is 0.6708
2023-08-09 16:40:34,959:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=190,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False) is best model
2023-08-09 16:40:34,959:INFO:choose_better completed
2023-08-09 16:40:34,966:INFO:_master_model_container: 19
2023-08-09 16:40:34,966:INFO:_display_container: 4
2023-08-09 16:40:34,966:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=190,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2023-08-09 16:40:34,967:INFO:tune_model() successfully completed......................................
2023-08-09 16:40:35,576:INFO:Initializing create_model()
2023-08-09 16:40:35,576:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712F3F2B0>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:40:35,576:INFO:Checking exceptions
2023-08-09 16:40:35,586:INFO:Importing libraries
2023-08-09 16:40:35,586:INFO:Copying training dataset
2023-08-09 16:40:35,590:INFO:Defining folds
2023-08-09 16:40:35,590:INFO:Declaring metric variables
2023-08-09 16:40:35,592:INFO:Importing untrained model
2023-08-09 16:40:35,595:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:40:35,600:INFO:Starting cross validation
2023-08-09 16:40:35,600:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:40:37,777:INFO:Calculating mean and std
2023-08-09 16:40:37,778:INFO:Creating metrics dataframe
2023-08-09 16:40:37,782:INFO:Finalizing model
2023-08-09 16:40:38,120:INFO:Uploading results into container
2023-08-09 16:40:38,120:INFO:Uploading model into container now
2023-08-09 16:40:38,126:INFO:_master_model_container: 20
2023-08-09 16:40:38,126:INFO:_display_container: 5
2023-08-09 16:40:38,126:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:40:38,127:INFO:create_model() successfully completed......................................
2023-08-09 16:40:38,521:INFO:Initializing tune_model()
2023-08-09 16:40:38,521:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712F3F2B0>)
2023-08-09 16:40:38,521:INFO:Checking exceptions
2023-08-09 16:40:38,532:INFO:Copying training dataset
2023-08-09 16:40:38,534:INFO:Checking base model
2023-08-09 16:40:38,534:INFO:Base model : Gradient Boosting Classifier
2023-08-09 16:40:38,536:INFO:Declaring metric variables
2023-08-09 16:40:38,538:INFO:Defining Hyperparameters
2023-08-09 16:40:38,948:INFO:Tuning with n_jobs=-1
2023-08-09 16:40:38,949:INFO:Initializing RandomizedSearchCV
2023-08-09 16:41:05,947:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 140, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.05, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.01}
2023-08-09 16:41:05,948:INFO:Hyperparameter search completed
2023-08-09 16:41:05,948:INFO:SubProcess create_model() called ==================================
2023-08-09 16:41:05,948:INFO:Initializing create_model()
2023-08-09 16:41:05,949:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712F3F2B0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236D86E1180>, model_only=True, return_train_score=False, kwargs={'subsample': 0.35, 'n_estimators': 140, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.05, 'max_features': 'sqrt', 'max_depth': 7, 'learning_rate': 0.01})
2023-08-09 16:41:05,949:INFO:Checking exceptions
2023-08-09 16:41:05,949:INFO:Importing libraries
2023-08-09 16:41:05,949:INFO:Copying training dataset
2023-08-09 16:41:05,954:INFO:Defining folds
2023-08-09 16:41:05,954:INFO:Declaring metric variables
2023-08-09 16:41:05,956:INFO:Importing untrained model
2023-08-09 16:41:05,956:INFO:Declaring custom model
2023-08-09 16:41:05,959:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:41:05,963:INFO:Starting cross validation
2023-08-09 16:41:05,965:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:41:08,265:INFO:Calculating mean and std
2023-08-09 16:41:08,266:INFO:Creating metrics dataframe
2023-08-09 16:41:08,269:INFO:Finalizing model
2023-08-09 16:41:09,116:INFO:Uploading results into container
2023-08-09 16:41:09,118:INFO:Uploading model into container now
2023-08-09 16:41:09,119:INFO:_master_model_container: 21
2023-08-09 16:41:09,119:INFO:_display_container: 6
2023-08-09 16:41:09,119:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:41:09,119:INFO:create_model() successfully completed......................................
2023-08-09 16:41:09,511:INFO:SubProcess create_model() end ==================================
2023-08-09 16:41:09,511:INFO:choose_better activated
2023-08-09 16:41:09,515:INFO:SubProcess create_model() called ==================================
2023-08-09 16:41:09,515:INFO:Initializing create_model()
2023-08-09 16:41:09,515:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712F3F2B0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:41:09,515:INFO:Checking exceptions
2023-08-09 16:41:09,516:INFO:Importing libraries
2023-08-09 16:41:09,516:INFO:Copying training dataset
2023-08-09 16:41:09,519:INFO:Defining folds
2023-08-09 16:41:09,519:INFO:Declaring metric variables
2023-08-09 16:41:09,519:INFO:Importing untrained model
2023-08-09 16:41:09,519:INFO:Declaring custom model
2023-08-09 16:41:09,520:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:41:09,520:INFO:Starting cross validation
2023-08-09 16:41:09,520:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:41:11,785:INFO:Calculating mean and std
2023-08-09 16:41:11,785:INFO:Creating metrics dataframe
2023-08-09 16:41:11,786:INFO:Finalizing model
2023-08-09 16:41:12,129:INFO:Uploading results into container
2023-08-09 16:41:12,130:INFO:Uploading model into container now
2023-08-09 16:41:12,130:INFO:_master_model_container: 22
2023-08-09 16:41:12,130:INFO:_display_container: 7
2023-08-09 16:41:12,131:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:41:12,131:INFO:create_model() successfully completed......................................
2023-08-09 16:41:12,539:INFO:SubProcess create_model() end ==================================
2023-08-09 16:41:12,540:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.6571
2023-08-09 16:41:12,540:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.6416
2023-08-09 16:41:12,541:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-08-09 16:41:12,541:INFO:choose_better completed
2023-08-09 16:41:12,541:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-08-09 16:41:12,548:INFO:_master_model_container: 22
2023-08-09 16:41:12,548:INFO:_display_container: 6
2023-08-09 16:41:12,548:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:41:12,548:INFO:tune_model() successfully completed......................................
2023-08-09 16:41:13,161:INFO:Initializing blend_models()
2023-08-09 16:41:13,161:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712F3F2B0>, estimator_list=[RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=6, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.001,
                       min_samples_leaf=6, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=190,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-08-09 16:41:13,161:INFO:Checking exceptions
2023-08-09 16:41:13,173:INFO:Importing libraries
2023-08-09 16:41:13,173:INFO:Copying training dataset
2023-08-09 16:41:13,177:INFO:Getting model names
2023-08-09 16:41:13,179:INFO:SubProcess create_model() called ==================================
2023-08-09 16:41:13,182:INFO:Initializing create_model()
2023-08-09 16:41:13,182:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712F3F2B0>, estimator=VotingClassifier(estimators=[('Random Forest Classifier',
                              RandomForestClassifier(bootstrap=False,
                                                     ccp_alpha=0.0,
                                                     class_weight='balanced_subsample',
                                                     criterion='gini',
                                                     max_depth=6,
                                                     max_features='log2',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.001,
                                                     min_samples_leaf=6,
                                                     min_samples_split=9,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=190,
                                                     n_jobs=-1...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000237070E88B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:41:13,182:INFO:Checking exceptions
2023-08-09 16:41:13,182:INFO:Importing libraries
2023-08-09 16:41:13,182:INFO:Copying training dataset
2023-08-09 16:41:13,186:INFO:Defining folds
2023-08-09 16:41:13,186:INFO:Declaring metric variables
2023-08-09 16:41:13,188:INFO:Importing untrained model
2023-08-09 16:41:13,188:INFO:Declaring custom model
2023-08-09 16:41:13,191:INFO:Voting Classifier Imported successfully
2023-08-09 16:41:13,195:INFO:Starting cross validation
2023-08-09 16:41:13,196:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:41:16,677:INFO:Calculating mean and std
2023-08-09 16:41:16,678:INFO:Creating metrics dataframe
2023-08-09 16:41:16,683:INFO:Finalizing model
2023-08-09 16:41:17,790:INFO:Uploading results into container
2023-08-09 16:41:17,790:INFO:Uploading model into container now
2023-08-09 16:41:17,790:INFO:_master_model_container: 23
2023-08-09 16:41:17,790:INFO:_display_container: 7
2023-08-09 16:41:17,793:INFO:VotingClassifier(estimators=[('Random Forest Classifier',
                              RandomForestClassifier(bootstrap=False,
                                                     ccp_alpha=0.0,
                                                     class_weight='balanced_subsample',
                                                     criterion='gini',
                                                     max_depth=6,
                                                     max_features='log2',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.001,
                                                     min_samples_leaf=6,
                                                     min_samples_split=9,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=190,
                                                     n_jobs=-1...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 16:41:17,793:INFO:create_model() successfully completed......................................
2023-08-09 16:41:18,185:INFO:SubProcess create_model() end ==================================
2023-08-09 16:41:18,194:INFO:_master_model_container: 23
2023-08-09 16:41:18,194:INFO:_display_container: 7
2023-08-09 16:41:18,196:INFO:VotingClassifier(estimators=[('Random Forest Classifier',
                              RandomForestClassifier(bootstrap=False,
                                                     ccp_alpha=0.0,
                                                     class_weight='balanced_subsample',
                                                     criterion='gini',
                                                     max_depth=6,
                                                     max_features='log2',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.001,
                                                     min_samples_leaf=6,
                                                     min_samples_split=9,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=190,
                                                     n_jobs=-1...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 16:41:18,196:INFO:blend_models() successfully completed......................................
2023-08-09 16:41:18,596:INFO:Initializing finalize_model()
2023-08-09 16:41:18,596:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712F3F2B0>, estimator=VotingClassifier(estimators=[('Random Forest Classifier',
                              RandomForestClassifier(bootstrap=False,
                                                     ccp_alpha=0.0,
                                                     class_weight='balanced_subsample',
                                                     criterion='gini',
                                                     max_depth=6,
                                                     max_features='log2',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.001,
                                                     min_samples_leaf=6,
                                                     min_samples_split=9,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=190,
                                                     n_jobs=-1...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-08-09 16:41:18,598:INFO:Finalizing VotingClassifier(estimators=[('Random Forest Classifier',
                              RandomForestClassifier(bootstrap=False,
                                                     ccp_alpha=0.0,
                                                     class_weight='balanced_subsample',
                                                     criterion='gini',
                                                     max_depth=6,
                                                     max_features='log2',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.001,
                                                     min_samples_leaf=6,
                                                     min_samples_split=9,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=190,
                                                     n_jobs=-1...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 16:41:18,602:INFO:Initializing create_model()
2023-08-09 16:41:18,602:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712F3F2B0>, estimator=VotingClassifier(estimators=[('Random Forest Classifier',
                              RandomForestClassifier(bootstrap=False,
                                                     ccp_alpha=0.0,
                                                     class_weight='balanced_subsample',
                                                     criterion='gini',
                                                     max_depth=6,
                                                     max_features='log2',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.001,
                                                     min_samples_leaf=6,
                                                     min_samples_split=9,
                                                     min_weight_fraction_leaf=0.0,
                                                     n_estimators=190,
                                                     n_jobs=-1...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-08-09 16:41:18,602:INFO:Checking exceptions
2023-08-09 16:41:18,603:INFO:Importing libraries
2023-08-09 16:41:18,603:INFO:Copying training dataset
2023-08-09 16:41:18,603:INFO:Defining folds
2023-08-09 16:41:18,603:INFO:Declaring metric variables
2023-08-09 16:41:18,604:INFO:Importing untrained model
2023-08-09 16:41:18,604:INFO:Declaring custom model
2023-08-09 16:41:18,604:INFO:Voting Classifier Imported successfully
2023-08-09 16:41:18,604:INFO:Cross validation set to False
2023-08-09 16:41:18,604:INFO:Fitting Model
2023-08-09 16:41:19,442:INFO:Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases', 'Weight_in_gms',
                                             'Warehouse_block_A',
                                             'Warehouse_block_B',
                                             'Warehouse_block_C',
                                             'Warehouse_block_D',
                                             'Warehouse_block_F',
                                             'Mode_...
                                                                          max_features=None,
                                                                          max_leaf_nodes=None,
                                                                          min_impurity_decrease=0.0,
                                                                          min_samples_leaf=1,
                                                                          min_samples_split=2,
                                                                          min_weight_fraction_leaf=0.0,
                                                                          n_estimators=100,
                                                                          n_iter_no_change=None,
                                                                          random_state=123,
                                                                          subsample=1.0,
                                                                          tol=0.0001,
                                                                          validation_fraction=0.1,
                                                                          verbose=0,
                                                                          warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-09 16:41:19,442:INFO:create_model() successfully completed......................................
2023-08-09 16:41:19,850:INFO:_master_model_container: 23
2023-08-09 16:41:19,850:INFO:_display_container: 7
2023-08-09 16:41:19,859:INFO:Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases', 'Weight_in_gms',
                                             'Warehouse_block_A',
                                             'Warehouse_block_B',
                                             'Warehouse_block_C',
                                             'Warehouse_block_D',
                                             'Warehouse_block_F',
                                             'Mode_...
                                                                          max_features=None,
                                                                          max_leaf_nodes=None,
                                                                          min_impurity_decrease=0.0,
                                                                          min_samples_leaf=1,
                                                                          min_samples_split=2,
                                                                          min_weight_fraction_leaf=0.0,
                                                                          n_estimators=100,
                                                                          n_iter_no_change=None,
                                                                          random_state=123,
                                                                          subsample=1.0,
                                                                          tol=0.0001,
                                                                          validation_fraction=0.1,
                                                                          verbose=0,
                                                                          warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-09 16:41:19,859:INFO:finalize_model() successfully completed......................................
2023-08-09 16:41:51,503:INFO:Initializing predict_model()
2023-08-09 16:41:51,504:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712F3F2B0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases', 'Weight_in_gms',
                                             'Warehouse_block_A',
                                             'Warehouse_block_B',
                                             'Warehouse_block_C',
                                             'Warehouse_block_D',
                                             'Warehouse_block_F',
                                             'Mode_...
                                                                          max_features=None,
                                                                          max_leaf_nodes=None,
                                                                          min_impurity_decrease=0.0,
                                                                          min_samples_leaf=1,
                                                                          min_samples_split=2,
                                                                          min_weight_fraction_leaf=0.0,
                                                                          n_estimators=100,
                                                                          n_iter_no_change=None,
                                                                          random_state=123,
                                                                          subsample=1.0,
                                                                          tol=0.0001,
                                                                          validation_fraction=0.1,
                                                                          verbose=0,
                                                                          warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000023712C6AE60>)
2023-08-09 16:41:51,504:INFO:Checking exceptions
2023-08-09 16:41:51,504:INFO:Preloading libraries
2023-08-09 16:41:51,505:INFO:Set up data.
2023-08-09 16:41:51,510:INFO:Set up index.
2023-08-09 16:52:18,676:INFO:PyCaret ClassificationExperiment
2023-08-09 16:52:18,676:INFO:Logging name: clf-default-name
2023-08-09 16:52:18,676:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-09 16:52:18,676:INFO:version 3.0.4
2023-08-09 16:52:18,676:INFO:Initializing setup()
2023-08-09 16:52:18,676:INFO:self.USI: 32fa
2023-08-09 16:52:18,676:INFO:self._variable_keys: {'data', 'y_train', 'USI', 'html_param', 'seed', 'target_param', 'exp_name_log', 'fold_groups_param', 'y', 'gpu_param', '_available_plots', 'gpu_n_jobs_param', 'fold_shuffle_param', 'pipeline', 'memory', 'X', 'fix_imbalance', 'fold_generator', 'is_multiclass', '_ml_usecase', 'log_plots_param', 'X_test', 'y_test', 'logging_param', 'n_jobs_param', 'exp_id', 'X_train', 'idx'}
2023-08-09 16:52:18,676:INFO:Checking environment
2023-08-09 16:52:18,676:INFO:python_version: 3.10.12
2023-08-09 16:52:18,676:INFO:python_build: ('main', 'Jul  5 2023 19:09:20')
2023-08-09 16:52:18,676:INFO:machine: AMD64
2023-08-09 16:52:18,676:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-09 16:52:18,676:INFO:Memory: svmem(total=16828977152, available=6928896000, percent=58.8, used=9900081152, free=6928896000)
2023-08-09 16:52:18,676:INFO:Physical Core: 14
2023-08-09 16:52:18,676:INFO:Logical Core: 20
2023-08-09 16:52:18,676:INFO:Checking libraries
2023-08-09 16:52:18,676:INFO:System:
2023-08-09 16:52:18,676:INFO:    python: 3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:09:20) [MSC v.1916 64 bit (AMD64)]
2023-08-09 16:52:18,677:INFO:executable: C:\Users\user21\anaconda3\python.exe
2023-08-09 16:52:18,677:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-09 16:52:18,677:INFO:PyCaret required dependencies:
2023-08-09 16:52:18,677:INFO:                 pip: 23.2.1
2023-08-09 16:52:18,677:INFO:          setuptools: 68.0.0
2023-08-09 16:52:18,677:INFO:             pycaret: 3.0.4
2023-08-09 16:52:18,677:INFO:             IPython: 8.12.0
2023-08-09 16:52:18,677:INFO:          ipywidgets: 8.1.0
2023-08-09 16:52:18,677:INFO:                tqdm: 4.65.0
2023-08-09 16:52:18,677:INFO:               numpy: 1.23.5
2023-08-09 16:52:18,677:INFO:              pandas: 1.5.3
2023-08-09 16:52:18,677:INFO:              jinja2: 3.1.2
2023-08-09 16:52:18,677:INFO:               scipy: 1.11.1
2023-08-09 16:52:18,677:INFO:              joblib: 1.3.1
2023-08-09 16:52:18,677:INFO:             sklearn: 1.2.2
2023-08-09 16:52:18,677:INFO:                pyod: 1.1.0
2023-08-09 16:52:18,677:INFO:            imblearn: 0.11.0
2023-08-09 16:52:18,677:INFO:   category_encoders: 2.6.1
2023-08-09 16:52:18,677:INFO:            lightgbm: 4.0.0
2023-08-09 16:52:18,677:INFO:               numba: 0.57.1
2023-08-09 16:52:18,677:INFO:            requests: 2.31.0
2023-08-09 16:52:18,677:INFO:          matplotlib: 3.7.2
2023-08-09 16:52:18,677:INFO:          scikitplot: 0.3.7
2023-08-09 16:52:18,677:INFO:         yellowbrick: 1.5
2023-08-09 16:52:18,677:INFO:              plotly: 5.15.0
2023-08-09 16:52:18,677:INFO:    plotly-resampler: Not installed
2023-08-09 16:52:18,677:INFO:             kaleido: 0.2.1
2023-08-09 16:52:18,677:INFO:           schemdraw: 0.15
2023-08-09 16:52:18,677:INFO:         statsmodels: 0.14.0
2023-08-09 16:52:18,677:INFO:              sktime: 0.21.0
2023-08-09 16:52:18,677:INFO:               tbats: 1.1.3
2023-08-09 16:52:18,677:INFO:            pmdarima: 2.0.3
2023-08-09 16:52:18,677:INFO:              psutil: 5.9.0
2023-08-09 16:52:18,677:INFO:          markupsafe: 2.1.1
2023-08-09 16:52:18,677:INFO:             pickle5: Not installed
2023-08-09 16:52:18,677:INFO:         cloudpickle: 2.2.1
2023-08-09 16:52:18,677:INFO:         deprecation: 2.1.0
2023-08-09 16:52:18,677:INFO:              xxhash: 3.3.0
2023-08-09 16:52:18,677:INFO:           wurlitzer: Not installed
2023-08-09 16:52:18,677:INFO:PyCaret optional dependencies:
2023-08-09 16:52:18,677:INFO:                shap: Not installed
2023-08-09 16:52:18,678:INFO:           interpret: Not installed
2023-08-09 16:52:18,678:INFO:                umap: Not installed
2023-08-09 16:52:18,678:INFO:    pandas_profiling: Not installed
2023-08-09 16:52:18,678:INFO:  explainerdashboard: Not installed
2023-08-09 16:52:18,678:INFO:             autoviz: Not installed
2023-08-09 16:52:18,678:INFO:           fairlearn: Not installed
2023-08-09 16:52:18,678:INFO:          deepchecks: Not installed
2023-08-09 16:52:18,678:INFO:             xgboost: 1.7.6
2023-08-09 16:52:18,678:INFO:            catboost: 1.2
2023-08-09 16:52:18,678:INFO:              kmodes: Not installed
2023-08-09 16:52:18,678:INFO:             mlxtend: Not installed
2023-08-09 16:52:18,678:INFO:       statsforecast: Not installed
2023-08-09 16:52:18,678:INFO:        tune_sklearn: Not installed
2023-08-09 16:52:18,678:INFO:                 ray: Not installed
2023-08-09 16:52:18,678:INFO:            hyperopt: Not installed
2023-08-09 16:52:18,678:INFO:              optuna: 3.2.0
2023-08-09 16:52:18,678:INFO:               skopt: Not installed
2023-08-09 16:52:18,678:INFO:              mlflow: Not installed
2023-08-09 16:52:18,678:INFO:              gradio: Not installed
2023-08-09 16:52:18,678:INFO:             fastapi: Not installed
2023-08-09 16:52:18,678:INFO:             uvicorn: Not installed
2023-08-09 16:52:18,678:INFO:              m2cgen: Not installed
2023-08-09 16:52:18,678:INFO:           evidently: Not installed
2023-08-09 16:52:18,678:INFO:               fugue: Not installed
2023-08-09 16:52:18,678:INFO:           streamlit: Not installed
2023-08-09 16:52:18,678:INFO:             prophet: Not installed
2023-08-09 16:52:18,678:INFO:None
2023-08-09 16:52:18,678:INFO:Set up data.
2023-08-09 16:52:18,683:INFO:Set up train/test split.
2023-08-09 16:52:18,686:INFO:Set up index.
2023-08-09 16:52:18,686:INFO:Set up folding strategy.
2023-08-09 16:52:18,686:INFO:Assigning column types.
2023-08-09 16:52:18,690:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-09 16:52:18,720:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-09 16:52:18,720:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 16:52:18,736:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:52:18,738:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:52:18,767:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-09 16:52:18,768:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 16:52:18,786:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:52:18,788:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:52:18,788:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-09 16:52:18,816:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 16:52:18,833:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:52:18,835:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:52:18,863:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 16:52:18,881:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:52:18,883:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:52:18,883:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-09 16:52:18,929:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:52:18,931:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:52:18,976:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:52:18,978:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:52:18,979:INFO:Preparing preprocessing pipeline...
2023-08-09 16:52:18,980:INFO:Set up simple imputation.
2023-08-09 16:52:18,980:INFO:Set up column name cleaning.
2023-08-09 16:52:18,994:INFO:Finished creating preprocessing pipeline.
2023-08-09 16:52:18,997:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Warehouse_block ',
                                             'Mode_of_Shipment',
                                             'Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Product_importance',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(ad...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-09 16:52:18,997:INFO:Creating final display dataframe.
2023-08-09 16:52:19,051:INFO:Setup _display_container:                     Description                Value
0                    Session id                  123
1                        Target  Reached.on.Time_Y.N
2                   Target type               Binary
3           Original data shape           (6994, 10)
4        Transformed data shape           (6994, 10)
5   Transformed train set shape           (4895, 10)
6    Transformed test set shape           (2099, 10)
7              Numeric features                    9
8                    Preprocess                 True
9               Imputation type               simple
10           Numeric imputation                 mean
11       Categorical imputation                 mode
12               Fold Generator      StratifiedKFold
13                  Fold Number                   10
14                     CPU Jobs                   -1
15                      Use GPU                False
16               Log Experiment                False
17              Experiment Name     clf-default-name
18                          USI                 32fa
2023-08-09 16:52:19,103:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:52:19,105:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:52:19,151:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 16:52:19,153:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 16:52:19,153:INFO:setup() successfully completed in 0.7s...............
2023-08-09 16:52:19,379:INFO:Initializing compare_models()
2023-08-09 16:52:19,379:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-09 16:52:19,379:INFO:Checking exceptions
2023-08-09 16:52:19,382:INFO:Preparing display monitor
2023-08-09 16:52:19,401:INFO:Initializing Logistic Regression
2023-08-09 16:52:19,401:INFO:Total runtime is 0.0 minutes
2023-08-09 16:52:19,403:INFO:SubProcess create_model() called ==================================
2023-08-09 16:52:19,403:INFO:Initializing create_model()
2023-08-09 16:52:19,403:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023712F3F700>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:52:19,404:INFO:Checking exceptions
2023-08-09 16:52:19,404:INFO:Importing libraries
2023-08-09 16:52:19,404:INFO:Copying training dataset
2023-08-09 16:52:19,407:INFO:Defining folds
2023-08-09 16:52:19,407:INFO:Declaring metric variables
2023-08-09 16:52:19,410:INFO:Importing untrained model
2023-08-09 16:52:19,412:INFO:Logistic Regression Imported successfully
2023-08-09 16:52:19,417:INFO:Starting cross validation
2023-08-09 16:52:19,418:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:52:23,956:INFO:Calculating mean and std
2023-08-09 16:52:23,957:INFO:Creating metrics dataframe
2023-08-09 16:52:24,275:INFO:Uploading results into container
2023-08-09 16:52:24,276:INFO:Uploading model into container now
2023-08-09 16:52:24,276:INFO:_master_model_container: 1
2023-08-09 16:52:24,276:INFO:_display_container: 2
2023-08-09 16:52:24,277:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-09 16:52:24,277:INFO:create_model() successfully completed......................................
2023-08-09 16:52:24,923:INFO:SubProcess create_model() end ==================================
2023-08-09 16:52:24,923:INFO:Creating metrics dataframe
2023-08-09 16:52:24,929:INFO:Initializing K Neighbors Classifier
2023-08-09 16:52:24,929:INFO:Total runtime is 0.0921363353729248 minutes
2023-08-09 16:52:24,931:INFO:SubProcess create_model() called ==================================
2023-08-09 16:52:24,931:INFO:Initializing create_model()
2023-08-09 16:52:24,931:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023712F3F700>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:52:24,931:INFO:Checking exceptions
2023-08-09 16:52:24,932:INFO:Importing libraries
2023-08-09 16:52:24,932:INFO:Copying training dataset
2023-08-09 16:52:24,934:INFO:Defining folds
2023-08-09 16:52:24,934:INFO:Declaring metric variables
2023-08-09 16:52:24,937:INFO:Importing untrained model
2023-08-09 16:52:24,940:INFO:K Neighbors Classifier Imported successfully
2023-08-09 16:52:24,945:INFO:Starting cross validation
2023-08-09 16:52:24,946:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:52:29,052:INFO:Calculating mean and std
2023-08-09 16:52:29,053:INFO:Creating metrics dataframe
2023-08-09 16:52:29,370:INFO:Uploading results into container
2023-08-09 16:52:29,371:INFO:Uploading model into container now
2023-08-09 16:52:29,371:INFO:_master_model_container: 2
2023-08-09 16:52:29,371:INFO:_display_container: 2
2023-08-09 16:52:29,371:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-09 16:52:29,372:INFO:create_model() successfully completed......................................
2023-08-09 16:52:29,768:INFO:SubProcess create_model() end ==================================
2023-08-09 16:52:29,768:INFO:Creating metrics dataframe
2023-08-09 16:52:29,776:INFO:Initializing Naive Bayes
2023-08-09 16:52:29,776:INFO:Total runtime is 0.17291859785715738 minutes
2023-08-09 16:52:29,779:INFO:SubProcess create_model() called ==================================
2023-08-09 16:52:29,780:INFO:Initializing create_model()
2023-08-09 16:52:29,780:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023712F3F700>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:52:29,780:INFO:Checking exceptions
2023-08-09 16:52:29,781:INFO:Importing libraries
2023-08-09 16:52:29,781:INFO:Copying training dataset
2023-08-09 16:52:29,784:INFO:Defining folds
2023-08-09 16:52:29,784:INFO:Declaring metric variables
2023-08-09 16:52:29,787:INFO:Importing untrained model
2023-08-09 16:52:29,789:INFO:Naive Bayes Imported successfully
2023-08-09 16:52:29,793:INFO:Starting cross validation
2023-08-09 16:52:29,794:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:52:32,019:INFO:Calculating mean and std
2023-08-09 16:52:32,020:INFO:Creating metrics dataframe
2023-08-09 16:52:32,335:INFO:Uploading results into container
2023-08-09 16:52:32,335:INFO:Uploading model into container now
2023-08-09 16:52:32,336:INFO:_master_model_container: 3
2023-08-09 16:52:32,336:INFO:_display_container: 2
2023-08-09 16:52:32,336:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-09 16:52:32,336:INFO:create_model() successfully completed......................................
2023-08-09 16:52:32,721:INFO:SubProcess create_model() end ==================================
2023-08-09 16:52:32,721:INFO:Creating metrics dataframe
2023-08-09 16:52:32,728:INFO:Initializing Decision Tree Classifier
2023-08-09 16:52:32,728:INFO:Total runtime is 0.22212932109832761 minutes
2023-08-09 16:52:32,731:INFO:SubProcess create_model() called ==================================
2023-08-09 16:52:32,731:INFO:Initializing create_model()
2023-08-09 16:52:32,731:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023712F3F700>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:52:32,731:INFO:Checking exceptions
2023-08-09 16:52:32,731:INFO:Importing libraries
2023-08-09 16:52:32,731:INFO:Copying training dataset
2023-08-09 16:52:32,734:INFO:Defining folds
2023-08-09 16:52:32,734:INFO:Declaring metric variables
2023-08-09 16:52:32,738:INFO:Importing untrained model
2023-08-09 16:52:32,740:INFO:Decision Tree Classifier Imported successfully
2023-08-09 16:52:32,745:INFO:Starting cross validation
2023-08-09 16:52:32,745:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:52:34,950:INFO:Calculating mean and std
2023-08-09 16:52:34,952:INFO:Creating metrics dataframe
2023-08-09 16:52:35,266:INFO:Uploading results into container
2023-08-09 16:52:35,266:INFO:Uploading model into container now
2023-08-09 16:52:35,267:INFO:_master_model_container: 4
2023-08-09 16:52:35,267:INFO:_display_container: 2
2023-08-09 16:52:35,267:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-08-09 16:52:35,267:INFO:create_model() successfully completed......................................
2023-08-09 16:52:35,659:INFO:SubProcess create_model() end ==================================
2023-08-09 16:52:35,659:INFO:Creating metrics dataframe
2023-08-09 16:52:35,666:INFO:Initializing SVM - Linear Kernel
2023-08-09 16:52:35,666:INFO:Total runtime is 0.2710909485816955 minutes
2023-08-09 16:52:35,671:INFO:SubProcess create_model() called ==================================
2023-08-09 16:52:35,671:INFO:Initializing create_model()
2023-08-09 16:52:35,671:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023712F3F700>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:52:35,671:INFO:Checking exceptions
2023-08-09 16:52:35,671:INFO:Importing libraries
2023-08-09 16:52:35,671:INFO:Copying training dataset
2023-08-09 16:52:35,676:INFO:Defining folds
2023-08-09 16:52:35,676:INFO:Declaring metric variables
2023-08-09 16:52:35,679:INFO:Importing untrained model
2023-08-09 16:52:35,682:INFO:SVM - Linear Kernel Imported successfully
2023-08-09 16:52:35,687:INFO:Starting cross validation
2023-08-09 16:52:35,687:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:52:35,763:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:52:35,764:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:52:35,764:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:52:35,774:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:52:35,776:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:52:35,782:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:52:35,784:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:52:35,790:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:52:35,790:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:52:35,794:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 16:52:37,916:INFO:Calculating mean and std
2023-08-09 16:52:37,916:INFO:Creating metrics dataframe
2023-08-09 16:52:38,228:INFO:Uploading results into container
2023-08-09 16:52:38,228:INFO:Uploading model into container now
2023-08-09 16:52:38,229:INFO:_master_model_container: 5
2023-08-09 16:52:38,229:INFO:_display_container: 2
2023-08-09 16:52:38,229:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-09 16:52:38,229:INFO:create_model() successfully completed......................................
2023-08-09 16:52:38,618:INFO:SubProcess create_model() end ==================================
2023-08-09 16:52:38,619:INFO:Creating metrics dataframe
2023-08-09 16:52:38,627:INFO:Initializing Ridge Classifier
2023-08-09 16:52:38,627:INFO:Total runtime is 0.32043850819269815 minutes
2023-08-09 16:52:38,629:INFO:SubProcess create_model() called ==================================
2023-08-09 16:52:38,630:INFO:Initializing create_model()
2023-08-09 16:52:38,630:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023712F3F700>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:52:38,630:INFO:Checking exceptions
2023-08-09 16:52:38,630:INFO:Importing libraries
2023-08-09 16:52:38,630:INFO:Copying training dataset
2023-08-09 16:52:38,634:INFO:Defining folds
2023-08-09 16:52:38,635:INFO:Declaring metric variables
2023-08-09 16:52:38,637:INFO:Importing untrained model
2023-08-09 16:52:38,639:INFO:Ridge Classifier Imported successfully
2023-08-09 16:52:38,644:INFO:Starting cross validation
2023-08-09 16:52:38,645:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:52:38,692:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:52:38,698:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:52:38,701:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:52:38,702:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:52:38,716:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:52:38,717:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:52:38,720:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:52:38,721:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:52:38,723:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:52:38,730:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 16:52:40,823:INFO:Calculating mean and std
2023-08-09 16:52:40,824:INFO:Creating metrics dataframe
2023-08-09 16:52:41,146:INFO:Uploading results into container
2023-08-09 16:52:41,147:INFO:Uploading model into container now
2023-08-09 16:52:41,147:INFO:_master_model_container: 6
2023-08-09 16:52:41,147:INFO:_display_container: 2
2023-08-09 16:52:41,147:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-08-09 16:52:41,147:INFO:create_model() successfully completed......................................
2023-08-09 16:52:41,541:INFO:SubProcess create_model() end ==================================
2023-08-09 16:52:41,541:INFO:Creating metrics dataframe
2023-08-09 16:52:41,548:INFO:Initializing Random Forest Classifier
2023-08-09 16:52:41,549:INFO:Total runtime is 0.36913553476333616 minutes
2023-08-09 16:52:41,551:INFO:SubProcess create_model() called ==================================
2023-08-09 16:52:41,553:INFO:Initializing create_model()
2023-08-09 16:52:41,553:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023712F3F700>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:52:41,553:INFO:Checking exceptions
2023-08-09 16:52:41,553:INFO:Importing libraries
2023-08-09 16:52:41,553:INFO:Copying training dataset
2023-08-09 16:52:41,557:INFO:Defining folds
2023-08-09 16:52:41,557:INFO:Declaring metric variables
2023-08-09 16:52:41,560:INFO:Importing untrained model
2023-08-09 16:52:41,562:INFO:Random Forest Classifier Imported successfully
2023-08-09 16:52:41,566:INFO:Starting cross validation
2023-08-09 16:52:41,567:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:52:44,441:INFO:Calculating mean and std
2023-08-09 16:52:44,442:INFO:Creating metrics dataframe
2023-08-09 16:52:44,764:INFO:Uploading results into container
2023-08-09 16:52:44,766:INFO:Uploading model into container now
2023-08-09 16:52:44,766:INFO:_master_model_container: 7
2023-08-09 16:52:44,766:INFO:_display_container: 2
2023-08-09 16:52:44,766:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-09 16:52:44,766:INFO:create_model() successfully completed......................................
2023-08-09 16:52:45,156:INFO:SubProcess create_model() end ==================================
2023-08-09 16:52:45,156:INFO:Creating metrics dataframe
2023-08-09 16:52:45,163:INFO:Initializing Quadratic Discriminant Analysis
2023-08-09 16:52:45,164:INFO:Total runtime is 0.4293741106986999 minutes
2023-08-09 16:52:45,167:INFO:SubProcess create_model() called ==================================
2023-08-09 16:52:45,167:INFO:Initializing create_model()
2023-08-09 16:52:45,167:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023712F3F700>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:52:45,167:INFO:Checking exceptions
2023-08-09 16:52:45,167:INFO:Importing libraries
2023-08-09 16:52:45,167:INFO:Copying training dataset
2023-08-09 16:52:45,170:INFO:Defining folds
2023-08-09 16:52:45,170:INFO:Declaring metric variables
2023-08-09 16:52:45,172:INFO:Importing untrained model
2023-08-09 16:52:45,174:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-09 16:52:45,179:INFO:Starting cross validation
2023-08-09 16:52:45,181:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:52:47,415:INFO:Calculating mean and std
2023-08-09 16:52:47,416:INFO:Creating metrics dataframe
2023-08-09 16:52:47,741:INFO:Uploading results into container
2023-08-09 16:52:47,741:INFO:Uploading model into container now
2023-08-09 16:52:47,741:INFO:_master_model_container: 8
2023-08-09 16:52:47,742:INFO:_display_container: 2
2023-08-09 16:52:47,742:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-09 16:52:47,742:INFO:create_model() successfully completed......................................
2023-08-09 16:52:48,146:INFO:SubProcess create_model() end ==================================
2023-08-09 16:52:48,146:INFO:Creating metrics dataframe
2023-08-09 16:52:48,153:INFO:Initializing Ada Boost Classifier
2023-08-09 16:52:48,153:INFO:Total runtime is 0.4792100628217061 minutes
2023-08-09 16:52:48,156:INFO:SubProcess create_model() called ==================================
2023-08-09 16:52:48,156:INFO:Initializing create_model()
2023-08-09 16:52:48,157:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023712F3F700>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:52:48,157:INFO:Checking exceptions
2023-08-09 16:52:48,157:INFO:Importing libraries
2023-08-09 16:52:48,157:INFO:Copying training dataset
2023-08-09 16:52:48,161:INFO:Defining folds
2023-08-09 16:52:48,161:INFO:Declaring metric variables
2023-08-09 16:52:48,163:INFO:Importing untrained model
2023-08-09 16:52:48,166:INFO:Ada Boost Classifier Imported successfully
2023-08-09 16:52:48,170:INFO:Starting cross validation
2023-08-09 16:52:48,171:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:52:50,649:INFO:Calculating mean and std
2023-08-09 16:52:50,650:INFO:Creating metrics dataframe
2023-08-09 16:52:50,975:INFO:Uploading results into container
2023-08-09 16:52:50,976:INFO:Uploading model into container now
2023-08-09 16:52:50,976:INFO:_master_model_container: 9
2023-08-09 16:52:50,976:INFO:_display_container: 2
2023-08-09 16:52:50,976:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-08-09 16:52:50,976:INFO:create_model() successfully completed......................................
2023-08-09 16:52:51,374:INFO:SubProcess create_model() end ==================================
2023-08-09 16:52:51,374:INFO:Creating metrics dataframe
2023-08-09 16:52:51,384:INFO:Initializing Gradient Boosting Classifier
2023-08-09 16:52:51,384:INFO:Total runtime is 0.5330544153849284 minutes
2023-08-09 16:52:51,386:INFO:SubProcess create_model() called ==================================
2023-08-09 16:52:51,388:INFO:Initializing create_model()
2023-08-09 16:52:51,388:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023712F3F700>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:52:51,388:INFO:Checking exceptions
2023-08-09 16:52:51,388:INFO:Importing libraries
2023-08-09 16:52:51,388:INFO:Copying training dataset
2023-08-09 16:52:51,391:INFO:Defining folds
2023-08-09 16:52:51,392:INFO:Declaring metric variables
2023-08-09 16:52:51,395:INFO:Importing untrained model
2023-08-09 16:52:51,397:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:52:51,401:INFO:Starting cross validation
2023-08-09 16:52:51,402:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:52:54,262:INFO:Calculating mean and std
2023-08-09 16:52:54,264:INFO:Creating metrics dataframe
2023-08-09 16:52:54,586:INFO:Uploading results into container
2023-08-09 16:52:54,586:INFO:Uploading model into container now
2023-08-09 16:52:54,588:INFO:_master_model_container: 10
2023-08-09 16:52:54,588:INFO:_display_container: 2
2023-08-09 16:52:54,588:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:52:54,588:INFO:create_model() successfully completed......................................
2023-08-09 16:52:54,979:INFO:SubProcess create_model() end ==================================
2023-08-09 16:52:54,979:INFO:Creating metrics dataframe
2023-08-09 16:52:54,987:INFO:Initializing Linear Discriminant Analysis
2023-08-09 16:52:54,987:INFO:Total runtime is 0.5931099851926168 minutes
2023-08-09 16:52:54,989:INFO:SubProcess create_model() called ==================================
2023-08-09 16:52:54,989:INFO:Initializing create_model()
2023-08-09 16:52:54,989:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023712F3F700>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:52:54,989:INFO:Checking exceptions
2023-08-09 16:52:54,989:INFO:Importing libraries
2023-08-09 16:52:54,989:INFO:Copying training dataset
2023-08-09 16:52:54,994:INFO:Defining folds
2023-08-09 16:52:54,994:INFO:Declaring metric variables
2023-08-09 16:52:54,997:INFO:Importing untrained model
2023-08-09 16:52:54,999:INFO:Linear Discriminant Analysis Imported successfully
2023-08-09 16:52:55,004:INFO:Starting cross validation
2023-08-09 16:52:55,004:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:52:57,266:INFO:Calculating mean and std
2023-08-09 16:52:57,267:INFO:Creating metrics dataframe
2023-08-09 16:52:57,583:INFO:Uploading results into container
2023-08-09 16:52:57,584:INFO:Uploading model into container now
2023-08-09 16:52:57,585:INFO:_master_model_container: 11
2023-08-09 16:52:57,585:INFO:_display_container: 2
2023-08-09 16:52:57,585:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-09 16:52:57,585:INFO:create_model() successfully completed......................................
2023-08-09 16:52:57,968:INFO:SubProcess create_model() end ==================================
2023-08-09 16:52:57,968:INFO:Creating metrics dataframe
2023-08-09 16:52:57,977:INFO:Initializing Extra Trees Classifier
2023-08-09 16:52:57,977:INFO:Total runtime is 0.6429426074028015 minutes
2023-08-09 16:52:57,980:INFO:SubProcess create_model() called ==================================
2023-08-09 16:52:57,980:INFO:Initializing create_model()
2023-08-09 16:52:57,980:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023712F3F700>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:52:57,980:INFO:Checking exceptions
2023-08-09 16:52:57,980:INFO:Importing libraries
2023-08-09 16:52:57,980:INFO:Copying training dataset
2023-08-09 16:52:57,984:INFO:Defining folds
2023-08-09 16:52:57,984:INFO:Declaring metric variables
2023-08-09 16:52:57,988:INFO:Importing untrained model
2023-08-09 16:52:57,990:INFO:Extra Trees Classifier Imported successfully
2023-08-09 16:52:57,994:INFO:Starting cross validation
2023-08-09 16:52:57,996:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:53:00,889:INFO:Calculating mean and std
2023-08-09 16:53:00,890:INFO:Creating metrics dataframe
2023-08-09 16:53:01,218:INFO:Uploading results into container
2023-08-09 16:53:01,218:INFO:Uploading model into container now
2023-08-09 16:53:01,218:INFO:_master_model_container: 12
2023-08-09 16:53:01,219:INFO:_display_container: 2
2023-08-09 16:53:01,219:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-08-09 16:53:01,219:INFO:create_model() successfully completed......................................
2023-08-09 16:53:01,603:INFO:SubProcess create_model() end ==================================
2023-08-09 16:53:01,603:INFO:Creating metrics dataframe
2023-08-09 16:53:01,613:INFO:Initializing Extreme Gradient Boosting
2023-08-09 16:53:01,614:INFO:Total runtime is 0.7035510619481404 minutes
2023-08-09 16:53:01,616:INFO:SubProcess create_model() called ==================================
2023-08-09 16:53:01,616:INFO:Initializing create_model()
2023-08-09 16:53:01,616:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023712F3F700>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:53:01,616:INFO:Checking exceptions
2023-08-09 16:53:01,616:INFO:Importing libraries
2023-08-09 16:53:01,616:INFO:Copying training dataset
2023-08-09 16:53:01,619:INFO:Defining folds
2023-08-09 16:53:01,619:INFO:Declaring metric variables
2023-08-09 16:53:01,622:INFO:Importing untrained model
2023-08-09 16:53:01,625:INFO:Extreme Gradient Boosting Imported successfully
2023-08-09 16:53:01,629:INFO:Starting cross validation
2023-08-09 16:53:01,629:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:53:04,237:INFO:Calculating mean and std
2023-08-09 16:53:04,239:INFO:Creating metrics dataframe
2023-08-09 16:53:04,559:INFO:Uploading results into container
2023-08-09 16:53:04,560:INFO:Uploading model into container now
2023-08-09 16:53:04,560:INFO:_master_model_container: 13
2023-08-09 16:53:04,560:INFO:_display_container: 2
2023-08-09 16:53:04,560:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-09 16:53:04,560:INFO:create_model() successfully completed......................................
2023-08-09 16:53:04,954:INFO:SubProcess create_model() end ==================================
2023-08-09 16:53:04,954:INFO:Creating metrics dataframe
2023-08-09 16:53:04,964:INFO:Initializing Light Gradient Boosting Machine
2023-08-09 16:53:04,964:INFO:Total runtime is 0.7593848307927449 minutes
2023-08-09 16:53:04,966:INFO:SubProcess create_model() called ==================================
2023-08-09 16:53:04,967:INFO:Initializing create_model()
2023-08-09 16:53:04,967:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023712F3F700>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:53:04,967:INFO:Checking exceptions
2023-08-09 16:53:04,967:INFO:Importing libraries
2023-08-09 16:53:04,967:INFO:Copying training dataset
2023-08-09 16:53:04,970:INFO:Defining folds
2023-08-09 16:53:04,970:INFO:Declaring metric variables
2023-08-09 16:53:04,973:INFO:Importing untrained model
2023-08-09 16:53:04,976:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-09 16:53:04,980:INFO:Starting cross validation
2023-08-09 16:53:04,981:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:53:08,397:INFO:Calculating mean and std
2023-08-09 16:53:08,398:INFO:Creating metrics dataframe
2023-08-09 16:53:08,727:INFO:Uploading results into container
2023-08-09 16:53:08,727:INFO:Uploading model into container now
2023-08-09 16:53:08,728:INFO:_master_model_container: 14
2023-08-09 16:53:08,728:INFO:_display_container: 2
2023-08-09 16:53:08,728:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-09 16:53:08,728:INFO:create_model() successfully completed......................................
2023-08-09 16:53:09,131:INFO:SubProcess create_model() end ==================================
2023-08-09 16:53:09,131:INFO:Creating metrics dataframe
2023-08-09 16:53:09,140:INFO:Initializing CatBoost Classifier
2023-08-09 16:53:09,141:INFO:Total runtime is 0.8290024876594543 minutes
2023-08-09 16:53:09,142:INFO:SubProcess create_model() called ==================================
2023-08-09 16:53:09,143:INFO:Initializing create_model()
2023-08-09 16:53:09,143:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023712F3F700>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:53:09,143:INFO:Checking exceptions
2023-08-09 16:53:09,143:INFO:Importing libraries
2023-08-09 16:53:09,143:INFO:Copying training dataset
2023-08-09 16:53:09,147:INFO:Defining folds
2023-08-09 16:53:09,147:INFO:Declaring metric variables
2023-08-09 16:53:09,149:INFO:Importing untrained model
2023-08-09 16:53:09,151:INFO:CatBoost Classifier Imported successfully
2023-08-09 16:53:09,156:INFO:Starting cross validation
2023-08-09 16:53:09,157:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:53:15,734:INFO:Calculating mean and std
2023-08-09 16:53:15,735:INFO:Creating metrics dataframe
2023-08-09 16:53:16,060:INFO:Uploading results into container
2023-08-09 16:53:16,061:INFO:Uploading model into container now
2023-08-09 16:53:16,061:INFO:_master_model_container: 15
2023-08-09 16:53:16,061:INFO:_display_container: 2
2023-08-09 16:53:16,061:INFO:<catboost.core.CatBoostClassifier object at 0x00000236D8C550F0>
2023-08-09 16:53:16,061:INFO:create_model() successfully completed......................................
2023-08-09 16:53:16,462:INFO:SubProcess create_model() end ==================================
2023-08-09 16:53:16,462:INFO:Creating metrics dataframe
2023-08-09 16:53:16,472:INFO:Initializing Dummy Classifier
2023-08-09 16:53:16,472:INFO:Total runtime is 0.9511932174364726 minutes
2023-08-09 16:53:16,475:INFO:SubProcess create_model() called ==================================
2023-08-09 16:53:16,476:INFO:Initializing create_model()
2023-08-09 16:53:16,476:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023712F3F700>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:53:16,476:INFO:Checking exceptions
2023-08-09 16:53:16,476:INFO:Importing libraries
2023-08-09 16:53:16,476:INFO:Copying training dataset
2023-08-09 16:53:16,479:INFO:Defining folds
2023-08-09 16:53:16,479:INFO:Declaring metric variables
2023-08-09 16:53:16,481:INFO:Importing untrained model
2023-08-09 16:53:16,484:INFO:Dummy Classifier Imported successfully
2023-08-09 16:53:16,489:INFO:Starting cross validation
2023-08-09 16:53:16,489:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:53:18,778:INFO:Calculating mean and std
2023-08-09 16:53:18,779:INFO:Creating metrics dataframe
2023-08-09 16:53:19,114:INFO:Uploading results into container
2023-08-09 16:53:19,114:INFO:Uploading model into container now
2023-08-09 16:53:19,115:INFO:_master_model_container: 16
2023-08-09 16:53:19,115:INFO:_display_container: 2
2023-08-09 16:53:19,115:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-08-09 16:53:19,115:INFO:create_model() successfully completed......................................
2023-08-09 16:53:19,502:INFO:SubProcess create_model() end ==================================
2023-08-09 16:53:19,502:INFO:Creating metrics dataframe
2023-08-09 16:53:19,520:INFO:Initializing create_model()
2023-08-09 16:53:19,520:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:53:19,520:INFO:Checking exceptions
2023-08-09 16:53:19,521:INFO:Importing libraries
2023-08-09 16:53:19,521:INFO:Copying training dataset
2023-08-09 16:53:19,526:INFO:Defining folds
2023-08-09 16:53:19,526:INFO:Declaring metric variables
2023-08-09 16:53:19,526:INFO:Importing untrained model
2023-08-09 16:53:19,526:INFO:Declaring custom model
2023-08-09 16:53:19,527:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:53:19,527:INFO:Cross validation set to False
2023-08-09 16:53:19,527:INFO:Fitting Model
2023-08-09 16:53:20,271:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:53:20,271:INFO:create_model() successfully completed......................................
2023-08-09 16:53:20,697:INFO:_master_model_container: 16
2023-08-09 16:53:20,698:INFO:_display_container: 2
2023-08-09 16:53:20,698:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:53:20,698:INFO:compare_models() successfully completed......................................
2023-08-09 16:53:37,793:INFO:Initializing create_model()
2023-08-09 16:53:37,794:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:53:37,794:INFO:Checking exceptions
2023-08-09 16:53:37,805:INFO:Importing libraries
2023-08-09 16:53:37,805:INFO:Copying training dataset
2023-08-09 16:53:37,808:INFO:Defining folds
2023-08-09 16:53:37,808:INFO:Declaring metric variables
2023-08-09 16:53:37,810:INFO:Importing untrained model
2023-08-09 16:53:37,813:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-09 16:53:37,819:INFO:Starting cross validation
2023-08-09 16:53:37,820:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:53:40,267:INFO:Calculating mean and std
2023-08-09 16:53:40,268:INFO:Creating metrics dataframe
2023-08-09 16:53:40,271:INFO:Finalizing model
2023-08-09 16:53:40,294:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-09 16:53:40,294:INFO:[LightGBM] [Info] Number of positive: 2910, number of negative: 1985
2023-08-09 16:53:40,294:INFO:[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000269 seconds.
2023-08-09 16:53:40,295:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-08-09 16:53:40,295:INFO:[LightGBM] [Info] Total Bins 560
2023-08-09 16:53:40,295:INFO:[LightGBM] [Info] Number of data points in the train set: 4895, number of used features: 9
2023-08-09 16:53:40,295:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.594484 -> initscore=0.382534
2023-08-09 16:53:40,295:INFO:[LightGBM] [Info] Start training from score 0.382534
2023-08-09 16:53:40,700:INFO:Uploading results into container
2023-08-09 16:53:40,701:INFO:Uploading model into container now
2023-08-09 16:53:40,708:INFO:_master_model_container: 17
2023-08-09 16:53:40,708:INFO:_display_container: 3
2023-08-09 16:53:40,708:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-09 16:53:40,708:INFO:create_model() successfully completed......................................
2023-08-09 16:53:41,111:INFO:Initializing tune_model()
2023-08-09 16:53:41,111:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>)
2023-08-09 16:53:41,111:INFO:Checking exceptions
2023-08-09 16:53:41,121:INFO:Copying training dataset
2023-08-09 16:53:41,125:INFO:Checking base model
2023-08-09 16:53:41,125:INFO:Base model : Light Gradient Boosting Machine
2023-08-09 16:53:41,126:INFO:Declaring metric variables
2023-08-09 16:53:41,129:INFO:Defining Hyperparameters
2023-08-09 16:53:41,536:INFO:Tuning with n_jobs=-1
2023-08-09 16:53:41,536:INFO:Initializing RandomizedSearchCV
2023-08-09 16:54:14,056:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-08-09 16:54:14,057:INFO:Hyperparameter search completed
2023-08-09 16:54:14,057:INFO:SubProcess create_model() called ==================================
2023-08-09 16:54:14,058:INFO:Initializing create_model()
2023-08-09 16:54:14,058:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000023706EAF220>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-08-09 16:54:14,058:INFO:Checking exceptions
2023-08-09 16:54:14,058:INFO:Importing libraries
2023-08-09 16:54:14,058:INFO:Copying training dataset
2023-08-09 16:54:14,061:INFO:Defining folds
2023-08-09 16:54:14,061:INFO:Declaring metric variables
2023-08-09 16:54:14,063:INFO:Importing untrained model
2023-08-09 16:54:14,063:INFO:Declaring custom model
2023-08-09 16:54:14,066:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-09 16:54:14,070:INFO:Starting cross validation
2023-08-09 16:54:14,070:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:54:16,601:INFO:Calculating mean and std
2023-08-09 16:54:16,602:INFO:Creating metrics dataframe
2023-08-09 16:54:16,606:INFO:Finalizing model
2023-08-09 16:54:16,626:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-08-09 16:54:16,626:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-08-09 16:54:16,626:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-08-09 16:54:16,628:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-09 16:54:16,628:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-08-09 16:54:16,628:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-08-09 16:54:16,628:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-08-09 16:54:16,629:INFO:[LightGBM] [Info] Number of positive: 2910, number of negative: 1985
2023-08-09 16:54:16,629:INFO:[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000237 seconds.
2023-08-09 16:54:16,629:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-08-09 16:54:16,629:INFO:[LightGBM] [Info] Total Bins 560
2023-08-09 16:54:16,629:INFO:[LightGBM] [Info] Number of data points in the train set: 4895, number of used features: 9
2023-08-09 16:54:16,630:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.594484 -> initscore=0.382534
2023-08-09 16:54:16,630:INFO:[LightGBM] [Info] Start training from score 0.382534
2023-08-09 16:54:16,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,654:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-09 16:54:16,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,654:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-09 16:54:16,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,654:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-09 16:54:16,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,658:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-09 16:54:16,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,663:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-09 16:54:16,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,664:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-09 16:54:16,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,664:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-09 16:54:16,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,664:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-09 16:54:16,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,664:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-09 16:54:16,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,664:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-09 16:54:16,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,666:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-09 16:54:16,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,666:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-09 16:54:16,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,671:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-09 16:54:16,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,671:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-09 16:54:16,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,673:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-09 16:54:16,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,677:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-09 16:54:16,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,680:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-09 16:54:16,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,681:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-09 16:54:16,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,683:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-09 16:54:16,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,685:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-09 16:54:16,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,686:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-09 16:54:16,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,690:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-09 16:54:16,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,697:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-09 16:54:16,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,699:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-09 16:54:16,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,699:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-09 16:54:16,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,700:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-09 16:54:16,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,702:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-09 16:54:16,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,702:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-09 16:54:16,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,703:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-09 16:54:16,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,703:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-09 16:54:16,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,707:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-09 16:54:16,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,711:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-09 16:54:16,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,711:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-09 16:54:16,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2023-08-09 16:54:16,712:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2023-08-09 16:54:17,072:INFO:Uploading results into container
2023-08-09 16:54:17,072:INFO:Uploading model into container now
2023-08-09 16:54:17,073:INFO:_master_model_container: 18
2023-08-09 16:54:17,073:INFO:_display_container: 4
2023-08-09 16:54:17,073:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-09 16:54:17,073:INFO:create_model() successfully completed......................................
2023-08-09 16:54:17,458:INFO:SubProcess create_model() end ==================================
2023-08-09 16:54:17,458:INFO:choose_better activated
2023-08-09 16:54:17,461:INFO:SubProcess create_model() called ==================================
2023-08-09 16:54:17,462:INFO:Initializing create_model()
2023-08-09 16:54:17,462:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:54:17,462:INFO:Checking exceptions
2023-08-09 16:54:17,463:INFO:Importing libraries
2023-08-09 16:54:17,463:INFO:Copying training dataset
2023-08-09 16:54:17,466:INFO:Defining folds
2023-08-09 16:54:17,466:INFO:Declaring metric variables
2023-08-09 16:54:17,466:INFO:Importing untrained model
2023-08-09 16:54:17,466:INFO:Declaring custom model
2023-08-09 16:54:17,466:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-09 16:54:17,466:INFO:Starting cross validation
2023-08-09 16:54:17,467:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:54:20,014:INFO:Calculating mean and std
2023-08-09 16:54:20,014:INFO:Creating metrics dataframe
2023-08-09 16:54:20,016:INFO:Finalizing model
2023-08-09 16:54:20,038:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-08-09 16:54:20,038:INFO:[LightGBM] [Info] Number of positive: 2910, number of negative: 1985
2023-08-09 16:54:20,039:INFO:[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000119 seconds.
2023-08-09 16:54:20,039:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-08-09 16:54:20,039:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-08-09 16:54:20,039:INFO:[LightGBM] [Info] Total Bins 560
2023-08-09 16:54:20,039:INFO:[LightGBM] [Info] Number of data points in the train set: 4895, number of used features: 9
2023-08-09 16:54:20,039:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.594484 -> initscore=0.382534
2023-08-09 16:54:20,039:INFO:[LightGBM] [Info] Start training from score 0.382534
2023-08-09 16:54:20,504:INFO:Uploading results into container
2023-08-09 16:54:20,506:INFO:Uploading model into container now
2023-08-09 16:54:20,506:INFO:_master_model_container: 19
2023-08-09 16:54:20,506:INFO:_display_container: 5
2023-08-09 16:54:20,506:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-09 16:54:20,506:INFO:create_model() successfully completed......................................
2023-08-09 16:54:20,908:INFO:SubProcess create_model() end ==================================
2023-08-09 16:54:20,908:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.6529
2023-08-09 16:54:20,909:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.6592
2023-08-09 16:54:20,909:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2023-08-09 16:54:20,909:INFO:choose_better completed
2023-08-09 16:54:20,916:INFO:_master_model_container: 19
2023-08-09 16:54:20,916:INFO:_display_container: 4
2023-08-09 16:54:20,917:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-09 16:54:20,917:INFO:tune_model() successfully completed......................................
2023-08-09 16:54:21,564:INFO:Initializing create_model()
2023-08-09 16:54:21,564:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:54:21,564:INFO:Checking exceptions
2023-08-09 16:54:21,573:INFO:Importing libraries
2023-08-09 16:54:21,574:INFO:Copying training dataset
2023-08-09 16:54:21,577:INFO:Defining folds
2023-08-09 16:54:21,578:INFO:Declaring metric variables
2023-08-09 16:54:21,580:INFO:Importing untrained model
2023-08-09 16:54:21,582:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:54:21,588:INFO:Starting cross validation
2023-08-09 16:54:21,588:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:54:24,117:INFO:Calculating mean and std
2023-08-09 16:54:24,118:INFO:Creating metrics dataframe
2023-08-09 16:54:24,122:INFO:Finalizing model
2023-08-09 16:54:24,493:INFO:Uploading results into container
2023-08-09 16:54:24,494:INFO:Uploading model into container now
2023-08-09 16:54:24,499:INFO:_master_model_container: 20
2023-08-09 16:54:24,499:INFO:_display_container: 5
2023-08-09 16:54:24,500:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:54:24,500:INFO:create_model() successfully completed......................................
2023-08-09 16:54:24,897:INFO:Initializing tune_model()
2023-08-09 16:54:24,897:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>)
2023-08-09 16:54:24,897:INFO:Checking exceptions
2023-08-09 16:54:24,907:INFO:Copying training dataset
2023-08-09 16:54:24,909:INFO:Checking base model
2023-08-09 16:54:24,910:INFO:Base model : Gradient Boosting Classifier
2023-08-09 16:54:24,912:INFO:Declaring metric variables
2023-08-09 16:54:24,914:INFO:Defining Hyperparameters
2023-08-09 16:54:25,337:INFO:Tuning with n_jobs=-1
2023-08-09 16:54:25,337:INFO:Initializing RandomizedSearchCV
2023-08-09 16:54:59,043:INFO:best_params: {'actual_estimator__subsample': 0.85, 'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.02, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.15}
2023-08-09 16:54:59,044:INFO:Hyperparameter search completed
2023-08-09 16:54:59,044:INFO:SubProcess create_model() called ==================================
2023-08-09 16:54:59,044:INFO:Initializing create_model()
2023-08-09 16:54:59,044:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236D8482AD0>, model_only=True, return_train_score=False, kwargs={'subsample': 0.85, 'n_estimators': 230, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.02, 'max_features': 1.0, 'max_depth': 7, 'learning_rate': 0.15})
2023-08-09 16:54:59,044:INFO:Checking exceptions
2023-08-09 16:54:59,045:INFO:Importing libraries
2023-08-09 16:54:59,045:INFO:Copying training dataset
2023-08-09 16:54:59,048:INFO:Defining folds
2023-08-09 16:54:59,048:INFO:Declaring metric variables
2023-08-09 16:54:59,050:INFO:Importing untrained model
2023-08-09 16:54:59,050:INFO:Declaring custom model
2023-08-09 16:54:59,053:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:54:59,058:INFO:Starting cross validation
2023-08-09 16:54:59,059:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:55:01,780:INFO:Calculating mean and std
2023-08-09 16:55:01,781:INFO:Creating metrics dataframe
2023-08-09 16:55:01,785:INFO:Finalizing model
2023-08-09 16:55:04,099:INFO:Uploading results into container
2023-08-09 16:55:04,099:INFO:Uploading model into container now
2023-08-09 16:55:04,100:INFO:_master_model_container: 21
2023-08-09 16:55:04,100:INFO:_display_container: 6
2023-08-09 16:55:04,100:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.15, loss='log_loss', max_depth=7,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.02, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=230, n_iter_no_change=None,
                           random_state=123, subsample=0.85, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:55:04,100:INFO:create_model() successfully completed......................................
2023-08-09 16:55:04,502:INFO:SubProcess create_model() end ==================================
2023-08-09 16:55:04,502:INFO:choose_better activated
2023-08-09 16:55:04,504:INFO:SubProcess create_model() called ==================================
2023-08-09 16:55:04,504:INFO:Initializing create_model()
2023-08-09 16:55:04,504:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:55:04,504:INFO:Checking exceptions
2023-08-09 16:55:04,507:INFO:Importing libraries
2023-08-09 16:55:04,507:INFO:Copying training dataset
2023-08-09 16:55:04,509:INFO:Defining folds
2023-08-09 16:55:04,510:INFO:Declaring metric variables
2023-08-09 16:55:04,510:INFO:Importing untrained model
2023-08-09 16:55:04,510:INFO:Declaring custom model
2023-08-09 16:55:04,510:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 16:55:04,510:INFO:Starting cross validation
2023-08-09 16:55:04,511:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:55:07,143:INFO:Calculating mean and std
2023-08-09 16:55:07,143:INFO:Creating metrics dataframe
2023-08-09 16:55:07,145:INFO:Finalizing model
2023-08-09 16:55:07,528:INFO:Uploading results into container
2023-08-09 16:55:07,528:INFO:Uploading model into container now
2023-08-09 16:55:07,529:INFO:_master_model_container: 22
2023-08-09 16:55:07,529:INFO:_display_container: 7
2023-08-09 16:55:07,529:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:55:07,529:INFO:create_model() successfully completed......................................
2023-08-09 16:55:07,915:INFO:SubProcess create_model() end ==================================
2023-08-09 16:55:07,916:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.6686
2023-08-09 16:55:07,916:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.15, loss='log_loss', max_depth=7,
                           max_features=1.0, max_leaf_nodes=None,
                           min_impurity_decrease=0.02, min_samples_leaf=5,
                           min_samples_split=5, min_weight_fraction_leaf=0.0,
                           n_estimators=230, n_iter_no_change=None,
                           random_state=123, subsample=0.85, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.6511
2023-08-09 16:55:07,917:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-08-09 16:55:07,917:INFO:choose_better completed
2023-08-09 16:55:07,917:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-08-09 16:55:07,924:INFO:_master_model_container: 22
2023-08-09 16:55:07,924:INFO:_display_container: 6
2023-08-09 16:55:07,925:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 16:55:07,925:INFO:tune_model() successfully completed......................................
2023-08-09 16:55:08,571:INFO:Initializing blend_models()
2023-08-09 16:55:08,571:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>, estimator_list=[LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-08-09 16:55:08,571:INFO:Checking exceptions
2023-08-09 16:55:08,582:INFO:Importing libraries
2023-08-09 16:55:08,583:INFO:Copying training dataset
2023-08-09 16:55:08,585:INFO:Getting model names
2023-08-09 16:55:08,587:INFO:SubProcess create_model() called ==================================
2023-08-09 16:55:08,590:INFO:Initializing create_model()
2023-08-09 16:55:08,590:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.6,
                                             bagging_freq=2,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.4,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=41,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=260, n_jobs=-1,
                                             num_leaves=7...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000236D88E5660>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 16:55:08,591:INFO:Checking exceptions
2023-08-09 16:55:08,591:INFO:Importing libraries
2023-08-09 16:55:08,591:INFO:Copying training dataset
2023-08-09 16:55:08,594:INFO:Defining folds
2023-08-09 16:55:08,594:INFO:Declaring metric variables
2023-08-09 16:55:08,598:INFO:Importing untrained model
2023-08-09 16:55:08,598:INFO:Declaring custom model
2023-08-09 16:55:08,602:INFO:Voting Classifier Imported successfully
2023-08-09 16:55:08,606:INFO:Starting cross validation
2023-08-09 16:55:08,606:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 16:55:13,541:INFO:Calculating mean and std
2023-08-09 16:55:13,542:INFO:Creating metrics dataframe
2023-08-09 16:55:13,546:INFO:Finalizing model
2023-08-09 16:55:14,652:INFO:Uploading results into container
2023-08-09 16:55:14,653:INFO:Uploading model into container now
2023-08-09 16:55:14,653:INFO:_master_model_container: 23
2023-08-09 16:55:14,653:INFO:_display_container: 7
2023-08-09 16:55:14,656:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.6,
                                             bagging_freq=2,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.4,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=41,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=260, n_jobs=-1,
                                             num_leaves=7...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 16:55:14,656:INFO:create_model() successfully completed......................................
2023-08-09 16:55:15,069:INFO:SubProcess create_model() end ==================================
2023-08-09 16:55:15,076:INFO:_master_model_container: 23
2023-08-09 16:55:15,076:INFO:_display_container: 7
2023-08-09 16:55:15,078:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.6,
                                             bagging_freq=2,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.4,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=41,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=260, n_jobs=-1,
                                             num_leaves=7...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 16:55:15,078:INFO:blend_models() successfully completed......................................
2023-08-09 16:55:15,463:INFO:Initializing finalize_model()
2023-08-09 16:55:15,463:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.6,
                                             bagging_freq=2,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.4,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=41,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=260, n_jobs=-1,
                                             num_leaves=7...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-08-09 16:55:15,466:INFO:Finalizing VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.6,
                                             bagging_freq=2,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.4,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=41,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=260, n_jobs=-1,
                                             num_leaves=7...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 16:55:15,470:INFO:Initializing create_model()
2023-08-09 16:55:15,470:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.6,
                                             bagging_freq=2,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.4,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=41,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=260, n_jobs=-1,
                                             num_leaves=7...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-08-09 16:55:15,471:INFO:Checking exceptions
2023-08-09 16:55:15,472:INFO:Importing libraries
2023-08-09 16:55:15,472:INFO:Copying training dataset
2023-08-09 16:55:15,472:INFO:Defining folds
2023-08-09 16:55:15,472:INFO:Declaring metric variables
2023-08-09 16:55:15,472:INFO:Importing untrained model
2023-08-09 16:55:15,472:INFO:Declaring custom model
2023-08-09 16:55:15,473:INFO:Voting Classifier Imported successfully
2023-08-09 16:55:15,474:INFO:Cross validation set to False
2023-08-09 16:55:15,474:INFO:Fitting Model
2023-08-09 16:55:16,235:INFO:Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Warehouse_block ',
                                             'Mode_of_Shipment',
                                             'Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Product_importance',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(ad...
                                                                          max_features=None,
                                                                          max_leaf_nodes=None,
                                                                          min_impurity_decrease=0.0,
                                                                          min_samples_leaf=1,
                                                                          min_samples_split=2,
                                                                          min_weight_fraction_leaf=0.0,
                                                                          n_estimators=100,
                                                                          n_iter_no_change=None,
                                                                          random_state=123,
                                                                          subsample=1.0,
                                                                          tol=0.0001,
                                                                          validation_fraction=0.1,
                                                                          verbose=0,
                                                                          warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-09 16:55:16,235:INFO:create_model() successfully completed......................................
2023-08-09 16:55:16,631:INFO:_master_model_container: 23
2023-08-09 16:55:16,631:INFO:_display_container: 7
2023-08-09 16:55:16,641:INFO:Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Warehouse_block ',
                                             'Mode_of_Shipment',
                                             'Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Product_importance',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(ad...
                                                                          max_features=None,
                                                                          max_leaf_nodes=None,
                                                                          min_impurity_decrease=0.0,
                                                                          min_samples_leaf=1,
                                                                          min_samples_split=2,
                                                                          min_weight_fraction_leaf=0.0,
                                                                          n_estimators=100,
                                                                          n_iter_no_change=None,
                                                                          random_state=123,
                                                                          subsample=1.0,
                                                                          tol=0.0001,
                                                                          validation_fraction=0.1,
                                                                          verbose=0,
                                                                          warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-09 16:55:16,641:INFO:finalize_model() successfully completed......................................
2023-08-09 16:56:41,086:INFO:Initializing finalize_model()
2023-08-09 16:56:41,086:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.6,
                                             bagging_freq=2,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.4,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=41,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=260, n_jobs=-1,
                                             num_leaves=7...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-08-09 16:56:41,088:INFO:Finalizing VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.6,
                                             bagging_freq=2,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.4,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=41,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=260, n_jobs=-1,
                                             num_leaves=7...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 16:56:41,093:INFO:Initializing create_model()
2023-08-09 16:56:41,093:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.6,
                                             bagging_freq=2,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.4,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=41,
                                             min_child_weight=0.001,
                                             min_split_gain=0.9,
                                             n_estimators=260, n_jobs=-1,
                                             num_leaves=7...
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-08-09 16:56:41,093:INFO:Checking exceptions
2023-08-09 16:56:41,094:INFO:Importing libraries
2023-08-09 16:56:41,094:INFO:Copying training dataset
2023-08-09 16:56:41,094:INFO:Defining folds
2023-08-09 16:56:41,094:INFO:Declaring metric variables
2023-08-09 16:56:41,096:INFO:Importing untrained model
2023-08-09 16:56:41,096:INFO:Declaring custom model
2023-08-09 16:56:41,096:INFO:Voting Classifier Imported successfully
2023-08-09 16:56:41,097:INFO:Cross validation set to False
2023-08-09 16:56:41,097:INFO:Fitting Model
2023-08-09 16:56:41,139:INFO:Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Warehouse_block ',
                                             'Mode_of_Shipment',
                                             'Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Product_importance',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(ad...
                                                                          max_features=None,
                                                                          max_leaf_nodes=None,
                                                                          min_impurity_decrease=0.0,
                                                                          min_samples_leaf=1,
                                                                          min_samples_split=2,
                                                                          min_weight_fraction_leaf=0.0,
                                                                          n_estimators=100,
                                                                          n_iter_no_change=None,
                                                                          random_state=123,
                                                                          subsample=1.0,
                                                                          tol=0.0001,
                                                                          validation_fraction=0.1,
                                                                          verbose=0,
                                                                          warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-09 16:56:41,139:INFO:create_model() successfully completed......................................
2023-08-09 16:56:41,552:INFO:_master_model_container: 23
2023-08-09 16:56:41,552:INFO:_display_container: 7
2023-08-09 16:56:41,562:INFO:Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Warehouse_block ',
                                             'Mode_of_Shipment',
                                             'Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Product_importance',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(ad...
                                                                          max_features=None,
                                                                          max_leaf_nodes=None,
                                                                          min_impurity_decrease=0.0,
                                                                          min_samples_leaf=1,
                                                                          min_samples_split=2,
                                                                          min_weight_fraction_leaf=0.0,
                                                                          n_estimators=100,
                                                                          n_iter_no_change=None,
                                                                          random_state=123,
                                                                          subsample=1.0,
                                                                          tol=0.0001,
                                                                          validation_fraction=0.1,
                                                                          verbose=0,
                                                                          warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-09 16:56:41,562:INFO:finalize_model() successfully completed......................................
2023-08-09 16:56:48,744:INFO:Initializing predict_model()
2023-08-09 16:56:48,744:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Warehouse_block ',
                                             'Mode_of_Shipment',
                                             'Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Product_importance',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(ad...
                                                                          max_features=None,
                                                                          max_leaf_nodes=None,
                                                                          min_impurity_decrease=0.0,
                                                                          min_samples_leaf=1,
                                                                          min_samples_split=2,
                                                                          min_weight_fraction_leaf=0.0,
                                                                          n_estimators=100,
                                                                          n_iter_no_change=None,
                                                                          random_state=123,
                                                                          subsample=1.0,
                                                                          tol=0.0001,
                                                                          validation_fraction=0.1,
                                                                          verbose=0,
                                                                          warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000023708DBFE20>)
2023-08-09 16:56:48,744:INFO:Checking exceptions
2023-08-09 16:56:48,744:INFO:Preloading libraries
2023-08-09 16:56:48,746:INFO:Set up data.
2023-08-09 16:56:48,752:INFO:Set up index.
2023-08-09 16:56:59,593:INFO:Initializing predict_model()
2023-08-09 16:56:59,593:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000023712488AC0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Warehouse_block ',
                                             'Mode_of_Shipment',
                                             'Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Product_importance',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(ad...
                                                                          max_features=None,
                                                                          max_leaf_nodes=None,
                                                                          min_impurity_decrease=0.0,
                                                                          min_samples_leaf=1,
                                                                          min_samples_split=2,
                                                                          min_weight_fraction_leaf=0.0,
                                                                          n_estimators=100,
                                                                          n_iter_no_change=None,
                                                                          random_state=123,
                                                                          subsample=1.0,
                                                                          tol=0.0001,
                                                                          validation_fraction=0.1,
                                                                          verbose=0,
                                                                          warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000023706CDAEF0>)
2023-08-09 16:56:59,593:INFO:Checking exceptions
2023-08-09 16:56:59,593:INFO:Preloading libraries
2023-08-09 16:56:59,594:INFO:Set up data.
2023-08-09 16:56:59,600:INFO:Set up index.
2023-08-09 16:58:55,772:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_ede3a0411d3c4d2e841e317b1d86b5ba
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,772:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_a24332b606204bc989fb0320bfd1d37e_0fbcb6c197f84d0da08758b643267784
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,772:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_3f999acae9414b0080261d3054a2a2ae
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,772:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_fd5d3bf203744965962b8d82b2e8d5c9_c3a7e0cbd3ab4bfb9d065004488e4997
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,772:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_b4aa1dfe9a5f48cab05407a4f0b16221
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,772:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_61915a52228b47fd90da5524106a9d99_a486d9989a5d490289386b43cff25e3b
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,773:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_6965fbb995bd4d3abff5d402f7b8b7a1
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,773:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_597b29361e564bf38638d52221cfae40_205087be33f34caaa612c2f6b3b86570
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,773:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_952215cc4cb5480396a6029565bc0bf7
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,773:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_4aebc35aa68b4ca3bfb8e6ec57c31d50_8f5469dee9aa48938340522e59fd784a
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,773:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_5e1121976bf5421d9eb2cb16e81e2f9d
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,773:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_ac96a341c04041ed89b78d627a28729c_6e84dc825df54673910258deee58d294
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,773:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_c331e0a2fb054feaaefd158bb14eb2ae
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,773:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_5ff307a5a91d467a8d5202dee1662f04_b980bc7882bc4444b2abf09eaeb07122
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,773:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_3a47586b016b4971a70e19450ba24fae
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,773:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_1ea0f3e457e64ce1b76f32a50fb2bcd1_f38d88986ace4d60b5b4bc1042de00b7
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,773:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_8421524ff1fe4b85987167e3a79f3bd7
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,773:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_e64f5ba924d7434ca8d07831af374aa9_68191cf760af4bc79278a59a640b25f2
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,773:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_edf7c59919954b79a7827bb313db7aa8
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,773:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_a2c5dff840bc431692a92377f9bce22a_f9259060f375466f827fc809913bce53
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,773:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_58c4893d543841a8bf48cf1b74548e69
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,773:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_ec572b0e2446477893fc80ca58611ce3_57eb93a52c5a435796303a8e0333a074
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,773:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_e3c7e399534247b0b37b914764431aab
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,773:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_c43567aa08864e9b902ee9092d1481ee_36cbd2f169e34d7ca18fcf7ee99c2570
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,773:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_c673dd14dd4c4760941c1f4acd20fc7a
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,774:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_ffbbce20a9dc40fda07b1e735dd2f707_f1db9511dfe64ab79d53cf52d8cb7b2e
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,774:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_ac83ed1f085a4855ae67818eb4ebe679
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,774:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_ffc57ac44e5245a6a3069bcda9e4b1bb_655317a06c724a8fb3d456721f8b7966
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,774:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_a25c8b00becc4a5da83bf06318c04f11
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,774:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_a63690537d9f456e9226ce4893d16be7_178e7e57eded42aab322bbfa319f774e
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,774:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_aa127e117bef4ab7870567b09c4f6683
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,774:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_5fbedca9038c40cd88751721122ee235_6c42a85341fe4acda2401beda45db038
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,774:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_64da24dd7bb748fa87bc5a82685b9712
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,774:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_5e08662dc9c04cfdb85942d8bc312439_8e30e34391e0481d833239924bd27c45
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,774:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_7aca0257074c4f7c9229f7e5d0f1b347
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,774:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_ffc09cd793ad4ab781e571c9ccfc0ad5_72bdee9e3c0e47ce8fb14215db8615de
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,774:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_413847b3f82d42f0bcde3cfdc30f5680
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,774:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_dfec64f4a23840cca68c62b04233ec94_6579bbb601cf4132b1441b01c1791659
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,774:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_65a4ddf81a0a45a6b3be015c8b37e5fd
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,774:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_2639e44bf7fa493d8e1d6bb6d0414430_59e6dc9a83b94c6a8f98c2b28d1f5c55
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,774:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_36211b568ef747dd907b46bb422d04b9
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,774:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_bf049f182b204a0da7ac76b8d602cd5d_ae2dbd3c498c4fd49006062761829f56
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,774:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_84f3a80c71ba4892b5e221448c4b5181
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,774:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_0fb487c57a25401db693fea0aec9ae36_c8f5bbb54b18441d8abbe7836004dd93
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,774:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_fdcfbe9b80e446ccbb901fee509c56a8
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,774:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_e5a60c87585a439ab4c697a404456699_db9561df66b04e0db1ad7da0945eb78d
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,774:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_d31363912b6f4c5fb22b44316fd19c8f
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,775:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_ec3fa597fec2478e8623dae560c2e588_67554f8ebc9248edaf864377c4c72ade
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,775:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_ede3093d357c42398a79fd3a9de1a1cc
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,775:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_34a9e272b8604c7bbafec6be6b51edb9_c6e4bee78f084d9fa85f655f4e0379d1
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,775:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_4267c184d2c940c9a8fd186de42530b5
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,775:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_ce7e7d13661a4c9784295ee1c0ab395b_5f5239da5cb541f4bdb5040b590aced8
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,775:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_5c5abcf3496440adbe062cd2482a71a4
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,775:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_0904ff8191b649bd9ebdb6f9d2279f73_7fb8bcd18a3149b2a71c50a8e06c5b8b
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,775:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_ee80442a646b4ee29c04eb642aae4107
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,775:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_3abe4180b955479aa1b7fb4efb1b4489_e10a3a5fa2eb4b0ca71f142cc5db0ced
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,775:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_ca5458c6887b415287ebe807bc8d581a
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,775:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_9331e24eff0c48a99793953462e8f1e8_24d1352f12144ad1998771c48b669df5
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,775:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_be0549eb4fa941ff91a61516387d646c
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,775:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_becd8601b6b2479791abade24f9ae685_e07309f8f6d54f0c88e317a6aca113e4
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,775:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_f8104a0d1fe041f39409dd7dd327fbca
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,775:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_b603ed2638d14e479b5eaf9bdb78c94f_ccd9561c973747069ce38e7af44a8d1a
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,775:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_7bfc774e18ef4a1bb50a30e4dc5dffaa
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,775:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_fe5e62abf1a74f2db75dfee7409e8867_fb0801b0a2da4ab29ef3dc8519947081
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,776:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_dd7b0184ea3545e2b5fc6570e384ce40
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,776:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_71e37b33aa4a4f1a847270be4eecce65_d53c82d575124d96b7697a975fb9a73e
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,776:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_88a0310d9ccd47babdc0945edbcbc0f0
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,776:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_639b37b221044997b5198a34d32ef308_b903c8c5b07143d794c72cda3d9f2b30
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,776:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_8ea3d118c9204cd999bf26215f3b704a
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,776:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_87cda1e1b1f54bd09146bb7cbc663192_2fda07185b04452397a27898d6a475c6
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,776:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_71cd1d6bdc584a938599b37685cfae8e
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,776:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_782f93b96c14403da1dd130babb962d0_536796bc93d94c7393036c3570895d9c
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,776:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_e5621debf4bd46afbc6849ea75781f31
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,776:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_b5015d18642b4af8946e8411cd36e1f7_130f9748b2b74eb8b509662ac8aef240
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,776:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_e902a2b25a8d4d6eaf4d79cef132ee6b
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,776:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_c798f13a334145df84cdd21e2452af02_fa86e31f36f7435dba304ee7899528f4
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,776:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_42ce97172c754580b8181c7c53b9bd54
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,776:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_b5d98ded086b41fdaf6e91a6c46d4561_ac1746c74f4845909ab53b4dbb2aa150
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,776:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_99121fa4e6324445b48f6f93289cd274
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,776:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_bcda5691bac34a68b9e5e61f97954d49_f89fd995b6d249ad8ac75dceb6c78f90
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,776:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_0ac0960ccf7f4232bef6d8afbce0dd7a
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,776:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_6bd40d47a48f40319110af83b94c62cf_8fffa3a5a9884caf8da38c47ce1842f6
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,777:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_fb4c8f68352043f0ac002dc2cb39d02a
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,777:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_6bbd4de56bd94fb38b79b50ab6a37b73_2207161f5ab24451aeeed593a88855fc
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,777:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_e627beb1c8d2496385be53aa71376ae9
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,777:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_008d84fcc052432eafba17253f0be299_c40fcb1c8bee4698afc625f800b451aa
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,777:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_9fe54879cf1946da932fd6fd13f0e0d8
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,777:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_5271e7142eaf496692a3837d67f5dc55_25e15d5724a54a0db723e3cf32da2485
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,777:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_f7538f97928444aebd2185e670486aae
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,777:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_4bfd392c1d5b401d8dbfa3251c513ed6_73c8e55fb73f4db386f24211f297a43d
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,777:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_7626d9b586564b35a8a2127a1b83dadf
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,777:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_7bbb44fdd31a4948973eccf67f1f3aca_7935cf259d1c45a78f202485ce6586ee
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,777:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_079c8cbcb9654fc4aec5f00aab70a7e0
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,777:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_462f5f4592ad45fc9893d66f013bb8ca_ae15d55dd5b740b9bacaab5962306358
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,777:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_062fb050b1ed482784d4934b2fdb1bdc
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,777:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_b05494027b384d0d865538a0b628d2f2_af6882df441c4cb4ab5f10aeed192bb1
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,777:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_8d54a36255974e079b1993f33ed69195
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,777:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_784ca2ee00744001a6689af278e1ab1c_87b181b4478248ad8e0efe3a5e884373
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,777:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_70be3f14b3194ce1b43ea9bb70b47ac6
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,777:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_3e0d316d2754480287937dca5c1ce5cf_5b680b583af24ffeb293873749fd94be
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,778:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_52fa2df9119f49ee8e20f2df9c1c3795
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,778:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_a0478f92266e40ca9da3f322a0718eda_c42908f014894ab59f329cd50f0f9716
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,778:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_9a0113febb4c4d9481b5718eed078dc9
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,778:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_0471a30fd7b045a3beba6a97de95db70_ab765c7d11aa4597972073fda23ac711
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,778:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_8d69de97691944cd8a5610d289580499
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,778:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_07d93b1cc1e1488ba97e4064999ab1d9_d72eb1e4d6154821a92383b2a77522e5
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,778:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_aa7433be9198434b8f59c5e6437ea923
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,778:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_e87d9cf4ce4c423dab449b72310a4022_cd95b939e6184369971e22bb73621b45
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,778:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_231fe7da384c43539e77ba1b70ad8338
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,778:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_0d08478192a94d6fb59023d2de8649e8_62b09878c4f8456482257f5ca348b6d6
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,778:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_4d2ba091a2de44a587d967456a252f87
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,778:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_6602974e5ff2423e9caef65b50f16b3f_8de0b6f4535a4efa848f8e63c83720e4
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,778:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_0d92d58b23964771b921cff1ce060ebf
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,778:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_88ee11c163474e5fabb15c0dd0b13d05_1bd08750f0f14589bbee0e7853f644df
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,778:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_2a3c52cb19484930b3739242babc58df
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,778:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_5d9d6a95eb644305a7c6890a84dc53b3_26a260dc85864248b42f7c7d2866919c
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,778:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_f958f6b8a1bf4c78a219c3cd542e8c28
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,778:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_f501aa3ded684ed7bbf3a60f7503e62a_dc22bd9455fe43ae86b8288f74d1ee0b
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,778:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_ab54dce6741f4cada0d9e6e51a5c4754
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,778:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d3a6905ce21740e291d1967d09238994_5369bf957a4c42fb8e0fdc22665c506d
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,778:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_a180473058ac417f86c913bd2b41f5df
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,779:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_715e5a4bc9c84172b3f7267f965600fd_0dc8a66586ca4acda3555e037ee394a5
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,779:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_da855daa255a4c90a67186487a139e2e
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,779:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_2b166d497dc1434d925216681922c239_6fe2db6b85f948a490f4e70c9be891a6
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,779:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_ce4345b20b494aba943fce677edefc41
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,779:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_66d940e0df24478d91dc7f8f3ae4880d_ca44ff8bf61049a18aa37b88f644cfbd
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,779:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_c610f2a6679d49d89abd6fcce459ba8a
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,779:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_a1db3dd2f9764fdf9dec0d52cd2a6090_bdfdd2439b614263b193489bd6d4587c
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,779:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_a9bd2dab0b1f4860a9fa99beb6f66f1e
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,779:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_7bfbd8ec4c8a426fba0d066a03b4b4f5_5e118fda760840b6b859d7a66522be2e
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,779:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_a3f9134463d842b2b52e266316d9ca33
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,779:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_12fb0ff8ae9a4228bba13b473d125ad0_38e9c61a5eb04a53bff315dabfeb0ff0
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,779:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_b08af54d05f84fe4b13d79f646e624c8
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,779:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_ec9da9e789f84dfeb55eac1097737f70_d5b3f6be67c842e5b90fed7b1348afd2
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,779:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_5e022d6dcd1a4fa7a75806b5e99302c2
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,779:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_46363ee6b2ad4c5180373ca5c5c81a23_110ec2efd9684fc2a4f89a3e85644538
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,779:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_1a949166f80f45b5a1069ae15d71c440
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,779:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_79a8742a2d9e4a7ba933ecb9b82934eb_4efc55fd698842a6877f72744fa3fa6e
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,779:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_0a1767d1232d4d3aac13a2fec3eae460
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,779:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_435e33de31d34e2795f53889b07b2ad3_3806f899dcbe42b4ada867ac460ce6e7
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,779:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_db977aff557c4f4f8ab5953c2ae920cc
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,779:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_fe4735203ad94f2a88b72412bee4110d_0175c758698c4bd9b79fa114f8c29864
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,780:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_fa1fdf438b654a1f8fd36f950d9423c1
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,780:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_f1eb9bd0674b4c23a5f33103618d416f_220edc6950584e94b58937d3c0d53f82
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,780:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_3f27abec01514a2ba32badcc1d44d856
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,780:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_f8191fbfa8934d31b2d1fa4ec0db4058_7c32d48a36a94d69a1f51f0c98824ca1
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,780:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_85863566e54f44d5a8f5e2bf87ea79f1
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,780:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_2493f43a60864d99be0b66a71ad854b9_399195c1077c4b38b1d2dc5bc0d3a9a1
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,780:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_ae02f679bbb845219537dc34c40e3ec5
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,780:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_dfc19bea77104b7bbd37ce80e9839c5e_67b8583333e146678711a44ad2b6deb9
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,780:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_a2f65b4c2c8b4078885f11e37bb563a9
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,780:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_0afbfcf57b9540f2ae1170c6aae778d9_50b3868478d4448e9381aef459aee638
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,780:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_076242ab338448b0aef6b8f4d4b7bc4d
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,780:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_1a7d8ac76a124b14bc84d7ff17439fda_21fc4351d66a4a9c97664fca777d75c6
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,780:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_b3910ec947a641248332d7decd4b4f82
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,780:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_932017e5b16d429ca06d388cab652a01_5ce32b29b94345ed91509c4d391f4443
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,780:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_de26858300794dae9c7d87eafb02d1a4
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,780:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_81b8b1e7aaa643dabdb641f3dac6adc4_f829ca0a1b774934b27c83da46ec3deb
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,780:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_296670eeafe34c859d2ce2aa56461d68
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,780:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_2a0776725d3647cb9d9d0f988ef80e76_28504a0a5b9a41e39e899b6a6dcc862c
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,780:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_90f67d6dea1542c2a3dc105eefe70cb9
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,780:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_9b1b1cbd0749467f9e379477fdeaf2a4_ee9e736e49e0468e9fe14d9aacb90a49
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,780:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_c1cad9a98ef84d71996d0bf0ed6341c5
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,781:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_ef31da6774df4418aabda118e2eeb06a_40e92c69ac3a429c829661c4c148ff22
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,781:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_06e5722717c84c7e8a149de6b0ba6623
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,781:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_88cc68b4244049e999c6db6038017dc2_edaa3d02e65e4678aa898a0da32e704f
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,781:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_515ffc2273644772969b38c15af231ad
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,781:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_f809b2862cd245598dd40d72ab4a2860_2fdf8a1327514b99a874a7a362d3cd9f
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,781:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_f21da7421b304fe0b52cba3e5ea6e549
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,781:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_6ccc95b43f214ea3ba51a35dc6742b0a_29be28d2258841b59e5bef529bb2766a
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,781:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_72d984fbe548482e98a62630c2802cf1
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,781:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_7c5c63d494a64f6c8a83a431933330d4_13567778fb0b4d72a6b7882b6c62db4f
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,781:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_defef9d24027459b994e3c3d6d3f8f51
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,781:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_e4d611e787ed417fb277bed2d840b507_2b6f23ab33a94f8da1b49ad40e9591f9
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,781:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_8bbc3f4255e545159a2c09109a0ad50e
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,781:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_2df6fd29f60e4744b924df5a960fd8e6_57db9fa4f7684ce0810fa10fde371b00
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,781:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_ab3d6afd90534d8696cde4a0cf846a1a
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,781:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_96323c0ed82e4b5f90914998ab6615cb_1795a620e1fe4acb8dc0e55e23c475b4
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,781:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_f390a95465e04346ada1a6720dbf3fba
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,781:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_88e408f89dc3413c9ebf8a14f126d162_b2c53e9696a74fc09418a4b7237211a1
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,781:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_0510d21d5c54434c9a0def6a01429a6d
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,781:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d9f1733777bc4e93ac9e6c4bdba9912d_3746dbe2fd364866849d51e49f6fcb8f
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,781:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_fd164f55f41c4b5ba51e3d33c3527284
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,782:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_3e5798d479ad4e3793f9d5113b487c3e_cb07dc0133c549008ed8e7f3a86fb913
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,782:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_bfe3d012241c46d58a4106054ca87d2f
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,782:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_db4b1ec69c1b497eaf05b037eb78b88b_e8c0bd4504c54779933562d970d9b6c1
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,782:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_768cca39ba334f67a25dcecd7312d7ee
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,782:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_ef2c25c0e746413393eaeb03a3cf91e6_a96e10e7bd4f499dae159969fc584d52
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,782:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_8c41dfff6b2543b4a6310b387643ca8f
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,782:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_37ea7583f23c4b3986b7aa46ad630fba_eef8f95dc36248b4ac00da9a0f5170ee
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,782:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_a80e20d060054d3ca806a2344a728dd6
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,782:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_b97e95768b984a1c9387664bce3f7d33_b34e10910ec64c759972d6a73c5eec84
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,782:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_909fdcb6e42a4df29a69970988def0ff
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,782:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_ded8981c12e8476182e8ebf4495b3e02_5de965a464d34b4094e77e174bc257f3
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,782:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_dad497015dd4425580dd49f5964c6fa7
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,782:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_15cbfcfe29694de188467b966f970fc3_b3350af501a340419b6beed5cb69cded
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,782:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_34e34478fb9a4fec89aed5b23cc890e4
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,782:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_8d296c0a296847498290a982d989016f_ccb0fca5c01c4751b68bd79556584387
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,782:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_9d90272e5e3f4bfc98c16659f4223174
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,782:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_755c39a51dcc45278c751d3397fc56e0_4efaff5d6edb4695b26c9839cbcf63cd
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,782:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_be11ee5c63db42dabb555b724176445d
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,782:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_a70d53a6d4554148a6ad6264bbd1e120_e71326e8bcc848afbc1f820e8285182e
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,783:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_01a414f8050a4c2c8691379aa33d106b
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,783:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_16514cabb6674896b3e5131f1d0f5f3c_b6bf2de3f3134da69fc3c368ccb5800f
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,783:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_cc908ddf07a84601b1cbfbd1720ba85f
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,783:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_1967a6c2b2424dce9b3d944adfb3f3c6_a7e38b31ea6e4d2ca5f476085d698ebc
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,783:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_d722a098a04f4447a0189653971084c2
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,783:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_155ca199aee549569c66cf522f76ef47_8160e301ef62405ca3d9ff5bb6244346
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,783:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_6b7b9dd0ad8c433e81bca7836aea8d12
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,783:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_adfeb265e96c44cc8546a3edb40ef836_96150328c23d460a8fe970319b22d056
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,783:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_ae4cca2287fd45f99fedcfef7f31cac3
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,783:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_ad38e08ec7d44e48afbc12dbcb891a68_f21cc3f0097f4c5ca3f0534b893b1312
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,783:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_58effb563b074f09be9dda29d410c5a3
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,783:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d269e48ce42e4973898ad42a07eca40c_59ab4935294d43a7a02dbe097db63997
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,783:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_c6eba73bded4419197af13214fff0dc1
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,783:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_f4e80b3a9f424ffab4906c62250d8dfc_9b481a629dbd454188c5fc5d952cb66c
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,783:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_432cb3b8018d446da757803b24deb1d5
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,783:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_f91a59d56f3d470fb00da08297b0da25_a30a1b8a63194772bad993684a4a338d
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,783:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_b7b607fe6f4844efa7c0c3ab15d83227
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,783:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_0a2cb6117c144992b666af81a080fa40_d7d4f5fbacca4d70a09724f9de5d5ce6
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,783:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_58d15c877cb04acd96c405e5c3f8faaa
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,784:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_358445f4a28646bc9bd0dda82fe55446_3b03d3c5a98e4de7ad84cce6bb480049
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,784:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_64fe360d927449478042623b9151b05b
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,784:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_f443c3d4de93419f91b8e46fe81314db_e863b67ef995485ca96a99859b2d2f38
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,784:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_49a0239a430e4b4597935eadbc448c8c
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,784:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_e71cf281a33c440f9acba5e120c35e41_b0276bf7118f4625849f683815707346
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,784:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_9888a81944d349a1a6071cc99d909bcf
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,784:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_b2ee92ee9cfd48218a396e012bc15b9d_c2dd1b10fdfe45a88b4e724004744d3c
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,784:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_5c422f0874be472bb48540857862721c
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,784:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_9dff4a7d9a764001830d250b83010fb0_8ea12edea8a0488f9f4667870affd8bb
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,784:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_3835fe460915468c983acb06e7bb3b9b
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,784:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_711d74f04a724016a2fef1a051b6809b_27e26335d86148dfb02dbc84537cfcb3
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,784:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_d26d4557f3234fa887db0ccc08c0cc81
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,784:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_4ebd6574d7674362a94fcbdf3549309a_40300b49a9594fb4ae0b39d936626f6b
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,784:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_e1754677e58541bf8b0cd216409fe974
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,784:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_740c608c1b714b4e996fdef37dba16df_a6b282b99c754a2a98f50bc3f451c8ee
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,784:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_a4b85af792ab43ed872c424296875a46
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,784:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_cd21be6835c94c94967356b9a60b4f15_96681f99e51d466c8e240d89bac8072d
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,784:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_dbddb04842c64d50a71305e863fca544
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,784:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_952c863b45c449a2a28754568659be50_cb83d7d107664d3796c715a0a7169ebf
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,784:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_c74bc15a6333464eb04bdbf0f0759c4d
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,784:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_b7d131df9771446baaf96a5ee2a24d40_45ea7ed285c243c4820547f6b013fe81
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,784:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_eb8f4f6d32d949d295b1808c87eb79bc
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,784:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_5592c4d0698846d9a16ab3ae5aed0696_2f6c11323b744f14a9eeb5d543a45104
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,784:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_e2c8bb7c7c084d328f07b05bdbef2de5
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,784:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d1b6fba82f4646429541df1b26499574_0a34d68d7f334df286f46f39c9a6175d
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,784:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_82f90a85930b4ff1a24f017b70a0f889
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,785:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_ad7f29c470334e989f95edb215976953_5005e941a5b54c9f83caa483a9cfbad3
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,785:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_165f558f7f714881ac8624d96765c540
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,785:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_6436faa2948842d7a89a8974a2dfc74c_efdbd082ffe342f4818d946484054194
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,785:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_b7a0cb8f3c3e45988cf93a02e424b5a3
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,785:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_c64b58fb073349c5980befe18c3f7774_986ef8c6ef22409ca45ab35bbdb87c4e
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,785:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_1262a961666149b49fbae5e7252d6f02
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,785:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_cfea7a5bf0fc451aad90a729b81ffcbf_a85987bb33fe46678135f1dc82f0ade2
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,785:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_ee6f728e63f14bde8a5c7b8c38906e2b
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,785:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_fb42eaab2f7349feac6c598985914965_440f0fee2cfb45cebaeacf49eb1194bc
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,785:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_a148316938cc4b0ea0ed16ed58f5c206
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,785:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_83f6c79484234d298b948e07b6c03e57_c66b99d528da4728b0e1bbd96639020c
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,785:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_ff7634a1e7334cf79a5302e0266f6e67
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,785:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_39862d2987e44ab18eec6a1b96a58677_97d2dad21af8464fb4ce4300a04a9ecf
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,785:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_2796f81235fa4a1ea36406f8bb166fa6
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,785:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_627c8dcc4b364f97afe7134ce21bf78c_6a8caae224044c77a5db01d3e1805fdd
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,785:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_6f6280c516af4adcb4822bc962607c30
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,785:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_6581f510172c40f1a8da913f5b66fcfe_f325327f765a40fc88ac7b5a59a9cb76
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,785:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_ea2fdf4239dc40dfb708e61ea77720ab
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,785:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_467327b58d03416992a824069458c57e_54fff3e01fcb4541824cab62b0885aae
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,785:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_9cfc8c4a8a6a4425b3b268f93fdb5816
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,786:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_0bb7e9402bdc415c9720d2f7e287dc89_2f906e42977a447f82720734d87708be
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,786:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_2f41a03bc1924aba812ceb2cd618bf1a
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,786:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_51543d3a28a041aab715ab0428558805_4583639c4e1c41d2a216ff9769942005
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,786:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_64201c4ddd784730af614966d8b1ef7b
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,786:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_c29447add7fd4d1cb1797d68e9f6d5b6_622fb80d33974d71bbc8c5c471b16190
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,786:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_b2bbfe4ed68642dab1fef9f47ef9f934
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,786:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_49b4fd5d271448f9a5bcd4c7fa9a77fa_0e52346a91664922be86285596fd8f63
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,786:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_f9e5443183be48d08ccc4413056412b7
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,786:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_9929296605dc4e35a4a7e9def83ce913_4a1206a3e494474e9f1baae85bb46caf
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,786:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_60e3b6fe2b8748468415e4f5a4823511
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,786:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_01bc1a85381642398a5fcf2b0f2417d5_0afeb892b098410ab91a727a1fe78434
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,786:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_258dc8b7e67a43c4be27f98143373498
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,786:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_1fe777ba56984c1f9c5014858efd0254_5615f93163034c55b9f2b3eeb048425b
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,786:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_e90284d3aa6940c5810e3f5bce2e1836
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,786:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_0ad868b946ae42deb9051800a300199a_672dc2bcd703492abca92a42097a33c4
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,786:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_bdd570228bda427780a18fd4e32796cc
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,786:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_475d4c595fe84a0495651a2b92988ac0_bccf67346e2d4b45aa45d090a394881e
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,786:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_445b9ee5b96545569f2260eb0187049c
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,786:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_5badc6ff82fe469e855c9953e953dd2c_df1140de277c4da281ee940291feb405
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,786:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_19d669888c1c43ecbdeade9c3fdd0c3a
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,786:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d27417d21e174db09ebd3a6e2d0e38c8_a98e8ac8b5e74b4a919f460c92a93da6
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,787:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_0e007c0c6438472784d73b05cec694f8
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,787:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_20789cdcb05340ed80671c148b934a5c_337100b7084443c8a0486f4208981c4c
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,787:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_73f59b3b900e41eb93511d5bb74ab7e0
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,787:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_7ae532ac167d4a948b480f5b428545af_09ebdb4571d4401a91a49fa6e9ce053a
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,787:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_2142528a525340dc9696dad05584c75c
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,787:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_477acaadcf844d6ba974fdceab5b5698_e9395b15131248f6901dcda40ad93bc6
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,787:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_93c7d976f02e4f77b4e700cd491037bd
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,787:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_ae164d0b4abb426cbf1cb794f94d3a69_d9f64faf064e4eec96565571e81a1f05
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,787:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_aa011550a1914aca88f9577e5cb38827
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,787:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_0032eb7e3cd245ddb33b3da97bf865bc_6aa34c6030a44509b4f10867921d6ade
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,787:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_61c06cd549784e8c902217cb8af70c17
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,787:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_ea371d8f3924461dbadaaa2e6943f1ba_2a2b99caaa2145e89fd87d697935ce99
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,787:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_62edac72340a49018757a7c3e8969e88
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,787:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_8e5ba19090594b3cb2d83d303b9ad157_3c789f04dbd34027a17b417eed11f299
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,787:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_06ec1a18b8cf4d53b820d0dd34a9b0db
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,787:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_841c566ea3b5468d88f48b0cf72510c2_2d43e67c3e154b2da3b0ad62f570bf32
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,787:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_40e75877f7cb4d63a098b8a0363eca68
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,787:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_4e94d2d5c968414d99746e5a72ba9098_def2416c8d8c4c28b1668fa2baa26439
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,787:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_905a65b8cef7431d9f755bb78f54fd36
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,787:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_9e48d4b68e7d42289f9cad48f369be2b_3ab22babb99e4164bda9d70caa8a4bdf
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,787:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_e8670524e6524ee6b06d11bf8455f82e
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,788:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_9d53292d9fcf43b6a09792e07997b534_c6e7905b88a446e0a775a576b45607db
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,788:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_046c0d075e2348acbbaf2468ad32a2c2
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,788:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_b4663f418a924abca4c114c5ed926e3f_432a3080c7914a60b09cb9b57561d023
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,788:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_6940b664e3214d8284c6dbe1f70e4a08
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,788:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_f110f5331c4d4abaaee246f7ae0c17d4_ab951319204b404bb7bb5acaf251faa1
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,788:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_9627f12fa75e43cbb21adeea4bb8644a
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,788:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_adb0f6cf84db4e6cb432ae89b77fdf70_e91f40a76adc44f6a1d39a10c17c3c0c
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,788:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_e4361064e3144ad38038ff4b75df9e0e
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,788:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_dbfc56d5c91e4105861b87d595bdea88_e54e06d38d524bd2be1fecee82421d09
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,788:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_12402c413e3b4bc68bafa5a17106e04c
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,788:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_c0e5d1b8dcbf43ebad26f538586c88e3_749c7e6ef7a94803980cd0c0b0976f4f
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,788:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_a7c77fc2327146b7b2d9f6c9c391eb06
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,788:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_0c66999bc0d24768ba9e873a31bd3e26_d940d74a7b5345d5b1a2ff26aa169b4d
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,788:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_b948886a13f84a929eb4aaf65f36fd06
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,788:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_531ceb74ce0e480f8a39fd8fbc5c0e3e_aa9eced2b96445d8a8cfec0404ca12c6
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,788:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_9162b88d5a56425cb67def4978c9b948
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,789:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_2841f8677f3446028d36d7e561cf3110_6b0ae1ff32ca43f4868e7b0b1bab049d
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,789:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_bd24c1f6507e4a348a2e1124a8973874
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,789:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_efcb86ffcb904cd5a519c5eca0dc0f0d_bf2220d97adb48ff9a8be014f3a62501
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,789:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_2d1eff685e4f49ea908d725342ea98aa
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,789:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_37cfd7aec3024fb389cfb10217350a93_e4af2e2114984076b2df2b6e55763990
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,789:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_8d16b2c974dc480ca17dd56981ff737b
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,789:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d13f3223e432406c93bb559d5be2125f_c1933214acd0497e9b05deae7d40e0a4
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,789:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_c854f85592ea43858997ce1e9079a619
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,789:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_1bfb32668af240c7b56f9187fee73590_1eabb2fcd86f4629b084cb982b296d0c
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,789:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_4a0cb1da3fe643278ca05ca8d45bf394
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,789:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_680f08001ef24ef5be74a05f147b033e_d4a4a9a1cff54a4f94d21da8907360d9
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,789:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_f94821e6f5eb4784a7b0001716bd8069
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,789:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_09da48cb1b134fb2a492e79ce414b00b_f6f3a782bfde43c1a11895f87a81b001
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,789:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_0513a709590247709a0f5cd97345dfc8
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,789:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_55e9222ea64b4acab1f93c712ae9c0b3_9810c40f90974beb815d0ee2eac64c60
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,789:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_197f47d03dc84cf0a4968f0838bab1a5
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,790:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_b00ccef7e63f4c3680949f005a67eed3_561f8544df064c5faa7152632e93ed7a
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,790:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_27a78b2b0c0b4183bfcafd57bf5b0d4c
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,790:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_754d403072b347d9984c597a694fbbda_36fc83c667b14c5985ee727c17a862e3
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,790:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_0144042c2fc94faba6513e5105c4d78a
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,790:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_3d1ea5db7a02418e9a7dd57698247bad_142d8cb0484a488e9d4b9aa72c50f272
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,790:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_31c780865386495e943c06234cd26ec4
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,790:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_eb4e2c012a79413b976b8e956e0258b6_39f9afb205ea4573a4159fc985fc664c
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,790:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_138a22c0d38f48a9b23adc799b4d1cb7
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,790:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_e82a2930230444319162454507dd8554_bfc5b2738c564e779bfa6ae7798d724a
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,790:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_df495800a2c84d1eaba9ceaabfc78eef
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,790:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_3a363a45375c46a9952a2dfdf0d712f4_6688f36e8b284c68a147f07e48dbd630
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,790:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_d14122055f66435a93ce490ac641e8f2
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,790:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_97232879a4db43789106cf812423df92_c5b8dc0afd0e4173a84a8a4aee6b6dd6
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,790:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_53b8f38e7edd49cd9af5d07799774b9c
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,790:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_72c34928b2c045efbdb24f01b26c4823_b5df1dd22d19449e965c374491eee4ce
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,791:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_8faf5e9182ad47d79cfe2a663fc7f918
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,791:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_86fb5d08a41a49a89b33b5e507d264a7_9d689fda285242a4b7b97332bb2719df
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,791:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_4844005aa2674f94812285878ed8a05c
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,791:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_43ad718c4bcf404381111511aa8003a1_7eab6229f6294791a18c0ce47583d9a2
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,791:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_5503fe76d27b4beba996cdc728e4be74
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,791:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_2c0ac41c19844b0fa09c202fc81284bb_a82f4b9b242e478c80d1e115b2091a3f
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,791:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_f164105975984c11a94ae9495d4ea24a
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,791:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_5ceba8c22f704e06bd5d078b35cd7d9d_b73b3c41f4fb49a4944ce24486a3e1b9
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,791:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_5e87e9298ae34051b01984eccf7b330d
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,791:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_82c2ba10fa8a43c981c652fa640e1566_fe2ba4de2e0344d98e3d2461ba88c08d
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,791:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_acc105210f9f46a896a17184c9cf8bde
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,791:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_543f05c826654f37bf5ae08f0823f292_e5c5c85e1f644f1380a693cb80388b31
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,791:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_d880442865fe4f0496af37444fdbacf0
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,791:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_6b821e5f58794b109376e4fc86f2ac5c_7f36094ce13546ceb28d1140ace86b35
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,791:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_98eedbef274f42a4be6f70b3c91a8499
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,791:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_1a5d0fe1040c463cbb3102a29f07b606_733e227caa70413db58b300ac0fa7516
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,791:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_3ab37f74f94243ff9b4598f3fd4d6e44
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,791:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_c0867ff9c88e43558e7ef009edc0be96_0a4b49d4ef864857acf910c68827fbbf
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,791:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_42942ee5a61e43f3972c14eb9f5ae066
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,791:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_9e29436dc0f842bab1bf1a6f98e2bb14_669adf39d5ef4bf68a5fe3b67fa5dd28
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,791:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_868ec3358a3545b1b48ba4e0ce79a743
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,793:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_b6d80b52bf5f402e9525eb87661e9ac6_ade427a290ab43fda71c73fb3dc2b030
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,793:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_b8ed365c98884c9a8a76353591e73b30
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,793:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_af95ad68015e4f168141bd26751ee8ef_db0e5b13f5944e56a5bad4ab0a87d0ef
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,793:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_a9eefeece8fe44309ba4acbedce2fc32
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,793:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_9f1577988d044a34ab600c099665e360_9e6060064e734801b09a551578a0d7e0
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,793:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_1001f8a616fd48e9b0f3f7f2cc635726
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,793:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_ae35f75a273f4871b4484c777c66fb41_498406c8cfd44029b0fa00aebcaaaae4
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,793:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_01d22914c2b84342a955536f5ca24240
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,793:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_1c973c0396cf4991a3c85cd02e5fabd1_be4d312f90934f919378079b0e25040e
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,793:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_76517bf0710a49cea309bd7bde869981
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,793:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_582e2ca517cc453caa540e1093ad9e46_1aca14bd2fc14a2dbeb7ebf0524fc50c
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,793:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_5b8b652e029040acb401e1b9148f6e17
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,793:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_dd810c8bf5a94dbd8ab82741a3e8e52d_75d15966fe5a4b9cbd9e0b4c9ebd5693
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,793:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_1f05fee081d54c2f9a3e01be85690bc0
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,793:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_0d0c13fbdbea4d4d9fb5db70f02d20dd_e2afec1db2fa4d66838cad735e651120
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,793:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_37a936eb14084bdead73e5b09c46bc0e
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,793:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_cb6da8f55dc547e9bde7837f099422a6_d2e4d439315a4b21be89fa130a50b5ea
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,793:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_7be1fb4038c44518b131106c0c6bd782
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,793:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_f2b638933d994e8a9d5d29a42fb42edf_07c7333fe4f34f959a3d35cce2c468bb
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,793:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_2eb900371b2c4630aac58032c586cf88
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,794:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_c0c2fc12147649aab3f09b9c0b7b8b42_d31b4719885d48fca5712d570846198a
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,794:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_d48ba8e64e2a40a7bbcf52964b60b24e
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,794:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_992de1cef1e54cef9721d5b971c5ea66_3706c301783d4d59bc63872d1d35110b
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,794:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_84ec24361abb4e5e89af844e11ecccbc
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,794:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_b4f07c22a623405f913d1584734c7244_bccca054f8874e15bcd2c44c6704c922
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,794:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_b4ce7e0d247740d98e7c7c8d0844efa1
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,794:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_fafd638acdb44483bc1594958ee17809_17379896c6b84800a90acd3bf29bd41f
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,794:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_3e312b8fecab4b71a1c0b90ca0e6b634
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,794:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_8add67bebd514c9c93a5499549d4af80_15bf5ef63f6f44b78f7a165ae5d527b8
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,794:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_57b54527406a48c5891ab85a7890e0ea
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,794:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_8f77e7f2ca47475cb0d84286382c63ef_fa2f4a2cedc84938ac02a4e4685635dd
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,794:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_c840abe46f754cd9a746c112de36467a
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,794:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_8e3d77eefade42239b53fddb4e3b6272_5706e452f172460d9ca18caf868c80b8
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,794:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_df6ed6647cfb41c3b19098efca7c1d98
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,794:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_80262c47b49241359322683fd9ebc0ac_b1fcee4bb2d44c82953de8eb1f16049a
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,794:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_eca7afbac2eb4b0880e685fce3cb4171
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,794:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_8539dec70d634f47b3bd4c191907c393_b37eb026e12b42e89c9c9236dad88897
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,794:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_49b130bb1a5140cf97c78eb12f22c422
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,794:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_67bffb6ed6074f9c958aa2c147e272fc_43660554f6b24dfbae315e87bf006afd
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,794:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_84cfdd72aa324af79f6e41e1de64ab11
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,794:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_be8fe292a8194e62b9b77cb0ccb163d7_7455993062c44d068df2b5f3cf48dba2
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,795:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_4f1277c97765481d86da3db605893262
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,795:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_f221507bdda74d528727cf1ba37d0224_4b7d0cd41a7b45d69f1db9646f6ca2f0
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,795:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_1e7ecfa6fb2647938a1e9a4c37b815b4
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,795:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_098b157f618d406f9daeb731c456b2b9_e5e50228c15d44f2ae426be9986c0d51
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,795:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_ad650d35c2e84ab3afbfb76b013d2c90
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,795:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_f67ae6f47a564d24ae9db6c1d3e7ef8b_1c380c065ddf4784825203e544eb1430
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,795:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_76d946853e7e4f3eb6b12114c2db632f
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,795:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_6257dc66d23e4f919fa4d30ed69b11df_fc0216ddb00642189c889d7937fb4ce6
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,795:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_60fe3eb4191f40e4b9e0ff885c9dbf78
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,795:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_bdd707e3dbfc4b29ab6e46f3a8bd4752_948371e5f0c3422294d3f1c7ea5150ec
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,795:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_6dea3955492a468dbe7760b405244f33
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,795:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_7ce3d606218a42538b86e5a7db0c7f4a_801c15da3be84f0c812f397169822456
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,795:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_da7ea93efaae4d90a426c06dfce612c0
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,795:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_1b692b1a277d47068cc1f14f2cc6ac4e_92e6d51e77c043c79a2bd0a7b3dcf772
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,795:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_e36120b6fbfc47629a17a10b069140c7
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,795:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_1aa289156ec74b0882734e82abfee403_3f859b5dc91d41989743981faba0bc91
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,795:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_9db47ae434274ef0bc3392315d4b0519
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,795:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_bcec8d2dc9f4469393cb70b27307b1b9_0b5cc0f9075649a6aeeada4b82f894f1
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,795:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_92ee0e838f3247d38b0a0f3b83bf4cca
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,795:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_909efa1a2f094633a5c661499399c523_9291821d49ef4dfd92952b1abd112ddc
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,795:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_783c421a47f3420cbaf7255c62fc5897
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,796:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_de71786d4c824851acc184c2728a16a5_bf11fed3aebd4e688e2a34e90df857e0
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,796:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_e00d5ca9af194dbc904278fe8f56e71b
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,796:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_5c5249e23244428793fafe2e49622001_f32ec51c4d7041768513f63b1dae100a
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,796:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_407281c848064502b5f9e44aad687a53
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,796:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_5f93b0429dfd43338870fd77563b6b8c_02c0780261034df99c0573d4629ee08f
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,796:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_00a71a847a7e48108f197e3b1a76e188
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,796:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_68809bbe07f046cf815cc431b67e849c_09534b9bdf3843cba6f10d7752896960
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,796:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_6599a1e0bdf24af4bdb71c84bf520103
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,796:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_772333f0eea54b11872e7f3ea2ed84a7_6a4d51ff94ab4b46b2f100fa90c75509
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,796:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_e389d5cba0fd41f982a4b1b12ea80395
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,796:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_11024684d52a498eb74319204f20bb05_865428a7f44342ca8d2a7d65b276c57a
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,796:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_7f24da00be5a41eabfd4be77caacdd40
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,796:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_42e1e96fa1e84894bdeef1d5ccee4f79_36f3c4bf5daf4723a970857995ca686a
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,796:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_fa37868c1531442696a35e5e00b5547b
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,796:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_bbd6eee3b4644aeb8853a02888940d84_f525feb8505e4abfa1ceff6e1f6a2a71
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,796:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_bc8bb3a8a9d3467eacebebcc5fdbcd6f
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,796:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_63cf4b8f3c3d43fcb28a3643bd58afc1_210c9112fe22480cb6d3f3047e725efa
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,796:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_661ae0ebaac04737bcd903fde8c6e5da
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,796:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_e7e1295118714b29b2ba2dbbc3801991_3b8d9b094a7049a5b60067414f7f8296
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,796:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_2777faca87004bd7b5823c5dd4bb0252
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,796:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_902286b0efd2430191d243bc3f3d9dd4_46dbac39ee494ac5b127c2f7b8cb6957
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,796:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_09d185ac22a145f89014a222bb0a7fab
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,796:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_e07e967d14954f31aa9d179db0146878_049483a6135b4f3c80508255620be623
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,796:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_f84056c8b60b4272909aad4ce67a96ce
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,796:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_42e1ec3f298b48f98b8fe256511fb73f_183022d295d24830827cc9408f0dd34f
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,796:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_6b3ba57fb3584d3797348ee91c40cc5f
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,796:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_3eaf3408609c4129b384337f67b5c57e_08f8b3a24f094323beaefaf0b30836fa
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,797:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_6f642202cba5478abe779a8d3f63ff53
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,797:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_687a202eda6443f8a556f6c0a5ae9b4b_ab86dec8d12a4aadad2c6114921debf0
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,797:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_f478a9439a234083a8e44c6d2bd0d0ac
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,797:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_87fa4646729741bd943502f4204dc169_d9ac9d31c9a749d4ad3cd6a487c764f5
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,797:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_7835230068b04f889eb5b0cedbfc364b
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,797:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_b5fd7748822145c49fb68f0e793ae01a_c358532034914dadb77b7782984a8fe7
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,797:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_fd1bba1fd5be46eba8fae0010ba41744
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,797:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_9da8b0f5f3d44d1a891f897eb5c9a4e1_0968120b1f4944f8a96b0e2b14c3027b
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,797:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_16d5c81c8ea74a04bfbc33bb91bf2365
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,797:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_5685ad06e87b4e679c9b48170aaf1816_0c749dab1132427e862d303f17527758
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,797:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_c85cc753f40f4757a5a3d69ae894137f
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,797:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_86868f0aad2142b6be1d080646fbcf28_8a52a5a8a23f4fb98ead93a53876fc2b
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,797:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_7427ea447a234dc98aba46eec1698fd7
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,797:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_63bd05d627de4c6198b2cbc5b538927b_34bbddb94b6346ada1f5b77b7ecb6e91
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,797:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_b52c59b6e6d44ef79951562d4bfcf40a
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,797:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_ba617cabf84d4edba9cd00e28e5dfad9_5c4bcce3a42347049b6883c05fa5058f
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,797:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_66502538e62346c39334a433ca8c468a
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,797:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_75834f68f81c466bad66002ba594faba_121f9f8c3eaa4e7e8d470d098b94230a
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,797:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_540d03ed7cc047769b92f89e28b0972e
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,798:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_abc57fdd574c458c917d63e293bbf53b_b5297506c39e4ccdbdaac201b6ba0afd
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,798:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_69ac28ea1a074b8eadfc5819113a43ce
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,798:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_1d954f35c78e4a2286d9c5a99f0c44ee_2435f435ba5f49f9b19488fb3573ba10
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,798:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_e2c8de0be5314c67bd59323356988361
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,798:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_fa351c78a9ef43ff8e886cd02c6f3959_7ef3ee97915b45e5ba34412a2add8615
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,798:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_cf26ef261a9d4777afcc423e4e14f2df
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,798:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_1eed1530eb79420dafca85a263e62079_8c35acbac9d7483e828f67f5341a4ba6
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,798:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_86302a4b002644c3ab0b349ed6b350cd
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:58:55,798:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_2764_d2913431dd1c494394a420273841868c_19dc22ce8fdd4d9ba552251f1b5c3020
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 16:59:01,444:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-09 16:59:01,444:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-09 16:59:01,444:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-09 16:59:01,444:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-09 17:06:19,018:INFO:PyCaret ClassificationExperiment
2023-08-09 17:06:19,018:INFO:Logging name: clf-default-name
2023-08-09 17:06:19,018:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-09 17:06:19,018:INFO:version 3.0.4
2023-08-09 17:06:19,018:INFO:Initializing setup()
2023-08-09 17:06:19,019:INFO:self.USI: b85a
2023-08-09 17:06:19,019:INFO:self._variable_keys: {'logging_param', '_available_plots', 'fold_groups_param', 'fold_generator', 'gpu_param', 'y', 'y_train', 'pipeline', 'data', 'X_train', 'X', 'X_test', 'is_multiclass', '_ml_usecase', 'log_plots_param', 'fold_shuffle_param', 'memory', 'y_test', 'fix_imbalance', 'idx', 'exp_name_log', 'target_param', 'n_jobs_param', 'seed', 'html_param', 'exp_id', 'gpu_n_jobs_param', 'USI'}
2023-08-09 17:06:19,019:INFO:Checking environment
2023-08-09 17:06:19,019:INFO:python_version: 3.10.12
2023-08-09 17:06:19,019:INFO:python_build: ('main', 'Jul  5 2023 19:09:20')
2023-08-09 17:06:19,019:INFO:machine: AMD64
2023-08-09 17:06:19,019:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-09 17:06:19,019:INFO:Memory: svmem(total=16828977152, available=7386230784, percent=56.1, used=9442746368, free=7386230784)
2023-08-09 17:06:19,019:INFO:Physical Core: 14
2023-08-09 17:06:19,019:INFO:Logical Core: 20
2023-08-09 17:06:19,019:INFO:Checking libraries
2023-08-09 17:06:19,019:INFO:System:
2023-08-09 17:06:19,019:INFO:    python: 3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:09:20) [MSC v.1916 64 bit (AMD64)]
2023-08-09 17:06:19,019:INFO:executable: C:\Users\user21\anaconda3\python.exe
2023-08-09 17:06:19,019:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-09 17:06:19,019:INFO:PyCaret required dependencies:
2023-08-09 17:06:19,020:INFO:                 pip: 23.2.1
2023-08-09 17:06:19,020:INFO:          setuptools: 68.0.0
2023-08-09 17:06:19,020:INFO:             pycaret: 3.0.4
2023-08-09 17:06:19,020:INFO:             IPython: 8.12.0
2023-08-09 17:06:19,020:INFO:          ipywidgets: 8.1.0
2023-08-09 17:06:19,020:INFO:                tqdm: 4.65.0
2023-08-09 17:06:19,020:INFO:               numpy: 1.23.5
2023-08-09 17:06:19,020:INFO:              pandas: 1.5.3
2023-08-09 17:06:19,020:INFO:              jinja2: 3.1.2
2023-08-09 17:06:19,020:INFO:               scipy: 1.11.1
2023-08-09 17:06:19,020:INFO:              joblib: 1.3.1
2023-08-09 17:06:19,020:INFO:             sklearn: 1.2.2
2023-08-09 17:06:19,020:INFO:                pyod: 1.1.0
2023-08-09 17:06:19,020:INFO:            imblearn: 0.11.0
2023-08-09 17:06:19,020:INFO:   category_encoders: 2.6.1
2023-08-09 17:06:19,021:INFO:            lightgbm: 4.0.0
2023-08-09 17:06:19,021:INFO:               numba: 0.57.1
2023-08-09 17:06:19,021:INFO:            requests: 2.31.0
2023-08-09 17:06:19,021:INFO:          matplotlib: 3.7.2
2023-08-09 17:06:19,021:INFO:          scikitplot: 0.3.7
2023-08-09 17:06:19,021:INFO:         yellowbrick: 1.5
2023-08-09 17:06:19,021:INFO:              plotly: 5.15.0
2023-08-09 17:06:19,021:INFO:    plotly-resampler: Not installed
2023-08-09 17:06:19,021:INFO:             kaleido: 0.2.1
2023-08-09 17:06:19,021:INFO:           schemdraw: 0.15
2023-08-09 17:06:19,021:INFO:         statsmodels: 0.14.0
2023-08-09 17:06:19,021:INFO:              sktime: 0.21.0
2023-08-09 17:06:19,021:INFO:               tbats: 1.1.3
2023-08-09 17:06:19,021:INFO:            pmdarima: 2.0.3
2023-08-09 17:06:19,021:INFO:              psutil: 5.9.0
2023-08-09 17:06:19,021:INFO:          markupsafe: 2.1.1
2023-08-09 17:06:19,021:INFO:             pickle5: Not installed
2023-08-09 17:06:19,021:INFO:         cloudpickle: 2.2.1
2023-08-09 17:06:19,021:INFO:         deprecation: 2.1.0
2023-08-09 17:06:19,021:INFO:              xxhash: 3.3.0
2023-08-09 17:06:19,021:INFO:           wurlitzer: Not installed
2023-08-09 17:06:19,021:INFO:PyCaret optional dependencies:
2023-08-09 17:06:19,027:INFO:                shap: Not installed
2023-08-09 17:06:19,027:INFO:           interpret: Not installed
2023-08-09 17:06:19,027:INFO:                umap: Not installed
2023-08-09 17:06:19,027:INFO:    pandas_profiling: Not installed
2023-08-09 17:06:19,028:INFO:  explainerdashboard: Not installed
2023-08-09 17:06:19,028:INFO:             autoviz: Not installed
2023-08-09 17:06:19,028:INFO:           fairlearn: Not installed
2023-08-09 17:06:19,028:INFO:          deepchecks: Not installed
2023-08-09 17:06:19,028:INFO:             xgboost: 1.7.6
2023-08-09 17:06:19,028:INFO:            catboost: 1.2
2023-08-09 17:06:19,028:INFO:              kmodes: Not installed
2023-08-09 17:06:19,028:INFO:             mlxtend: Not installed
2023-08-09 17:06:19,028:INFO:       statsforecast: Not installed
2023-08-09 17:06:19,028:INFO:        tune_sklearn: Not installed
2023-08-09 17:06:19,028:INFO:                 ray: Not installed
2023-08-09 17:06:19,028:INFO:            hyperopt: Not installed
2023-08-09 17:06:19,028:INFO:              optuna: 3.2.0
2023-08-09 17:06:19,028:INFO:               skopt: Not installed
2023-08-09 17:06:19,028:INFO:              mlflow: Not installed
2023-08-09 17:06:19,028:INFO:              gradio: Not installed
2023-08-09 17:06:19,028:INFO:             fastapi: Not installed
2023-08-09 17:06:19,028:INFO:             uvicorn: Not installed
2023-08-09 17:06:19,028:INFO:              m2cgen: Not installed
2023-08-09 17:06:19,028:INFO:           evidently: Not installed
2023-08-09 17:06:19,028:INFO:               fugue: Not installed
2023-08-09 17:06:19,028:INFO:           streamlit: Not installed
2023-08-09 17:06:19,028:INFO:             prophet: Not installed
2023-08-09 17:06:19,028:INFO:None
2023-08-09 17:06:19,028:INFO:Set up data.
2023-08-09 17:06:19,033:INFO:Set up train/test split.
2023-08-09 17:06:19,036:INFO:Set up index.
2023-08-09 17:06:19,036:INFO:Set up folding strategy.
2023-08-09 17:06:19,036:INFO:Assigning column types.
2023-08-09 17:06:19,039:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-09 17:06:19,067:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-09 17:06:19,069:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 17:06:19,105:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 17:06:19,107:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 17:06:19,135:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-09 17:06:19,136:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 17:06:19,154:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 17:06:19,157:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 17:06:19,157:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-09 17:06:19,185:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 17:06:19,203:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 17:06:19,205:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 17:06:19,233:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 17:06:19,250:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 17:06:19,252:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 17:06:19,252:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-09 17:06:19,298:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 17:06:19,300:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 17:06:19,346:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 17:06:19,347:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 17:06:19,350:INFO:Preparing preprocessing pipeline...
2023-08-09 17:06:19,351:INFO:Set up simple imputation.
2023-08-09 17:06:19,351:INFO:Set up column name cleaning.
2023-08-09 17:06:19,367:INFO:Finished creating preprocessing pipeline.
2023-08-09 17:06:19,372:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Warehouse_block ',
                                             'Mode_of_Shipment',
                                             'Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Product_importance',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(ad...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-09 17:06:19,372:INFO:Creating final display dataframe.
2023-08-09 17:06:19,424:INFO:Setup _display_container:                     Description                Value
0                    Session id                  123
1                        Target  Reached.on.Time_Y.N
2                   Target type               Binary
3           Original data shape           (6994, 10)
4        Transformed data shape           (6994, 10)
5   Transformed train set shape           (4895, 10)
6    Transformed test set shape           (2099, 10)
7              Numeric features                    9
8                    Preprocess                 True
9               Imputation type               simple
10           Numeric imputation                 mean
11       Categorical imputation                 mode
12               Fold Generator      StratifiedKFold
13                  Fold Number                   10
14                     CPU Jobs                   -1
15                      Use GPU                False
16               Log Experiment                False
17              Experiment Name     clf-default-name
18                          USI                 b85a
2023-08-09 17:06:19,475:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 17:06:19,478:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 17:06:19,523:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 17:06:19,525:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 17:06:19,526:INFO:setup() successfully completed in 0.78s...............
2023-08-09 17:06:19,526:INFO:Initializing compare_models()
2023-08-09 17:06:19,527:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B335781FF0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001B335781FF0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-09 17:06:19,527:INFO:Checking exceptions
2023-08-09 17:06:19,529:INFO:Preparing display monitor
2023-08-09 17:06:19,548:INFO:Initializing Logistic Regression
2023-08-09 17:06:19,548:INFO:Total runtime is 0.0 minutes
2023-08-09 17:06:19,550:INFO:SubProcess create_model() called ==================================
2023-08-09 17:06:19,550:INFO:Initializing create_model()
2023-08-09 17:06:19,550:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B335781FF0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B33581CDF0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:06:19,551:INFO:Checking exceptions
2023-08-09 17:06:19,551:INFO:Importing libraries
2023-08-09 17:06:19,551:INFO:Copying training dataset
2023-08-09 17:06:19,553:INFO:Defining folds
2023-08-09 17:06:19,553:INFO:Declaring metric variables
2023-08-09 17:06:19,556:INFO:Importing untrained model
2023-08-09 17:06:19,558:INFO:Logistic Regression Imported successfully
2023-08-09 17:06:19,563:INFO:Starting cross validation
2023-08-09 17:06:19,563:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:06:24,496:INFO:Calculating mean and std
2023-08-09 17:06:24,496:INFO:Creating metrics dataframe
2023-08-09 17:06:24,878:INFO:Uploading results into container
2023-08-09 17:06:24,878:INFO:Uploading model into container now
2023-08-09 17:06:24,879:INFO:_master_model_container: 1
2023-08-09 17:06:24,879:INFO:_display_container: 2
2023-08-09 17:06:24,879:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-09 17:06:24,879:INFO:create_model() successfully completed......................................
2023-08-09 17:06:25,057:INFO:SubProcess create_model() end ==================================
2023-08-09 17:06:25,057:INFO:Creating metrics dataframe
2023-08-09 17:06:25,063:INFO:Initializing K Neighbors Classifier
2023-08-09 17:06:25,064:INFO:Total runtime is 0.09193082650502522 minutes
2023-08-09 17:06:25,066:INFO:SubProcess create_model() called ==================================
2023-08-09 17:06:25,066:INFO:Initializing create_model()
2023-08-09 17:06:25,066:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B335781FF0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B33581CDF0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:06:25,066:INFO:Checking exceptions
2023-08-09 17:06:25,066:INFO:Importing libraries
2023-08-09 17:06:25,066:INFO:Copying training dataset
2023-08-09 17:06:25,070:INFO:Defining folds
2023-08-09 17:06:25,072:INFO:Declaring metric variables
2023-08-09 17:06:25,074:INFO:Importing untrained model
2023-08-09 17:06:25,078:INFO:K Neighbors Classifier Imported successfully
2023-08-09 17:06:25,082:INFO:Starting cross validation
2023-08-09 17:06:25,083:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:06:29,673:INFO:Calculating mean and std
2023-08-09 17:06:29,673:INFO:Creating metrics dataframe
2023-08-09 17:06:30,078:INFO:Uploading results into container
2023-08-09 17:06:30,079:INFO:Uploading model into container now
2023-08-09 17:06:30,079:INFO:_master_model_container: 2
2023-08-09 17:06:30,079:INFO:_display_container: 2
2023-08-09 17:06:30,080:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-09 17:06:30,080:INFO:create_model() successfully completed......................................
2023-08-09 17:06:30,257:INFO:SubProcess create_model() end ==================================
2023-08-09 17:06:30,257:INFO:Creating metrics dataframe
2023-08-09 17:06:30,263:INFO:Initializing Naive Bayes
2023-08-09 17:06:30,263:INFO:Total runtime is 0.1785754879315694 minutes
2023-08-09 17:06:30,266:INFO:SubProcess create_model() called ==================================
2023-08-09 17:06:30,266:INFO:Initializing create_model()
2023-08-09 17:06:30,266:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B335781FF0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B33581CDF0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:06:30,266:INFO:Checking exceptions
2023-08-09 17:06:30,266:INFO:Importing libraries
2023-08-09 17:06:30,266:INFO:Copying training dataset
2023-08-09 17:06:30,269:INFO:Defining folds
2023-08-09 17:06:30,269:INFO:Declaring metric variables
2023-08-09 17:06:30,271:INFO:Importing untrained model
2023-08-09 17:06:30,273:INFO:Naive Bayes Imported successfully
2023-08-09 17:06:30,278:INFO:Starting cross validation
2023-08-09 17:06:30,279:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:06:32,868:INFO:Calculating mean and std
2023-08-09 17:06:32,869:INFO:Creating metrics dataframe
2023-08-09 17:06:33,246:INFO:Uploading results into container
2023-08-09 17:06:33,246:INFO:Uploading model into container now
2023-08-09 17:06:33,247:INFO:_master_model_container: 3
2023-08-09 17:06:33,247:INFO:_display_container: 2
2023-08-09 17:06:33,247:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-09 17:06:33,247:INFO:create_model() successfully completed......................................
2023-08-09 17:06:33,404:INFO:SubProcess create_model() end ==================================
2023-08-09 17:06:33,405:INFO:Creating metrics dataframe
2023-08-09 17:06:33,413:INFO:Initializing Decision Tree Classifier
2023-08-09 17:06:33,413:INFO:Total runtime is 0.23108770449956256 minutes
2023-08-09 17:06:33,416:INFO:SubProcess create_model() called ==================================
2023-08-09 17:06:33,417:INFO:Initializing create_model()
2023-08-09 17:06:33,417:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B335781FF0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B33581CDF0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:06:33,417:INFO:Checking exceptions
2023-08-09 17:06:33,417:INFO:Importing libraries
2023-08-09 17:06:33,417:INFO:Copying training dataset
2023-08-09 17:06:33,420:INFO:Defining folds
2023-08-09 17:06:33,420:INFO:Declaring metric variables
2023-08-09 17:06:33,423:INFO:Importing untrained model
2023-08-09 17:06:33,425:INFO:Decision Tree Classifier Imported successfully
2023-08-09 17:06:33,429:INFO:Starting cross validation
2023-08-09 17:06:33,430:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:06:36,021:INFO:Calculating mean and std
2023-08-09 17:06:36,022:INFO:Creating metrics dataframe
2023-08-09 17:06:36,392:INFO:Uploading results into container
2023-08-09 17:06:36,392:INFO:Uploading model into container now
2023-08-09 17:06:36,393:INFO:_master_model_container: 4
2023-08-09 17:06:36,393:INFO:_display_container: 2
2023-08-09 17:06:36,393:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-08-09 17:06:36,394:INFO:create_model() successfully completed......................................
2023-08-09 17:06:36,545:INFO:SubProcess create_model() end ==================================
2023-08-09 17:06:36,545:INFO:Creating metrics dataframe
2023-08-09 17:06:36,553:INFO:Initializing SVM - Linear Kernel
2023-08-09 17:06:36,553:INFO:Total runtime is 0.283412496248881 minutes
2023-08-09 17:06:36,555:INFO:SubProcess create_model() called ==================================
2023-08-09 17:06:36,555:INFO:Initializing create_model()
2023-08-09 17:06:36,555:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B335781FF0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B33581CDF0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:06:36,555:INFO:Checking exceptions
2023-08-09 17:06:36,555:INFO:Importing libraries
2023-08-09 17:06:36,555:INFO:Copying training dataset
2023-08-09 17:06:36,559:INFO:Defining folds
2023-08-09 17:06:36,559:INFO:Declaring metric variables
2023-08-09 17:06:36,562:INFO:Importing untrained model
2023-08-09 17:06:36,565:INFO:SVM - Linear Kernel Imported successfully
2023-08-09 17:06:36,570:INFO:Starting cross validation
2023-08-09 17:06:36,571:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:06:36,643:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:06:36,654:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:06:36,654:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:06:36,660:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:06:36,661:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:06:36,665:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:06:36,666:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:06:36,679:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:06:36,680:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:06:36,698:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:06:39,187:INFO:Calculating mean and std
2023-08-09 17:06:39,187:INFO:Creating metrics dataframe
2023-08-09 17:06:39,564:INFO:Uploading results into container
2023-08-09 17:06:39,565:INFO:Uploading model into container now
2023-08-09 17:06:39,565:INFO:_master_model_container: 5
2023-08-09 17:06:39,565:INFO:_display_container: 2
2023-08-09 17:06:39,565:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-09 17:06:39,567:INFO:create_model() successfully completed......................................
2023-08-09 17:06:39,720:INFO:SubProcess create_model() end ==================================
2023-08-09 17:06:39,720:INFO:Creating metrics dataframe
2023-08-09 17:06:39,727:INFO:Initializing Ridge Classifier
2023-08-09 17:06:39,727:INFO:Total runtime is 0.33631099065144854 minutes
2023-08-09 17:06:39,729:INFO:SubProcess create_model() called ==================================
2023-08-09 17:06:39,729:INFO:Initializing create_model()
2023-08-09 17:06:39,730:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B335781FF0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B33581CDF0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:06:39,730:INFO:Checking exceptions
2023-08-09 17:06:39,730:INFO:Importing libraries
2023-08-09 17:06:39,730:INFO:Copying training dataset
2023-08-09 17:06:39,733:INFO:Defining folds
2023-08-09 17:06:39,733:INFO:Declaring metric variables
2023-08-09 17:06:39,735:INFO:Importing untrained model
2023-08-09 17:06:39,737:INFO:Ridge Classifier Imported successfully
2023-08-09 17:06:39,742:INFO:Starting cross validation
2023-08-09 17:06:39,743:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:06:39,796:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:06:39,800:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:06:39,800:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:06:39,806:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:06:39,810:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:06:39,819:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:06:39,819:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:06:39,824:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:06:39,826:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:06:39,829:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:06:42,353:INFO:Calculating mean and std
2023-08-09 17:06:42,354:INFO:Creating metrics dataframe
2023-08-09 17:06:42,720:INFO:Uploading results into container
2023-08-09 17:06:42,721:INFO:Uploading model into container now
2023-08-09 17:06:42,721:INFO:_master_model_container: 6
2023-08-09 17:06:42,721:INFO:_display_container: 2
2023-08-09 17:06:42,721:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-08-09 17:06:42,722:INFO:create_model() successfully completed......................................
2023-08-09 17:06:42,879:INFO:SubProcess create_model() end ==================================
2023-08-09 17:06:42,879:INFO:Creating metrics dataframe
2023-08-09 17:06:42,887:INFO:Initializing Random Forest Classifier
2023-08-09 17:06:42,887:INFO:Total runtime is 0.38898171583811436 minutes
2023-08-09 17:06:42,889:INFO:SubProcess create_model() called ==================================
2023-08-09 17:06:42,890:INFO:Initializing create_model()
2023-08-09 17:06:42,890:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B335781FF0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B33581CDF0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:06:42,890:INFO:Checking exceptions
2023-08-09 17:06:42,890:INFO:Importing libraries
2023-08-09 17:06:42,890:INFO:Copying training dataset
2023-08-09 17:06:42,893:INFO:Defining folds
2023-08-09 17:06:42,893:INFO:Declaring metric variables
2023-08-09 17:06:42,896:INFO:Importing untrained model
2023-08-09 17:06:42,898:INFO:Random Forest Classifier Imported successfully
2023-08-09 17:06:42,903:INFO:Starting cross validation
2023-08-09 17:06:42,903:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:06:46,185:INFO:Calculating mean and std
2023-08-09 17:06:46,186:INFO:Creating metrics dataframe
2023-08-09 17:06:46,560:INFO:Uploading results into container
2023-08-09 17:06:46,560:INFO:Uploading model into container now
2023-08-09 17:06:46,561:INFO:_master_model_container: 7
2023-08-09 17:06:46,561:INFO:_display_container: 2
2023-08-09 17:06:46,561:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-09 17:06:46,561:INFO:create_model() successfully completed......................................
2023-08-09 17:06:46,718:INFO:SubProcess create_model() end ==================================
2023-08-09 17:06:46,718:INFO:Creating metrics dataframe
2023-08-09 17:06:46,725:INFO:Initializing Quadratic Discriminant Analysis
2023-08-09 17:06:46,725:INFO:Total runtime is 0.45295516649881995 minutes
2023-08-09 17:06:46,729:INFO:SubProcess create_model() called ==================================
2023-08-09 17:06:46,729:INFO:Initializing create_model()
2023-08-09 17:06:46,729:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B335781FF0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B33581CDF0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:06:46,729:INFO:Checking exceptions
2023-08-09 17:06:46,729:INFO:Importing libraries
2023-08-09 17:06:46,729:INFO:Copying training dataset
2023-08-09 17:06:46,733:INFO:Defining folds
2023-08-09 17:06:46,733:INFO:Declaring metric variables
2023-08-09 17:06:46,735:INFO:Importing untrained model
2023-08-09 17:06:46,738:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-09 17:06:46,742:INFO:Starting cross validation
2023-08-09 17:06:46,742:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:06:49,376:INFO:Calculating mean and std
2023-08-09 17:06:49,376:INFO:Creating metrics dataframe
2023-08-09 17:06:49,753:INFO:Uploading results into container
2023-08-09 17:06:49,754:INFO:Uploading model into container now
2023-08-09 17:06:49,754:INFO:_master_model_container: 8
2023-08-09 17:06:49,754:INFO:_display_container: 2
2023-08-09 17:06:49,754:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-09 17:06:49,754:INFO:create_model() successfully completed......................................
2023-08-09 17:06:49,907:INFO:SubProcess create_model() end ==================================
2023-08-09 17:06:49,907:INFO:Creating metrics dataframe
2023-08-09 17:06:49,915:INFO:Initializing Ada Boost Classifier
2023-08-09 17:06:49,915:INFO:Total runtime is 0.5061187068621317 minutes
2023-08-09 17:06:49,918:INFO:SubProcess create_model() called ==================================
2023-08-09 17:06:49,918:INFO:Initializing create_model()
2023-08-09 17:06:49,918:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B335781FF0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B33581CDF0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:06:49,918:INFO:Checking exceptions
2023-08-09 17:06:49,918:INFO:Importing libraries
2023-08-09 17:06:49,918:INFO:Copying training dataset
2023-08-09 17:06:49,921:INFO:Defining folds
2023-08-09 17:06:49,921:INFO:Declaring metric variables
2023-08-09 17:06:49,923:INFO:Importing untrained model
2023-08-09 17:06:49,926:INFO:Ada Boost Classifier Imported successfully
2023-08-09 17:06:49,931:INFO:Starting cross validation
2023-08-09 17:06:49,932:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:06:52,878:INFO:Calculating mean and std
2023-08-09 17:06:52,879:INFO:Creating metrics dataframe
2023-08-09 17:06:53,261:INFO:Uploading results into container
2023-08-09 17:06:53,262:INFO:Uploading model into container now
2023-08-09 17:06:53,262:INFO:_master_model_container: 9
2023-08-09 17:06:53,262:INFO:_display_container: 2
2023-08-09 17:06:53,262:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-08-09 17:06:53,262:INFO:create_model() successfully completed......................................
2023-08-09 17:06:53,434:INFO:SubProcess create_model() end ==================================
2023-08-09 17:06:53,434:INFO:Creating metrics dataframe
2023-08-09 17:06:53,444:INFO:Initializing Gradient Boosting Classifier
2023-08-09 17:06:53,444:INFO:Total runtime is 0.5649358510971069 minutes
2023-08-09 17:06:53,448:INFO:SubProcess create_model() called ==================================
2023-08-09 17:06:53,448:INFO:Initializing create_model()
2023-08-09 17:06:53,448:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B335781FF0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B33581CDF0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:06:53,448:INFO:Checking exceptions
2023-08-09 17:06:53,448:INFO:Importing libraries
2023-08-09 17:06:53,448:INFO:Copying training dataset
2023-08-09 17:06:53,452:INFO:Defining folds
2023-08-09 17:06:53,452:INFO:Declaring metric variables
2023-08-09 17:06:53,454:INFO:Importing untrained model
2023-08-09 17:06:53,457:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 17:06:53,464:INFO:Starting cross validation
2023-08-09 17:06:53,464:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:06:56,738:INFO:Calculating mean and std
2023-08-09 17:06:56,739:INFO:Creating metrics dataframe
2023-08-09 17:06:57,124:INFO:Uploading results into container
2023-08-09 17:06:57,124:INFO:Uploading model into container now
2023-08-09 17:06:57,125:INFO:_master_model_container: 10
2023-08-09 17:06:57,125:INFO:_display_container: 2
2023-08-09 17:06:57,125:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 17:06:57,125:INFO:create_model() successfully completed......................................
2023-08-09 17:06:57,277:INFO:SubProcess create_model() end ==================================
2023-08-09 17:06:57,277:INFO:Creating metrics dataframe
2023-08-09 17:06:57,287:INFO:Initializing Linear Discriminant Analysis
2023-08-09 17:06:57,287:INFO:Total runtime is 0.6289738059043883 minutes
2023-08-09 17:06:57,290:INFO:SubProcess create_model() called ==================================
2023-08-09 17:06:57,290:INFO:Initializing create_model()
2023-08-09 17:06:57,290:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B335781FF0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B33581CDF0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:06:57,290:INFO:Checking exceptions
2023-08-09 17:06:57,290:INFO:Importing libraries
2023-08-09 17:06:57,291:INFO:Copying training dataset
2023-08-09 17:06:57,294:INFO:Defining folds
2023-08-09 17:06:57,294:INFO:Declaring metric variables
2023-08-09 17:06:57,295:INFO:Importing untrained model
2023-08-09 17:06:57,299:INFO:Linear Discriminant Analysis Imported successfully
2023-08-09 17:06:57,303:INFO:Starting cross validation
2023-08-09 17:06:57,304:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:06:59,962:INFO:Calculating mean and std
2023-08-09 17:06:59,963:INFO:Creating metrics dataframe
2023-08-09 17:07:00,340:INFO:Uploading results into container
2023-08-09 17:07:00,341:INFO:Uploading model into container now
2023-08-09 17:07:00,341:INFO:_master_model_container: 11
2023-08-09 17:07:00,342:INFO:_display_container: 2
2023-08-09 17:07:00,342:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-09 17:07:00,342:INFO:create_model() successfully completed......................................
2023-08-09 17:07:00,501:INFO:SubProcess create_model() end ==================================
2023-08-09 17:07:00,501:INFO:Creating metrics dataframe
2023-08-09 17:07:00,510:INFO:Initializing Extra Trees Classifier
2023-08-09 17:07:00,510:INFO:Total runtime is 0.6826932748158772 minutes
2023-08-09 17:07:00,513:INFO:SubProcess create_model() called ==================================
2023-08-09 17:07:00,513:INFO:Initializing create_model()
2023-08-09 17:07:00,514:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B335781FF0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B33581CDF0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:07:00,514:INFO:Checking exceptions
2023-08-09 17:07:00,514:INFO:Importing libraries
2023-08-09 17:07:00,514:INFO:Copying training dataset
2023-08-09 17:07:00,518:INFO:Defining folds
2023-08-09 17:07:00,518:INFO:Declaring metric variables
2023-08-09 17:07:00,521:INFO:Importing untrained model
2023-08-09 17:07:00,523:INFO:Extra Trees Classifier Imported successfully
2023-08-09 17:07:00,527:INFO:Starting cross validation
2023-08-09 17:07:00,528:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:07:03,756:INFO:Calculating mean and std
2023-08-09 17:07:03,757:INFO:Creating metrics dataframe
2023-08-09 17:07:04,153:INFO:Uploading results into container
2023-08-09 17:07:04,154:INFO:Uploading model into container now
2023-08-09 17:07:04,154:INFO:_master_model_container: 12
2023-08-09 17:07:04,154:INFO:_display_container: 2
2023-08-09 17:07:04,154:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-08-09 17:07:04,154:INFO:create_model() successfully completed......................................
2023-08-09 17:07:04,319:INFO:SubProcess create_model() end ==================================
2023-08-09 17:07:04,319:INFO:Creating metrics dataframe
2023-08-09 17:07:04,328:INFO:Initializing Extreme Gradient Boosting
2023-08-09 17:07:04,328:INFO:Total runtime is 0.7463266253471373 minutes
2023-08-09 17:07:04,330:INFO:SubProcess create_model() called ==================================
2023-08-09 17:07:04,330:INFO:Initializing create_model()
2023-08-09 17:07:04,331:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B335781FF0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B33581CDF0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:07:04,331:INFO:Checking exceptions
2023-08-09 17:07:04,331:INFO:Importing libraries
2023-08-09 17:07:04,331:INFO:Copying training dataset
2023-08-09 17:07:04,335:INFO:Defining folds
2023-08-09 17:07:04,335:INFO:Declaring metric variables
2023-08-09 17:07:04,338:INFO:Importing untrained model
2023-08-09 17:07:04,342:INFO:Extreme Gradient Boosting Imported successfully
2023-08-09 17:07:04,349:INFO:Starting cross validation
2023-08-09 17:07:04,350:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:07:08,589:INFO:Calculating mean and std
2023-08-09 17:07:08,590:INFO:Creating metrics dataframe
2023-08-09 17:07:08,979:INFO:Uploading results into container
2023-08-09 17:07:08,979:INFO:Uploading model into container now
2023-08-09 17:07:08,981:INFO:_master_model_container: 13
2023-08-09 17:07:08,981:INFO:_display_container: 2
2023-08-09 17:07:08,982:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-09 17:07:08,982:INFO:create_model() successfully completed......................................
2023-08-09 17:07:09,132:INFO:SubProcess create_model() end ==================================
2023-08-09 17:07:09,132:INFO:Creating metrics dataframe
2023-08-09 17:07:09,141:INFO:Initializing Light Gradient Boosting Machine
2023-08-09 17:07:09,141:INFO:Total runtime is 0.8265458623568216 minutes
2023-08-09 17:07:09,143:INFO:SubProcess create_model() called ==================================
2023-08-09 17:07:09,143:INFO:Initializing create_model()
2023-08-09 17:07:09,143:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B335781FF0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B33581CDF0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:07:09,143:INFO:Checking exceptions
2023-08-09 17:07:09,144:INFO:Importing libraries
2023-08-09 17:07:09,144:INFO:Copying training dataset
2023-08-09 17:07:09,149:INFO:Defining folds
2023-08-09 17:07:09,149:INFO:Declaring metric variables
2023-08-09 17:07:09,152:INFO:Importing untrained model
2023-08-09 17:07:09,154:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-09 17:07:09,160:INFO:Starting cross validation
2023-08-09 17:07:09,161:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:07:13,040:INFO:Calculating mean and std
2023-08-09 17:07:13,041:INFO:Creating metrics dataframe
2023-08-09 17:07:13,442:INFO:Uploading results into container
2023-08-09 17:07:13,443:INFO:Uploading model into container now
2023-08-09 17:07:13,443:INFO:_master_model_container: 14
2023-08-09 17:07:13,443:INFO:_display_container: 2
2023-08-09 17:07:13,443:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-09 17:07:13,443:INFO:create_model() successfully completed......................................
2023-08-09 17:07:13,606:INFO:SubProcess create_model() end ==================================
2023-08-09 17:07:13,606:INFO:Creating metrics dataframe
2023-08-09 17:07:13,615:INFO:Initializing CatBoost Classifier
2023-08-09 17:07:13,615:INFO:Total runtime is 0.9011219064394632 minutes
2023-08-09 17:07:13,617:INFO:SubProcess create_model() called ==================================
2023-08-09 17:07:13,617:INFO:Initializing create_model()
2023-08-09 17:07:13,617:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B335781FF0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B33581CDF0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:07:13,617:INFO:Checking exceptions
2023-08-09 17:07:13,617:INFO:Importing libraries
2023-08-09 17:07:13,619:INFO:Copying training dataset
2023-08-09 17:07:13,621:INFO:Defining folds
2023-08-09 17:07:13,621:INFO:Declaring metric variables
2023-08-09 17:07:13,624:INFO:Importing untrained model
2023-08-09 17:07:13,627:INFO:CatBoost Classifier Imported successfully
2023-08-09 17:07:13,630:INFO:Starting cross validation
2023-08-09 17:07:13,630:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:07:20,719:INFO:Calculating mean and std
2023-08-09 17:07:20,720:INFO:Creating metrics dataframe
2023-08-09 17:07:21,110:INFO:Uploading results into container
2023-08-09 17:07:21,111:INFO:Uploading model into container now
2023-08-09 17:07:21,112:INFO:_master_model_container: 15
2023-08-09 17:07:21,112:INFO:_display_container: 2
2023-08-09 17:07:21,112:INFO:<catboost.core.CatBoostClassifier object at 0x000001B3359BC2B0>
2023-08-09 17:07:21,112:INFO:create_model() successfully completed......................................
2023-08-09 17:07:21,291:INFO:SubProcess create_model() end ==================================
2023-08-09 17:07:21,291:INFO:Creating metrics dataframe
2023-08-09 17:07:21,300:INFO:Initializing Dummy Classifier
2023-08-09 17:07:21,300:INFO:Total runtime is 1.0291924635569254 minutes
2023-08-09 17:07:21,302:INFO:SubProcess create_model() called ==================================
2023-08-09 17:07:21,302:INFO:Initializing create_model()
2023-08-09 17:07:21,302:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B335781FF0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B33581CDF0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:07:21,302:INFO:Checking exceptions
2023-08-09 17:07:21,303:INFO:Importing libraries
2023-08-09 17:07:21,303:INFO:Copying training dataset
2023-08-09 17:07:21,306:INFO:Defining folds
2023-08-09 17:07:21,306:INFO:Declaring metric variables
2023-08-09 17:07:21,308:INFO:Importing untrained model
2023-08-09 17:07:21,310:INFO:Dummy Classifier Imported successfully
2023-08-09 17:07:21,314:INFO:Starting cross validation
2023-08-09 17:07:21,314:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:07:24,081:INFO:Calculating mean and std
2023-08-09 17:07:24,082:INFO:Creating metrics dataframe
2023-08-09 17:07:24,477:INFO:Uploading results into container
2023-08-09 17:07:24,477:INFO:Uploading model into container now
2023-08-09 17:07:24,478:INFO:_master_model_container: 16
2023-08-09 17:07:24,478:INFO:_display_container: 2
2023-08-09 17:07:24,478:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-08-09 17:07:24,478:INFO:create_model() successfully completed......................................
2023-08-09 17:07:24,635:INFO:SubProcess create_model() end ==================================
2023-08-09 17:07:24,635:INFO:Creating metrics dataframe
2023-08-09 17:07:24,650:INFO:Initializing create_model()
2023-08-09 17:07:24,650:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B335781FF0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:07:24,650:INFO:Checking exceptions
2023-08-09 17:07:24,651:INFO:Importing libraries
2023-08-09 17:07:24,651:INFO:Copying training dataset
2023-08-09 17:07:24,654:INFO:Defining folds
2023-08-09 17:07:24,654:INFO:Declaring metric variables
2023-08-09 17:07:24,654:INFO:Importing untrained model
2023-08-09 17:07:24,654:INFO:Declaring custom model
2023-08-09 17:07:24,654:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 17:07:24,654:INFO:Cross validation set to False
2023-08-09 17:07:24,654:INFO:Fitting Model
2023-08-09 17:07:25,428:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 17:07:25,429:INFO:create_model() successfully completed......................................
2023-08-09 17:07:25,605:INFO:_master_model_container: 16
2023-08-09 17:07:25,605:INFO:_display_container: 2
2023-08-09 17:07:25,605:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 17:07:25,605:INFO:compare_models() successfully completed......................................
2023-08-09 17:08:01,536:INFO:Initializing create_model()
2023-08-09 17:08:01,536:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B335781FF0>, estimator=catboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:08:01,536:INFO:Checking exceptions
2023-08-09 17:08:01,546:INFO:Importing libraries
2023-08-09 17:08:01,546:INFO:Copying training dataset
2023-08-09 17:08:01,548:INFO:Defining folds
2023-08-09 17:08:01,549:INFO:Declaring metric variables
2023-08-09 17:08:01,552:INFO:Importing untrained model
2023-08-09 17:08:01,553:INFO:CatBoost Classifier Imported successfully
2023-08-09 17:08:01,558:INFO:Starting cross validation
2023-08-09 17:08:01,559:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:08:04,328:INFO:Calculating mean and std
2023-08-09 17:08:04,329:INFO:Creating metrics dataframe
2023-08-09 17:08:04,333:INFO:Finalizing model
2023-08-09 17:08:06,763:INFO:Uploading results into container
2023-08-09 17:08:06,764:INFO:Uploading model into container now
2023-08-09 17:08:06,770:INFO:_master_model_container: 17
2023-08-09 17:08:06,770:INFO:_display_container: 3
2023-08-09 17:08:06,770:INFO:<catboost.core.CatBoostClassifier object at 0x000001B3349CE290>
2023-08-09 17:08:06,770:INFO:create_model() successfully completed......................................
2023-08-09 17:08:06,929:INFO:Initializing tune_model()
2023-08-09 17:08:06,929:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x000001B3349CE290>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B335781FF0>)
2023-08-09 17:08:06,929:INFO:Checking exceptions
2023-08-09 17:08:06,940:INFO:Copying training dataset
2023-08-09 17:08:06,942:INFO:Checking base model
2023-08-09 17:08:06,943:INFO:Base model : CatBoost Classifier
2023-08-09 17:08:06,944:INFO:Declaring metric variables
2023-08-09 17:08:06,946:INFO:Defining Hyperparameters
2023-08-09 17:08:07,103:INFO:Tuning with n_jobs=-1
2023-08-09 17:08:07,103:INFO:Initializing RandomizedSearchCV
2023-08-09 17:08:42,164:INFO:best_params: {'actual_estimator__random_strength': 0.2, 'actual_estimator__n_estimators': 270, 'actual_estimator__l2_leaf_reg': 8, 'actual_estimator__eta': 0.0005, 'actual_estimator__depth': 4}
2023-08-09 17:08:42,165:INFO:Hyperparameter search completed
2023-08-09 17:08:42,165:INFO:SubProcess create_model() called ==================================
2023-08-09 17:08:42,165:INFO:Initializing create_model()
2023-08-09 17:08:42,165:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B335781FF0>, estimator=<catboost.core.CatBoostClassifier object at 0x000001B33493B6D0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B332198F10>, model_only=True, return_train_score=False, kwargs={'random_strength': 0.2, 'n_estimators': 270, 'l2_leaf_reg': 8, 'eta': 0.0005, 'depth': 4})
2023-08-09 17:08:42,165:INFO:Checking exceptions
2023-08-09 17:08:42,165:INFO:Importing libraries
2023-08-09 17:08:42,165:INFO:Copying training dataset
2023-08-09 17:08:42,169:INFO:Defining folds
2023-08-09 17:08:42,170:INFO:Declaring metric variables
2023-08-09 17:08:42,171:INFO:Importing untrained model
2023-08-09 17:08:42,171:INFO:Declaring custom model
2023-08-09 17:08:42,175:INFO:CatBoost Classifier Imported successfully
2023-08-09 17:08:42,179:INFO:Starting cross validation
2023-08-09 17:08:42,179:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:08:45,018:INFO:Calculating mean and std
2023-08-09 17:08:45,019:INFO:Creating metrics dataframe
2023-08-09 17:08:45,023:INFO:Finalizing model
2023-08-09 17:08:45,770:INFO:Uploading results into container
2023-08-09 17:08:45,771:INFO:Uploading model into container now
2023-08-09 17:08:45,771:INFO:_master_model_container: 18
2023-08-09 17:08:45,771:INFO:_display_container: 4
2023-08-09 17:08:45,771:INFO:<catboost.core.CatBoostClassifier object at 0x000001B335974AC0>
2023-08-09 17:08:45,771:INFO:create_model() successfully completed......................................
2023-08-09 17:08:45,939:INFO:SubProcess create_model() end ==================================
2023-08-09 17:08:45,940:INFO:choose_better activated
2023-08-09 17:08:45,943:INFO:SubProcess create_model() called ==================================
2023-08-09 17:08:45,943:INFO:Initializing create_model()
2023-08-09 17:08:45,943:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B335781FF0>, estimator=<catboost.core.CatBoostClassifier object at 0x000001B3349CE290>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:08:45,943:INFO:Checking exceptions
2023-08-09 17:08:45,944:INFO:Importing libraries
2023-08-09 17:08:45,944:INFO:Copying training dataset
2023-08-09 17:08:45,946:INFO:Defining folds
2023-08-09 17:08:45,946:INFO:Declaring metric variables
2023-08-09 17:08:45,948:INFO:Importing untrained model
2023-08-09 17:08:45,948:INFO:Declaring custom model
2023-08-09 17:08:45,948:INFO:CatBoost Classifier Imported successfully
2023-08-09 17:08:45,948:INFO:Starting cross validation
2023-08-09 17:08:45,948:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:08:48,836:INFO:Calculating mean and std
2023-08-09 17:08:48,836:INFO:Creating metrics dataframe
2023-08-09 17:08:48,838:INFO:Finalizing model
2023-08-09 17:08:49,269:INFO:Uploading results into container
2023-08-09 17:08:49,270:INFO:Uploading model into container now
2023-08-09 17:08:49,270:INFO:_master_model_container: 19
2023-08-09 17:08:49,270:INFO:_display_container: 5
2023-08-09 17:08:49,270:INFO:<catboost.core.CatBoostClassifier object at 0x000001B33499E560>
2023-08-09 17:08:49,270:INFO:create_model() successfully completed......................................
2023-08-09 17:08:49,427:INFO:SubProcess create_model() end ==================================
2023-08-09 17:08:49,427:INFO:<catboost.core.CatBoostClassifier object at 0x000001B33499E560> result for Accuracy is 0.6541
2023-08-09 17:08:49,427:INFO:<catboost.core.CatBoostClassifier object at 0x000001B335974AC0> result for Accuracy is 0.6719
2023-08-09 17:08:49,427:INFO:<catboost.core.CatBoostClassifier object at 0x000001B335974AC0> is best model
2023-08-09 17:08:49,427:INFO:choose_better completed
2023-08-09 17:08:49,434:INFO:_master_model_container: 19
2023-08-09 17:08:49,434:INFO:_display_container: 4
2023-08-09 17:08:49,435:INFO:<catboost.core.CatBoostClassifier object at 0x000001B335974AC0>
2023-08-09 17:08:49,435:INFO:tune_model() successfully completed......................................
2023-08-09 17:08:49,887:INFO:Initializing create_model()
2023-08-09 17:08:49,887:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B335781FF0>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:08:49,887:INFO:Checking exceptions
2023-08-09 17:08:49,898:INFO:Importing libraries
2023-08-09 17:08:49,898:INFO:Copying training dataset
2023-08-09 17:08:49,900:INFO:Defining folds
2023-08-09 17:08:49,900:INFO:Declaring metric variables
2023-08-09 17:08:49,903:INFO:Importing untrained model
2023-08-09 17:08:49,905:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 17:08:49,910:INFO:Starting cross validation
2023-08-09 17:08:49,910:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:08:52,863:INFO:Calculating mean and std
2023-08-09 17:08:52,864:INFO:Creating metrics dataframe
2023-08-09 17:08:52,868:INFO:Finalizing model
2023-08-09 17:08:53,329:INFO:Uploading results into container
2023-08-09 17:08:53,329:INFO:Uploading model into container now
2023-08-09 17:08:53,336:INFO:_master_model_container: 20
2023-08-09 17:08:53,336:INFO:_display_container: 5
2023-08-09 17:08:53,336:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 17:08:53,337:INFO:create_model() successfully completed......................................
2023-08-09 17:08:53,494:INFO:Initializing tune_model()
2023-08-09 17:08:53,494:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B335781FF0>)
2023-08-09 17:08:53,494:INFO:Checking exceptions
2023-08-09 17:08:53,502:INFO:Copying training dataset
2023-08-09 17:08:53,505:INFO:Checking base model
2023-08-09 17:08:53,505:INFO:Base model : Gradient Boosting Classifier
2023-08-09 17:08:53,507:INFO:Declaring metric variables
2023-08-09 17:08:53,509:INFO:Defining Hyperparameters
2023-08-09 17:08:53,665:INFO:Tuning with n_jobs=-1
2023-08-09 17:08:53,665:INFO:Initializing RandomizedSearchCV
2023-08-09 17:09:29,089:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 140, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.05, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.01}
2023-08-09 17:09:29,090:INFO:Hyperparameter search completed
2023-08-09 17:09:29,090:INFO:SubProcess create_model() called ==================================
2023-08-09 17:09:29,091:INFO:Initializing create_model()
2023-08-09 17:09:29,091:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B335781FF0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B330BA5030>, model_only=True, return_train_score=False, kwargs={'subsample': 0.35, 'n_estimators': 140, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.05, 'max_features': 'sqrt', 'max_depth': 7, 'learning_rate': 0.01})
2023-08-09 17:09:29,091:INFO:Checking exceptions
2023-08-09 17:09:29,091:INFO:Importing libraries
2023-08-09 17:09:29,091:INFO:Copying training dataset
2023-08-09 17:09:29,094:INFO:Defining folds
2023-08-09 17:09:29,094:INFO:Declaring metric variables
2023-08-09 17:09:29,097:INFO:Importing untrained model
2023-08-09 17:09:29,097:INFO:Declaring custom model
2023-08-09 17:09:29,100:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 17:09:29,104:INFO:Starting cross validation
2023-08-09 17:09:29,106:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:09:32,206:INFO:Calculating mean and std
2023-08-09 17:09:32,206:INFO:Creating metrics dataframe
2023-08-09 17:09:32,212:INFO:Finalizing model
2023-08-09 17:09:33,173:INFO:Uploading results into container
2023-08-09 17:09:33,173:INFO:Uploading model into container now
2023-08-09 17:09:33,174:INFO:_master_model_container: 21
2023-08-09 17:09:33,174:INFO:_display_container: 6
2023-08-09 17:09:33,174:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 17:09:33,174:INFO:create_model() successfully completed......................................
2023-08-09 17:09:33,335:INFO:SubProcess create_model() end ==================================
2023-08-09 17:09:33,335:INFO:choose_better activated
2023-08-09 17:09:33,338:INFO:SubProcess create_model() called ==================================
2023-08-09 17:09:33,338:INFO:Initializing create_model()
2023-08-09 17:09:33,338:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B335781FF0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:09:33,338:INFO:Checking exceptions
2023-08-09 17:09:33,340:INFO:Importing libraries
2023-08-09 17:09:33,340:INFO:Copying training dataset
2023-08-09 17:09:33,343:INFO:Defining folds
2023-08-09 17:09:33,343:INFO:Declaring metric variables
2023-08-09 17:09:33,343:INFO:Importing untrained model
2023-08-09 17:09:33,343:INFO:Declaring custom model
2023-08-09 17:09:33,344:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 17:09:33,344:INFO:Starting cross validation
2023-08-09 17:09:33,345:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:09:36,435:INFO:Calculating mean and std
2023-08-09 17:09:36,436:INFO:Creating metrics dataframe
2023-08-09 17:09:36,437:INFO:Finalizing model
2023-08-09 17:09:36,900:INFO:Uploading results into container
2023-08-09 17:09:36,901:INFO:Uploading model into container now
2023-08-09 17:09:36,901:INFO:_master_model_container: 22
2023-08-09 17:09:36,901:INFO:_display_container: 7
2023-08-09 17:09:36,901:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 17:09:36,902:INFO:create_model() successfully completed......................................
2023-08-09 17:09:37,081:INFO:SubProcess create_model() end ==================================
2023-08-09 17:09:37,082:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.6697
2023-08-09 17:09:37,082:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.6541
2023-08-09 17:09:37,082:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-08-09 17:09:37,083:INFO:choose_better completed
2023-08-09 17:09:37,083:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-08-09 17:09:37,090:INFO:_master_model_container: 22
2023-08-09 17:09:37,090:INFO:_display_container: 6
2023-08-09 17:09:37,090:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 17:09:37,090:INFO:tune_model() successfully completed......................................
2023-08-09 17:09:37,556:INFO:Initializing blend_models()
2023-08-09 17:09:37,556:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B335781FF0>, estimator_list=[<catboost.core.CatBoostClassifier object at 0x000001B335974AC0>, GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-08-09 17:09:37,556:INFO:Checking exceptions
2023-08-09 17:09:37,567:INFO:Importing libraries
2023-08-09 17:09:37,567:INFO:Copying training dataset
2023-08-09 17:09:37,569:INFO:Getting model names
2023-08-09 17:09:37,571:INFO:SubProcess create_model() called ==================================
2023-08-09 17:09:37,573:INFO:Initializing create_model()
2023-08-09 17:09:37,573:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B335781FF0>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x000001B335974AC0>),
                             ('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B3354DBA90>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:09:37,573:INFO:Checking exceptions
2023-08-09 17:09:37,573:INFO:Importing libraries
2023-08-09 17:09:37,573:INFO:Copying training dataset
2023-08-09 17:09:37,575:INFO:Defining folds
2023-08-09 17:09:37,576:INFO:Declaring metric variables
2023-08-09 17:09:37,577:INFO:Importing untrained model
2023-08-09 17:09:37,578:INFO:Declaring custom model
2023-08-09 17:09:37,581:INFO:Voting Classifier Imported successfully
2023-08-09 17:09:37,587:INFO:Starting cross validation
2023-08-09 17:09:37,588:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:09:41,885:INFO:Calculating mean and std
2023-08-09 17:09:41,886:INFO:Creating metrics dataframe
2023-08-09 17:09:41,889:INFO:Finalizing model
2023-08-09 17:09:43,040:INFO:Uploading results into container
2023-08-09 17:09:43,041:INFO:Uploading model into container now
2023-08-09 17:09:43,041:INFO:_master_model_container: 23
2023-08-09 17:09:43,041:INFO:_display_container: 7
2023-08-09 17:09:43,042:INFO:VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x000001B335547CA0>),
                             ('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 17:09:43,042:INFO:create_model() successfully completed......................................
2023-08-09 17:09:43,204:INFO:SubProcess create_model() end ==================================
2023-08-09 17:09:43,211:INFO:_master_model_container: 23
2023-08-09 17:09:43,211:INFO:_display_container: 7
2023-08-09 17:09:43,212:INFO:VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x000001B335547CA0>),
                             ('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 17:09:43,212:INFO:blend_models() successfully completed......................................
2023-08-09 17:09:50,079:INFO:Initializing finalize_model()
2023-08-09 17:09:50,080:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B335781FF0>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x000001B335547CA0>),
                             ('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-08-09 17:09:50,081:INFO:Finalizing VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x000001B335547CA0>),
                             ('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 17:09:50,084:INFO:Initializing create_model()
2023-08-09 17:09:50,084:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B335781FF0>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x000001B335547CA0>),
                             ('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-08-09 17:09:50,084:INFO:Checking exceptions
2023-08-09 17:09:50,086:INFO:Importing libraries
2023-08-09 17:09:50,086:INFO:Copying training dataset
2023-08-09 17:09:50,086:INFO:Defining folds
2023-08-09 17:09:50,086:INFO:Declaring metric variables
2023-08-09 17:09:50,086:INFO:Importing untrained model
2023-08-09 17:09:50,086:INFO:Declaring custom model
2023-08-09 17:09:50,087:INFO:Voting Classifier Imported successfully
2023-08-09 17:09:50,087:INFO:Cross validation set to False
2023-08-09 17:09:50,087:INFO:Fitting Model
2023-08-09 17:09:50,817:INFO:Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Warehouse_block ',
                                             'Mode_of_Shipment',
                                             'Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Product_importance',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(ad...
                                                                          max_features=None,
                                                                          max_leaf_nodes=None,
                                                                          min_impurity_decrease=0.0,
                                                                          min_samples_leaf=1,
                                                                          min_samples_split=2,
                                                                          min_weight_fraction_leaf=0.0,
                                                                          n_estimators=100,
                                                                          n_iter_no_change=None,
                                                                          random_state=123,
                                                                          subsample=1.0,
                                                                          tol=0.0001,
                                                                          validation_fraction=0.1,
                                                                          verbose=0,
                                                                          warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-09 17:09:50,818:INFO:create_model() successfully completed......................................
2023-08-09 17:09:50,968:INFO:_master_model_container: 23
2023-08-09 17:09:50,968:INFO:_display_container: 7
2023-08-09 17:09:50,975:INFO:Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Warehouse_block ',
                                             'Mode_of_Shipment',
                                             'Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Product_importance',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(ad...
                                                                          max_features=None,
                                                                          max_leaf_nodes=None,
                                                                          min_impurity_decrease=0.0,
                                                                          min_samples_leaf=1,
                                                                          min_samples_split=2,
                                                                          min_weight_fraction_leaf=0.0,
                                                                          n_estimators=100,
                                                                          n_iter_no_change=None,
                                                                          random_state=123,
                                                                          subsample=1.0,
                                                                          tol=0.0001,
                                                                          validation_fraction=0.1,
                                                                          verbose=0,
                                                                          warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-09 17:09:50,975:INFO:finalize_model() successfully completed......................................
2023-08-09 17:10:05,068:INFO:Initializing predict_model()
2023-08-09 17:10:05,069:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B335781FF0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Warehouse_block ',
                                             'Mode_of_Shipment',
                                             'Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Product_importance',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(ad...
                                                                          max_features=None,
                                                                          max_leaf_nodes=None,
                                                                          min_impurity_decrease=0.0,
                                                                          min_samples_leaf=1,
                                                                          min_samples_split=2,
                                                                          min_weight_fraction_leaf=0.0,
                                                                          n_estimators=100,
                                                                          n_iter_no_change=None,
                                                                          random_state=123,
                                                                          subsample=1.0,
                                                                          tol=0.0001,
                                                                          validation_fraction=0.1,
                                                                          verbose=0,
                                                                          warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B335E611B0>)
2023-08-09 17:10:05,069:INFO:Checking exceptions
2023-08-09 17:10:05,069:INFO:Preloading libraries
2023-08-09 17:10:05,070:INFO:Set up data.
2023-08-09 17:10:05,073:INFO:Set up index.
2023-08-09 17:27:09,654:INFO:PyCaret ClassificationExperiment
2023-08-09 17:27:09,654:INFO:Logging name: clf-default-name
2023-08-09 17:27:09,654:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-09 17:27:09,654:INFO:version 3.0.4
2023-08-09 17:27:09,654:INFO:Initializing setup()
2023-08-09 17:27:09,654:INFO:self.USI: da77
2023-08-09 17:27:09,654:INFO:self._variable_keys: {'logging_param', '_available_plots', 'fold_groups_param', 'fold_generator', 'gpu_param', 'y', 'y_train', 'pipeline', 'data', 'X_train', 'X', 'X_test', 'is_multiclass', '_ml_usecase', 'log_plots_param', 'fold_shuffle_param', 'memory', 'y_test', 'fix_imbalance', 'idx', 'exp_name_log', 'target_param', 'n_jobs_param', 'seed', 'html_param', 'exp_id', 'gpu_n_jobs_param', 'USI'}
2023-08-09 17:27:09,654:INFO:Checking environment
2023-08-09 17:27:09,654:INFO:python_version: 3.10.12
2023-08-09 17:27:09,654:INFO:python_build: ('main', 'Jul  5 2023 19:09:20')
2023-08-09 17:27:09,654:INFO:machine: AMD64
2023-08-09 17:27:09,654:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-09 17:27:09,654:INFO:Memory: svmem(total=16828977152, available=7647113216, percent=54.6, used=9181863936, free=7647113216)
2023-08-09 17:27:09,654:INFO:Physical Core: 14
2023-08-09 17:27:09,654:INFO:Logical Core: 20
2023-08-09 17:27:09,655:INFO:Checking libraries
2023-08-09 17:27:09,655:INFO:System:
2023-08-09 17:27:09,655:INFO:    python: 3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:09:20) [MSC v.1916 64 bit (AMD64)]
2023-08-09 17:27:09,655:INFO:executable: C:\Users\user21\anaconda3\python.exe
2023-08-09 17:27:09,655:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-09 17:27:09,655:INFO:PyCaret required dependencies:
2023-08-09 17:27:09,655:INFO:                 pip: 23.2.1
2023-08-09 17:27:09,655:INFO:          setuptools: 68.0.0
2023-08-09 17:27:09,655:INFO:             pycaret: 3.0.4
2023-08-09 17:27:09,655:INFO:             IPython: 8.12.0
2023-08-09 17:27:09,655:INFO:          ipywidgets: 8.1.0
2023-08-09 17:27:09,655:INFO:                tqdm: 4.65.0
2023-08-09 17:27:09,655:INFO:               numpy: 1.23.5
2023-08-09 17:27:09,655:INFO:              pandas: 1.5.3
2023-08-09 17:27:09,655:INFO:              jinja2: 3.1.2
2023-08-09 17:27:09,655:INFO:               scipy: 1.11.1
2023-08-09 17:27:09,655:INFO:              joblib: 1.3.1
2023-08-09 17:27:09,655:INFO:             sklearn: 1.2.2
2023-08-09 17:27:09,655:INFO:                pyod: 1.1.0
2023-08-09 17:27:09,655:INFO:            imblearn: 0.11.0
2023-08-09 17:27:09,655:INFO:   category_encoders: 2.6.1
2023-08-09 17:27:09,655:INFO:            lightgbm: 4.0.0
2023-08-09 17:27:09,655:INFO:               numba: 0.57.1
2023-08-09 17:27:09,655:INFO:            requests: 2.31.0
2023-08-09 17:27:09,655:INFO:          matplotlib: 3.7.2
2023-08-09 17:27:09,655:INFO:          scikitplot: 0.3.7
2023-08-09 17:27:09,655:INFO:         yellowbrick: 1.5
2023-08-09 17:27:09,656:INFO:              plotly: 5.15.0
2023-08-09 17:27:09,656:INFO:    plotly-resampler: Not installed
2023-08-09 17:27:09,656:INFO:             kaleido: 0.2.1
2023-08-09 17:27:09,656:INFO:           schemdraw: 0.15
2023-08-09 17:27:09,656:INFO:         statsmodels: 0.14.0
2023-08-09 17:27:09,656:INFO:              sktime: 0.21.0
2023-08-09 17:27:09,656:INFO:               tbats: 1.1.3
2023-08-09 17:27:09,656:INFO:            pmdarima: 2.0.3
2023-08-09 17:27:09,656:INFO:              psutil: 5.9.0
2023-08-09 17:27:09,656:INFO:          markupsafe: 2.1.1
2023-08-09 17:27:09,656:INFO:             pickle5: Not installed
2023-08-09 17:27:09,656:INFO:         cloudpickle: 2.2.1
2023-08-09 17:27:09,656:INFO:         deprecation: 2.1.0
2023-08-09 17:27:09,656:INFO:              xxhash: 3.3.0
2023-08-09 17:27:09,656:INFO:           wurlitzer: Not installed
2023-08-09 17:27:09,656:INFO:PyCaret optional dependencies:
2023-08-09 17:27:09,656:INFO:                shap: Not installed
2023-08-09 17:27:09,656:INFO:           interpret: Not installed
2023-08-09 17:27:09,656:INFO:                umap: Not installed
2023-08-09 17:27:09,656:INFO:    pandas_profiling: Not installed
2023-08-09 17:27:09,656:INFO:  explainerdashboard: Not installed
2023-08-09 17:27:09,656:INFO:             autoviz: Not installed
2023-08-09 17:27:09,656:INFO:           fairlearn: Not installed
2023-08-09 17:27:09,656:INFO:          deepchecks: Not installed
2023-08-09 17:27:09,656:INFO:             xgboost: 1.7.6
2023-08-09 17:27:09,656:INFO:            catboost: 1.2
2023-08-09 17:27:09,656:INFO:              kmodes: Not installed
2023-08-09 17:27:09,656:INFO:             mlxtend: Not installed
2023-08-09 17:27:09,656:INFO:       statsforecast: Not installed
2023-08-09 17:27:09,656:INFO:        tune_sklearn: Not installed
2023-08-09 17:27:09,656:INFO:                 ray: Not installed
2023-08-09 17:27:09,656:INFO:            hyperopt: Not installed
2023-08-09 17:27:09,656:INFO:              optuna: 3.2.0
2023-08-09 17:27:09,656:INFO:               skopt: Not installed
2023-08-09 17:27:09,656:INFO:              mlflow: Not installed
2023-08-09 17:27:09,656:INFO:              gradio: Not installed
2023-08-09 17:27:09,656:INFO:             fastapi: Not installed
2023-08-09 17:27:09,656:INFO:             uvicorn: Not installed
2023-08-09 17:27:09,656:INFO:              m2cgen: Not installed
2023-08-09 17:27:09,656:INFO:           evidently: Not installed
2023-08-09 17:27:09,656:INFO:               fugue: Not installed
2023-08-09 17:27:09,656:INFO:           streamlit: Not installed
2023-08-09 17:27:09,656:INFO:             prophet: Not installed
2023-08-09 17:27:09,656:INFO:None
2023-08-09 17:27:09,656:INFO:Set up data.
2023-08-09 17:27:09,660:INFO:Set up train/test split.
2023-08-09 17:27:09,664:INFO:Set up index.
2023-08-09 17:27:09,664:INFO:Set up folding strategy.
2023-08-09 17:27:09,664:INFO:Assigning column types.
2023-08-09 17:27:09,666:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-09 17:27:09,695:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-09 17:27:09,696:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 17:27:09,713:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 17:27:09,715:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 17:27:09,743:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-09 17:27:09,743:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 17:27:09,761:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 17:27:09,763:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 17:27:09,763:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-09 17:27:09,791:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 17:27:09,810:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 17:27:09,812:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 17:27:09,840:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 17:27:09,858:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 17:27:09,859:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 17:27:09,860:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-09 17:27:09,906:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 17:27:09,908:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 17:27:09,956:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 17:27:09,957:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 17:27:09,958:INFO:Preparing preprocessing pipeline...
2023-08-09 17:27:09,959:INFO:Set up simple imputation.
2023-08-09 17:27:09,959:INFO:Set up column name cleaning.
2023-08-09 17:27:09,974:INFO:Finished creating preprocessing pipeline.
2023-08-09 17:27:09,976:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Warehouse_block ',
                                             'Mode_of_Shipment',
                                             'Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Product_importance',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(ad...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-09 17:27:09,977:INFO:Creating final display dataframe.
2023-08-09 17:27:10,028:INFO:Setup _display_container:                     Description                Value
0                    Session id                  123
1                        Target  Reached.on.Time_Y.N
2                   Target type               Binary
3           Original data shape           (6994, 10)
4        Transformed data shape           (6994, 10)
5   Transformed train set shape           (4895, 10)
6    Transformed test set shape           (2099, 10)
7              Numeric features                    9
8                    Preprocess                 True
9               Imputation type               simple
10           Numeric imputation                 mean
11       Categorical imputation                 mode
12               Fold Generator      StratifiedKFold
13                  Fold Number                   10
14                     CPU Jobs                   -1
15                      Use GPU                False
16               Log Experiment                False
17              Experiment Name     clf-default-name
18                          USI                 da77
2023-08-09 17:27:10,079:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 17:27:10,081:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 17:27:10,128:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 17:27:10,129:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 17:27:10,130:INFO:setup() successfully completed in 0.8s...............
2023-08-09 17:27:10,438:INFO:Initializing compare_models()
2023-08-09 17:27:10,438:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B33B649390>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001B33B649390>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-09 17:27:10,438:INFO:Checking exceptions
2023-08-09 17:27:10,441:INFO:Preparing display monitor
2023-08-09 17:27:10,456:INFO:Initializing Logistic Regression
2023-08-09 17:27:10,456:INFO:Total runtime is 0.0 minutes
2023-08-09 17:27:10,458:INFO:SubProcess create_model() called ==================================
2023-08-09 17:27:10,458:INFO:Initializing create_model()
2023-08-09 17:27:10,459:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B33B649390>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B3357C7940>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:27:10,459:INFO:Checking exceptions
2023-08-09 17:27:10,459:INFO:Importing libraries
2023-08-09 17:27:10,459:INFO:Copying training dataset
2023-08-09 17:27:10,462:INFO:Defining folds
2023-08-09 17:27:10,462:INFO:Declaring metric variables
2023-08-09 17:27:10,465:INFO:Importing untrained model
2023-08-09 17:27:10,468:INFO:Logistic Regression Imported successfully
2023-08-09 17:27:10,473:INFO:Starting cross validation
2023-08-09 17:27:10,474:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:27:15,753:INFO:Calculating mean and std
2023-08-09 17:27:15,754:INFO:Creating metrics dataframe
2023-08-09 17:27:16,193:INFO:Uploading results into container
2023-08-09 17:27:16,194:INFO:Uploading model into container now
2023-08-09 17:27:16,194:INFO:_master_model_container: 1
2023-08-09 17:27:16,194:INFO:_display_container: 2
2023-08-09 17:27:16,194:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-09 17:27:16,194:INFO:create_model() successfully completed......................................
2023-08-09 17:27:16,399:INFO:SubProcess create_model() end ==================================
2023-08-09 17:27:16,400:INFO:Creating metrics dataframe
2023-08-09 17:27:16,408:INFO:Initializing K Neighbors Classifier
2023-08-09 17:27:16,408:INFO:Total runtime is 0.0992021640141805 minutes
2023-08-09 17:27:16,410:INFO:SubProcess create_model() called ==================================
2023-08-09 17:27:16,410:INFO:Initializing create_model()
2023-08-09 17:27:16,410:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B33B649390>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B3357C7940>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:27:16,410:INFO:Checking exceptions
2023-08-09 17:27:16,410:INFO:Importing libraries
2023-08-09 17:27:16,410:INFO:Copying training dataset
2023-08-09 17:27:16,413:INFO:Defining folds
2023-08-09 17:27:16,413:INFO:Declaring metric variables
2023-08-09 17:27:16,416:INFO:Importing untrained model
2023-08-09 17:27:16,418:INFO:K Neighbors Classifier Imported successfully
2023-08-09 17:27:16,423:INFO:Starting cross validation
2023-08-09 17:27:16,423:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:27:21,300:INFO:Calculating mean and std
2023-08-09 17:27:21,301:INFO:Creating metrics dataframe
2023-08-09 17:27:21,745:INFO:Uploading results into container
2023-08-09 17:27:21,746:INFO:Uploading model into container now
2023-08-09 17:27:21,746:INFO:_master_model_container: 2
2023-08-09 17:27:21,746:INFO:_display_container: 2
2023-08-09 17:27:21,746:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-09 17:27:21,746:INFO:create_model() successfully completed......................................
2023-08-09 17:27:21,950:INFO:SubProcess create_model() end ==================================
2023-08-09 17:27:21,950:INFO:Creating metrics dataframe
2023-08-09 17:27:21,958:INFO:Initializing Naive Bayes
2023-08-09 17:27:21,958:INFO:Total runtime is 0.19170475800832112 minutes
2023-08-09 17:27:21,961:INFO:SubProcess create_model() called ==================================
2023-08-09 17:27:21,961:INFO:Initializing create_model()
2023-08-09 17:27:21,961:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B33B649390>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B3357C7940>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:27:21,961:INFO:Checking exceptions
2023-08-09 17:27:21,962:INFO:Importing libraries
2023-08-09 17:27:21,962:INFO:Copying training dataset
2023-08-09 17:27:21,966:INFO:Defining folds
2023-08-09 17:27:21,967:INFO:Declaring metric variables
2023-08-09 17:27:21,970:INFO:Importing untrained model
2023-08-09 17:27:21,972:INFO:Naive Bayes Imported successfully
2023-08-09 17:27:21,976:INFO:Starting cross validation
2023-08-09 17:27:21,977:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:27:24,970:INFO:Calculating mean and std
2023-08-09 17:27:24,971:INFO:Creating metrics dataframe
2023-08-09 17:27:25,396:INFO:Uploading results into container
2023-08-09 17:27:25,398:INFO:Uploading model into container now
2023-08-09 17:27:25,398:INFO:_master_model_container: 3
2023-08-09 17:27:25,398:INFO:_display_container: 2
2023-08-09 17:27:25,398:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-09 17:27:25,398:INFO:create_model() successfully completed......................................
2023-08-09 17:27:25,598:INFO:SubProcess create_model() end ==================================
2023-08-09 17:27:25,598:INFO:Creating metrics dataframe
2023-08-09 17:27:25,605:INFO:Initializing Decision Tree Classifier
2023-08-09 17:27:25,605:INFO:Total runtime is 0.25249308347702026 minutes
2023-08-09 17:27:25,608:INFO:SubProcess create_model() called ==================================
2023-08-09 17:27:25,608:INFO:Initializing create_model()
2023-08-09 17:27:25,608:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B33B649390>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B3357C7940>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:27:25,608:INFO:Checking exceptions
2023-08-09 17:27:25,608:INFO:Importing libraries
2023-08-09 17:27:25,608:INFO:Copying training dataset
2023-08-09 17:27:25,612:INFO:Defining folds
2023-08-09 17:27:25,613:INFO:Declaring metric variables
2023-08-09 17:27:25,615:INFO:Importing untrained model
2023-08-09 17:27:25,617:INFO:Decision Tree Classifier Imported successfully
2023-08-09 17:27:25,622:INFO:Starting cross validation
2023-08-09 17:27:25,623:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:27:28,618:INFO:Calculating mean and std
2023-08-09 17:27:28,620:INFO:Creating metrics dataframe
2023-08-09 17:27:29,073:INFO:Uploading results into container
2023-08-09 17:27:29,074:INFO:Uploading model into container now
2023-08-09 17:27:29,074:INFO:_master_model_container: 4
2023-08-09 17:27:29,074:INFO:_display_container: 2
2023-08-09 17:27:29,075:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-08-09 17:27:29,075:INFO:create_model() successfully completed......................................
2023-08-09 17:27:29,282:INFO:SubProcess create_model() end ==================================
2023-08-09 17:27:29,282:INFO:Creating metrics dataframe
2023-08-09 17:27:29,289:INFO:Initializing SVM - Linear Kernel
2023-08-09 17:27:29,289:INFO:Total runtime is 0.3138888200124105 minutes
2023-08-09 17:27:29,292:INFO:SubProcess create_model() called ==================================
2023-08-09 17:27:29,292:INFO:Initializing create_model()
2023-08-09 17:27:29,292:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B33B649390>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B3357C7940>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:27:29,292:INFO:Checking exceptions
2023-08-09 17:27:29,292:INFO:Importing libraries
2023-08-09 17:27:29,292:INFO:Copying training dataset
2023-08-09 17:27:29,295:INFO:Defining folds
2023-08-09 17:27:29,295:INFO:Declaring metric variables
2023-08-09 17:27:29,297:INFO:Importing untrained model
2023-08-09 17:27:29,299:INFO:SVM - Linear Kernel Imported successfully
2023-08-09 17:27:29,303:INFO:Starting cross validation
2023-08-09 17:27:29,303:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:27:29,378:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:27:29,383:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:27:29,388:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:27:29,392:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:27:29,399:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:27:29,400:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:27:29,401:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:27:29,409:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:27:29,414:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:27:29,419:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:27:32,319:INFO:Calculating mean and std
2023-08-09 17:27:32,320:INFO:Creating metrics dataframe
2023-08-09 17:27:32,751:INFO:Uploading results into container
2023-08-09 17:27:32,751:INFO:Uploading model into container now
2023-08-09 17:27:32,752:INFO:_master_model_container: 5
2023-08-09 17:27:32,752:INFO:_display_container: 2
2023-08-09 17:27:32,752:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-09 17:27:32,752:INFO:create_model() successfully completed......................................
2023-08-09 17:27:32,955:INFO:SubProcess create_model() end ==================================
2023-08-09 17:27:32,955:INFO:Creating metrics dataframe
2023-08-09 17:27:32,962:INFO:Initializing Ridge Classifier
2023-08-09 17:27:32,962:INFO:Total runtime is 0.3751043717066447 minutes
2023-08-09 17:27:32,965:INFO:SubProcess create_model() called ==================================
2023-08-09 17:27:32,965:INFO:Initializing create_model()
2023-08-09 17:27:32,965:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B33B649390>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B3357C7940>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:27:32,965:INFO:Checking exceptions
2023-08-09 17:27:32,965:INFO:Importing libraries
2023-08-09 17:27:32,965:INFO:Copying training dataset
2023-08-09 17:27:32,968:INFO:Defining folds
2023-08-09 17:27:32,968:INFO:Declaring metric variables
2023-08-09 17:27:32,970:INFO:Importing untrained model
2023-08-09 17:27:32,972:INFO:Ridge Classifier Imported successfully
2023-08-09 17:27:32,978:INFO:Starting cross validation
2023-08-09 17:27:32,979:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:27:33,028:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:27:33,029:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:27:33,034:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:27:33,039:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:27:33,045:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:27:33,049:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:27:33,063:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:27:33,066:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:27:33,068:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:27:33,070:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:27:35,944:INFO:Calculating mean and std
2023-08-09 17:27:35,945:INFO:Creating metrics dataframe
2023-08-09 17:27:36,379:INFO:Uploading results into container
2023-08-09 17:27:36,380:INFO:Uploading model into container now
2023-08-09 17:27:36,380:INFO:_master_model_container: 6
2023-08-09 17:27:36,380:INFO:_display_container: 2
2023-08-09 17:27:36,382:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-08-09 17:27:36,382:INFO:create_model() successfully completed......................................
2023-08-09 17:27:36,587:INFO:SubProcess create_model() end ==================================
2023-08-09 17:27:36,588:INFO:Creating metrics dataframe
2023-08-09 17:27:36,595:INFO:Initializing Random Forest Classifier
2023-08-09 17:27:36,596:INFO:Total runtime is 0.4356704751650492 minutes
2023-08-09 17:27:36,598:INFO:SubProcess create_model() called ==================================
2023-08-09 17:27:36,599:INFO:Initializing create_model()
2023-08-09 17:27:36,599:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B33B649390>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B3357C7940>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:27:36,599:INFO:Checking exceptions
2023-08-09 17:27:36,599:INFO:Importing libraries
2023-08-09 17:27:36,599:INFO:Copying training dataset
2023-08-09 17:27:36,601:INFO:Defining folds
2023-08-09 17:27:36,601:INFO:Declaring metric variables
2023-08-09 17:27:36,604:INFO:Importing untrained model
2023-08-09 17:27:36,607:INFO:Random Forest Classifier Imported successfully
2023-08-09 17:27:36,610:INFO:Starting cross validation
2023-08-09 17:27:36,611:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:27:39,826:INFO:Calculating mean and std
2023-08-09 17:27:39,827:INFO:Creating metrics dataframe
2023-08-09 17:27:40,265:INFO:Uploading results into container
2023-08-09 17:27:40,265:INFO:Uploading model into container now
2023-08-09 17:27:40,265:INFO:_master_model_container: 7
2023-08-09 17:27:40,266:INFO:_display_container: 2
2023-08-09 17:27:40,266:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-09 17:27:40,266:INFO:create_model() successfully completed......................................
2023-08-09 17:27:40,471:INFO:SubProcess create_model() end ==================================
2023-08-09 17:27:40,471:INFO:Creating metrics dataframe
2023-08-09 17:27:40,479:INFO:Initializing Quadratic Discriminant Analysis
2023-08-09 17:27:40,479:INFO:Total runtime is 0.50039009253184 minutes
2023-08-09 17:27:40,482:INFO:SubProcess create_model() called ==================================
2023-08-09 17:27:40,482:INFO:Initializing create_model()
2023-08-09 17:27:40,482:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B33B649390>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B3357C7940>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:27:40,482:INFO:Checking exceptions
2023-08-09 17:27:40,482:INFO:Importing libraries
2023-08-09 17:27:40,482:INFO:Copying training dataset
2023-08-09 17:27:40,487:INFO:Defining folds
2023-08-09 17:27:40,487:INFO:Declaring metric variables
2023-08-09 17:27:40,490:INFO:Importing untrained model
2023-08-09 17:27:40,494:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-09 17:27:40,498:INFO:Starting cross validation
2023-08-09 17:27:40,499:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:27:43,509:INFO:Calculating mean and std
2023-08-09 17:27:43,510:INFO:Creating metrics dataframe
2023-08-09 17:27:43,948:INFO:Uploading results into container
2023-08-09 17:27:43,949:INFO:Uploading model into container now
2023-08-09 17:27:43,949:INFO:_master_model_container: 8
2023-08-09 17:27:43,949:INFO:_display_container: 2
2023-08-09 17:27:43,949:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-09 17:27:43,949:INFO:create_model() successfully completed......................................
2023-08-09 17:27:44,156:INFO:SubProcess create_model() end ==================================
2023-08-09 17:27:44,156:INFO:Creating metrics dataframe
2023-08-09 17:27:44,164:INFO:Initializing Ada Boost Classifier
2023-08-09 17:27:44,165:INFO:Total runtime is 0.5618174433708191 minutes
2023-08-09 17:27:44,170:INFO:SubProcess create_model() called ==================================
2023-08-09 17:27:44,170:INFO:Initializing create_model()
2023-08-09 17:27:44,170:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B33B649390>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B3357C7940>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:27:44,170:INFO:Checking exceptions
2023-08-09 17:27:44,170:INFO:Importing libraries
2023-08-09 17:27:44,170:INFO:Copying training dataset
2023-08-09 17:27:44,173:INFO:Defining folds
2023-08-09 17:27:44,173:INFO:Declaring metric variables
2023-08-09 17:27:44,175:INFO:Importing untrained model
2023-08-09 17:27:44,179:INFO:Ada Boost Classifier Imported successfully
2023-08-09 17:27:44,183:INFO:Starting cross validation
2023-08-09 17:27:44,184:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:27:47,216:INFO:Calculating mean and std
2023-08-09 17:27:47,217:INFO:Creating metrics dataframe
2023-08-09 17:27:47,648:INFO:Uploading results into container
2023-08-09 17:27:47,650:INFO:Uploading model into container now
2023-08-09 17:27:47,650:INFO:_master_model_container: 9
2023-08-09 17:27:47,651:INFO:_display_container: 2
2023-08-09 17:27:47,651:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-08-09 17:27:47,651:INFO:create_model() successfully completed......................................
2023-08-09 17:27:47,854:INFO:SubProcess create_model() end ==================================
2023-08-09 17:27:47,854:INFO:Creating metrics dataframe
2023-08-09 17:27:47,862:INFO:Initializing Gradient Boosting Classifier
2023-08-09 17:27:47,862:INFO:Total runtime is 0.6234353303909301 minutes
2023-08-09 17:27:47,865:INFO:SubProcess create_model() called ==================================
2023-08-09 17:27:47,865:INFO:Initializing create_model()
2023-08-09 17:27:47,865:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B33B649390>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B3357C7940>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:27:47,865:INFO:Checking exceptions
2023-08-09 17:27:47,865:INFO:Importing libraries
2023-08-09 17:27:47,865:INFO:Copying training dataset
2023-08-09 17:27:47,869:INFO:Defining folds
2023-08-09 17:27:47,869:INFO:Declaring metric variables
2023-08-09 17:27:47,872:INFO:Importing untrained model
2023-08-09 17:27:47,875:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 17:27:47,879:INFO:Starting cross validation
2023-08-09 17:27:47,880:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:27:50,925:INFO:Calculating mean and std
2023-08-09 17:27:50,926:INFO:Creating metrics dataframe
2023-08-09 17:27:51,362:INFO:Uploading results into container
2023-08-09 17:27:51,362:INFO:Uploading model into container now
2023-08-09 17:27:51,364:INFO:_master_model_container: 10
2023-08-09 17:27:51,364:INFO:_display_container: 2
2023-08-09 17:27:51,364:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 17:27:51,364:INFO:create_model() successfully completed......................................
2023-08-09 17:27:51,572:INFO:SubProcess create_model() end ==================================
2023-08-09 17:27:51,572:INFO:Creating metrics dataframe
2023-08-09 17:27:51,579:INFO:Initializing Linear Discriminant Analysis
2023-08-09 17:27:51,580:INFO:Total runtime is 0.685410992304484 minutes
2023-08-09 17:27:51,581:INFO:SubProcess create_model() called ==================================
2023-08-09 17:27:51,582:INFO:Initializing create_model()
2023-08-09 17:27:51,582:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B33B649390>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B3357C7940>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:27:51,582:INFO:Checking exceptions
2023-08-09 17:27:51,582:INFO:Importing libraries
2023-08-09 17:27:51,582:INFO:Copying training dataset
2023-08-09 17:27:51,585:INFO:Defining folds
2023-08-09 17:27:51,586:INFO:Declaring metric variables
2023-08-09 17:27:51,588:INFO:Importing untrained model
2023-08-09 17:27:51,590:INFO:Linear Discriminant Analysis Imported successfully
2023-08-09 17:27:51,593:INFO:Starting cross validation
2023-08-09 17:27:51,595:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:27:54,609:INFO:Calculating mean and std
2023-08-09 17:27:54,610:INFO:Creating metrics dataframe
2023-08-09 17:27:55,035:INFO:Uploading results into container
2023-08-09 17:27:55,035:INFO:Uploading model into container now
2023-08-09 17:27:55,036:INFO:_master_model_container: 11
2023-08-09 17:27:55,036:INFO:_display_container: 2
2023-08-09 17:27:55,036:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-09 17:27:55,036:INFO:create_model() successfully completed......................................
2023-08-09 17:27:55,240:INFO:SubProcess create_model() end ==================================
2023-08-09 17:27:55,240:INFO:Creating metrics dataframe
2023-08-09 17:27:55,249:INFO:Initializing Extra Trees Classifier
2023-08-09 17:27:55,249:INFO:Total runtime is 0.7465531269709269 minutes
2023-08-09 17:27:55,252:INFO:SubProcess create_model() called ==================================
2023-08-09 17:27:55,252:INFO:Initializing create_model()
2023-08-09 17:27:55,252:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B33B649390>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B3357C7940>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:27:55,252:INFO:Checking exceptions
2023-08-09 17:27:55,252:INFO:Importing libraries
2023-08-09 17:27:55,252:INFO:Copying training dataset
2023-08-09 17:27:55,256:INFO:Defining folds
2023-08-09 17:27:55,256:INFO:Declaring metric variables
2023-08-09 17:27:55,258:INFO:Importing untrained model
2023-08-09 17:27:55,262:INFO:Extra Trees Classifier Imported successfully
2023-08-09 17:27:55,266:INFO:Starting cross validation
2023-08-09 17:27:55,266:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:27:58,463:INFO:Calculating mean and std
2023-08-09 17:27:58,464:INFO:Creating metrics dataframe
2023-08-09 17:27:58,901:INFO:Uploading results into container
2023-08-09 17:27:58,902:INFO:Uploading model into container now
2023-08-09 17:27:58,902:INFO:_master_model_container: 12
2023-08-09 17:27:58,902:INFO:_display_container: 2
2023-08-09 17:27:58,903:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-08-09 17:27:58,903:INFO:create_model() successfully completed......................................
2023-08-09 17:27:59,100:INFO:SubProcess create_model() end ==================================
2023-08-09 17:27:59,100:INFO:Creating metrics dataframe
2023-08-09 17:27:59,109:INFO:Initializing Extreme Gradient Boosting
2023-08-09 17:27:59,109:INFO:Total runtime is 0.8108869592348734 minutes
2023-08-09 17:27:59,112:INFO:SubProcess create_model() called ==================================
2023-08-09 17:27:59,112:INFO:Initializing create_model()
2023-08-09 17:27:59,112:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B33B649390>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B3357C7940>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:27:59,112:INFO:Checking exceptions
2023-08-09 17:27:59,112:INFO:Importing libraries
2023-08-09 17:27:59,112:INFO:Copying training dataset
2023-08-09 17:27:59,115:INFO:Defining folds
2023-08-09 17:27:59,115:INFO:Declaring metric variables
2023-08-09 17:27:59,117:INFO:Importing untrained model
2023-08-09 17:27:59,121:INFO:Extreme Gradient Boosting Imported successfully
2023-08-09 17:27:59,125:INFO:Starting cross validation
2023-08-09 17:27:59,125:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:28:03,428:INFO:Calculating mean and std
2023-08-09 17:28:03,429:INFO:Creating metrics dataframe
2023-08-09 17:28:03,868:INFO:Uploading results into container
2023-08-09 17:28:03,868:INFO:Uploading model into container now
2023-08-09 17:28:03,869:INFO:_master_model_container: 13
2023-08-09 17:28:03,869:INFO:_display_container: 2
2023-08-09 17:28:03,870:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-09 17:28:03,870:INFO:create_model() successfully completed......................................
2023-08-09 17:28:04,066:INFO:SubProcess create_model() end ==================================
2023-08-09 17:28:04,067:INFO:Creating metrics dataframe
2023-08-09 17:28:04,075:INFO:Initializing Light Gradient Boosting Machine
2023-08-09 17:28:04,075:INFO:Total runtime is 0.8936580578486124 minutes
2023-08-09 17:28:04,078:INFO:SubProcess create_model() called ==================================
2023-08-09 17:28:04,078:INFO:Initializing create_model()
2023-08-09 17:28:04,078:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B33B649390>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B3357C7940>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:28:04,078:INFO:Checking exceptions
2023-08-09 17:28:04,078:INFO:Importing libraries
2023-08-09 17:28:04,078:INFO:Copying training dataset
2023-08-09 17:28:04,081:INFO:Defining folds
2023-08-09 17:28:04,081:INFO:Declaring metric variables
2023-08-09 17:28:04,084:INFO:Importing untrained model
2023-08-09 17:28:04,086:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-09 17:28:04,090:INFO:Starting cross validation
2023-08-09 17:28:04,091:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:28:07,136:INFO:Calculating mean and std
2023-08-09 17:28:07,137:INFO:Creating metrics dataframe
2023-08-09 17:28:07,575:INFO:Uploading results into container
2023-08-09 17:28:07,576:INFO:Uploading model into container now
2023-08-09 17:28:07,576:INFO:_master_model_container: 14
2023-08-09 17:28:07,576:INFO:_display_container: 2
2023-08-09 17:28:07,577:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-09 17:28:07,577:INFO:create_model() successfully completed......................................
2023-08-09 17:28:07,779:INFO:SubProcess create_model() end ==================================
2023-08-09 17:28:07,779:INFO:Creating metrics dataframe
2023-08-09 17:28:07,789:INFO:Initializing CatBoost Classifier
2023-08-09 17:28:07,789:INFO:Total runtime is 0.9555507858594258 minutes
2023-08-09 17:28:07,791:INFO:SubProcess create_model() called ==================================
2023-08-09 17:28:07,791:INFO:Initializing create_model()
2023-08-09 17:28:07,791:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B33B649390>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B3357C7940>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:28:07,791:INFO:Checking exceptions
2023-08-09 17:28:07,791:INFO:Importing libraries
2023-08-09 17:28:07,791:INFO:Copying training dataset
2023-08-09 17:28:07,797:INFO:Defining folds
2023-08-09 17:28:07,797:INFO:Declaring metric variables
2023-08-09 17:28:07,799:INFO:Importing untrained model
2023-08-09 17:28:07,802:INFO:CatBoost Classifier Imported successfully
2023-08-09 17:28:07,807:INFO:Starting cross validation
2023-08-09 17:28:07,808:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:28:11,254:INFO:Calculating mean and std
2023-08-09 17:28:11,254:INFO:Creating metrics dataframe
2023-08-09 17:28:11,697:INFO:Uploading results into container
2023-08-09 17:28:11,697:INFO:Uploading model into container now
2023-08-09 17:28:11,698:INFO:_master_model_container: 15
2023-08-09 17:28:11,698:INFO:_display_container: 2
2023-08-09 17:28:11,698:INFO:<catboost.core.CatBoostClassifier object at 0x000001B33579C760>
2023-08-09 17:28:11,698:INFO:create_model() successfully completed......................................
2023-08-09 17:28:11,903:INFO:SubProcess create_model() end ==================================
2023-08-09 17:28:11,903:INFO:Creating metrics dataframe
2023-08-09 17:28:11,913:INFO:Initializing Dummy Classifier
2023-08-09 17:28:11,913:INFO:Total runtime is 1.0242882808049518 minutes
2023-08-09 17:28:11,915:INFO:SubProcess create_model() called ==================================
2023-08-09 17:28:11,916:INFO:Initializing create_model()
2023-08-09 17:28:11,916:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B33B649390>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B3357C7940>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:28:11,916:INFO:Checking exceptions
2023-08-09 17:28:11,916:INFO:Importing libraries
2023-08-09 17:28:11,916:INFO:Copying training dataset
2023-08-09 17:28:11,920:INFO:Defining folds
2023-08-09 17:28:11,920:INFO:Declaring metric variables
2023-08-09 17:28:11,923:INFO:Importing untrained model
2023-08-09 17:28:11,925:INFO:Dummy Classifier Imported successfully
2023-08-09 17:28:11,929:INFO:Starting cross validation
2023-08-09 17:28:11,929:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:28:14,925:INFO:Calculating mean and std
2023-08-09 17:28:14,926:INFO:Creating metrics dataframe
2023-08-09 17:28:15,367:INFO:Uploading results into container
2023-08-09 17:28:15,368:INFO:Uploading model into container now
2023-08-09 17:28:15,368:INFO:_master_model_container: 16
2023-08-09 17:28:15,368:INFO:_display_container: 2
2023-08-09 17:28:15,368:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-08-09 17:28:15,368:INFO:create_model() successfully completed......................................
2023-08-09 17:28:15,573:INFO:SubProcess create_model() end ==================================
2023-08-09 17:28:15,573:INFO:Creating metrics dataframe
2023-08-09 17:28:15,589:INFO:Initializing create_model()
2023-08-09 17:28:15,589:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B33B649390>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:28:15,589:INFO:Checking exceptions
2023-08-09 17:28:15,590:INFO:Importing libraries
2023-08-09 17:28:15,590:INFO:Copying training dataset
2023-08-09 17:28:15,593:INFO:Defining folds
2023-08-09 17:28:15,593:INFO:Declaring metric variables
2023-08-09 17:28:15,593:INFO:Importing untrained model
2023-08-09 17:28:15,593:INFO:Declaring custom model
2023-08-09 17:28:15,593:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 17:28:15,593:INFO:Cross validation set to False
2023-08-09 17:28:15,593:INFO:Fitting Model
2023-08-09 17:28:15,924:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 17:28:15,924:INFO:create_model() successfully completed......................................
2023-08-09 17:28:16,150:INFO:_master_model_container: 16
2023-08-09 17:28:16,150:INFO:_display_container: 2
2023-08-09 17:28:16,150:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 17:28:16,150:INFO:compare_models() successfully completed......................................
2023-08-09 17:28:21,147:INFO:Initializing create_model()
2023-08-09 17:28:21,147:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B33B649390>, estimator=catboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:28:21,147:INFO:Checking exceptions
2023-08-09 17:28:21,159:INFO:Importing libraries
2023-08-09 17:28:21,159:INFO:Copying training dataset
2023-08-09 17:28:21,161:INFO:Defining folds
2023-08-09 17:28:21,161:INFO:Declaring metric variables
2023-08-09 17:28:21,163:INFO:Importing untrained model
2023-08-09 17:28:21,166:INFO:CatBoost Classifier Imported successfully
2023-08-09 17:28:21,171:INFO:Starting cross validation
2023-08-09 17:28:21,171:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:28:24,219:INFO:Calculating mean and std
2023-08-09 17:28:24,220:INFO:Creating metrics dataframe
2023-08-09 17:28:24,224:INFO:Finalizing model
2023-08-09 17:28:24,681:INFO:Uploading results into container
2023-08-09 17:28:24,683:INFO:Uploading model into container now
2023-08-09 17:28:24,689:INFO:_master_model_container: 17
2023-08-09 17:28:24,689:INFO:_display_container: 3
2023-08-09 17:28:24,689:INFO:<catboost.core.CatBoostClassifier object at 0x000001B33B580E50>
2023-08-09 17:28:24,689:INFO:create_model() successfully completed......................................
2023-08-09 17:28:24,896:INFO:Initializing tune_model()
2023-08-09 17:28:24,897:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x000001B33B580E50>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B33B649390>)
2023-08-09 17:28:24,897:INFO:Checking exceptions
2023-08-09 17:28:24,911:INFO:Copying training dataset
2023-08-09 17:28:24,914:INFO:Checking base model
2023-08-09 17:28:24,914:INFO:Base model : CatBoost Classifier
2023-08-09 17:28:24,916:INFO:Declaring metric variables
2023-08-09 17:28:24,919:INFO:Defining Hyperparameters
2023-08-09 17:28:25,124:INFO:Tuning with n_jobs=-1
2023-08-09 17:28:25,124:INFO:Initializing RandomizedSearchCV
2023-08-09 17:28:58,940:INFO:best_params: {'actual_estimator__random_strength': 0.2, 'actual_estimator__n_estimators': 270, 'actual_estimator__l2_leaf_reg': 8, 'actual_estimator__eta': 0.0005, 'actual_estimator__depth': 4}
2023-08-09 17:28:58,941:INFO:Hyperparameter search completed
2023-08-09 17:28:58,941:INFO:SubProcess create_model() called ==================================
2023-08-09 17:28:58,941:INFO:Initializing create_model()
2023-08-09 17:28:58,941:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B33B649390>, estimator=<catboost.core.CatBoostClassifier object at 0x000001B337A31E10>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B33333FC10>, model_only=True, return_train_score=False, kwargs={'random_strength': 0.2, 'n_estimators': 270, 'l2_leaf_reg': 8, 'eta': 0.0005, 'depth': 4})
2023-08-09 17:28:58,941:INFO:Checking exceptions
2023-08-09 17:28:58,941:INFO:Importing libraries
2023-08-09 17:28:58,941:INFO:Copying training dataset
2023-08-09 17:28:58,945:INFO:Defining folds
2023-08-09 17:28:58,953:INFO:Declaring metric variables
2023-08-09 17:28:58,955:INFO:Importing untrained model
2023-08-09 17:28:58,955:INFO:Declaring custom model
2023-08-09 17:28:58,957:INFO:CatBoost Classifier Imported successfully
2023-08-09 17:28:58,964:INFO:Starting cross validation
2023-08-09 17:28:58,964:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:29:01,967:INFO:Calculating mean and std
2023-08-09 17:29:01,969:INFO:Creating metrics dataframe
2023-08-09 17:29:01,972:INFO:Finalizing model
2023-08-09 17:29:02,446:INFO:Uploading results into container
2023-08-09 17:29:02,446:INFO:Uploading model into container now
2023-08-09 17:29:02,446:INFO:_master_model_container: 18
2023-08-09 17:29:02,446:INFO:_display_container: 4
2023-08-09 17:29:02,446:INFO:<catboost.core.CatBoostClassifier object at 0x000001B337A06B30>
2023-08-09 17:29:02,446:INFO:create_model() successfully completed......................................
2023-08-09 17:29:02,656:INFO:SubProcess create_model() end ==================================
2023-08-09 17:29:02,656:INFO:choose_better activated
2023-08-09 17:29:02,659:INFO:SubProcess create_model() called ==================================
2023-08-09 17:29:02,659:INFO:Initializing create_model()
2023-08-09 17:29:02,659:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B33B649390>, estimator=<catboost.core.CatBoostClassifier object at 0x000001B33B580E50>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:29:02,659:INFO:Checking exceptions
2023-08-09 17:29:02,660:INFO:Importing libraries
2023-08-09 17:29:02,660:INFO:Copying training dataset
2023-08-09 17:29:02,664:INFO:Defining folds
2023-08-09 17:29:02,664:INFO:Declaring metric variables
2023-08-09 17:29:02,664:INFO:Importing untrained model
2023-08-09 17:29:02,664:INFO:Declaring custom model
2023-08-09 17:29:02,664:INFO:CatBoost Classifier Imported successfully
2023-08-09 17:29:02,664:INFO:Starting cross validation
2023-08-09 17:29:02,665:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:29:05,674:INFO:Calculating mean and std
2023-08-09 17:29:05,674:INFO:Creating metrics dataframe
2023-08-09 17:29:05,675:INFO:Finalizing model
2023-08-09 17:29:06,128:INFO:Uploading results into container
2023-08-09 17:29:06,129:INFO:Uploading model into container now
2023-08-09 17:29:06,129:INFO:_master_model_container: 19
2023-08-09 17:29:06,129:INFO:_display_container: 5
2023-08-09 17:29:06,129:INFO:<catboost.core.CatBoostClassifier object at 0x000001B33581E200>
2023-08-09 17:29:06,129:INFO:create_model() successfully completed......................................
2023-08-09 17:29:06,328:INFO:SubProcess create_model() end ==================================
2023-08-09 17:29:06,329:INFO:<catboost.core.CatBoostClassifier object at 0x000001B33581E200> result for Accuracy is 0.6541
2023-08-09 17:29:06,329:INFO:<catboost.core.CatBoostClassifier object at 0x000001B337A06B30> result for Accuracy is 0.6719
2023-08-09 17:29:06,329:INFO:<catboost.core.CatBoostClassifier object at 0x000001B337A06B30> is best model
2023-08-09 17:29:06,329:INFO:choose_better completed
2023-08-09 17:29:06,335:INFO:_master_model_container: 19
2023-08-09 17:29:06,335:INFO:_display_container: 4
2023-08-09 17:29:06,335:INFO:<catboost.core.CatBoostClassifier object at 0x000001B337A06B30>
2023-08-09 17:29:06,335:INFO:tune_model() successfully completed......................................
2023-08-09 17:29:06,851:INFO:Initializing create_model()
2023-08-09 17:29:06,851:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B33B649390>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:29:06,851:INFO:Checking exceptions
2023-08-09 17:29:06,861:INFO:Importing libraries
2023-08-09 17:29:06,861:INFO:Copying training dataset
2023-08-09 17:29:06,864:INFO:Defining folds
2023-08-09 17:29:06,864:INFO:Declaring metric variables
2023-08-09 17:29:06,866:INFO:Importing untrained model
2023-08-09 17:29:06,868:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 17:29:06,874:INFO:Starting cross validation
2023-08-09 17:29:06,875:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:29:09,910:INFO:Calculating mean and std
2023-08-09 17:29:09,911:INFO:Creating metrics dataframe
2023-08-09 17:29:09,916:INFO:Finalizing model
2023-08-09 17:29:10,370:INFO:Uploading results into container
2023-08-09 17:29:10,370:INFO:Uploading model into container now
2023-08-09 17:29:10,376:INFO:_master_model_container: 20
2023-08-09 17:29:10,376:INFO:_display_container: 5
2023-08-09 17:29:10,377:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 17:29:10,377:INFO:create_model() successfully completed......................................
2023-08-09 17:29:10,585:INFO:Initializing tune_model()
2023-08-09 17:29:10,585:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B33B649390>)
2023-08-09 17:29:10,585:INFO:Checking exceptions
2023-08-09 17:29:10,597:INFO:Copying training dataset
2023-08-09 17:29:10,600:INFO:Checking base model
2023-08-09 17:29:10,600:INFO:Base model : Gradient Boosting Classifier
2023-08-09 17:29:10,602:INFO:Declaring metric variables
2023-08-09 17:29:10,604:INFO:Defining Hyperparameters
2023-08-09 17:29:10,805:INFO:Tuning with n_jobs=-1
2023-08-09 17:29:10,805:INFO:Initializing RandomizedSearchCV
2023-08-09 17:29:43,564:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 140, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.05, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.01}
2023-08-09 17:29:43,565:INFO:Hyperparameter search completed
2023-08-09 17:29:43,565:INFO:SubProcess create_model() called ==================================
2023-08-09 17:29:43,566:INFO:Initializing create_model()
2023-08-09 17:29:43,566:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B33B649390>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B335524910>, model_only=True, return_train_score=False, kwargs={'subsample': 0.35, 'n_estimators': 140, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.05, 'max_features': 'sqrt', 'max_depth': 7, 'learning_rate': 0.01})
2023-08-09 17:29:43,566:INFO:Checking exceptions
2023-08-09 17:29:43,566:INFO:Importing libraries
2023-08-09 17:29:43,566:INFO:Copying training dataset
2023-08-09 17:29:43,571:INFO:Defining folds
2023-08-09 17:29:43,571:INFO:Declaring metric variables
2023-08-09 17:29:43,575:INFO:Importing untrained model
2023-08-09 17:29:43,575:INFO:Declaring custom model
2023-08-09 17:29:43,577:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 17:29:43,582:INFO:Starting cross validation
2023-08-09 17:29:43,583:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:29:46,689:INFO:Calculating mean and std
2023-08-09 17:29:46,689:INFO:Creating metrics dataframe
2023-08-09 17:29:46,694:INFO:Finalizing model
2023-08-09 17:29:47,187:INFO:Uploading results into container
2023-08-09 17:29:47,187:INFO:Uploading model into container now
2023-08-09 17:29:47,188:INFO:_master_model_container: 21
2023-08-09 17:29:47,188:INFO:_display_container: 6
2023-08-09 17:29:47,188:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 17:29:47,188:INFO:create_model() successfully completed......................................
2023-08-09 17:29:47,397:INFO:SubProcess create_model() end ==================================
2023-08-09 17:29:47,397:INFO:choose_better activated
2023-08-09 17:29:47,400:INFO:SubProcess create_model() called ==================================
2023-08-09 17:29:47,401:INFO:Initializing create_model()
2023-08-09 17:29:47,401:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B33B649390>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:29:47,401:INFO:Checking exceptions
2023-08-09 17:29:47,402:INFO:Importing libraries
2023-08-09 17:29:47,402:INFO:Copying training dataset
2023-08-09 17:29:47,405:INFO:Defining folds
2023-08-09 17:29:47,406:INFO:Declaring metric variables
2023-08-09 17:29:47,406:INFO:Importing untrained model
2023-08-09 17:29:47,406:INFO:Declaring custom model
2023-08-09 17:29:47,406:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 17:29:47,406:INFO:Starting cross validation
2023-08-09 17:29:47,407:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:29:50,525:INFO:Calculating mean and std
2023-08-09 17:29:50,525:INFO:Creating metrics dataframe
2023-08-09 17:29:50,527:INFO:Finalizing model
2023-08-09 17:29:50,987:INFO:Uploading results into container
2023-08-09 17:29:50,988:INFO:Uploading model into container now
2023-08-09 17:29:50,988:INFO:_master_model_container: 22
2023-08-09 17:29:50,988:INFO:_display_container: 7
2023-08-09 17:29:50,988:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 17:29:50,988:INFO:create_model() successfully completed......................................
2023-08-09 17:29:51,184:INFO:SubProcess create_model() end ==================================
2023-08-09 17:29:51,184:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.6697
2023-08-09 17:29:51,185:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.6541
2023-08-09 17:29:51,185:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-08-09 17:29:51,185:INFO:choose_better completed
2023-08-09 17:29:51,185:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-08-09 17:29:51,193:INFO:_master_model_container: 22
2023-08-09 17:29:51,193:INFO:_display_container: 6
2023-08-09 17:29:51,193:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 17:29:51,195:INFO:tune_model() successfully completed......................................
2023-08-09 17:29:51,721:INFO:Initializing blend_models()
2023-08-09 17:29:51,722:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B33B649390>, estimator_list=[<catboost.core.CatBoostClassifier object at 0x000001B337A06B30>, GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-08-09 17:29:51,722:INFO:Checking exceptions
2023-08-09 17:29:51,731:INFO:Importing libraries
2023-08-09 17:29:51,731:INFO:Copying training dataset
2023-08-09 17:29:51,733:INFO:Getting model names
2023-08-09 17:29:51,736:INFO:SubProcess create_model() called ==================================
2023-08-09 17:29:51,738:INFO:Initializing create_model()
2023-08-09 17:29:51,738:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B33B649390>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x000001B337A06B30>),
                             ('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B337402B30>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:29:51,738:INFO:Checking exceptions
2023-08-09 17:29:51,738:INFO:Importing libraries
2023-08-09 17:29:51,738:INFO:Copying training dataset
2023-08-09 17:29:51,741:INFO:Defining folds
2023-08-09 17:29:51,741:INFO:Declaring metric variables
2023-08-09 17:29:51,744:INFO:Importing untrained model
2023-08-09 17:29:51,744:INFO:Declaring custom model
2023-08-09 17:29:51,749:INFO:Voting Classifier Imported successfully
2023-08-09 17:29:51,753:INFO:Starting cross validation
2023-08-09 17:29:51,754:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:29:54,885:INFO:Calculating mean and std
2023-08-09 17:29:54,886:INFO:Creating metrics dataframe
2023-08-09 17:29:54,890:INFO:Finalizing model
2023-08-09 17:29:55,352:INFO:Uploading results into container
2023-08-09 17:29:55,353:INFO:Uploading model into container now
2023-08-09 17:29:55,353:INFO:_master_model_container: 23
2023-08-09 17:29:55,353:INFO:_display_container: 7
2023-08-09 17:29:55,355:INFO:VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x000001B33B904CA0>),
                             ('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 17:29:55,355:INFO:create_model() successfully completed......................................
2023-08-09 17:29:55,557:INFO:SubProcess create_model() end ==================================
2023-08-09 17:29:55,565:INFO:_master_model_container: 23
2023-08-09 17:29:55,565:INFO:_display_container: 7
2023-08-09 17:29:55,566:INFO:VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x000001B33B904CA0>),
                             ('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 17:29:55,566:INFO:blend_models() successfully completed......................................
2023-08-09 17:30:58,408:INFO:Initializing finalize_model()
2023-08-09 17:30:58,408:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B33B649390>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x000001B33B904CA0>),
                             ('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-08-09 17:30:58,408:INFO:Finalizing VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x000001B33B904CA0>),
                             ('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 17:30:58,414:INFO:Initializing create_model()
2023-08-09 17:30:58,414:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B33B649390>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x000001B33B904CA0>),
                             ('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-08-09 17:30:58,415:INFO:Checking exceptions
2023-08-09 17:30:58,416:INFO:Importing libraries
2023-08-09 17:30:58,416:INFO:Copying training dataset
2023-08-09 17:30:58,416:INFO:Defining folds
2023-08-09 17:30:58,416:INFO:Declaring metric variables
2023-08-09 17:30:58,416:INFO:Importing untrained model
2023-08-09 17:30:58,416:INFO:Declaring custom model
2023-08-09 17:30:58,417:INFO:Voting Classifier Imported successfully
2023-08-09 17:30:58,418:INFO:Cross validation set to False
2023-08-09 17:30:58,418:INFO:Fitting Model
2023-08-09 17:30:58,451:INFO:Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Warehouse_block ',
                                             'Mode_of_Shipment',
                                             'Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Product_importance',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(ad...
                                                                          max_features=None,
                                                                          max_leaf_nodes=None,
                                                                          min_impurity_decrease=0.0,
                                                                          min_samples_leaf=1,
                                                                          min_samples_split=2,
                                                                          min_weight_fraction_leaf=0.0,
                                                                          n_estimators=100,
                                                                          n_iter_no_change=None,
                                                                          random_state=123,
                                                                          subsample=1.0,
                                                                          tol=0.0001,
                                                                          validation_fraction=0.1,
                                                                          verbose=0,
                                                                          warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-09 17:30:58,451:INFO:create_model() successfully completed......................................
2023-08-09 17:30:58,654:INFO:_master_model_container: 23
2023-08-09 17:30:58,654:INFO:_display_container: 7
2023-08-09 17:30:58,661:INFO:Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Warehouse_block ',
                                             'Mode_of_Shipment',
                                             'Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Product_importance',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(ad...
                                                                          max_features=None,
                                                                          max_leaf_nodes=None,
                                                                          min_impurity_decrease=0.0,
                                                                          min_samples_leaf=1,
                                                                          min_samples_split=2,
                                                                          min_weight_fraction_leaf=0.0,
                                                                          n_estimators=100,
                                                                          n_iter_no_change=None,
                                                                          random_state=123,
                                                                          subsample=1.0,
                                                                          tol=0.0001,
                                                                          validation_fraction=0.1,
                                                                          verbose=0,
                                                                          warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-09 17:30:58,661:INFO:finalize_model() successfully completed......................................
2023-08-09 17:31:03,974:INFO:Initializing predict_model()
2023-08-09 17:31:03,974:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B33B649390>, estimator=Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Warehouse_block ',
                                             'Mode_of_Shipment',
                                             'Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Product_importance',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(ad...
                                                                          max_features=None,
                                                                          max_leaf_nodes=None,
                                                                          min_impurity_decrease=0.0,
                                                                          min_samples_leaf=1,
                                                                          min_samples_split=2,
                                                                          min_weight_fraction_leaf=0.0,
                                                                          n_estimators=100,
                                                                          n_iter_no_change=None,
                                                                          random_state=123,
                                                                          subsample=1.0,
                                                                          tol=0.0001,
                                                                          validation_fraction=0.1,
                                                                          verbose=0,
                                                                          warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B33728F490>)
2023-08-09 17:31:03,974:INFO:Checking exceptions
2023-08-09 17:31:03,974:INFO:Preloading libraries
2023-08-09 17:31:03,976:INFO:Set up data.
2023-08-09 17:31:03,979:INFO:Set up index.
2023-08-09 17:35:34,476:INFO:Initializing predict_model()
2023-08-09 17:35:34,476:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B33B649390>, estimator=Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Warehouse_block ',
                                             'Mode_of_Shipment',
                                             'Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Product_importance',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(ad...
                                                                          max_features=None,
                                                                          max_leaf_nodes=None,
                                                                          min_impurity_decrease=0.0,
                                                                          min_samples_leaf=1,
                                                                          min_samples_split=2,
                                                                          min_weight_fraction_leaf=0.0,
                                                                          n_estimators=100,
                                                                          n_iter_no_change=None,
                                                                          random_state=123,
                                                                          subsample=1.0,
                                                                          tol=0.0001,
                                                                          validation_fraction=0.1,
                                                                          verbose=0,
                                                                          warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B33C3100D0>)
2023-08-09 17:35:34,477:INFO:Checking exceptions
2023-08-09 17:35:34,477:INFO:Preloading libraries
2023-08-09 17:35:34,479:INFO:Set up data.
2023-08-09 17:35:34,482:INFO:Set up index.
2023-08-09 17:35:45,051:INFO:Initializing predict_model()
2023-08-09 17:35:45,051:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B33B649390>, estimator=Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Warehouse_block ',
                                             'Mode_of_Shipment',
                                             'Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Product_importance',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(ad...
                                                                          max_features=None,
                                                                          max_leaf_nodes=None,
                                                                          min_impurity_decrease=0.0,
                                                                          min_samples_leaf=1,
                                                                          min_samples_split=2,
                                                                          min_weight_fraction_leaf=0.0,
                                                                          n_estimators=100,
                                                                          n_iter_no_change=None,
                                                                          random_state=123,
                                                                          subsample=1.0,
                                                                          tol=0.0001,
                                                                          validation_fraction=0.1,
                                                                          verbose=0,
                                                                          warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001B33B68C160>)
2023-08-09 17:35:45,051:INFO:Checking exceptions
2023-08-09 17:35:45,051:INFO:Preloading libraries
2023-08-09 17:35:45,052:INFO:Set up data.
2023-08-09 17:35:45,052:INFO:Set up index.
2023-08-09 17:38:59,594:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_a861bafeaaa540b485fd6d4b4b238b9e
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,594:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_212da42812e142b0a678f3fd43179f36_f933d8a2e4e84f17bc3abf1d86415ac2
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,594:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_279b367b90574b62b12bad25a1cddb36
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,595:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_f2d462954d584710b49c01eeb216bdd2_757e90d7c56042eb8fb4f6384bb2acf2
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,595:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_a52fae962b134b0d814f997d9e91559e
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,595:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_e41dd3d888a24d7a90a1d982c9f441c6_f0b227dfe36f41bb875ee5d046b09713
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,595:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_75bd9ea84bd84a3598e30e5644f60276
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,595:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_b5bc661c9f244639a643aa4f1c97cd71_47ccbb8a87d1485b98daca7cb55db411
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,595:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_74a3054e835d408aa0e2015def9d0436
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,595:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_3be00695de7e43f2ad1fbb525aac4f05_1c2704072e964a87bad04b74b369b31f
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,595:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_9ecd2c1a958641d895ff0eff78e941d3
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,595:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_6afece81e815436e915e5c63c7f01a55_b8c1b3e614054f39863e0a207cc01032
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,595:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_4352cc15c3a74f47aacd928b4800afcd
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,595:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_3e8e5a255744489c95b094b0f630fb36_cf3d82b577344e1ead3cf9d65bdba085
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,595:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_3e5b9153f5ff4cc3bd0344e85f8a52fe
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,595:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_bca2a12162e1459bb81a1409d2f031a3_5e29e79589bd455c858b1108b9dd29cd
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,595:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_0a92344540be4f068716e5e06500e087
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,595:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_66d189e4102e44c3bc61bdd3bb7f4bca_5745680cf85b4e98a371ecbd698c94e2
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,595:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_3c1b4a41af7340958e91e587edf24d9a
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,595:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_7f0d31a905034b3fb17988d2231feb53_2ce32a3bdc194db9b25b3546ef0a6a4b
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,595:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_9ec921cfa88e4f3ca2633acaeefac65c
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,595:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_c457c7b21d414413882724fb935650df_bb3d00c21d8b4943b348e56cbdc94408
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,596:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_cb8b00ce13e344b6afe696ad23125055
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,596:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_6c8fafc75862427eb1ca8807a78750e0_e947f06ccdb245d78d943207c7018374
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,596:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_693fc687bb844b029b9d7236b9bb3ad8
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,596:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_da3ddd907cad447eab80cafd9dd42404_62beb5cd561a4d088cddec3a73a1d552
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,596:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_ebcaa59404ec4f3c802f9fb28b1c16ef
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,596:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_c05e4eed51e543d1ba126fd646760f1c_69da4e1d86eb4c19b7d2e2c036a4bc2a
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,596:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_d6f2f7d3a5bf479cb90e6c8801acca3f
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,596:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_e34fb13d915142e6b3f6e488bf8ebaf0_bf38459f48e345288984561f078fdb89
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,596:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_1cab78046f03414c8c03dcd78278353c
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,596:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_d80a908642df45c3ace3c517a8a8bf9e_294df9955272458e88eec11a41149fa9
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,596:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_a64231a34dec470ba01c968fe57e9fa0
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,596:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_399c59b5aa39437b9dc52af5f002e031_0ede292b50e64a6681695514a49a601b
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,596:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_f3ec9495c2e44b069284c24616c71dee
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,596:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_33c866fd12d941a091f64da12d8bd450_651248cedb044ec5a885725ea8cf60ec
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,596:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_e57b0507f4694332bed529292965fd78
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,596:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_931682d69a9d4fa2a44f4aacca09b191_4c624e79738849739eb6ceb0808ce10e
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,596:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_74449f60428844d18771b340bccd8f93
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,596:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_6168287bc190488a963c8ad98f9bcdbc_00d121f255fa48c38b52b4d2aebd81c4
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,596:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_3fd42f4619284b80aa0eb1fd54cbcc18
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,596:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_aac988038ce14e008d9c8dbf5a4e1186_6c5b7917e401488fa901cda8dd6d0bc7
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,596:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_076c8a2160eb4737ac92e9429f49cbda
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,597:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_09d82f5f85d640bbb9ce66b0ad4d2723_f96c821c6b734e5daeca5e4f0985f4e9
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,597:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_ba4823e84828475e9790e89bf3551386
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,597:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_3431be0ecaae4b17a7e2512cff683395_3dd747b2e81d4ec782dbd7ff59c0628b
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,597:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_f42e270f9bd54a5c80e9d227d9133ff3
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,597:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_650fa8bdc8cd43be8b736ea17c92034e_7f3e3904676d41bea32a49921e77d4a1
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,597:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_b9aa665103264986b9a5c9d9fef20a4d
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,597:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_1f5715e23b74446089ea6290295b790d_5fa094f3f066492595fabf6d1518506f
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,597:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_f5c13b70767b41e6b50eec53a689b387
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,597:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_54c78567cba94c8eae1f65593a2e99f0_7416d9908574405289d8eae13f5c8601
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,597:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_e7971c7f965942f3b5fcff23c2b273d3
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,597:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_785371d3a19c468797309283ed0ecfbe_98e3797061f147e49466e4fa0a821830
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,597:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_682e4196b6ec44d091b0c14b48ed8cfd
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,597:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_6e109f778a964110a460bdd070b92581_45eeefff14b049f394e9f01bab11e6c2
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,597:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_50e64373b4884410b23f40e1413a89df
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,597:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_8abda5bab6a7421fb55f735df4fba53f_a4038bcee11346d5aab61b7a4e547b49
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,597:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_794072ea978c47dfa39730a674edac56
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,597:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_4065d8f9f0f54309a43642ec8309d27b_343828f5f5c54576b982bb9decf9cdb5
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,597:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_ed77ffc6235749a1843855642eca8978
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,597:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_1c5b5fe15831418bbe40ded5727165ef_defe73f5dc474aa1a77a1e713e789f25
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,597:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_8fe5b3f8a11b434bae28f7bcb05e078a
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,597:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_6bd9567c8b314ee18c1eb1972af86e9b_95cd387a73a04c7b96ba39308fdb45dc
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,597:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_9486c8261e914d1b9d1c023ec4591973
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,598:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_6b6d6d2e71b64f73b7527153ddbd0d45_ed30715e9acb4e0aa65835d439795a38
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,598:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_0021c63727774a7fa981a2ac44c57a4c
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,598:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_d419b0840a9e45bd9f0839914b2982a6_563bf3168c3549bca9ed1c3b035f6071
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,598:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_2e7321015d8e43c285f5af4cc7e16897
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,598:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_ad1d4fab5a774768b7becde06c4f610d_beabee9d8d4a4295a629f929b16a3d5c
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,598:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_f2214f02c41c4dbd95b18596ab01e865
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,598:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_bb4bd6e010804b4a8b048ac1a9640dbd_66088a7f96d743378beead763e521ebc
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,598:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_247540ce22ea445b83edcc6c69648d0e
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,598:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_834b2cd08bab49b5b9dcee44f1a1d91b_59917324b387425c84253aa7a64694c6
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,598:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_dcaddfc83b6c4807887b6ca557d43f10
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,598:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_c1a65b7509934978ab19686124dfc5eb_2fd8c4ee4c554aa1be6b0a07575ad8fd
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,598:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_114dfc5e942e4811ad454b875c6c2e36
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,598:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_6df2b573ccd141a1a74f7a92883db1e1_338f3ec730af48d5af59932e4efbebfa
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,598:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_ea00efd471b6471fa91c3d8862fd7a56
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,598:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_e9b410d5bfd747ec92349e8b6e4ab28e_c8909dccec29497881908089b17b0137
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,598:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_11ffaefcdad64b3d97bb0a03196396e5
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,598:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_30a4e4429bbd4285b42fe8cbf6e230c9_fa638c0273804d298bc0406658171b44
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,598:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_a6c7d4eda9774fe492bf5abd3703a70c
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,598:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_72fa428f35474d0999f3efc0e1b53f90_e91b4d4fef114aeaa4fba741cc9a1c4c
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,598:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_89ac1b6fb0014d0191960598c9c9b68c
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,598:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_deac729544924bf6ba686b5855750731_ec8a86c6e2684d918b5d143ecf3715f7
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,598:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_493446b25ba643978064a510846592d6
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,598:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_e967c5cfab8e429f8367e4e8d2f438db_9a1136343f1b4efe9051b970756481d3
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,599:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_6c7964f8c8ca48f58369d4f86fec5fd5
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,599:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_9e1544f3e83648f88f258e654932e362_aba7b8afd0474aceae2106a0bfb19ffb
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,599:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_66c0319f59334438b27f91f76c09b111
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,599:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_e5cc3783c0b54d278f3c4009f5d351a8_e4506bcf1d804a3ea8e7dd778060eaf6
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,599:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_7f98bbd252634d8f898663fc6f1e8f8d
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,599:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_044d9e8ee9984d0191d8c909d767dfa2_f18ac6453a154be39b3092918c95698d
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,599:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_0f3163af51864dc5942f943e5779b72e
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,599:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_a9ec68f7de504526aae6698d80fdfce8_f9d211af6d964410a5556c947b77dbd6
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,599:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_eced7b82ccf34d199d26b0d9af0aa772
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,599:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_37a87e3534664001942951caa87a0b73_9db2fef5f5504c60b6c0c1c99eb3dbd9
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,599:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_4cf6e666adfc459796007d7e48cee5d6
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,599:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_8557b433cffd489a954176d5192db1eb_b4324ca0a05c4d8284f717800f5df63b
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,599:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_20ac7fbc24eb4f3d9c901babda0d414b
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,599:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_74d2b55a2a8340c09940859d2d5dcb53_e90a89007e8a4a23aa1c061d5fbe25e9
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,599:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_7041fa123b0e4e9a901367df47e51c8a
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:38:59,599:WARNING:C:\Users\user21\anaconda3\lib\site-packages\joblib\_memmapping_reducer.py:598: UserWarning: Failed to delete temporary folder: C:\Users\user21\AppData\Local\Temp\joblib_memmapping_folder_6148_885a824b78564085bb6218c3f3d89ff0_675a692ce64a493a9efe3d5354f55e4e
  warnings.warn("Failed to delete temporary folder: {}"

2023-08-09 17:39:07,498:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-09 17:39:07,498:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-09 17:39:07,498:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-09 17:39:07,498:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-08-09 17:40:03,865:INFO:PyCaret ClassificationExperiment
2023-08-09 17:40:03,865:INFO:Logging name: clf-default-name
2023-08-09 17:40:03,865:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-09 17:40:03,865:INFO:version 3.0.4
2023-08-09 17:40:03,865:INFO:Initializing setup()
2023-08-09 17:40:03,865:INFO:self.USI: 165c
2023-08-09 17:40:03,865:INFO:self._variable_keys: {'idx', 'y_train', 'html_param', 'log_plots_param', 'fold_generator', 'X', 'seed', 'target_param', 'logging_param', 'y_test', 'fold_groups_param', '_available_plots', 'data', 'n_jobs_param', 'exp_id', 'fold_shuffle_param', 'USI', 'exp_name_log', 'gpu_n_jobs_param', 'memory', '_ml_usecase', 'is_multiclass', 'X_test', 'fix_imbalance', 'y', 'pipeline', 'gpu_param', 'X_train'}
2023-08-09 17:40:03,865:INFO:Checking environment
2023-08-09 17:40:03,865:INFO:python_version: 3.10.12
2023-08-09 17:40:03,865:INFO:python_build: ('main', 'Jul  5 2023 19:09:20')
2023-08-09 17:40:03,865:INFO:machine: AMD64
2023-08-09 17:40:03,865:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-09 17:40:03,865:INFO:Memory: svmem(total=16828977152, available=7782006784, percent=53.8, used=9046970368, free=7782006784)
2023-08-09 17:40:03,865:INFO:Physical Core: 14
2023-08-09 17:40:03,865:INFO:Logical Core: 20
2023-08-09 17:40:03,865:INFO:Checking libraries
2023-08-09 17:40:03,865:INFO:System:
2023-08-09 17:40:03,865:INFO:    python: 3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:09:20) [MSC v.1916 64 bit (AMD64)]
2023-08-09 17:40:03,865:INFO:executable: C:\Users\user21\anaconda3\python.exe
2023-08-09 17:40:03,867:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-09 17:40:03,867:INFO:PyCaret required dependencies:
2023-08-09 17:40:03,868:INFO:                 pip: 23.2.1
2023-08-09 17:40:03,868:INFO:          setuptools: 68.0.0
2023-08-09 17:40:03,868:INFO:             pycaret: 3.0.4
2023-08-09 17:40:03,868:INFO:             IPython: 8.12.0
2023-08-09 17:40:03,868:INFO:          ipywidgets: 8.1.0
2023-08-09 17:40:03,868:INFO:                tqdm: 4.65.0
2023-08-09 17:40:03,868:INFO:               numpy: 1.23.5
2023-08-09 17:40:03,868:INFO:              pandas: 1.5.3
2023-08-09 17:40:03,868:INFO:              jinja2: 3.1.2
2023-08-09 17:40:03,868:INFO:               scipy: 1.11.1
2023-08-09 17:40:03,868:INFO:              joblib: 1.3.1
2023-08-09 17:40:03,868:INFO:             sklearn: 1.2.2
2023-08-09 17:40:03,868:INFO:                pyod: 1.1.0
2023-08-09 17:40:03,868:INFO:            imblearn: 0.11.0
2023-08-09 17:40:03,868:INFO:   category_encoders: 2.6.1
2023-08-09 17:40:03,868:INFO:            lightgbm: 4.0.0
2023-08-09 17:40:03,868:INFO:               numba: 0.57.1
2023-08-09 17:40:03,868:INFO:            requests: 2.31.0
2023-08-09 17:40:03,868:INFO:          matplotlib: 3.7.2
2023-08-09 17:40:03,868:INFO:          scikitplot: 0.3.7
2023-08-09 17:40:03,868:INFO:         yellowbrick: 1.5
2023-08-09 17:40:03,868:INFO:              plotly: 5.15.0
2023-08-09 17:40:03,868:INFO:    plotly-resampler: Not installed
2023-08-09 17:40:03,868:INFO:             kaleido: 0.2.1
2023-08-09 17:40:03,868:INFO:           schemdraw: 0.15
2023-08-09 17:40:03,868:INFO:         statsmodels: 0.14.0
2023-08-09 17:40:03,868:INFO:              sktime: 0.21.0
2023-08-09 17:40:03,868:INFO:               tbats: 1.1.3
2023-08-09 17:40:03,868:INFO:            pmdarima: 2.0.3
2023-08-09 17:40:03,868:INFO:              psutil: 5.9.0
2023-08-09 17:40:03,868:INFO:          markupsafe: 2.1.1
2023-08-09 17:40:03,868:INFO:             pickle5: Not installed
2023-08-09 17:40:03,868:INFO:         cloudpickle: 2.2.1
2023-08-09 17:40:03,868:INFO:         deprecation: 2.1.0
2023-08-09 17:40:03,868:INFO:              xxhash: 3.3.0
2023-08-09 17:40:03,868:INFO:           wurlitzer: Not installed
2023-08-09 17:40:03,868:INFO:PyCaret optional dependencies:
2023-08-09 17:40:03,873:INFO:                shap: Not installed
2023-08-09 17:40:03,875:INFO:           interpret: Not installed
2023-08-09 17:40:03,875:INFO:                umap: Not installed
2023-08-09 17:40:03,875:INFO:    pandas_profiling: Not installed
2023-08-09 17:40:03,875:INFO:  explainerdashboard: Not installed
2023-08-09 17:40:03,875:INFO:             autoviz: Not installed
2023-08-09 17:40:03,875:INFO:           fairlearn: Not installed
2023-08-09 17:40:03,875:INFO:          deepchecks: Not installed
2023-08-09 17:40:03,875:INFO:             xgboost: 1.7.6
2023-08-09 17:40:03,875:INFO:            catboost: 1.2
2023-08-09 17:40:03,875:INFO:              kmodes: Not installed
2023-08-09 17:40:03,875:INFO:             mlxtend: Not installed
2023-08-09 17:40:03,875:INFO:       statsforecast: Not installed
2023-08-09 17:40:03,875:INFO:        tune_sklearn: Not installed
2023-08-09 17:40:03,875:INFO:                 ray: Not installed
2023-08-09 17:40:03,875:INFO:            hyperopt: Not installed
2023-08-09 17:40:03,875:INFO:              optuna: 3.2.0
2023-08-09 17:40:03,875:INFO:               skopt: Not installed
2023-08-09 17:40:03,875:INFO:              mlflow: Not installed
2023-08-09 17:40:03,875:INFO:              gradio: Not installed
2023-08-09 17:40:03,875:INFO:             fastapi: Not installed
2023-08-09 17:40:03,875:INFO:             uvicorn: Not installed
2023-08-09 17:40:03,875:INFO:              m2cgen: Not installed
2023-08-09 17:40:03,875:INFO:           evidently: Not installed
2023-08-09 17:40:03,875:INFO:               fugue: Not installed
2023-08-09 17:40:03,875:INFO:           streamlit: Not installed
2023-08-09 17:40:03,875:INFO:             prophet: Not installed
2023-08-09 17:40:03,875:INFO:None
2023-08-09 17:40:03,875:INFO:Set up data.
2023-08-09 17:40:03,879:INFO:Set up train/test split.
2023-08-09 17:40:03,884:INFO:Set up index.
2023-08-09 17:40:03,884:INFO:Set up folding strategy.
2023-08-09 17:40:03,884:INFO:Assigning column types.
2023-08-09 17:40:03,886:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-09 17:40:03,913:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-09 17:40:03,915:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 17:40:03,935:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 17:40:03,938:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 17:40:03,966:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-09 17:40:03,966:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 17:40:03,983:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 17:40:03,985:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 17:40:03,985:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-09 17:40:04,012:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 17:40:04,030:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 17:40:04,031:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 17:40:04,059:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 17:40:04,076:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 17:40:04,078:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 17:40:04,078:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-09 17:40:04,123:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 17:40:04,125:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 17:40:04,170:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 17:40:04,172:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 17:40:04,174:INFO:Preparing preprocessing pipeline...
2023-08-09 17:40:04,175:INFO:Set up simple imputation.
2023-08-09 17:40:04,176:INFO:Set up column name cleaning.
2023-08-09 17:40:04,192:INFO:Finished creating preprocessing pipeline.
2023-08-09 17:40:04,195:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Warehouse_block ',
                                             'Mode_of_Shipment',
                                             'Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Product_importance',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(ad...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-09 17:40:04,196:INFO:Creating final display dataframe.
2023-08-09 17:40:04,246:INFO:Setup _display_container:                     Description                Value
0                    Session id                  123
1                        Target  Reached.on.Time_Y.N
2                   Target type               Binary
3           Original data shape           (6994, 10)
4        Transformed data shape           (6994, 10)
5   Transformed train set shape           (4895, 10)
6    Transformed test set shape           (2099, 10)
7              Numeric features                    9
8                    Preprocess                 True
9               Imputation type               simple
10           Numeric imputation                 mean
11       Categorical imputation                 mode
12               Fold Generator      StratifiedKFold
13                  Fold Number                   10
14                     CPU Jobs                   -1
15                      Use GPU                False
16               Log Experiment                False
17              Experiment Name     clf-default-name
18                          USI                 165c
2023-08-09 17:40:04,297:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 17:40:04,298:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 17:40:04,346:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 17:40:04,348:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 17:40:04,349:INFO:setup() successfully completed in 0.86s...............
2023-08-09 17:40:04,349:INFO:Initializing compare_models()
2023-08-09 17:40:04,349:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B40017E0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000178B40017E0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-09 17:40:04,349:INFO:Checking exceptions
2023-08-09 17:40:04,352:INFO:Preparing display monitor
2023-08-09 17:40:04,369:INFO:Initializing Logistic Regression
2023-08-09 17:40:04,369:INFO:Total runtime is 0.0 minutes
2023-08-09 17:40:04,371:INFO:SubProcess create_model() called ==================================
2023-08-09 17:40:04,372:INFO:Initializing create_model()
2023-08-09 17:40:04,372:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B40017E0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178B427A9B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:40:04,372:INFO:Checking exceptions
2023-08-09 17:40:04,372:INFO:Importing libraries
2023-08-09 17:40:04,372:INFO:Copying training dataset
2023-08-09 17:40:04,375:INFO:Defining folds
2023-08-09 17:40:04,375:INFO:Declaring metric variables
2023-08-09 17:40:04,377:INFO:Importing untrained model
2023-08-09 17:40:04,379:INFO:Logistic Regression Imported successfully
2023-08-09 17:40:04,384:INFO:Starting cross validation
2023-08-09 17:40:04,385:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:40:09,705:INFO:Calculating mean and std
2023-08-09 17:40:09,706:INFO:Creating metrics dataframe
2023-08-09 17:40:10,145:INFO:Uploading results into container
2023-08-09 17:40:10,146:INFO:Uploading model into container now
2023-08-09 17:40:10,146:INFO:_master_model_container: 1
2023-08-09 17:40:10,147:INFO:_display_container: 2
2023-08-09 17:40:10,147:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-09 17:40:10,147:INFO:create_model() successfully completed......................................
2023-08-09 17:40:10,213:INFO:SubProcess create_model() end ==================================
2023-08-09 17:40:10,214:INFO:Creating metrics dataframe
2023-08-09 17:40:10,220:INFO:Initializing K Neighbors Classifier
2023-08-09 17:40:10,220:INFO:Total runtime is 0.0975226640701294 minutes
2023-08-09 17:40:10,223:INFO:SubProcess create_model() called ==================================
2023-08-09 17:40:10,223:INFO:Initializing create_model()
2023-08-09 17:40:10,223:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B40017E0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178B427A9B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:40:10,223:INFO:Checking exceptions
2023-08-09 17:40:10,224:INFO:Importing libraries
2023-08-09 17:40:10,224:INFO:Copying training dataset
2023-08-09 17:40:10,226:INFO:Defining folds
2023-08-09 17:40:10,226:INFO:Declaring metric variables
2023-08-09 17:40:10,228:INFO:Importing untrained model
2023-08-09 17:40:10,231:INFO:K Neighbors Classifier Imported successfully
2023-08-09 17:40:10,236:INFO:Starting cross validation
2023-08-09 17:40:10,236:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:40:15,263:INFO:Calculating mean and std
2023-08-09 17:40:15,264:INFO:Creating metrics dataframe
2023-08-09 17:40:15,727:INFO:Uploading results into container
2023-08-09 17:40:15,728:INFO:Uploading model into container now
2023-08-09 17:40:15,728:INFO:_master_model_container: 2
2023-08-09 17:40:15,728:INFO:_display_container: 2
2023-08-09 17:40:15,730:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-09 17:40:15,730:INFO:create_model() successfully completed......................................
2023-08-09 17:40:15,802:INFO:SubProcess create_model() end ==================================
2023-08-09 17:40:15,803:INFO:Creating metrics dataframe
2023-08-09 17:40:15,810:INFO:Initializing Naive Bayes
2023-08-09 17:40:15,810:INFO:Total runtime is 0.1906765937805176 minutes
2023-08-09 17:40:15,812:INFO:SubProcess create_model() called ==================================
2023-08-09 17:40:15,812:INFO:Initializing create_model()
2023-08-09 17:40:15,812:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B40017E0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178B427A9B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:40:15,812:INFO:Checking exceptions
2023-08-09 17:40:15,812:INFO:Importing libraries
2023-08-09 17:40:15,812:INFO:Copying training dataset
2023-08-09 17:40:15,816:INFO:Defining folds
2023-08-09 17:40:15,816:INFO:Declaring metric variables
2023-08-09 17:40:15,818:INFO:Importing untrained model
2023-08-09 17:40:15,820:INFO:Naive Bayes Imported successfully
2023-08-09 17:40:15,825:INFO:Starting cross validation
2023-08-09 17:40:15,825:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:40:18,829:INFO:Calculating mean and std
2023-08-09 17:40:18,830:INFO:Creating metrics dataframe
2023-08-09 17:40:19,272:INFO:Uploading results into container
2023-08-09 17:40:19,273:INFO:Uploading model into container now
2023-08-09 17:40:19,273:INFO:_master_model_container: 3
2023-08-09 17:40:19,273:INFO:_display_container: 2
2023-08-09 17:40:19,273:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-09 17:40:19,273:INFO:create_model() successfully completed......................................
2023-08-09 17:40:19,343:INFO:SubProcess create_model() end ==================================
2023-08-09 17:40:19,343:INFO:Creating metrics dataframe
2023-08-09 17:40:19,349:INFO:Initializing Decision Tree Classifier
2023-08-09 17:40:19,349:INFO:Total runtime is 0.24966898759206138 minutes
2023-08-09 17:40:19,351:INFO:SubProcess create_model() called ==================================
2023-08-09 17:40:19,351:INFO:Initializing create_model()
2023-08-09 17:40:19,351:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B40017E0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178B427A9B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:40:19,351:INFO:Checking exceptions
2023-08-09 17:40:19,351:INFO:Importing libraries
2023-08-09 17:40:19,351:INFO:Copying training dataset
2023-08-09 17:40:19,355:INFO:Defining folds
2023-08-09 17:40:19,355:INFO:Declaring metric variables
2023-08-09 17:40:19,356:INFO:Importing untrained model
2023-08-09 17:40:19,358:INFO:Decision Tree Classifier Imported successfully
2023-08-09 17:40:19,363:INFO:Starting cross validation
2023-08-09 17:40:19,363:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:40:22,381:INFO:Calculating mean and std
2023-08-09 17:40:22,382:INFO:Creating metrics dataframe
2023-08-09 17:40:22,826:INFO:Uploading results into container
2023-08-09 17:40:22,826:INFO:Uploading model into container now
2023-08-09 17:40:22,827:INFO:_master_model_container: 4
2023-08-09 17:40:22,827:INFO:_display_container: 2
2023-08-09 17:40:22,827:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-08-09 17:40:22,827:INFO:create_model() successfully completed......................................
2023-08-09 17:40:22,899:INFO:SubProcess create_model() end ==================================
2023-08-09 17:40:22,899:INFO:Creating metrics dataframe
2023-08-09 17:40:22,906:INFO:Initializing SVM - Linear Kernel
2023-08-09 17:40:22,907:INFO:Total runtime is 0.30896143515904745 minutes
2023-08-09 17:40:22,908:INFO:SubProcess create_model() called ==================================
2023-08-09 17:40:22,909:INFO:Initializing create_model()
2023-08-09 17:40:22,909:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B40017E0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178B427A9B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:40:22,909:INFO:Checking exceptions
2023-08-09 17:40:22,909:INFO:Importing libraries
2023-08-09 17:40:22,909:INFO:Copying training dataset
2023-08-09 17:40:22,911:INFO:Defining folds
2023-08-09 17:40:22,911:INFO:Declaring metric variables
2023-08-09 17:40:22,914:INFO:Importing untrained model
2023-08-09 17:40:22,916:INFO:SVM - Linear Kernel Imported successfully
2023-08-09 17:40:22,920:INFO:Starting cross validation
2023-08-09 17:40:22,921:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:40:22,998:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:40:23,002:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:40:23,009:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:40:23,009:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:40:23,012:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:40:23,018:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:40:23,027:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:40:23,033:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:40:23,041:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:40:23,043:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:40:25,953:INFO:Calculating mean and std
2023-08-09 17:40:25,954:INFO:Creating metrics dataframe
2023-08-09 17:40:26,391:INFO:Uploading results into container
2023-08-09 17:40:26,391:INFO:Uploading model into container now
2023-08-09 17:40:26,392:INFO:_master_model_container: 5
2023-08-09 17:40:26,392:INFO:_display_container: 2
2023-08-09 17:40:26,392:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-09 17:40:26,392:INFO:create_model() successfully completed......................................
2023-08-09 17:40:26,463:INFO:SubProcess create_model() end ==================================
2023-08-09 17:40:26,464:INFO:Creating metrics dataframe
2023-08-09 17:40:26,471:INFO:Initializing Ridge Classifier
2023-08-09 17:40:26,471:INFO:Total runtime is 0.36835880676905314 minutes
2023-08-09 17:40:26,473:INFO:SubProcess create_model() called ==================================
2023-08-09 17:40:26,473:INFO:Initializing create_model()
2023-08-09 17:40:26,473:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B40017E0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178B427A9B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:40:26,473:INFO:Checking exceptions
2023-08-09 17:40:26,473:INFO:Importing libraries
2023-08-09 17:40:26,473:INFO:Copying training dataset
2023-08-09 17:40:26,475:INFO:Defining folds
2023-08-09 17:40:26,475:INFO:Declaring metric variables
2023-08-09 17:40:26,476:INFO:Importing untrained model
2023-08-09 17:40:26,479:INFO:Ridge Classifier Imported successfully
2023-08-09 17:40:26,483:INFO:Starting cross validation
2023-08-09 17:40:26,484:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:40:26,537:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:40:26,538:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:40:26,544:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:40:26,549:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:40:26,550:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:40:26,556:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:40:26,558:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:40:26,561:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:40:26,562:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:40:26,573:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:40:29,481:INFO:Calculating mean and std
2023-08-09 17:40:29,482:INFO:Creating metrics dataframe
2023-08-09 17:40:29,915:INFO:Uploading results into container
2023-08-09 17:40:29,916:INFO:Uploading model into container now
2023-08-09 17:40:29,916:INFO:_master_model_container: 6
2023-08-09 17:40:29,916:INFO:_display_container: 2
2023-08-09 17:40:29,916:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-08-09 17:40:29,916:INFO:create_model() successfully completed......................................
2023-08-09 17:40:29,985:INFO:SubProcess create_model() end ==================================
2023-08-09 17:40:29,985:INFO:Creating metrics dataframe
2023-08-09 17:40:29,994:INFO:Initializing Random Forest Classifier
2023-08-09 17:40:29,994:INFO:Total runtime is 0.42708212534586587 minutes
2023-08-09 17:40:29,997:INFO:SubProcess create_model() called ==================================
2023-08-09 17:40:29,997:INFO:Initializing create_model()
2023-08-09 17:40:29,997:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B40017E0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178B427A9B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:40:29,997:INFO:Checking exceptions
2023-08-09 17:40:29,997:INFO:Importing libraries
2023-08-09 17:40:29,997:INFO:Copying training dataset
2023-08-09 17:40:30,001:INFO:Defining folds
2023-08-09 17:40:30,001:INFO:Declaring metric variables
2023-08-09 17:40:30,003:INFO:Importing untrained model
2023-08-09 17:40:30,005:INFO:Random Forest Classifier Imported successfully
2023-08-09 17:40:30,009:INFO:Starting cross validation
2023-08-09 17:40:30,010:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:40:33,217:INFO:Calculating mean and std
2023-08-09 17:40:33,218:INFO:Creating metrics dataframe
2023-08-09 17:40:33,657:INFO:Uploading results into container
2023-08-09 17:40:33,658:INFO:Uploading model into container now
2023-08-09 17:40:33,658:INFO:_master_model_container: 7
2023-08-09 17:40:33,658:INFO:_display_container: 2
2023-08-09 17:40:33,658:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-09 17:40:33,658:INFO:create_model() successfully completed......................................
2023-08-09 17:40:33,729:INFO:SubProcess create_model() end ==================================
2023-08-09 17:40:33,729:INFO:Creating metrics dataframe
2023-08-09 17:40:33,737:INFO:Initializing Quadratic Discriminant Analysis
2023-08-09 17:40:33,737:INFO:Total runtime is 0.4894714554150899 minutes
2023-08-09 17:40:33,739:INFO:SubProcess create_model() called ==================================
2023-08-09 17:40:33,739:INFO:Initializing create_model()
2023-08-09 17:40:33,739:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B40017E0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178B427A9B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:40:33,739:INFO:Checking exceptions
2023-08-09 17:40:33,739:INFO:Importing libraries
2023-08-09 17:40:33,740:INFO:Copying training dataset
2023-08-09 17:40:33,742:INFO:Defining folds
2023-08-09 17:40:33,742:INFO:Declaring metric variables
2023-08-09 17:40:33,745:INFO:Importing untrained model
2023-08-09 17:40:33,747:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-09 17:40:33,752:INFO:Starting cross validation
2023-08-09 17:40:33,753:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:40:36,757:INFO:Calculating mean and std
2023-08-09 17:40:36,758:INFO:Creating metrics dataframe
2023-08-09 17:40:37,198:INFO:Uploading results into container
2023-08-09 17:40:37,199:INFO:Uploading model into container now
2023-08-09 17:40:37,199:INFO:_master_model_container: 8
2023-08-09 17:40:37,199:INFO:_display_container: 2
2023-08-09 17:40:37,200:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-09 17:40:37,200:INFO:create_model() successfully completed......................................
2023-08-09 17:40:37,271:INFO:SubProcess create_model() end ==================================
2023-08-09 17:40:37,271:INFO:Creating metrics dataframe
2023-08-09 17:40:37,280:INFO:Initializing Ada Boost Classifier
2023-08-09 17:40:37,280:INFO:Total runtime is 0.5485115289688111 minutes
2023-08-09 17:40:37,282:INFO:SubProcess create_model() called ==================================
2023-08-09 17:40:37,283:INFO:Initializing create_model()
2023-08-09 17:40:37,283:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B40017E0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178B427A9B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:40:37,283:INFO:Checking exceptions
2023-08-09 17:40:37,283:INFO:Importing libraries
2023-08-09 17:40:37,283:INFO:Copying training dataset
2023-08-09 17:40:37,285:INFO:Defining folds
2023-08-09 17:40:37,285:INFO:Declaring metric variables
2023-08-09 17:40:37,287:INFO:Importing untrained model
2023-08-09 17:40:37,289:INFO:Ada Boost Classifier Imported successfully
2023-08-09 17:40:37,293:INFO:Starting cross validation
2023-08-09 17:40:37,293:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:40:40,363:INFO:Calculating mean and std
2023-08-09 17:40:40,363:INFO:Creating metrics dataframe
2023-08-09 17:40:40,807:INFO:Uploading results into container
2023-08-09 17:40:40,808:INFO:Uploading model into container now
2023-08-09 17:40:40,809:INFO:_master_model_container: 9
2023-08-09 17:40:40,809:INFO:_display_container: 2
2023-08-09 17:40:40,809:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-08-09 17:40:40,809:INFO:create_model() successfully completed......................................
2023-08-09 17:40:40,877:INFO:SubProcess create_model() end ==================================
2023-08-09 17:40:40,877:INFO:Creating metrics dataframe
2023-08-09 17:40:40,886:INFO:Initializing Gradient Boosting Classifier
2023-08-09 17:40:40,886:INFO:Total runtime is 0.6086114247639974 minutes
2023-08-09 17:40:40,889:INFO:SubProcess create_model() called ==================================
2023-08-09 17:40:40,889:INFO:Initializing create_model()
2023-08-09 17:40:40,889:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B40017E0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178B427A9B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:40:40,889:INFO:Checking exceptions
2023-08-09 17:40:40,889:INFO:Importing libraries
2023-08-09 17:40:40,889:INFO:Copying training dataset
2023-08-09 17:40:40,892:INFO:Defining folds
2023-08-09 17:40:40,892:INFO:Declaring metric variables
2023-08-09 17:40:40,895:INFO:Importing untrained model
2023-08-09 17:40:40,896:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 17:40:40,900:INFO:Starting cross validation
2023-08-09 17:40:40,901:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:40:44,017:INFO:Calculating mean and std
2023-08-09 17:40:44,018:INFO:Creating metrics dataframe
2023-08-09 17:40:44,470:INFO:Uploading results into container
2023-08-09 17:40:44,470:INFO:Uploading model into container now
2023-08-09 17:40:44,471:INFO:_master_model_container: 10
2023-08-09 17:40:44,471:INFO:_display_container: 2
2023-08-09 17:40:44,472:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 17:40:44,472:INFO:create_model() successfully completed......................................
2023-08-09 17:40:44,544:INFO:SubProcess create_model() end ==================================
2023-08-09 17:40:44,544:INFO:Creating metrics dataframe
2023-08-09 17:40:44,552:INFO:Initializing Linear Discriminant Analysis
2023-08-09 17:40:44,552:INFO:Total runtime is 0.6697190999984741 minutes
2023-08-09 17:40:44,553:INFO:SubProcess create_model() called ==================================
2023-08-09 17:40:44,555:INFO:Initializing create_model()
2023-08-09 17:40:44,555:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B40017E0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178B427A9B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:40:44,555:INFO:Checking exceptions
2023-08-09 17:40:44,555:INFO:Importing libraries
2023-08-09 17:40:44,555:INFO:Copying training dataset
2023-08-09 17:40:44,558:INFO:Defining folds
2023-08-09 17:40:44,558:INFO:Declaring metric variables
2023-08-09 17:40:44,560:INFO:Importing untrained model
2023-08-09 17:40:44,562:INFO:Linear Discriminant Analysis Imported successfully
2023-08-09 17:40:44,566:INFO:Starting cross validation
2023-08-09 17:40:44,566:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:40:47,576:INFO:Calculating mean and std
2023-08-09 17:40:47,577:INFO:Creating metrics dataframe
2023-08-09 17:40:48,011:INFO:Uploading results into container
2023-08-09 17:40:48,012:INFO:Uploading model into container now
2023-08-09 17:40:48,012:INFO:_master_model_container: 11
2023-08-09 17:40:48,012:INFO:_display_container: 2
2023-08-09 17:40:48,012:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-09 17:40:48,012:INFO:create_model() successfully completed......................................
2023-08-09 17:40:48,077:INFO:SubProcess create_model() end ==================================
2023-08-09 17:40:48,077:INFO:Creating metrics dataframe
2023-08-09 17:40:48,086:INFO:Initializing Extra Trees Classifier
2023-08-09 17:40:48,086:INFO:Total runtime is 0.7286185264587403 minutes
2023-08-09 17:40:48,089:INFO:SubProcess create_model() called ==================================
2023-08-09 17:40:48,089:INFO:Initializing create_model()
2023-08-09 17:40:48,089:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B40017E0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178B427A9B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:40:48,089:INFO:Checking exceptions
2023-08-09 17:40:48,089:INFO:Importing libraries
2023-08-09 17:40:48,089:INFO:Copying training dataset
2023-08-09 17:40:48,092:INFO:Defining folds
2023-08-09 17:40:48,092:INFO:Declaring metric variables
2023-08-09 17:40:48,095:INFO:Importing untrained model
2023-08-09 17:40:48,098:INFO:Extra Trees Classifier Imported successfully
2023-08-09 17:40:48,102:INFO:Starting cross validation
2023-08-09 17:40:48,103:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:40:51,325:INFO:Calculating mean and std
2023-08-09 17:40:51,326:INFO:Creating metrics dataframe
2023-08-09 17:40:51,757:INFO:Uploading results into container
2023-08-09 17:40:51,758:INFO:Uploading model into container now
2023-08-09 17:40:51,758:INFO:_master_model_container: 12
2023-08-09 17:40:51,759:INFO:_display_container: 2
2023-08-09 17:40:51,759:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-08-09 17:40:51,759:INFO:create_model() successfully completed......................................
2023-08-09 17:40:51,829:INFO:SubProcess create_model() end ==================================
2023-08-09 17:40:51,829:INFO:Creating metrics dataframe
2023-08-09 17:40:51,838:INFO:Initializing Extreme Gradient Boosting
2023-08-09 17:40:51,838:INFO:Total runtime is 0.791152290503184 minutes
2023-08-09 17:40:51,840:INFO:SubProcess create_model() called ==================================
2023-08-09 17:40:51,840:INFO:Initializing create_model()
2023-08-09 17:40:51,840:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B40017E0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178B427A9B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:40:51,840:INFO:Checking exceptions
2023-08-09 17:40:51,840:INFO:Importing libraries
2023-08-09 17:40:51,840:INFO:Copying training dataset
2023-08-09 17:40:51,844:INFO:Defining folds
2023-08-09 17:40:51,844:INFO:Declaring metric variables
2023-08-09 17:40:51,845:INFO:Importing untrained model
2023-08-09 17:40:51,847:INFO:Extreme Gradient Boosting Imported successfully
2023-08-09 17:40:51,852:INFO:Starting cross validation
2023-08-09 17:40:51,853:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:40:56,140:INFO:Calculating mean and std
2023-08-09 17:40:56,141:INFO:Creating metrics dataframe
2023-08-09 17:40:56,575:INFO:Uploading results into container
2023-08-09 17:40:56,575:INFO:Uploading model into container now
2023-08-09 17:40:56,576:INFO:_master_model_container: 13
2023-08-09 17:40:56,576:INFO:_display_container: 2
2023-08-09 17:40:56,577:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-09 17:40:56,577:INFO:create_model() successfully completed......................................
2023-08-09 17:40:56,647:INFO:SubProcess create_model() end ==================================
2023-08-09 17:40:56,647:INFO:Creating metrics dataframe
2023-08-09 17:40:56,656:INFO:Initializing Light Gradient Boosting Machine
2023-08-09 17:40:56,656:INFO:Total runtime is 0.8714453856150309 minutes
2023-08-09 17:40:56,659:INFO:SubProcess create_model() called ==================================
2023-08-09 17:40:56,659:INFO:Initializing create_model()
2023-08-09 17:40:56,659:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B40017E0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178B427A9B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:40:56,659:INFO:Checking exceptions
2023-08-09 17:40:56,659:INFO:Importing libraries
2023-08-09 17:40:56,659:INFO:Copying training dataset
2023-08-09 17:40:56,662:INFO:Defining folds
2023-08-09 17:40:56,662:INFO:Declaring metric variables
2023-08-09 17:40:56,665:INFO:Importing untrained model
2023-08-09 17:40:56,667:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-09 17:40:56,671:INFO:Starting cross validation
2023-08-09 17:40:56,672:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:40:59,768:INFO:Calculating mean and std
2023-08-09 17:40:59,768:INFO:Creating metrics dataframe
2023-08-09 17:41:00,225:INFO:Uploading results into container
2023-08-09 17:41:00,225:INFO:Uploading model into container now
2023-08-09 17:41:00,226:INFO:_master_model_container: 14
2023-08-09 17:41:00,226:INFO:_display_container: 2
2023-08-09 17:41:00,226:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-09 17:41:00,226:INFO:create_model() successfully completed......................................
2023-08-09 17:41:00,298:INFO:SubProcess create_model() end ==================================
2023-08-09 17:41:00,298:INFO:Creating metrics dataframe
2023-08-09 17:41:00,306:INFO:Initializing CatBoost Classifier
2023-08-09 17:41:00,306:INFO:Total runtime is 0.9322749773661295 minutes
2023-08-09 17:41:00,308:INFO:SubProcess create_model() called ==================================
2023-08-09 17:41:00,309:INFO:Initializing create_model()
2023-08-09 17:41:00,309:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B40017E0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178B427A9B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:41:00,309:INFO:Checking exceptions
2023-08-09 17:41:00,309:INFO:Importing libraries
2023-08-09 17:41:00,309:INFO:Copying training dataset
2023-08-09 17:41:00,311:INFO:Defining folds
2023-08-09 17:41:00,311:INFO:Declaring metric variables
2023-08-09 17:41:00,313:INFO:Importing untrained model
2023-08-09 17:41:00,316:INFO:CatBoost Classifier Imported successfully
2023-08-09 17:41:00,320:INFO:Starting cross validation
2023-08-09 17:41:00,322:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:41:03,838:INFO:Calculating mean and std
2023-08-09 17:41:03,839:INFO:Creating metrics dataframe
2023-08-09 17:41:04,270:INFO:Uploading results into container
2023-08-09 17:41:04,270:INFO:Uploading model into container now
2023-08-09 17:41:04,272:INFO:_master_model_container: 15
2023-08-09 17:41:04,272:INFO:_display_container: 2
2023-08-09 17:41:04,272:INFO:<catboost.core.CatBoostClassifier object at 0x00000178B4278610>
2023-08-09 17:41:04,272:INFO:create_model() successfully completed......................................
2023-08-09 17:41:04,338:INFO:SubProcess create_model() end ==================================
2023-08-09 17:41:04,338:INFO:Creating metrics dataframe
2023-08-09 17:41:04,347:INFO:Initializing Dummy Classifier
2023-08-09 17:41:04,347:INFO:Total runtime is 0.9996319572130838 minutes
2023-08-09 17:41:04,350:INFO:SubProcess create_model() called ==================================
2023-08-09 17:41:04,350:INFO:Initializing create_model()
2023-08-09 17:41:04,350:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B40017E0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178B427A9B0>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:41:04,350:INFO:Checking exceptions
2023-08-09 17:41:04,350:INFO:Importing libraries
2023-08-09 17:41:04,350:INFO:Copying training dataset
2023-08-09 17:41:04,352:INFO:Defining folds
2023-08-09 17:41:04,352:INFO:Declaring metric variables
2023-08-09 17:41:04,355:INFO:Importing untrained model
2023-08-09 17:41:04,356:INFO:Dummy Classifier Imported successfully
2023-08-09 17:41:04,361:INFO:Starting cross validation
2023-08-09 17:41:04,362:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:41:07,314:INFO:Calculating mean and std
2023-08-09 17:41:07,315:INFO:Creating metrics dataframe
2023-08-09 17:41:07,743:INFO:Uploading results into container
2023-08-09 17:41:07,743:INFO:Uploading model into container now
2023-08-09 17:41:07,743:INFO:_master_model_container: 16
2023-08-09 17:41:07,743:INFO:_display_container: 2
2023-08-09 17:41:07,743:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-08-09 17:41:07,743:INFO:create_model() successfully completed......................................
2023-08-09 17:41:07,813:INFO:SubProcess create_model() end ==================================
2023-08-09 17:41:07,814:INFO:Creating metrics dataframe
2023-08-09 17:41:07,828:INFO:Initializing create_model()
2023-08-09 17:41:07,828:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B40017E0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:41:07,829:INFO:Checking exceptions
2023-08-09 17:41:07,830:INFO:Importing libraries
2023-08-09 17:41:07,830:INFO:Copying training dataset
2023-08-09 17:41:07,832:INFO:Defining folds
2023-08-09 17:41:07,832:INFO:Declaring metric variables
2023-08-09 17:41:07,832:INFO:Importing untrained model
2023-08-09 17:41:07,832:INFO:Declaring custom model
2023-08-09 17:41:07,833:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 17:41:07,833:INFO:Cross validation set to False
2023-08-09 17:41:07,833:INFO:Fitting Model
2023-08-09 17:41:08,155:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 17:41:08,155:INFO:create_model() successfully completed......................................
2023-08-09 17:41:08,250:INFO:_master_model_container: 16
2023-08-09 17:41:08,250:INFO:_display_container: 2
2023-08-09 17:41:08,251:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 17:41:08,251:INFO:compare_models() successfully completed......................................
2023-08-09 17:41:12,277:INFO:Initializing create_model()
2023-08-09 17:41:12,277:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B40017E0>, estimator=catboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:41:12,277:INFO:Checking exceptions
2023-08-09 17:41:12,286:INFO:Importing libraries
2023-08-09 17:41:12,286:INFO:Copying training dataset
2023-08-09 17:41:12,289:INFO:Defining folds
2023-08-09 17:41:12,289:INFO:Declaring metric variables
2023-08-09 17:41:12,292:INFO:Importing untrained model
2023-08-09 17:41:12,294:INFO:CatBoost Classifier Imported successfully
2023-08-09 17:41:12,299:INFO:Starting cross validation
2023-08-09 17:41:12,299:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:41:15,359:INFO:Calculating mean and std
2023-08-09 17:41:15,360:INFO:Creating metrics dataframe
2023-08-09 17:41:15,364:INFO:Finalizing model
2023-08-09 17:41:15,818:INFO:Uploading results into container
2023-08-09 17:41:15,818:INFO:Uploading model into container now
2023-08-09 17:41:15,825:INFO:_master_model_container: 17
2023-08-09 17:41:15,825:INFO:_display_container: 3
2023-08-09 17:41:15,825:INFO:<catboost.core.CatBoostClassifier object at 0x00000178B4184CD0>
2023-08-09 17:41:15,825:INFO:create_model() successfully completed......................................
2023-08-09 17:41:15,896:INFO:Initializing tune_model()
2023-08-09 17:41:15,896:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x00000178B4184CD0>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B40017E0>)
2023-08-09 17:41:15,896:INFO:Checking exceptions
2023-08-09 17:41:15,909:INFO:Copying training dataset
2023-08-09 17:41:15,911:INFO:Checking base model
2023-08-09 17:41:15,911:INFO:Base model : CatBoost Classifier
2023-08-09 17:41:15,914:INFO:Declaring metric variables
2023-08-09 17:41:15,916:INFO:Defining Hyperparameters
2023-08-09 17:41:15,989:INFO:Tuning with n_jobs=-1
2023-08-09 17:41:15,989:INFO:Initializing RandomizedSearchCV
2023-08-09 17:41:49,179:INFO:best_params: {'actual_estimator__random_strength': 0.2, 'actual_estimator__n_estimators': 270, 'actual_estimator__l2_leaf_reg': 8, 'actual_estimator__eta': 0.0005, 'actual_estimator__depth': 4}
2023-08-09 17:41:49,180:INFO:Hyperparameter search completed
2023-08-09 17:41:49,180:INFO:SubProcess create_model() called ==================================
2023-08-09 17:41:49,180:INFO:Initializing create_model()
2023-08-09 17:41:49,180:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B40017E0>, estimator=<catboost.core.CatBoostClassifier object at 0x00000178B4185570>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178AEBF96C0>, model_only=True, return_train_score=False, kwargs={'random_strength': 0.2, 'n_estimators': 270, 'l2_leaf_reg': 8, 'eta': 0.0005, 'depth': 4})
2023-08-09 17:41:49,180:INFO:Checking exceptions
2023-08-09 17:41:49,181:INFO:Importing libraries
2023-08-09 17:41:49,181:INFO:Copying training dataset
2023-08-09 17:41:49,184:INFO:Defining folds
2023-08-09 17:41:49,184:INFO:Declaring metric variables
2023-08-09 17:41:49,186:INFO:Importing untrained model
2023-08-09 17:41:49,186:INFO:Declaring custom model
2023-08-09 17:41:49,189:INFO:CatBoost Classifier Imported successfully
2023-08-09 17:41:49,195:INFO:Starting cross validation
2023-08-09 17:41:49,195:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:41:52,251:INFO:Calculating mean and std
2023-08-09 17:41:52,251:INFO:Creating metrics dataframe
2023-08-09 17:41:52,255:INFO:Finalizing model
2023-08-09 17:41:52,707:INFO:Uploading results into container
2023-08-09 17:41:52,707:INFO:Uploading model into container now
2023-08-09 17:41:52,712:INFO:_master_model_container: 18
2023-08-09 17:41:52,712:INFO:_display_container: 4
2023-08-09 17:41:52,712:INFO:<catboost.core.CatBoostClassifier object at 0x00000178B44636D0>
2023-08-09 17:41:52,712:INFO:create_model() successfully completed......................................
2023-08-09 17:41:52,763:INFO:SubProcess create_model() end ==================================
2023-08-09 17:41:52,763:INFO:choose_better activated
2023-08-09 17:41:52,779:INFO:SubProcess create_model() called ==================================
2023-08-09 17:41:52,779:INFO:Initializing create_model()
2023-08-09 17:41:52,779:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B40017E0>, estimator=<catboost.core.CatBoostClassifier object at 0x00000178B4184CD0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:41:52,779:INFO:Checking exceptions
2023-08-09 17:41:52,779:INFO:Importing libraries
2023-08-09 17:41:52,779:INFO:Copying training dataset
2023-08-09 17:41:52,784:INFO:Defining folds
2023-08-09 17:41:52,784:INFO:Declaring metric variables
2023-08-09 17:41:52,784:INFO:Importing untrained model
2023-08-09 17:41:52,784:INFO:Declaring custom model
2023-08-09 17:41:52,784:INFO:CatBoost Classifier Imported successfully
2023-08-09 17:41:52,784:INFO:Starting cross validation
2023-08-09 17:41:52,785:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:41:55,785:INFO:Calculating mean and std
2023-08-09 17:41:55,785:INFO:Creating metrics dataframe
2023-08-09 17:41:55,787:INFO:Finalizing model
2023-08-09 17:41:56,248:INFO:Uploading results into container
2023-08-09 17:41:56,251:INFO:Uploading model into container now
2023-08-09 17:41:56,251:INFO:_master_model_container: 19
2023-08-09 17:41:56,251:INFO:_display_container: 5
2023-08-09 17:41:56,251:INFO:<catboost.core.CatBoostClassifier object at 0x00000178B4463790>
2023-08-09 17:41:56,251:INFO:create_model() successfully completed......................................
2023-08-09 17:41:56,320:INFO:SubProcess create_model() end ==================================
2023-08-09 17:41:56,320:INFO:<catboost.core.CatBoostClassifier object at 0x00000178B4463790> result for Accuracy is 0.6541
2023-08-09 17:41:56,320:INFO:<catboost.core.CatBoostClassifier object at 0x00000178B44636D0> result for Accuracy is 0.6719
2023-08-09 17:41:56,320:INFO:<catboost.core.CatBoostClassifier object at 0x00000178B44636D0> is best model
2023-08-09 17:41:56,320:INFO:choose_better completed
2023-08-09 17:41:56,324:INFO:_master_model_container: 19
2023-08-09 17:41:56,324:INFO:_display_container: 4
2023-08-09 17:41:56,324:INFO:<catboost.core.CatBoostClassifier object at 0x00000178B44636D0>
2023-08-09 17:41:56,324:INFO:tune_model() successfully completed......................................
2023-08-09 17:41:56,677:INFO:Initializing create_model()
2023-08-09 17:41:56,677:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B40017E0>, estimator=gbc, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:41:56,677:INFO:Checking exceptions
2023-08-09 17:41:56,693:INFO:Importing libraries
2023-08-09 17:41:56,693:INFO:Copying training dataset
2023-08-09 17:41:56,693:INFO:Defining folds
2023-08-09 17:41:56,693:INFO:Declaring metric variables
2023-08-09 17:41:56,693:INFO:Importing untrained model
2023-08-09 17:41:56,693:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 17:41:56,693:INFO:Starting cross validation
2023-08-09 17:41:56,708:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:41:59,783:INFO:Calculating mean and std
2023-08-09 17:41:59,784:INFO:Creating metrics dataframe
2023-08-09 17:41:59,784:INFO:Finalizing model
2023-08-09 17:42:00,255:INFO:Uploading results into container
2023-08-09 17:42:00,257:INFO:Uploading model into container now
2023-08-09 17:42:00,262:INFO:_master_model_container: 20
2023-08-09 17:42:00,262:INFO:_display_container: 5
2023-08-09 17:42:00,262:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 17:42:00,262:INFO:create_model() successfully completed......................................
2023-08-09 17:42:00,325:INFO:Initializing tune_model()
2023-08-09 17:42:00,330:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B40017E0>)
2023-08-09 17:42:00,330:INFO:Checking exceptions
2023-08-09 17:42:00,339:INFO:Copying training dataset
2023-08-09 17:42:00,341:INFO:Checking base model
2023-08-09 17:42:00,342:INFO:Base model : Gradient Boosting Classifier
2023-08-09 17:42:00,344:INFO:Declaring metric variables
2023-08-09 17:42:00,344:INFO:Defining Hyperparameters
2023-08-09 17:42:00,407:INFO:Tuning with n_jobs=-1
2023-08-09 17:42:00,407:INFO:Initializing RandomizedSearchCV
2023-08-09 17:43:15,807:INFO:best_params: {'actual_estimator__subsample': 0.35, 'actual_estimator__n_estimators': 140, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.05, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.01}
2023-08-09 17:43:15,808:INFO:Hyperparameter search completed
2023-08-09 17:43:15,808:INFO:SubProcess create_model() called ==================================
2023-08-09 17:43:15,809:INFO:Initializing create_model()
2023-08-09 17:43:15,809:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B40017E0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178B15B18D0>, model_only=True, return_train_score=False, kwargs={'subsample': 0.35, 'n_estimators': 140, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.05, 'max_features': 'sqrt', 'max_depth': 7, 'learning_rate': 0.01})
2023-08-09 17:43:15,809:INFO:Checking exceptions
2023-08-09 17:43:15,809:INFO:Importing libraries
2023-08-09 17:43:15,809:INFO:Copying training dataset
2023-08-09 17:43:15,816:INFO:Defining folds
2023-08-09 17:43:15,816:INFO:Declaring metric variables
2023-08-09 17:43:15,822:INFO:Importing untrained model
2023-08-09 17:43:15,822:INFO:Declaring custom model
2023-08-09 17:43:15,829:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 17:43:15,840:INFO:Starting cross validation
2023-08-09 17:43:15,842:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:43:23,671:INFO:Calculating mean and std
2023-08-09 17:43:23,672:INFO:Creating metrics dataframe
2023-08-09 17:43:23,692:INFO:Finalizing model
2023-08-09 17:43:25,200:INFO:Uploading results into container
2023-08-09 17:43:25,201:INFO:Uploading model into container now
2023-08-09 17:43:25,202:INFO:_master_model_container: 21
2023-08-09 17:43:25,202:INFO:_display_container: 6
2023-08-09 17:43:25,202:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 17:43:25,202:INFO:create_model() successfully completed......................................
2023-08-09 17:43:25,321:INFO:SubProcess create_model() end ==================================
2023-08-09 17:43:25,321:INFO:choose_better activated
2023-08-09 17:43:25,329:INFO:SubProcess create_model() called ==================================
2023-08-09 17:43:25,329:INFO:Initializing create_model()
2023-08-09 17:43:25,329:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B40017E0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:43:25,329:INFO:Checking exceptions
2023-08-09 17:43:25,332:INFO:Importing libraries
2023-08-09 17:43:25,332:INFO:Copying training dataset
2023-08-09 17:43:25,337:INFO:Defining folds
2023-08-09 17:43:25,337:INFO:Declaring metric variables
2023-08-09 17:43:25,337:INFO:Importing untrained model
2023-08-09 17:43:25,338:INFO:Declaring custom model
2023-08-09 17:43:25,338:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 17:43:25,338:INFO:Starting cross validation
2023-08-09 17:43:25,339:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:43:33,086:INFO:Calculating mean and std
2023-08-09 17:43:33,087:INFO:Creating metrics dataframe
2023-08-09 17:43:33,087:INFO:Finalizing model
2023-08-09 17:43:34,337:INFO:Uploading results into container
2023-08-09 17:43:34,337:INFO:Uploading model into container now
2023-08-09 17:43:34,337:INFO:_master_model_container: 22
2023-08-09 17:43:34,337:INFO:_display_container: 7
2023-08-09 17:43:34,337:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 17:43:34,337:INFO:create_model() successfully completed......................................
2023-08-09 17:43:34,462:INFO:SubProcess create_model() end ==================================
2023-08-09 17:43:34,462:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.6697
2023-08-09 17:43:34,462:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.01, loss='log_loss', max_depth=7,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.05, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=140, n_iter_no_change=None,
                           random_state=123, subsample=0.35, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.6541
2023-08-09 17:43:34,462:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-08-09 17:43:34,462:INFO:choose_better completed
2023-08-09 17:43:34,462:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-08-09 17:43:34,483:INFO:_master_model_container: 22
2023-08-09 17:43:34,483:INFO:_display_container: 6
2023-08-09 17:43:34,483:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 17:43:34,483:INFO:tune_model() successfully completed......................................
2023-08-09 17:43:35,485:INFO:Initializing blend_models()
2023-08-09 17:43:35,485:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B40017E0>, estimator_list=[<catboost.core.CatBoostClassifier object at 0x00000178B44636D0>, GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-08-09 17:43:35,485:INFO:Checking exceptions
2023-08-09 17:43:35,506:INFO:Importing libraries
2023-08-09 17:43:35,506:INFO:Copying training dataset
2023-08-09 17:43:35,510:INFO:Getting model names
2023-08-09 17:43:35,516:INFO:SubProcess create_model() called ==================================
2023-08-09 17:43:35,518:INFO:Initializing create_model()
2023-08-09 17:43:35,518:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B40017E0>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x00000178B44636D0>),
                             ('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178B329FD90>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:43:35,518:INFO:Checking exceptions
2023-08-09 17:43:35,519:INFO:Importing libraries
2023-08-09 17:43:35,519:INFO:Copying training dataset
2023-08-09 17:43:35,524:INFO:Defining folds
2023-08-09 17:43:35,524:INFO:Declaring metric variables
2023-08-09 17:43:35,528:INFO:Importing untrained model
2023-08-09 17:43:35,529:INFO:Declaring custom model
2023-08-09 17:43:35,535:INFO:Voting Classifier Imported successfully
2023-08-09 17:43:35,541:INFO:Starting cross validation
2023-08-09 17:43:35,542:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:43:42,971:INFO:Calculating mean and std
2023-08-09 17:43:42,972:INFO:Creating metrics dataframe
2023-08-09 17:43:42,981:INFO:Finalizing model
2023-08-09 17:43:44,411:INFO:Uploading results into container
2023-08-09 17:43:44,411:INFO:Uploading model into container now
2023-08-09 17:43:44,412:INFO:_master_model_container: 23
2023-08-09 17:43:44,412:INFO:_display_container: 7
2023-08-09 17:43:44,414:INFO:VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x00000178B418B4C0>),
                             ('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 17:43:44,414:INFO:create_model() successfully completed......................................
2023-08-09 17:43:44,492:INFO:SubProcess create_model() end ==================================
2023-08-09 17:43:44,510:INFO:_master_model_container: 23
2023-08-09 17:43:44,510:INFO:_display_container: 7
2023-08-09 17:43:44,512:INFO:VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x00000178B418B4C0>),
                             ('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 17:43:44,512:INFO:blend_models() successfully completed......................................
2023-08-09 17:43:52,620:INFO:Initializing finalize_model()
2023-08-09 17:43:52,621:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B40017E0>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x00000178B418B4C0>),
                             ('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-08-09 17:43:52,623:INFO:Finalizing VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x00000178B418B4C0>),
                             ('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-08-09 17:43:52,632:INFO:Initializing create_model()
2023-08-09 17:43:52,632:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B40017E0>, estimator=VotingClassifier(estimators=[('CatBoost Classifier',
                              <catboost.core.CatBoostClassifier object at 0x00000178B418B4C0>),
                             ('Gradient Boosting Classifier',
                              GradientBoostingClassifier(ccp_alpha=0.0,
                                                         criterion='friedman_mse',
                                                         init=None,
                                                         learning_rate=0.1,
                                                         loss='log_loss',
                                                         max_depth=3,
                                                         max_features=None,
                                                         max_leaf_nodes=None,
                                                         min_impurity_decrease=0.0,
                                                         min_samples_leaf=1,
                                                         min_samples_split=2,
                                                         min_weight_fraction_leaf=0.0,
                                                         n_estimators=100,
                                                         n_iter_no_change=None,
                                                         random_state=123,
                                                         subsample=1.0,
                                                         tol=0.0001,
                                                         validation_fraction=0.1,
                                                         verbose=0,
                                                         warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-08-09 17:43:52,632:INFO:Checking exceptions
2023-08-09 17:43:52,636:INFO:Importing libraries
2023-08-09 17:43:52,636:INFO:Copying training dataset
2023-08-09 17:43:52,637:INFO:Defining folds
2023-08-09 17:43:52,637:INFO:Declaring metric variables
2023-08-09 17:43:52,637:INFO:Importing untrained model
2023-08-09 17:43:52,637:INFO:Declaring custom model
2023-08-09 17:43:52,640:INFO:Voting Classifier Imported successfully
2023-08-09 17:43:52,641:INFO:Cross validation set to False
2023-08-09 17:43:52,641:INFO:Fitting Model
2023-08-09 17:43:52,712:INFO:Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Warehouse_block ',
                                             'Mode_of_Shipment',
                                             'Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Product_importance',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(ad...
                                                                          max_features=None,
                                                                          max_leaf_nodes=None,
                                                                          min_impurity_decrease=0.0,
                                                                          min_samples_leaf=1,
                                                                          min_samples_split=2,
                                                                          min_weight_fraction_leaf=0.0,
                                                                          n_estimators=100,
                                                                          n_iter_no_change=None,
                                                                          random_state=123,
                                                                          subsample=1.0,
                                                                          tol=0.0001,
                                                                          validation_fraction=0.1,
                                                                          verbose=0,
                                                                          warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-09 17:43:52,712:INFO:create_model() successfully completed......................................
2023-08-09 17:43:52,790:INFO:_master_model_container: 23
2023-08-09 17:43:52,790:INFO:_display_container: 7
2023-08-09 17:43:52,805:INFO:Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Warehouse_block ',
                                             'Mode_of_Shipment',
                                             'Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Product_importance',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(ad...
                                                                          max_features=None,
                                                                          max_leaf_nodes=None,
                                                                          min_impurity_decrease=0.0,
                                                                          min_samples_leaf=1,
                                                                          min_samples_split=2,
                                                                          min_weight_fraction_leaf=0.0,
                                                                          n_estimators=100,
                                                                          n_iter_no_change=None,
                                                                          random_state=123,
                                                                          subsample=1.0,
                                                                          tol=0.0001,
                                                                          validation_fraction=0.1,
                                                                          verbose=0,
                                                                          warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False)
2023-08-09 17:43:52,805:INFO:finalize_model() successfully completed......................................
2023-08-09 17:43:52,900:INFO:Initializing predict_model()
2023-08-09 17:43:52,900:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B40017E0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Warehouse_block ',
                                             'Mode_of_Shipment',
                                             'Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Product_importance',
                                             'Discount_offered',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(ad...
                                                                          max_features=None,
                                                                          max_leaf_nodes=None,
                                                                          min_impurity_decrease=0.0,
                                                                          min_samples_leaf=1,
                                                                          min_samples_split=2,
                                                                          min_weight_fraction_leaf=0.0,
                                                                          n_estimators=100,
                                                                          n_iter_no_change=None,
                                                                          random_state=123,
                                                                          subsample=1.0,
                                                                          tol=0.0001,
                                                                          validation_fraction=0.1,
                                                                          verbose=0,
                                                                          warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=None))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000178B446B2E0>)
2023-08-09 17:43:52,900:INFO:Checking exceptions
2023-08-09 17:43:52,900:INFO:Preloading libraries
2023-08-09 17:43:52,915:INFO:Set up data.
2023-08-09 17:43:52,923:INFO:Set up index.
2023-08-09 17:47:09,135:INFO:PyCaret ClassificationExperiment
2023-08-09 17:47:09,135:INFO:Logging name: clf-default-name
2023-08-09 17:47:09,135:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-08-09 17:47:09,135:INFO:version 3.0.4
2023-08-09 17:47:09,135:INFO:Initializing setup()
2023-08-09 17:47:09,135:INFO:self.USI: e04d
2023-08-09 17:47:09,135:INFO:self._variable_keys: {'idx', 'y_train', 'html_param', 'log_plots_param', 'fold_generator', 'X', 'seed', 'target_param', 'logging_param', 'y_test', 'fold_groups_param', '_available_plots', 'data', 'n_jobs_param', 'exp_id', 'fold_shuffle_param', 'USI', 'exp_name_log', 'gpu_n_jobs_param', 'memory', '_ml_usecase', 'is_multiclass', 'X_test', 'fix_imbalance', 'y', 'pipeline', 'gpu_param', 'X_train'}
2023-08-09 17:47:09,135:INFO:Checking environment
2023-08-09 17:47:09,135:INFO:python_version: 3.10.12
2023-08-09 17:47:09,135:INFO:python_build: ('main', 'Jul  5 2023 19:09:20')
2023-08-09 17:47:09,135:INFO:machine: AMD64
2023-08-09 17:47:09,135:INFO:platform: Windows-10-10.0.22621-SP0
2023-08-09 17:47:09,135:INFO:Memory: svmem(total=16828977152, available=6000603136, percent=64.3, used=10828374016, free=6000603136)
2023-08-09 17:47:09,135:INFO:Physical Core: 14
2023-08-09 17:47:09,135:INFO:Logical Core: 20
2023-08-09 17:47:09,135:INFO:Checking libraries
2023-08-09 17:47:09,135:INFO:System:
2023-08-09 17:47:09,135:INFO:    python: 3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:09:20) [MSC v.1916 64 bit (AMD64)]
2023-08-09 17:47:09,135:INFO:executable: C:\Users\user21\anaconda3\python.exe
2023-08-09 17:47:09,135:INFO:   machine: Windows-10-10.0.22621-SP0
2023-08-09 17:47:09,135:INFO:PyCaret required dependencies:
2023-08-09 17:47:09,135:INFO:                 pip: 23.2.1
2023-08-09 17:47:09,135:INFO:          setuptools: 68.0.0
2023-08-09 17:47:09,135:INFO:             pycaret: 3.0.4
2023-08-09 17:47:09,135:INFO:             IPython: 8.12.0
2023-08-09 17:47:09,135:INFO:          ipywidgets: 8.1.0
2023-08-09 17:47:09,135:INFO:                tqdm: 4.65.0
2023-08-09 17:47:09,135:INFO:               numpy: 1.23.5
2023-08-09 17:47:09,135:INFO:              pandas: 1.5.3
2023-08-09 17:47:09,135:INFO:              jinja2: 3.1.2
2023-08-09 17:47:09,135:INFO:               scipy: 1.11.1
2023-08-09 17:47:09,135:INFO:              joblib: 1.3.1
2023-08-09 17:47:09,135:INFO:             sklearn: 1.2.2
2023-08-09 17:47:09,135:INFO:                pyod: 1.1.0
2023-08-09 17:47:09,135:INFO:            imblearn: 0.11.0
2023-08-09 17:47:09,135:INFO:   category_encoders: 2.6.1
2023-08-09 17:47:09,135:INFO:            lightgbm: 4.0.0
2023-08-09 17:47:09,135:INFO:               numba: 0.57.1
2023-08-09 17:47:09,135:INFO:            requests: 2.31.0
2023-08-09 17:47:09,135:INFO:          matplotlib: 3.7.2
2023-08-09 17:47:09,135:INFO:          scikitplot: 0.3.7
2023-08-09 17:47:09,135:INFO:         yellowbrick: 1.5
2023-08-09 17:47:09,135:INFO:              plotly: 5.15.0
2023-08-09 17:47:09,135:INFO:    plotly-resampler: Not installed
2023-08-09 17:47:09,135:INFO:             kaleido: 0.2.1
2023-08-09 17:47:09,135:INFO:           schemdraw: 0.15
2023-08-09 17:47:09,135:INFO:         statsmodels: 0.14.0
2023-08-09 17:47:09,135:INFO:              sktime: 0.21.0
2023-08-09 17:47:09,135:INFO:               tbats: 1.1.3
2023-08-09 17:47:09,135:INFO:            pmdarima: 2.0.3
2023-08-09 17:47:09,135:INFO:              psutil: 5.9.0
2023-08-09 17:47:09,135:INFO:          markupsafe: 2.1.1
2023-08-09 17:47:09,135:INFO:             pickle5: Not installed
2023-08-09 17:47:09,135:INFO:         cloudpickle: 2.2.1
2023-08-09 17:47:09,135:INFO:         deprecation: 2.1.0
2023-08-09 17:47:09,135:INFO:              xxhash: 3.3.0
2023-08-09 17:47:09,135:INFO:           wurlitzer: Not installed
2023-08-09 17:47:09,135:INFO:PyCaret optional dependencies:
2023-08-09 17:47:09,135:INFO:                shap: Not installed
2023-08-09 17:47:09,135:INFO:           interpret: Not installed
2023-08-09 17:47:09,135:INFO:                umap: Not installed
2023-08-09 17:47:09,135:INFO:    pandas_profiling: Not installed
2023-08-09 17:47:09,135:INFO:  explainerdashboard: Not installed
2023-08-09 17:47:09,135:INFO:             autoviz: Not installed
2023-08-09 17:47:09,135:INFO:           fairlearn: Not installed
2023-08-09 17:47:09,135:INFO:          deepchecks: Not installed
2023-08-09 17:47:09,135:INFO:             xgboost: 1.7.6
2023-08-09 17:47:09,135:INFO:            catboost: 1.2
2023-08-09 17:47:09,135:INFO:              kmodes: Not installed
2023-08-09 17:47:09,135:INFO:             mlxtend: Not installed
2023-08-09 17:47:09,135:INFO:       statsforecast: Not installed
2023-08-09 17:47:09,135:INFO:        tune_sklearn: Not installed
2023-08-09 17:47:09,135:INFO:                 ray: Not installed
2023-08-09 17:47:09,135:INFO:            hyperopt: Not installed
2023-08-09 17:47:09,135:INFO:              optuna: 3.2.0
2023-08-09 17:47:09,135:INFO:               skopt: Not installed
2023-08-09 17:47:09,135:INFO:              mlflow: Not installed
2023-08-09 17:47:09,135:INFO:              gradio: Not installed
2023-08-09 17:47:09,135:INFO:             fastapi: Not installed
2023-08-09 17:47:09,135:INFO:             uvicorn: Not installed
2023-08-09 17:47:09,135:INFO:              m2cgen: Not installed
2023-08-09 17:47:09,135:INFO:           evidently: Not installed
2023-08-09 17:47:09,135:INFO:               fugue: Not installed
2023-08-09 17:47:09,135:INFO:           streamlit: Not installed
2023-08-09 17:47:09,135:INFO:             prophet: Not installed
2023-08-09 17:47:09,135:INFO:None
2023-08-09 17:47:09,135:INFO:Set up data.
2023-08-09 17:47:09,142:INFO:Set up train/test split.
2023-08-09 17:47:09,148:INFO:Set up index.
2023-08-09 17:47:09,148:INFO:Set up folding strategy.
2023-08-09 17:47:09,150:INFO:Assigning column types.
2023-08-09 17:47:09,150:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-08-09 17:47:09,183:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-09 17:47:09,183:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 17:47:09,209:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 17:47:09,211:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 17:47:09,246:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-08-09 17:47:09,246:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 17:47:09,266:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 17:47:09,272:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 17:47:09,273:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-08-09 17:47:09,308:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 17:47:09,324:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 17:47:09,324:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 17:47:09,371:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-08-09 17:47:09,402:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 17:47:09,402:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 17:47:09,402:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-08-09 17:47:09,511:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 17:47:09,511:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 17:47:09,658:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 17:47:09,658:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 17:47:09,658:INFO:Preparing preprocessing pipeline...
2023-08-09 17:47:09,658:INFO:Set up simple imputation.
2023-08-09 17:47:09,674:INFO:Set up encoding of categorical features.
2023-08-09 17:47:09,674:INFO:Set up column name cleaning.
2023-08-09 17:47:09,793:INFO:Finished creating preprocessing pipeline.
2023-08-09 17:47:09,793:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\user21\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Customer_care_calls',
                                             'Customer_rating',
                                             'Cost_of_the_Product',
                                             'Prior_purchases',
                                             'Weight_in_gms'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing...
                                    transformer=OneHotEncoder(cols=['Warehouse_block',
                                                                    'Mode_of_Shipment',
                                                                    'Product_importance'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-08-09 17:47:09,793:INFO:Creating final display dataframe.
2023-08-09 17:47:10,139:INFO:Setup _display_container:                     Description                Value
0                    Session id                  123
1                        Target  Reached.on.Time_Y.N
2                   Target type               Binary
3           Original data shape            (6897, 9)
4        Transformed data shape           (6897, 17)
5   Transformed train set shape           (4827, 17)
6    Transformed test set shape           (2070, 17)
7              Numeric features                    5
8          Categorical features                    3
9                    Preprocess                 True
10              Imputation type               simple
11           Numeric imputation                 mean
12       Categorical imputation                 mode
13     Maximum one-hot encoding                   25
14              Encoding method                 None
15               Fold Generator      StratifiedKFold
16                  Fold Number                   10
17                     CPU Jobs                   -1
18                      Use GPU                False
19               Log Experiment                False
20              Experiment Name     clf-default-name
21                          USI                 e04d
2023-08-09 17:47:10,361:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 17:47:10,361:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 17:47:10,565:INFO:Soft dependency imported: xgboost: 1.7.6
2023-08-09 17:47:10,580:INFO:Soft dependency imported: catboost: 1.2
2023-08-09 17:47:10,580:INFO:setup() successfully completed in 2.09s...............
2023-08-09 17:47:11,609:INFO:Initializing compare_models()
2023-08-09 17:47:11,609:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B7904C70>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000178B7904C70>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-08-09 17:47:11,609:INFO:Checking exceptions
2023-08-09 17:47:11,609:INFO:Preparing display monitor
2023-08-09 17:47:11,651:INFO:Initializing Logistic Regression
2023-08-09 17:47:11,651:INFO:Total runtime is 0.0 minutes
2023-08-09 17:47:11,655:INFO:SubProcess create_model() called ==================================
2023-08-09 17:47:11,655:INFO:Initializing create_model()
2023-08-09 17:47:11,655:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B7904C70>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178B3FE9A50>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:47:11,655:INFO:Checking exceptions
2023-08-09 17:47:11,655:INFO:Importing libraries
2023-08-09 17:47:11,655:INFO:Copying training dataset
2023-08-09 17:47:11,662:INFO:Defining folds
2023-08-09 17:47:11,662:INFO:Declaring metric variables
2023-08-09 17:47:11,667:INFO:Importing untrained model
2023-08-09 17:47:11,672:INFO:Logistic Regression Imported successfully
2023-08-09 17:47:11,684:INFO:Starting cross validation
2023-08-09 17:47:11,686:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:47:20,006:INFO:Calculating mean and std
2023-08-09 17:47:20,006:INFO:Creating metrics dataframe
2023-08-09 17:47:21,388:INFO:Uploading results into container
2023-08-09 17:47:21,388:INFO:Uploading model into container now
2023-08-09 17:47:21,388:INFO:_master_model_container: 1
2023-08-09 17:47:21,388:INFO:_display_container: 2
2023-08-09 17:47:21,395:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-08-09 17:47:21,395:INFO:create_model() successfully completed......................................
2023-08-09 17:47:21,517:INFO:SubProcess create_model() end ==================================
2023-08-09 17:47:21,517:INFO:Creating metrics dataframe
2023-08-09 17:47:21,532:INFO:Initializing K Neighbors Classifier
2023-08-09 17:47:21,532:INFO:Total runtime is 0.164695143699646 minutes
2023-08-09 17:47:21,543:INFO:SubProcess create_model() called ==================================
2023-08-09 17:47:21,543:INFO:Initializing create_model()
2023-08-09 17:47:21,543:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B7904C70>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178B3FE9A50>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:47:21,543:INFO:Checking exceptions
2023-08-09 17:47:21,543:INFO:Importing libraries
2023-08-09 17:47:21,543:INFO:Copying training dataset
2023-08-09 17:47:21,553:INFO:Defining folds
2023-08-09 17:47:21,553:INFO:Declaring metric variables
2023-08-09 17:47:21,558:INFO:Importing untrained model
2023-08-09 17:47:21,564:INFO:K Neighbors Classifier Imported successfully
2023-08-09 17:47:21,575:INFO:Starting cross validation
2023-08-09 17:47:21,577:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:47:31,096:INFO:Calculating mean and std
2023-08-09 17:47:31,101:INFO:Creating metrics dataframe
2023-08-09 17:47:32,489:INFO:Uploading results into container
2023-08-09 17:47:32,489:INFO:Uploading model into container now
2023-08-09 17:47:32,490:INFO:_master_model_container: 2
2023-08-09 17:47:32,490:INFO:_display_container: 2
2023-08-09 17:47:32,491:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-08-09 17:47:32,491:INFO:create_model() successfully completed......................................
2023-08-09 17:47:32,591:INFO:SubProcess create_model() end ==================================
2023-08-09 17:47:32,591:INFO:Creating metrics dataframe
2023-08-09 17:47:32,606:INFO:Initializing Naive Bayes
2023-08-09 17:47:32,606:INFO:Total runtime is 0.34926293293635047 minutes
2023-08-09 17:47:32,612:INFO:SubProcess create_model() called ==================================
2023-08-09 17:47:32,612:INFO:Initializing create_model()
2023-08-09 17:47:32,612:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B7904C70>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178B3FE9A50>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:47:32,612:INFO:Checking exceptions
2023-08-09 17:47:32,612:INFO:Importing libraries
2023-08-09 17:47:32,612:INFO:Copying training dataset
2023-08-09 17:47:32,619:INFO:Defining folds
2023-08-09 17:47:32,619:INFO:Declaring metric variables
2023-08-09 17:47:32,623:INFO:Importing untrained model
2023-08-09 17:47:32,627:INFO:Naive Bayes Imported successfully
2023-08-09 17:47:32,634:INFO:Starting cross validation
2023-08-09 17:47:32,639:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:47:40,240:INFO:Calculating mean and std
2023-08-09 17:47:40,240:INFO:Creating metrics dataframe
2023-08-09 17:47:41,761:INFO:Uploading results into container
2023-08-09 17:47:41,762:INFO:Uploading model into container now
2023-08-09 17:47:41,763:INFO:_master_model_container: 3
2023-08-09 17:47:41,763:INFO:_display_container: 2
2023-08-09 17:47:41,763:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-08-09 17:47:41,763:INFO:create_model() successfully completed......................................
2023-08-09 17:47:41,868:INFO:SubProcess create_model() end ==================================
2023-08-09 17:47:41,868:INFO:Creating metrics dataframe
2023-08-09 17:47:41,883:INFO:Initializing Decision Tree Classifier
2023-08-09 17:47:41,883:INFO:Total runtime is 0.5038649439811707 minutes
2023-08-09 17:47:41,883:INFO:SubProcess create_model() called ==================================
2023-08-09 17:47:41,883:INFO:Initializing create_model()
2023-08-09 17:47:41,883:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B7904C70>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178B3FE9A50>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:47:41,883:INFO:Checking exceptions
2023-08-09 17:47:41,883:INFO:Importing libraries
2023-08-09 17:47:41,889:INFO:Copying training dataset
2023-08-09 17:47:41,889:INFO:Defining folds
2023-08-09 17:47:41,889:INFO:Declaring metric variables
2023-08-09 17:47:41,899:INFO:Importing untrained model
2023-08-09 17:47:41,903:INFO:Decision Tree Classifier Imported successfully
2023-08-09 17:47:41,909:INFO:Starting cross validation
2023-08-09 17:47:41,909:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:47:49,268:INFO:Calculating mean and std
2023-08-09 17:47:49,279:INFO:Creating metrics dataframe
2023-08-09 17:47:50,681:INFO:Uploading results into container
2023-08-09 17:47:50,684:INFO:Uploading model into container now
2023-08-09 17:47:50,684:INFO:_master_model_container: 4
2023-08-09 17:47:50,684:INFO:_display_container: 2
2023-08-09 17:47:50,685:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-08-09 17:47:50,685:INFO:create_model() successfully completed......................................
2023-08-09 17:47:50,808:INFO:SubProcess create_model() end ==================================
2023-08-09 17:47:50,808:INFO:Creating metrics dataframe
2023-08-09 17:47:50,824:INFO:Initializing SVM - Linear Kernel
2023-08-09 17:47:50,824:INFO:Total runtime is 0.6528849283854167 minutes
2023-08-09 17:47:50,844:INFO:SubProcess create_model() called ==================================
2023-08-09 17:47:50,844:INFO:Initializing create_model()
2023-08-09 17:47:50,844:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B7904C70>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178B3FE9A50>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:47:50,844:INFO:Checking exceptions
2023-08-09 17:47:50,844:INFO:Importing libraries
2023-08-09 17:47:50,844:INFO:Copying training dataset
2023-08-09 17:47:50,853:INFO:Defining folds
2023-08-09 17:47:50,853:INFO:Declaring metric variables
2023-08-09 17:47:50,857:INFO:Importing untrained model
2023-08-09 17:47:50,864:INFO:SVM - Linear Kernel Imported successfully
2023-08-09 17:47:50,876:INFO:Starting cross validation
2023-08-09 17:47:50,878:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:47:51,153:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:47:51,168:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:47:51,201:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:47:51,216:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:47:51,231:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:47:51,247:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:47:51,294:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:47:51,294:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-09 17:47:51,325:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:47:51,325:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:47:51,357:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-08-09 17:47:51,372:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-08-09 17:47:58,243:INFO:Calculating mean and std
2023-08-09 17:47:58,243:INFO:Creating metrics dataframe
2023-08-09 17:47:59,677:INFO:Uploading results into container
2023-08-09 17:47:59,679:INFO:Uploading model into container now
2023-08-09 17:47:59,679:INFO:_master_model_container: 5
2023-08-09 17:47:59,679:INFO:_display_container: 2
2023-08-09 17:47:59,680:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-08-09 17:47:59,680:INFO:create_model() successfully completed......................................
2023-08-09 17:47:59,785:INFO:SubProcess create_model() end ==================================
2023-08-09 17:47:59,785:INFO:Creating metrics dataframe
2023-08-09 17:47:59,801:INFO:Initializing Ridge Classifier
2023-08-09 17:47:59,801:INFO:Total runtime is 0.8025059858957926 minutes
2023-08-09 17:47:59,808:INFO:SubProcess create_model() called ==================================
2023-08-09 17:47:59,808:INFO:Initializing create_model()
2023-08-09 17:47:59,808:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B7904C70>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178B3FE9A50>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:47:59,808:INFO:Checking exceptions
2023-08-09 17:47:59,808:INFO:Importing libraries
2023-08-09 17:47:59,808:INFO:Copying training dataset
2023-08-09 17:47:59,818:INFO:Defining folds
2023-08-09 17:47:59,818:INFO:Declaring metric variables
2023-08-09 17:47:59,826:INFO:Importing untrained model
2023-08-09 17:47:59,834:INFO:Ridge Classifier Imported successfully
2023-08-09 17:47:59,843:INFO:Starting cross validation
2023-08-09 17:47:59,844:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:48:00,149:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:48:00,149:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:48:00,182:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:48:00,196:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:48:00,216:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:48:00,228:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:48:00,259:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:48:00,259:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:48:00,259:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:48:00,322:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\user21\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-08-09 17:48:07,571:INFO:Calculating mean and std
2023-08-09 17:48:07,571:INFO:Creating metrics dataframe
2023-08-09 17:48:09,091:INFO:Uploading results into container
2023-08-09 17:48:09,092:INFO:Uploading model into container now
2023-08-09 17:48:09,093:INFO:_master_model_container: 6
2023-08-09 17:48:09,093:INFO:_display_container: 2
2023-08-09 17:48:09,094:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-08-09 17:48:09,094:INFO:create_model() successfully completed......................................
2023-08-09 17:48:09,233:INFO:SubProcess create_model() end ==================================
2023-08-09 17:48:09,233:INFO:Creating metrics dataframe
2023-08-09 17:48:09,233:INFO:Initializing Random Forest Classifier
2023-08-09 17:48:09,233:INFO:Total runtime is 0.9597031394640604 minutes
2023-08-09 17:48:09,258:INFO:SubProcess create_model() called ==================================
2023-08-09 17:48:09,259:INFO:Initializing create_model()
2023-08-09 17:48:09,259:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B7904C70>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178B3FE9A50>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:48:09,259:INFO:Checking exceptions
2023-08-09 17:48:09,259:INFO:Importing libraries
2023-08-09 17:48:09,259:INFO:Copying training dataset
2023-08-09 17:48:09,269:INFO:Defining folds
2023-08-09 17:48:09,270:INFO:Declaring metric variables
2023-08-09 17:48:09,273:INFO:Importing untrained model
2023-08-09 17:48:09,279:INFO:Random Forest Classifier Imported successfully
2023-08-09 17:48:09,291:INFO:Starting cross validation
2023-08-09 17:48:09,291:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:48:17,215:INFO:Calculating mean and std
2023-08-09 17:48:17,215:INFO:Creating metrics dataframe
2023-08-09 17:48:18,513:INFO:Uploading results into container
2023-08-09 17:48:18,513:INFO:Uploading model into container now
2023-08-09 17:48:18,513:INFO:_master_model_container: 7
2023-08-09 17:48:18,513:INFO:_display_container: 2
2023-08-09 17:48:18,513:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-09 17:48:18,513:INFO:create_model() successfully completed......................................
2023-08-09 17:48:18,628:INFO:SubProcess create_model() end ==================================
2023-08-09 17:48:18,628:INFO:Creating metrics dataframe
2023-08-09 17:48:18,642:INFO:Initializing Quadratic Discriminant Analysis
2023-08-09 17:48:18,642:INFO:Total runtime is 1.1165293097496032 minutes
2023-08-09 17:48:18,648:INFO:SubProcess create_model() called ==================================
2023-08-09 17:48:18,648:INFO:Initializing create_model()
2023-08-09 17:48:18,648:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B7904C70>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178B3FE9A50>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:48:18,648:INFO:Checking exceptions
2023-08-09 17:48:18,648:INFO:Importing libraries
2023-08-09 17:48:18,649:INFO:Copying training dataset
2023-08-09 17:48:18,649:INFO:Defining folds
2023-08-09 17:48:18,649:INFO:Declaring metric variables
2023-08-09 17:48:18,659:INFO:Importing untrained model
2023-08-09 17:48:18,659:INFO:Quadratic Discriminant Analysis Imported successfully
2023-08-09 17:48:18,659:INFO:Starting cross validation
2023-08-09 17:48:18,671:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:48:18,816:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 17:48:18,832:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 17:48:18,911:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 17:48:18,951:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 17:48:18,972:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 17:48:18,978:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 17:48:18,999:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 17:48:19,023:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 17:48:19,062:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 17:48:19,104:WARNING:C:\Users\user21\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-08-09 17:48:26,092:INFO:Calculating mean and std
2023-08-09 17:48:26,092:INFO:Creating metrics dataframe
2023-08-09 17:48:27,449:INFO:Uploading results into container
2023-08-09 17:48:27,451:INFO:Uploading model into container now
2023-08-09 17:48:27,452:INFO:_master_model_container: 8
2023-08-09 17:48:27,452:INFO:_display_container: 2
2023-08-09 17:48:27,452:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-08-09 17:48:27,452:INFO:create_model() successfully completed......................................
2023-08-09 17:48:27,555:INFO:SubProcess create_model() end ==================================
2023-08-09 17:48:27,555:INFO:Creating metrics dataframe
2023-08-09 17:48:27,577:INFO:Initializing Ada Boost Classifier
2023-08-09 17:48:27,577:INFO:Total runtime is 1.2654334863026935 minutes
2023-08-09 17:48:27,582:INFO:SubProcess create_model() called ==================================
2023-08-09 17:48:27,582:INFO:Initializing create_model()
2023-08-09 17:48:27,582:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B7904C70>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178B3FE9A50>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:48:27,582:INFO:Checking exceptions
2023-08-09 17:48:27,583:INFO:Importing libraries
2023-08-09 17:48:27,583:INFO:Copying training dataset
2023-08-09 17:48:27,589:INFO:Defining folds
2023-08-09 17:48:27,590:INFO:Declaring metric variables
2023-08-09 17:48:27,595:INFO:Importing untrained model
2023-08-09 17:48:27,604:INFO:Ada Boost Classifier Imported successfully
2023-08-09 17:48:27,612:INFO:Starting cross validation
2023-08-09 17:48:27,612:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:48:36,124:INFO:Calculating mean and std
2023-08-09 17:48:36,126:INFO:Creating metrics dataframe
2023-08-09 17:48:37,647:INFO:Uploading results into container
2023-08-09 17:48:37,648:INFO:Uploading model into container now
2023-08-09 17:48:37,648:INFO:_master_model_container: 9
2023-08-09 17:48:37,648:INFO:_display_container: 2
2023-08-09 17:48:37,649:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-08-09 17:48:37,649:INFO:create_model() successfully completed......................................
2023-08-09 17:48:37,747:INFO:SubProcess create_model() end ==================================
2023-08-09 17:48:37,747:INFO:Creating metrics dataframe
2023-08-09 17:48:37,775:INFO:Initializing Gradient Boosting Classifier
2023-08-09 17:48:37,775:INFO:Total runtime is 1.435409645239512 minutes
2023-08-09 17:48:37,780:INFO:SubProcess create_model() called ==================================
2023-08-09 17:48:37,780:INFO:Initializing create_model()
2023-08-09 17:48:37,780:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B7904C70>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178B3FE9A50>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:48:37,780:INFO:Checking exceptions
2023-08-09 17:48:37,780:INFO:Importing libraries
2023-08-09 17:48:37,781:INFO:Copying training dataset
2023-08-09 17:48:37,786:INFO:Defining folds
2023-08-09 17:48:37,787:INFO:Declaring metric variables
2023-08-09 17:48:37,791:INFO:Importing untrained model
2023-08-09 17:48:37,794:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 17:48:37,802:INFO:Starting cross validation
2023-08-09 17:48:37,803:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:48:45,526:INFO:Calculating mean and std
2023-08-09 17:48:45,526:INFO:Creating metrics dataframe
2023-08-09 17:48:46,721:INFO:Uploading results into container
2023-08-09 17:48:46,722:INFO:Uploading model into container now
2023-08-09 17:48:46,723:INFO:_master_model_container: 10
2023-08-09 17:48:46,723:INFO:_display_container: 2
2023-08-09 17:48:46,723:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 17:48:46,723:INFO:create_model() successfully completed......................................
2023-08-09 17:48:46,858:INFO:SubProcess create_model() end ==================================
2023-08-09 17:48:46,858:INFO:Creating metrics dataframe
2023-08-09 17:48:46,874:INFO:Initializing Linear Discriminant Analysis
2023-08-09 17:48:46,874:INFO:Total runtime is 1.5870470841725666 minutes
2023-08-09 17:48:46,882:INFO:SubProcess create_model() called ==================================
2023-08-09 17:48:46,882:INFO:Initializing create_model()
2023-08-09 17:48:46,882:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B7904C70>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178B3FE9A50>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:48:46,882:INFO:Checking exceptions
2023-08-09 17:48:46,882:INFO:Importing libraries
2023-08-09 17:48:46,882:INFO:Copying training dataset
2023-08-09 17:48:46,889:INFO:Defining folds
2023-08-09 17:48:46,889:INFO:Declaring metric variables
2023-08-09 17:48:46,893:INFO:Importing untrained model
2023-08-09 17:48:46,898:INFO:Linear Discriminant Analysis Imported successfully
2023-08-09 17:48:46,903:INFO:Starting cross validation
2023-08-09 17:48:46,907:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:48:54,430:INFO:Calculating mean and std
2023-08-09 17:48:54,430:INFO:Creating metrics dataframe
2023-08-09 17:48:55,917:INFO:Uploading results into container
2023-08-09 17:48:55,931:INFO:Uploading model into container now
2023-08-09 17:48:55,931:INFO:_master_model_container: 11
2023-08-09 17:48:55,931:INFO:_display_container: 2
2023-08-09 17:48:55,931:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-08-09 17:48:55,931:INFO:create_model() successfully completed......................................
2023-08-09 17:48:56,030:INFO:SubProcess create_model() end ==================================
2023-08-09 17:48:56,030:INFO:Creating metrics dataframe
2023-08-09 17:48:56,047:INFO:Initializing Extra Trees Classifier
2023-08-09 17:48:56,047:INFO:Total runtime is 1.7399334828058877 minutes
2023-08-09 17:48:56,054:INFO:SubProcess create_model() called ==================================
2023-08-09 17:48:56,055:INFO:Initializing create_model()
2023-08-09 17:48:56,055:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B7904C70>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178B3FE9A50>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:48:56,055:INFO:Checking exceptions
2023-08-09 17:48:56,055:INFO:Importing libraries
2023-08-09 17:48:56,055:INFO:Copying training dataset
2023-08-09 17:48:56,067:INFO:Defining folds
2023-08-09 17:48:56,068:INFO:Declaring metric variables
2023-08-09 17:48:56,074:INFO:Importing untrained model
2023-08-09 17:48:56,081:INFO:Extra Trees Classifier Imported successfully
2023-08-09 17:48:56,093:INFO:Starting cross validation
2023-08-09 17:48:56,095:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:49:04,212:INFO:Calculating mean and std
2023-08-09 17:49:04,212:INFO:Creating metrics dataframe
2023-08-09 17:49:05,639:INFO:Uploading results into container
2023-08-09 17:49:05,648:INFO:Uploading model into container now
2023-08-09 17:49:05,648:INFO:_master_model_container: 12
2023-08-09 17:49:05,648:INFO:_display_container: 2
2023-08-09 17:49:05,649:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-08-09 17:49:05,649:INFO:create_model() successfully completed......................................
2023-08-09 17:49:05,763:INFO:SubProcess create_model() end ==================================
2023-08-09 17:49:05,763:INFO:Creating metrics dataframe
2023-08-09 17:49:05,795:INFO:Initializing Extreme Gradient Boosting
2023-08-09 17:49:05,795:INFO:Total runtime is 1.9023977637290952 minutes
2023-08-09 17:49:05,813:INFO:SubProcess create_model() called ==================================
2023-08-09 17:49:05,814:INFO:Initializing create_model()
2023-08-09 17:49:05,814:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B7904C70>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178B3FE9A50>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:49:05,814:INFO:Checking exceptions
2023-08-09 17:49:05,814:INFO:Importing libraries
2023-08-09 17:49:05,814:INFO:Copying training dataset
2023-08-09 17:49:05,827:INFO:Defining folds
2023-08-09 17:49:05,828:INFO:Declaring metric variables
2023-08-09 17:49:05,834:INFO:Importing untrained model
2023-08-09 17:49:05,839:INFO:Extreme Gradient Boosting Imported successfully
2023-08-09 17:49:05,850:INFO:Starting cross validation
2023-08-09 17:49:05,852:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:49:14,021:INFO:Calculating mean and std
2023-08-09 17:49:14,021:INFO:Creating metrics dataframe
2023-08-09 17:49:15,427:INFO:Uploading results into container
2023-08-09 17:49:15,427:INFO:Uploading model into container now
2023-08-09 17:49:15,427:INFO:_master_model_container: 13
2023-08-09 17:49:15,427:INFO:_display_container: 2
2023-08-09 17:49:15,442:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=-1, num_parallel_tree=None,
              objective='binary:logistic', predictor=None, ...)
2023-08-09 17:49:15,442:INFO:create_model() successfully completed......................................
2023-08-09 17:49:15,544:INFO:SubProcess create_model() end ==================================
2023-08-09 17:49:15,544:INFO:Creating metrics dataframe
2023-08-09 17:49:15,560:INFO:Initializing Light Gradient Boosting Machine
2023-08-09 17:49:15,560:INFO:Total runtime is 2.06515204111735 minutes
2023-08-09 17:49:15,565:INFO:SubProcess create_model() called ==================================
2023-08-09 17:49:15,565:INFO:Initializing create_model()
2023-08-09 17:49:15,565:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B7904C70>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178B3FE9A50>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:49:15,565:INFO:Checking exceptions
2023-08-09 17:49:15,566:INFO:Importing libraries
2023-08-09 17:49:15,566:INFO:Copying training dataset
2023-08-09 17:49:15,574:INFO:Defining folds
2023-08-09 17:49:15,574:INFO:Declaring metric variables
2023-08-09 17:49:15,578:INFO:Importing untrained model
2023-08-09 17:49:15,582:INFO:Light Gradient Boosting Machine Imported successfully
2023-08-09 17:49:15,601:INFO:Starting cross validation
2023-08-09 17:49:15,602:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:49:25,237:INFO:Calculating mean and std
2023-08-09 17:49:25,237:INFO:Creating metrics dataframe
2023-08-09 17:49:26,737:INFO:Uploading results into container
2023-08-09 17:49:26,737:INFO:Uploading model into container now
2023-08-09 17:49:26,737:INFO:_master_model_container: 14
2023-08-09 17:49:26,737:INFO:_display_container: 2
2023-08-09 17:49:26,749:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-08-09 17:49:26,749:INFO:create_model() successfully completed......................................
2023-08-09 17:49:26,850:INFO:SubProcess create_model() end ==================================
2023-08-09 17:49:26,850:INFO:Creating metrics dataframe
2023-08-09 17:49:26,881:INFO:Initializing CatBoost Classifier
2023-08-09 17:49:26,881:INFO:Total runtime is 2.253844797611236 minutes
2023-08-09 17:49:26,898:INFO:SubProcess create_model() called ==================================
2023-08-09 17:49:26,899:INFO:Initializing create_model()
2023-08-09 17:49:26,899:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B7904C70>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178B3FE9A50>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:49:26,899:INFO:Checking exceptions
2023-08-09 17:49:26,899:INFO:Importing libraries
2023-08-09 17:49:26,899:INFO:Copying training dataset
2023-08-09 17:49:26,906:INFO:Defining folds
2023-08-09 17:49:26,906:INFO:Declaring metric variables
2023-08-09 17:49:26,910:INFO:Importing untrained model
2023-08-09 17:49:26,914:INFO:CatBoost Classifier Imported successfully
2023-08-09 17:49:26,922:INFO:Starting cross validation
2023-08-09 17:49:26,924:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:49:34,988:INFO:Calculating mean and std
2023-08-09 17:49:34,988:INFO:Creating metrics dataframe
2023-08-09 17:49:36,370:INFO:Uploading results into container
2023-08-09 17:49:36,370:INFO:Uploading model into container now
2023-08-09 17:49:36,370:INFO:_master_model_container: 15
2023-08-09 17:49:36,370:INFO:_display_container: 2
2023-08-09 17:49:36,370:INFO:<catboost.core.CatBoostClassifier object at 0x00000178B42EF130>
2023-08-09 17:49:36,370:INFO:create_model() successfully completed......................................
2023-08-09 17:49:36,482:INFO:SubProcess create_model() end ==================================
2023-08-09 17:49:36,482:INFO:Creating metrics dataframe
2023-08-09 17:49:36,498:INFO:Initializing Dummy Classifier
2023-08-09 17:49:36,498:INFO:Total runtime is 2.414115262031555 minutes
2023-08-09 17:49:36,509:INFO:SubProcess create_model() called ==================================
2023-08-09 17:49:36,509:INFO:Initializing create_model()
2023-08-09 17:49:36,509:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B7904C70>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000178B3FE9A50>, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:49:36,509:INFO:Checking exceptions
2023-08-09 17:49:36,510:INFO:Importing libraries
2023-08-09 17:49:36,510:INFO:Copying training dataset
2023-08-09 17:49:36,515:INFO:Defining folds
2023-08-09 17:49:36,515:INFO:Declaring metric variables
2023-08-09 17:49:36,520:INFO:Importing untrained model
2023-08-09 17:49:36,523:INFO:Dummy Classifier Imported successfully
2023-08-09 17:49:36,531:INFO:Starting cross validation
2023-08-09 17:49:36,533:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:49:44,452:INFO:Calculating mean and std
2023-08-09 17:49:44,456:INFO:Creating metrics dataframe
2023-08-09 17:49:45,857:INFO:Uploading results into container
2023-08-09 17:49:45,858:INFO:Uploading model into container now
2023-08-09 17:49:45,858:INFO:_master_model_container: 16
2023-08-09 17:49:45,859:INFO:_display_container: 2
2023-08-09 17:49:45,859:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-08-09 17:49:45,859:INFO:create_model() successfully completed......................................
2023-08-09 17:49:45,994:INFO:SubProcess create_model() end ==================================
2023-08-09 17:49:46,009:INFO:Creating metrics dataframe
2023-08-09 17:49:46,093:INFO:Initializing create_model()
2023-08-09 17:49:46,093:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B7904C70>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:49:46,093:INFO:Checking exceptions
2023-08-09 17:49:46,095:INFO:Importing libraries
2023-08-09 17:49:46,095:INFO:Copying training dataset
2023-08-09 17:49:46,100:INFO:Defining folds
2023-08-09 17:49:46,100:INFO:Declaring metric variables
2023-08-09 17:49:46,100:INFO:Importing untrained model
2023-08-09 17:49:46,100:INFO:Declaring custom model
2023-08-09 17:49:46,101:INFO:Gradient Boosting Classifier Imported successfully
2023-08-09 17:49:46,102:INFO:Cross validation set to False
2023-08-09 17:49:46,102:INFO:Fitting Model
2023-08-09 17:49:46,878:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 17:49:46,878:INFO:create_model() successfully completed......................................
2023-08-09 17:49:47,042:INFO:_master_model_container: 16
2023-08-09 17:49:47,042:INFO:_display_container: 2
2023-08-09 17:49:47,043:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-08-09 17:49:47,043:INFO:compare_models() successfully completed......................................
2023-08-09 17:49:47,044:INFO:Initializing create_model()
2023-08-09 17:49:47,044:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B7904C70>, estimator=rf, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-08-09 17:49:47,044:INFO:Checking exceptions
2023-08-09 17:49:47,066:INFO:Importing libraries
2023-08-09 17:49:47,066:INFO:Copying training dataset
2023-08-09 17:49:47,072:INFO:Defining folds
2023-08-09 17:49:47,072:INFO:Declaring metric variables
2023-08-09 17:49:47,075:INFO:Importing untrained model
2023-08-09 17:49:47,081:INFO:Random Forest Classifier Imported successfully
2023-08-09 17:49:47,088:INFO:Starting cross validation
2023-08-09 17:49:47,090:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-08-09 17:49:55,174:INFO:Calculating mean and std
2023-08-09 17:49:55,181:INFO:Creating metrics dataframe
2023-08-09 17:49:55,188:INFO:Finalizing model
2023-08-09 17:49:57,521:INFO:Uploading results into container
2023-08-09 17:49:57,523:INFO:Uploading model into container now
2023-08-09 17:49:57,535:INFO:_master_model_container: 17
2023-08-09 17:49:57,535:INFO:_display_container: 3
2023-08-09 17:49:57,535:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-08-09 17:49:57,535:INFO:create_model() successfully completed......................................
2023-08-09 17:49:57,633:INFO:Initializing tune_model()
2023-08-09 17:49:57,633:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000178B7904C70>)
2023-08-09 17:49:57,633:INFO:Checking exceptions
2023-08-09 17:49:57,658:INFO:Copying training dataset
2023-08-09 17:49:57,661:INFO:Checking base model
2023-08-09 17:49:57,661:INFO:Base model : Random Forest Classifier
2023-08-09 17:49:57,665:INFO:Declaring metric variables
2023-08-09 17:49:57,669:INFO:Defining Hyperparameters
2023-08-09 17:49:57,766:INFO:Tuning with n_jobs=-1
2023-08-09 17:49:57,766:INFO:Initializing RandomizedSearchCV
2023-08-09 17:50:03,775:WARNING:C:\Users\user21\anaconda3\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  fitted_estimator = self._memory_fit(

